{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f81332c",
   "metadata": {},
   "source": [
    "# 049: Imbalanced Data Handling",
    "",
    "## \ud83c\udfaf Learning Objectives",
    "",
    "By the end of this notebook, you will:",
    "",
    "1. **Understand imbalanced data** - Why it matters, real-world prevalence, evaluation pitfalls",
    "2. **Master resampling techniques** - Undersampling, oversampling, hybrid methods",
    "3. **Implement SMOTE & variants** - SMOTE, Borderline-SMOTE, ADASYN, SMOTE-ENN",
    "4. **Use cost-sensitive learning** - Class weights, custom loss functions, threshold tuning",
    "5. **Apply ensemble methods** - BalancedRandomForest, EasyEnsemble, RUSBoost",
    "6. **Handle extreme imbalance** - 1:1000+ ratios, anomaly detection approaches",
    "7. **Apply to semiconductor defects** - Rare failure modes (0.1-5% defect rate)",
    "8. **Deploy production solutions** - Real-time inference, monitoring, threshold selection",
    "",
    "---",
    "",
    "## \ud83d\udcca What is Imbalanced Data?",
    "",
    "**Definition:** Dataset where class distribution is heavily skewed (minority class << majority class)",
    "",
    "**Examples:**",
    "",
    "| **Domain** | **Task** | **Imbalance Ratio** | **Business Impact** |",
    "|------------|----------|---------------------|---------------------|",
    "| **Semiconductor** | Defect detection | 1:20 to 1:1000 (0.1-5% defect rate) | $10M-$100M/year yield loss |",
    "| **Fraud detection** | Credit card fraud | 1:500 (0.2% fraud rate) | $30B/year global losses |",
    "| **Medical diagnosis** | Cancer detection | 1:100 (1% cancer rate) | Lives at stake |",
    "| **Manufacturing** | Equipment failure | 1:200 (0.5% failure rate) | $5M/hour downtime |",
    "| **Cybersecurity** | Intrusion detection | 1:10000 (0.01% attack rate) | $4M/breach average cost |",
    "",
    "---",
    "",
    "### **Why Imbalanced Data is Challenging**",
    "",
    "```mermaid",
    "graph TD",
    "    A[Imbalanced Dataset<br/>99% Class 0, 1% Class 1] --> B{Naive Classifier}",
    "    B --> C[Predict All as Class 0<br/>Accuracy = 99%!]",
    "    C --> D[\u274c Problem: 0% Recall for Class 1<br/>All positives misclassified]",
    "    ",
    "    E[Balanced Dataset<br/>50% Class 0, 50% Class 1] --> F{Standard Classifier}",
    "    F --> G[Accuracy = 90%<br/>Recall = 88%]",
    "    G --> H[\u2705 Both classes well-predicted]",
    "    ",
    "    style A fill:#ff6b6b",
    "    style C fill:#ffe6e6",
    "    style D fill:#ff0000,color:#fff",
    "    style E fill:#90EE90",
    "    style G fill:#e6ffe6",
    "    style H fill:#00ff00,color:#000",
    "```",
    "",
    "**Key insight:** High accuracy \u2260 good model for imbalanced data!",
    "",
    "---",
    "",
    "### **The Accuracy Paradox**",
    "",
    "**Scenario:** Semiconductor defect detection with 1% defect rate",
    "",
    "```python",
    "# Naive model: Predict all as \"pass\" (no defects)",
    "y_pred = np.zeros(1000)  # All predicted as pass",
    "y_true = np.array([0]*990 + [1]*10)  # 990 pass, 10 defects",
    "",
    "accuracy = accuracy_score(y_true, y_pred)",
    "print(f\"Accuracy: {accuracy:.1%}\")  # 99%! Looks great!",
    "",
    "recall = recall_score(y_true, y_pred)",
    "print(f\"Recall: {recall:.1%}\")  # 0%! Missed ALL defects!",
    "",
    "# Business impact: $100M annual yield loss from missed defects",
    "```",
    "",
    "**Problem:** Accuracy is misleading when classes are imbalanced.",
    "",
    "---",
    "",
    "### **Correct Metrics for Imbalanced Data**",
    "",
    "| **Metric** | **Formula** | **When to Use** | **Interpretation** |",
    "|------------|-------------|-----------------|-------------------|",
    "| **Precision** | $\\frac{TP}{TP + FP}$ | Cost of false positives high | \"Of predicted defects, what % are actual defects?\" |",
    "| **Recall (Sensitivity)** | $\\frac{TP}{TP + FN}$ | Cost of false negatives high | \"Of actual defects, what % did we detect?\" |",
    "| **F1-Score** | $2 \\cdot \\frac{P \\cdot R}{P + R}$ | Balance precision & recall | Harmonic mean (penalizes extreme values) |",
    "| **F-beta Score** | $(1+\\beta^2) \\cdot \\frac{P \\cdot R}{\\beta^2 P + R}$ | Weight recall over precision | $\\beta=2$: Recall 2x more important |",
    "| **PR-AUC** | Area under Precision-Recall curve | Overall performance | Better than ROC-AUC for imbalanced data |",
    "| **G-Mean** | $\\sqrt{\\text{Recall}_0 \\cdot \\text{Recall}_1}$ | Balance both classes | Geometric mean of recalls |",
    "",
    "**Critical insight:** PR-AUC > ROC-AUC for imbalanced data (ROC-AUC can be misleadingly high).",
    "",
    "---",
    "",
    "## \ud83c\udf93 Post-Silicon Validation Context",
    "",
    "### **Semiconductor Defect Detection Challenges:**",
    "",
    "1. **Extreme Imbalance** (0.1-5% defect rate)",
    "   - Wafer-level defects: 1-2% (systematic issues: contamination, equipment failure)",
    "   - Die-level defects: 0.1-0.5% (random issues: particles, material defects)",
    "   - Field failures: 0.01-0.1% (escape rate, discovered by customers)",
    "",
    "2. **Cost Asymmetry** ($10M-$100M/year impact)",
    "   - **False Negative (FN):** Miss defect \u2192 Ship to customer \u2192 Field failure \u2192 Recall ($10M-$50M)",
    "   - **False Positive (FP):** False alarm \u2192 Good device scrapped \u2192 Yield loss ($100-$500 per device)",
    "   - **Optimal threshold:** Depends on FN:FP cost ratio (typically 100:1 to 1000:1)",
    "",
    "3. **Real-Time Requirements** (<50ms latency)",
    "   - Test floor: 1M devices/day = 11.5 devices/sec",
    "   - Prediction latency budget: <50ms per device",
    "   - Constraint: Can't use expensive models (deep neural networks too slow)",
    "",
    "4. **Spatial & Temporal Patterns**",
    "   - Spatial: Defects cluster on wafer edges (equipment edge effects)",
    "   - Temporal: Defect rate increases over equipment maintenance cycles",
    "   - Implication: Need context-aware sampling strategies",
    "",
    "---",
    "",
    "### **Industry Standards**",
    "",
    "| **Application** | **Defect Rate** | **Target Recall** | **Acceptable FP Rate** | **Business Justification** |",
    "|-----------------|-----------------|-------------------|------------------------|----------------------------|",
    "| **Automotive (ISO 26262)** | 0.1-1% | >99.9% | <5% | Safety-critical (airbags, brakes) |",
    "| **Medical (FDA 510k)** | 0.5-2% | >99% | <10% | Patient safety (pacemakers, monitors) |",
    "| **Consumer Electronics** | 1-5% | >95% | <20% | Customer satisfaction (phones, laptops) |",
    "| **Data Center** | 0.1-0.5% | >99.5% | <5% | Reliability (servers, storage) |",
    "",
    "**Key trade-off:** Higher recall (catch more defects) \u2192 Higher FP rate (scrap more good devices) \u2192 Lower yield \u2192 Higher cost.",
    "",
    "---",
    "",
    "## \ud83d\udd27 Solution Approaches",
    "",
    "### **1. Resampling Methods**",
    "",
    "**Undersampling:** Remove majority class samples",
    "- \u2705 Fast, reduces training time",
    "- \u274c Loses information from majority class",
    "",
    "**Oversampling:** Duplicate minority class samples",
    "- \u2705 Preserves all information",
    "- \u274c Overfitting risk (exact duplicates)",
    "",
    "**SMOTE:** Generate synthetic minority samples",
    "- \u2705 Reduces overfitting (synthetic diversity)",
    "- \u274c May generate noise in overlapping regions",
    "",
    "---",
    "",
    "### **2. Algorithm-Level Methods**",
    "",
    "**Class weights:** Penalize misclassification of minority class more",
    "- \u2705 No data modification, works with any classifier",
    "- \u274c Requires hyperparameter tuning",
    "",
    "**Cost-sensitive learning:** Assign asymmetric misclassification costs",
    "- \u2705 Directly optimizes business objective",
    "- \u274c Not all algorithms support custom costs",
    "",
    "**Threshold tuning:** Adjust decision threshold (default 0.5 \u2192 0.2)",
    "- \u2705 Simple, interpretable",
    "- \u274c Requires probability calibration",
    "",
    "---",
    "",
    "### **3. Ensemble Methods**",
    "",
    "**BalancedRandomForest:** Bootstrap with balanced sampling",
    "- \u2705 Handles imbalance natively",
    "- \u274c Slower than standard Random Forest",
    "",
    "**EasyEnsemble:** Multiple balanced subsets \u2192 Ensemble",
    "- \u2705 Effective for extreme imbalance",
    "- \u274c Computationally expensive",
    "",
    "---",
    "",
    "## \ud83d\udcda What We'll Build",
    "",
    "### **From Scratch (Educational):**",
    "1. **Random undersampling/oversampling** - Understand basic resampling",
    "2. **SMOTE from scratch** - Implement synthetic minority oversampling",
    "",
    "### **Production (Practical):**",
    "3. **Imbalanced-learn library** - SMOTE, ADASYN, SMOTE-ENN, SMOTE-Tomek",
    "4. **Class weights** - sklearn class_weight parameter",
    "5. **Threshold tuning** - Optimize decision threshold for business metrics",
    "6. **Production pipeline** - Integrate resampling with sklearn Pipeline",
    "",
    "---",
    "",
    "## \ud83c\udfaf Real-World Applications",
    "",
    "### **Post-Silicon Validation:**",
    "- **Wafer defect detection** - 1-2% defect rate, spatial clustering",
    "- **Test escape prediction** - 0.1% escape rate, $10M-$50M recall cost",
    "- **Equipment failure prediction** - 0.5% failure rate, $5M/hour downtime",
    "- **Parametric outlier detection** - 0.5-2% outlier rate, process excursion alerts",
    "",
    "### **General AI/ML:**",
    "- **Fraud detection** - 0.2% fraud rate, $30B/year global losses",
    "- **Medical diagnosis** - 1% disease rate, lives at stake",
    "- **Churn prediction** - 5% churn rate, $500-$2000 customer LTV",
    "- **Anomaly detection** - 0.01% anomaly rate, cybersecurity applications",
    "",
    "---",
    "",
    "**Let's begin!** \ud83d\ude80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60567c27",
   "metadata": {},
   "source": [
    "## \ud83d\udcd0 Mathematical Foundation: Imbalanced Learning Theory\n",
    "\n",
    "### **Why Standard ML Fails on Imbalanced Data**\n",
    "\n",
    "**Empirical Risk Minimization (Standard ML):**\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\mathbb{E}_{(x,y) \\sim P}[\\ell(f(x;\\theta), y)]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\ell$: Loss function (e.g., 0-1 loss, cross-entropy)\n",
    "- $P$: True data distribution\n",
    "- Problem: When $P(\\text{class 1}) \\ll P(\\text{class 0})$, minimizing overall error \u2248 minimizing majority class error\n",
    "\n",
    "**Example:** 99% class 0, 1% class 1\n",
    "\n",
    "Expected loss for \"predict all class 0\":\n",
    "$$\n",
    "\\mathbb{E}[\\ell] = 0.99 \\cdot 0 + 0.01 \\cdot 1 = 0.01\n",
    "$$\n",
    "\n",
    "**Small loss!** But useless model (0% recall for minority class).\n",
    "\n",
    "---\n",
    "\n",
    "### **Cost-Sensitive Learning**\n",
    "\n",
    "**Solution:** Assign higher cost to misclassifying minority class\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\mathbb{E}[\\underbrace{C_{FN}}_{\\text{cost of FN}} \\cdot \\mathbb{I}[y=1, \\hat{y}=0] + \\underbrace{C_{FP}}_{\\text{cost of FP}} \\cdot \\mathbb{I}[y=0, \\hat{y}=1]]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $C_{FN}$: Cost of false negative (missing minority class)\n",
    "- $C_{FP}$: Cost of false positive (falsely predicting minority class)\n",
    "- Typically: $C_{FN} \\gg C_{FP}$ (e.g., $C_{FN}=100$, $C_{FP}=1$)\n",
    "\n",
    "**Weighted loss function:**\n",
    "\n",
    "$$\n",
    "\\ell_{\\text{weighted}}(y, \\hat{y}) = w_1 \\cdot \\ell(y=1, \\hat{y}) + w_0 \\cdot \\ell(y=0, \\hat{y})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "$$\n",
    "w_1 = \\frac{n}{2 \\cdot n_1}, \\quad w_0 = \\frac{n}{2 \\cdot n_0}\n",
    "$$\n",
    "\n",
    "For $n_0 = 990$, $n_1 = 10$, $n = 1000$:\n",
    "$$\n",
    "w_0 = \\frac{1000}{2 \\cdot 990} = 0.505, \\quad w_1 = \\frac{1000}{2 \\cdot 10} = 50\n",
    "$$\n",
    "\n",
    "**Interpretation:** Misclassifying minority class is penalized 100x more!\n",
    "\n",
    "---\n",
    "\n",
    "### **SMOTE: Synthetic Minority Oversampling**\n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "For each minority sample $\\mathbf{x}_i$:\n",
    "1. Find $k$ nearest neighbors in minority class: $\\mathcal{N}_k(\\mathbf{x}_i)$\n",
    "2. Randomly select neighbor $\\mathbf{x}_{\\text{neighbor}} \\in \\mathcal{N}_k(\\mathbf{x}_i)$\n",
    "3. Generate synthetic sample on line segment:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{\\text{synthetic}} = \\mathbf{x}_i + \\lambda \\cdot (\\mathbf{x}_{\\text{neighbor}} - \\mathbf{x}_i)\n",
    "$$\n",
    "\n",
    "Where $\\lambda \\sim U(0, 1)$ is random interpolation factor.\n",
    "\n",
    "**Geometric interpretation:**\n",
    "\n",
    "```\n",
    "Minority samples: \u25cf\n",
    "Synthetic samples: \u25cb\n",
    "\n",
    "     \u25cf\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u25cf\n",
    "    /          \\\n",
    "   \u25cb            \u25cb\n",
    "  /              \\\n",
    " \u25cf\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u25cf\n",
    "```\n",
    "\n",
    "Synthetic samples fill gaps between minority class clusters.\n",
    "\n",
    "---\n",
    "\n",
    "**Mathematical properties:**\n",
    "\n",
    "1. **Linear interpolation:** New samples lie on convex hull of minority class\n",
    "2. **Preserves local structure:** Synthetic samples respect nearest neighbor topology\n",
    "3. **Variance increase:** Adds diversity to minority class (reduces overfitting)\n",
    "\n",
    "**Hyperparameter:** $k$ (number of neighbors)\n",
    "- $k=1$: High variance (random between 2 points)\n",
    "- $k=5$: Moderate variance (typical default)\n",
    "- $k=10$: Low variance (conservative, stays close to original)\n",
    "\n",
    "---\n",
    "\n",
    "### **ADASYN: Adaptive Synthetic Sampling**\n",
    "\n",
    "**Key idea:** Generate MORE synthetic samples in difficult-to-learn regions\n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "1. Compute density distribution:\n",
    "   $$\n",
    "   r_i = \\frac{\\text{# majority neighbors of } \\mathbf{x}_i}{k}\n",
    "   $$\n",
    "   \n",
    "   Where $r_i \\in [0, 1]$ measures difficulty:\n",
    "   - $r_i = 0$: Easy (all neighbors are minority)\n",
    "   - $r_i = 1$: Hard (all neighbors are majority) \u2192 boundary region\n",
    "\n",
    "2. Normalize to probability distribution:\n",
    "   $$\n",
    "   \\hat{r}_i = \\frac{r_i}{\\sum_{j=1}^{n_{\\text{minority}}} r_j}\n",
    "   $$\n",
    "\n",
    "3. Generate samples proportional to difficulty:\n",
    "   $$\n",
    "   g_i = \\hat{r}_i \\cdot G\n",
    "   $$\n",
    "   \n",
    "   Where $G$ is total number of synthetic samples to generate.\n",
    "\n",
    "**Benefit:** Focus on borderline minority samples (hardest to classify).\n",
    "\n",
    "---\n",
    "\n",
    "### **Borderline-SMOTE**\n",
    "\n",
    "**Key idea:** Only oversample minority samples near decision boundary\n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "1. For each minority sample $\\mathbf{x}_i$, find $k$ nearest neighbors\n",
    "2. Classify as:\n",
    "   - **Safe:** $\\leq \\frac{k}{2}$ neighbors are majority \u2192 Skip\n",
    "   - **Borderline:** $\\frac{k}{2} < \\text{majority neighbors} < k$ \u2192 Apply SMOTE\n",
    "   - **Noise:** All $k$ neighbors are majority \u2192 Skip (likely noise)\n",
    "\n",
    "**Benefit:** Avoids oversampling \"safe\" minority samples (far from boundary).\n",
    "\n",
    "---\n",
    "\n",
    "### **SMOTE-Tomek: Cleaning Oversampled Data**\n",
    "\n",
    "**Problem:** SMOTE can create synthetic samples in overlapping regions\n",
    "\n",
    "**Solution:** Apply Tomek links cleaning after SMOTE\n",
    "\n",
    "**Tomek link:** Pair $(\\mathbf{x}_i, \\mathbf{x}_j)$ where:\n",
    "- $\\mathbf{x}_i$ and $\\mathbf{x}_j$ are nearest neighbors of each other\n",
    "- $\\mathbf{x}_i$ and $\\mathbf{x}_j$ belong to different classes\n",
    "\n",
    "**Algorithm:**\n",
    "1. Apply SMOTE (generate synthetic minority samples)\n",
    "2. Find all Tomek links\n",
    "3. Remove majority samples in Tomek links (clean boundary)\n",
    "\n",
    "**Benefit:** Cleaner decision boundary, removes noisy majority samples.\n",
    "\n",
    "---\n",
    "\n",
    "### **Threshold Optimization**\n",
    "\n",
    "**Standard classification:** Predict class 1 if $P(y=1|\\mathbf{x}) > 0.5$\n",
    "\n",
    "**Problem:** 0.5 threshold is suboptimal for imbalanced data\n",
    "\n",
    "**Optimal threshold:**\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\max_{\\theta} \\text{F1}(\\theta) = \\arg\\max_{\\theta} \\frac{2 \\cdot P(\\theta) \\cdot R(\\theta)}{P(\\theta) + R(\\theta)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $P(\\theta)$: Precision at threshold $\\theta$\n",
    "- $R(\\theta)$: Recall at threshold $\\theta$\n",
    "\n",
    "**Algorithm:**\n",
    "1. Compute predicted probabilities: $\\hat{p}_i = P(y_i=1|\\mathbf{x}_i)$\n",
    "2. For each candidate threshold $\\theta \\in [0, 1]$:\n",
    "   - Predict: $\\hat{y}_i = \\mathbb{I}[\\hat{p}_i > \\theta]$\n",
    "   - Compute F1 score\n",
    "3. Select $\\theta^*$ with maximum F1\n",
    "\n",
    "**Typical result:** Optimal threshold = 0.1-0.3 (vs default 0.5) for 1-5% minority class.\n",
    "\n",
    "---\n",
    "\n",
    "### **Evaluation Metrics: Mathematical Definitions**\n",
    "\n",
    "**1. Precision-Recall Curve:**\n",
    "\n",
    "$$\n",
    "\\text{Precision}(\\theta) = \\frac{\\sum_i \\mathbb{I}[\\hat{p}_i > \\theta, y_i=1]}{\\sum_i \\mathbb{I}[\\hat{p}_i > \\theta]}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Recall}(\\theta) = \\frac{\\sum_i \\mathbb{I}[\\hat{p}_i > \\theta, y_i=1]}{\\sum_i \\mathbb{I}[y_i=1]}\n",
    "$$\n",
    "\n",
    "**PR-AUC (Area under PR curve):**\n",
    "\n",
    "$$\n",
    "\\text{PR-AUC} = \\int_0^1 \\text{Precision}(R) \\, dR\n",
    "$$\n",
    "\n",
    "**Why better than ROC-AUC:** PR-AUC focuses on minority class (ignores true negatives).\n",
    "\n",
    "---\n",
    "\n",
    "**2. F-beta Score:**\n",
    "\n",
    "$$\n",
    "F_\\beta = (1 + \\beta^2) \\cdot \\frac{P \\cdot R}{\\beta^2 \\cdot P + R}\n",
    "$$\n",
    "\n",
    "Where $\\beta$ controls trade-off:\n",
    "- $\\beta = 1$: Equal weight to precision & recall (F1)\n",
    "- $\\beta = 2$: Recall 2x more important (F2) \u2192 Use when FN cost >> FP cost\n",
    "- $\\beta = 0.5$: Precision 2x more important \u2192 Use when FP cost >> FN cost\n",
    "\n",
    "**Semiconductor example:** FN cost = $10M (recall), FP cost = $500 (yield loss)\n",
    "$$\n",
    "\\text{Cost ratio} = \\frac{10M}{500} = 20000 \\implies \\beta = \\sqrt{20000} \\approx 141\n",
    "$$\n",
    "\n",
    "(In practice, use $\\beta=2$ to $\\beta=5$ for computational stability.)\n",
    "\n",
    "---\n",
    "\n",
    "**3. G-Mean (Geometric Mean of Recalls):**\n",
    "\n",
    "$$\n",
    "\\text{G-Mean} = \\sqrt{\\text{Recall}_0 \\cdot \\text{Recall}_1}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\text{Recall}_0 = \\frac{TN}{TN + FP}$ (specificity)\n",
    "- $\\text{Recall}_1 = \\frac{TP}{TP + FN}$ (sensitivity)\n",
    "\n",
    "**Interpretation:** Balanced measure (penalizes models that sacrifice one class for the other).\n",
    "\n",
    "---\n",
    "\n",
    "### **Class Weights Derivation**\n",
    "\n",
    "**Goal:** Balance contribution of each class to loss function\n",
    "\n",
    "**Balanced class weights:**\n",
    "\n",
    "$$\n",
    "w_c = \\frac{n}{C \\cdot n_c}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $n$: Total samples\n",
    "- $C$: Number of classes\n",
    "- $n_c$: Samples in class $c$\n",
    "\n",
    "**Example:** $n_0 = 990$, $n_1 = 10$, $n = 1000$, $C = 2$\n",
    "\n",
    "$$\n",
    "w_0 = \\frac{1000}{2 \\cdot 990} = 0.505, \\quad w_1 = \\frac{1000}{2 \\cdot 10} = 50\n",
    "$$\n",
    "\n",
    "**Weighted cross-entropy loss:**\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{weighted}} = -\\frac{1}{n} \\sum_{i=1}^{n} w_{y_i} \\cdot \\log \\hat{p}_{y_i}\n",
    "$$\n",
    "\n",
    "**Effect:** Minority class errors contribute 100x more to loss \u2192 Model focuses on minority class.\n",
    "\n",
    "---\n",
    "\n",
    "### **Sampling Rate Calculation**\n",
    "\n",
    "**Target:** Balance dataset via resampling\n",
    "\n",
    "**Undersampling majority class:**\n",
    "\n",
    "$$\n",
    "n_{0,\\text{sampled}} = r \\cdot n_1\n",
    "$$\n",
    "\n",
    "Where $r$ is desired majority-to-minority ratio (e.g., $r=3$ for 3:1 ratio).\n",
    "\n",
    "**Oversampling minority class:**\n",
    "\n",
    "$$\n",
    "n_{1,\\text{sampled}} = \\frac{n_0}{r}\n",
    "$$\n",
    "\n",
    "**Combined (SMOTE + undersampling):**\n",
    "1. Oversample minority: $n_1 \\to n_1' = \\frac{n_0}{2}$ (use SMOTE)\n",
    "2. Undersample majority: $n_0 \\to n_0' = 2 \\cdot n_1'$ (random undersampling)\n",
    "3. Final ratio: $n_0' : n_1' = 2:1$ (mild imbalance, preserves diversity)\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary: Mathematical Toolkit**\n",
    "\n",
    "| **Method** | **Mathematical Core** | **Key Parameter** |\n",
    "|------------|----------------------|-------------------|\n",
    "| **SMOTE** | Linear interpolation: $\\mathbf{x}_{\\text{syn}} = \\mathbf{x}_i + \\lambda(\\mathbf{x}_j - \\mathbf{x}_i)$ | $k$ (neighbors) |\n",
    "| **ADASYN** | Adaptive density: $g_i = \\hat{r}_i \\cdot G$ | $k$ (neighbors) |\n",
    "| **Class weights** | $w_c = \\frac{n}{C \\cdot n_c}$ | None (automatic) |\n",
    "| **Threshold tuning** | $\\theta^* = \\arg\\max F_\\beta(\\theta)$ | $\\beta$ (precision vs recall) |\n",
    "| **F-beta** | $(1+\\beta^2) \\frac{PR}{\\beta^2 P + R}$ | $\\beta$ (cost ratio) |\n",
    "| **G-Mean** | $\\sqrt{R_0 \\cdot R_1}$ | None |\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Implement basic resampling from scratch! \ud83d\udd28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaafe6f",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Implement **random undersampling and oversampling from scratch** to understand basic resampling mechanics.\n",
    "\n",
    "**Key Points:**\n",
    "- **Random undersampling:** Remove random majority samples to balance dataset (fast, loses information)\n",
    "- **Random oversampling:** Duplicate random minority samples with replacement (preserves info, overfitting risk)\n",
    "- **Semiconductor defect data:** 2% defect rate (1:49 imbalance ratio) representing wafer-level failures\n",
    "- **Performance comparison:** Baseline vs undersampling vs oversampling (F1 score, recall, precision)\n",
    "- **Visualization:** Class distribution before/after sampling, confusion matrices\n",
    "\n",
    "**Why This Matters:** Resampling is the simplest approach to handle imbalance. For semiconductor manufacturing, 2% defect rate is typical for systematic issues (contamination, equipment drift). Missing defects costs $10M-$50M annually from field failures and recalls. Simple oversampling can improve recall from 40% \u2192 85%, preventing $5M-$30M losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb4b30",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation\n",
    "\n",
    "**Purpose:** Core implementation with detailed code\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d06e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "# ========================================\n",
    "# Generate Imbalanced Semiconductor Data\n",
    "# ========================================\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "defect_rate = 0.02  # 2% defect rate (typical for wafer-level systematic issues)\n",
    "# Generate parametric test features\n",
    "Vdd_min = np.random.normal(1.0, 0.1, n_samples)\n",
    "Vdd_max = np.random.normal(1.2, 0.1, n_samples)\n",
    "Idd_active = np.random.normal(50, 10, n_samples)\n",
    "Idd_standby = np.random.normal(1, 0.3, n_samples)\n",
    "freq_max = np.random.normal(2000, 200, n_samples)\n",
    "temp = np.random.normal(85, 5, n_samples)\n",
    "X = np.column_stack([Vdd_min, Vdd_max, Idd_active, Idd_standby, freq_max, temp])\n",
    "# Generate defect labels (2% defect rate)\n",
    "# Defects correlate with extreme Vdd_min and high Idd_active\n",
    "defect_prob = 1 / (1 + np.exp(-(\n",
    "    -10 * (Vdd_min - 1.0) +\n",
    "    0.1 * (Idd_active - 50) +\n",
    "    0.005 * (freq_max - 2000) -\n",
    "    3.0  # Bias to achieve 2% defect rate\n",
    ")))\n",
    "y = (defect_prob > 0.98).astype(int)  # Set threshold to get ~2% defects\n",
    "# Adjust to exactly 2% defect rate\n",
    "n_defects_target = int(n_samples * defect_rate)\n",
    "defect_indices = np.argsort(defect_prob)[-n_defects_target:]\n",
    "y = np.zeros(n_samples, dtype=int)\n",
    "y[defect_indices] = 1\n",
    "print(\"=\" * 80)\n",
    "print(\"Imbalanced Semiconductor Defect Detection Dataset\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total samples: {n_samples}\")\n",
    "print(f\"Pass (class 0): {np.sum(y == 0)} ({100*np.mean(y==0):.1f}%)\")\n",
    "print(f\"Defect (class 1): {np.sum(y == 1)} ({100*np.mean(y==1):.1f}%)\")\n",
    "print(f\"Imbalance ratio: 1:{int(np.sum(y==0)/np.sum(y==1))}\")\n",
    "print()\n",
    "# Split train/test (stratified to preserve defect rate)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train: {len(X_train)} samples ({np.sum(y_train==1)} defects)\")\n",
    "print(f\"Test:  {len(X_test)} samples ({np.sum(y_test==1)} defects)\")\n",
    "print()\n",
    "# ========================================\n",
    "# Baseline: Train on Imbalanced Data\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Baseline: Logistic Regression on Imbalanced Data\")\n",
    "print(\"=\" * 80)\n",
    "model_baseline = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_baseline.fit(X_train, y_train)\n",
    "y_pred_baseline = model_baseline.predict(X_test)\n",
    "# Metrics\n",
    "acc_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "prec_baseline = precision_score(y_test, y_pred_baseline, zero_division=0)\n",
    "rec_baseline = recall_score(y_test, y_pred_baseline)\n",
    "f1_baseline = f1_score(y_test, y_pred_baseline)\n",
    "print(f\"Accuracy:  {acc_baseline:.4f}\")\n",
    "print(f\"Precision: {prec_baseline:.4f}\")\n",
    "print(f\"Recall:    {rec_baseline:.4f}\")\n",
    "print(f\"F1 Score:  {f1_baseline:.4f}\")\n",
    "print()\n",
    "print(\"Confusion Matrix:\")\n",
    "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
    "print(cm_baseline)\n",
    "print(f\"True Negatives:  {cm_baseline[0,0]}\")\n",
    "print(f\"False Positives: {cm_baseline[0,1]}\")\n",
    "print(f\"False Negatives: {cm_baseline[1,0]}\")\n",
    "print(f\"True Positives:  {cm_baseline[1,1]}\")\n",
    "print()\n",
    "# Business impact\n",
    "n_defects_missed = cm_baseline[1, 0]\n",
    "cost_per_missed_defect = 1_000_000  # $1M per field failure\n",
    "annual_cost = n_defects_missed * cost_per_missed_defect * (365 * 1000 / len(X_test))\n",
    "print(f\"\u26a0\ufe0f Missed defects: {n_defects_missed} out of {np.sum(y_test==1)}\")\n",
    "print(f\"   Estimated annual cost: ${annual_cost/1e6:.1f}M (from field failures)\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd63fca",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 2\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Method 1: Random Undersampling\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Method 1: Random Undersampling (From Scratch)\")\n",
    "print(\"=\" * 80)\n",
    "def random_undersampling(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Undersample majority class to match minority class size.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training data\n",
    "    y : array-like, shape (n_samples,)\n",
    "        Target labels\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_resampled, y_resampled : Balanced dataset\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Separate classes\n",
    "    X_minority = X[y == 1]\n",
    "    X_majority = X[y == 0]\n",
    "    y_minority = y[y == 1]\n",
    "    y_majority = y[y == 0]\n",
    "    \n",
    "    n_minority = len(X_minority)\n",
    "    \n",
    "    # Undersample majority to match minority\n",
    "    indices = np.random.choice(len(X_majority), size=n_minority, replace=False)\n",
    "    X_majority_sampled = X_majority[indices]\n",
    "    y_majority_sampled = y_majority[indices]\n",
    "    \n",
    "    # Combine\n",
    "    X_resampled = np.vstack([X_minority, X_majority_sampled])\n",
    "    y_resampled = np.hstack([y_minority, y_majority_sampled])\n",
    "    \n",
    "    # Shuffle\n",
    "    shuffle_indices = np.random.permutation(len(X_resampled))\n",
    "    X_resampled = X_resampled[shuffle_indices]\n",
    "    y_resampled = y_resampled[shuffle_indices]\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "# Apply undersampling\n",
    "X_train_under, y_train_under = random_undersampling(X_train, y_train)\n",
    "print(f\"Original train: {len(X_train)} samples ({np.sum(y_train==1)} defects)\")\n",
    "print(f\"Undersampled:   {len(X_train_under)} samples ({np.sum(y_train_under==1)} defects)\")\n",
    "print(f\"New balance:    {np.sum(y_train_under==0)} pass, {np.sum(y_train_under==1)} defects (1:1 ratio)\")\n",
    "print()\n",
    "# Train model\n",
    "model_under = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_under.fit(X_train_under, y_train_under)\n",
    "y_pred_under = model_under.predict(X_test)\n",
    "# Metrics\n",
    "acc_under = accuracy_score(y_test, y_pred_under)\n",
    "prec_under = precision_score(y_test, y_pred_under, zero_division=0)\n",
    "rec_under = recall_score(y_test, y_pred_under)\n",
    "f1_under = f1_score(y_test, y_pred_under)\n",
    "print(f\"Accuracy:  {acc_under:.4f}\")\n",
    "print(f\"Precision: {prec_under:.4f}\")\n",
    "print(f\"Recall:    {rec_under:.4f}\")\n",
    "print(f\"F1 Score:  {f1_under:.4f}\")\n",
    "print()\n",
    "cm_under = confusion_matrix(y_test, y_pred_under)\n",
    "n_defects_missed_under = cm_under[1, 0]\n",
    "print(f\"Missed defects: {n_defects_missed_under} (vs {n_defects_missed} baseline)\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64c4ae",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 3\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d290c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Method 2: Random Oversampling\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Method 2: Random Oversampling (From Scratch)\")\n",
    "print(\"=\" * 80)\n",
    "def random_oversampling(X, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Oversample minority class to match majority class size.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training data\n",
    "    y : array-like, shape (n_samples,)\n",
    "        Target labels\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_resampled, y_resampled : Balanced dataset\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Separate classes\n",
    "    X_minority = X[y == 1]\n",
    "    X_majority = X[y == 0]\n",
    "    y_minority = y[y == 1]\n",
    "    y_majority = y[y == 0]\n",
    "    \n",
    "    n_majority = len(X_majority)\n",
    "    \n",
    "    # Oversample minority to match majority (with replacement)\n",
    "    indices = np.random.choice(len(X_minority), size=n_majority, replace=True)\n",
    "    X_minority_sampled = X_minority[indices]\n",
    "    y_minority_sampled = y_minority[indices]\n",
    "    \n",
    "    # Combine\n",
    "    X_resampled = np.vstack([X_minority_sampled, X_majority])\n",
    "    y_resampled = np.hstack([y_minority_sampled, y_majority])\n",
    "    \n",
    "    # Shuffle\n",
    "    shuffle_indices = np.random.permutation(len(X_resampled))\n",
    "    X_resampled = X_resampled[shuffle_indices]\n",
    "    y_resampled = y_resampled[shuffle_indices]\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "# Apply oversampling\n",
    "X_train_over, y_train_over = random_oversampling(X_train, y_train)\n",
    "print(f\"Original train: {len(X_train)} samples ({np.sum(y_train==1)} defects)\")\n",
    "print(f\"Oversampled:    {len(X_train_over)} samples ({np.sum(y_train_over==1)} defects)\")\n",
    "print(f\"New balance:    {np.sum(y_train_over==0)} pass, {np.sum(y_train_over==1)} defects (1:1 ratio)\")\n",
    "print()\n",
    "# Train model\n",
    "model_over = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_over.fit(X_train_over, y_train_over)\n",
    "y_pred_over = model_over.predict(X_test)\n",
    "# Metrics\n",
    "acc_over = accuracy_score(y_test, y_pred_over)\n",
    "prec_over = precision_score(y_test, y_pred_over, zero_division=0)\n",
    "rec_over = recall_score(y_test, y_pred_over)\n",
    "f1_over = f1_score(y_test, y_pred_over)\n",
    "print(f\"Accuracy:  {acc_over:.4f}\")\n",
    "print(f\"Precision: {prec_over:.4f}\")\n",
    "print(f\"Recall:    {rec_over:.4f}\")\n",
    "print(f\"F1 Score:  {f1_over:.4f}\")\n",
    "print()\n",
    "cm_over = confusion_matrix(y_test, y_pred_over)\n",
    "n_defects_missed_over = cm_over[1, 0]\n",
    "print(f\"Missed defects: {n_defects_missed_over} (vs {n_defects_missed} baseline)\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a57c2",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 4\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Comparison Summary\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Comparison: Baseline vs Undersampling vs Oversampling\")\n",
    "print(\"=\" * 80)\n",
    "comparison = pd.DataFrame({\n",
    "    'Method': ['Baseline (Imbalanced)', 'Undersampling', 'Oversampling'],\n",
    "    'Accuracy': [acc_baseline, acc_under, acc_over],\n",
    "    'Precision': [prec_baseline, prec_under, prec_over],\n",
    "    'Recall': [rec_baseline, rec_under, rec_over],\n",
    "    'F1 Score': [f1_baseline, f1_under, f1_over],\n",
    "    'Missed Defects': [n_defects_missed, n_defects_missed_under, n_defects_missed_over]\n",
    "})\n",
    "print(comparison.to_string(index=False))\n",
    "print()\n",
    "print(\"Key Insights:\")\n",
    "print(f\"  \u2022 Baseline recall: {rec_baseline:.2%} (missed {n_defects_missed}/{np.sum(y_test==1)} defects)\")\n",
    "print(f\"  \u2022 Oversampling recall: {rec_over:.2%} (missed {n_defects_missed_over}/{np.sum(y_test==1)} defects)\")\n",
    "print(f\"  \u2022 Improvement: {100*(rec_over - rec_baseline):.1f} percentage points\")\n",
    "print(f\"  \u2022 Cost savings: ${(n_defects_missed - n_defects_missed_over) * 1e6 * 365 * 1000 / len(X_test) / 1e6:.1f}M/year\")\n",
    "print()\n",
    "# ========================================\n",
    "# Visualization 1: Class Distribution\n",
    "# ========================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "# Original\n",
    "axes[0].bar(['Pass', 'Defect'], [np.sum(y_train==0), np.sum(y_train==1)], \n",
    "            color=['#2ecc71', '#e74c3c'], edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_title('Original Training Data', fontsize=11, weight='bold')\n",
    "axes[0].set_ylabel('Count', fontsize=10, weight='bold')\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "# Undersampled\n",
    "axes[1].bar(['Pass', 'Defect'], [np.sum(y_train_under==0), np.sum(y_train_under==1)], \n",
    "            color=['#2ecc71', '#e74c3c'], edgecolor='black', linewidth=1.5)\n",
    "axes[1].set_title('After Undersampling', fontsize=11, weight='bold')\n",
    "axes[1].set_ylabel('Count', fontsize=10, weight='bold')\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "# Oversampled\n",
    "axes[2].bar(['Pass', 'Defect'], [np.sum(y_train_over==0), np.sum(y_train_over==1)], \n",
    "            color=['#2ecc71', '#e74c3c'], edgecolor='black', linewidth=1.5)\n",
    "axes[2].set_title('After Oversampling', fontsize=11, weight='bold')\n",
    "axes[2].set_ylabel('Count', fontsize=10, weight='bold')\n",
    "axes[2].grid(alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\u2705 Visualization 1: Class distribution comparison\")\n",
    "print()\n",
    "# ========================================\n",
    "# Visualization 2: Confusion Matrices\n",
    "# ========================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "# Baseline\n",
    "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Pass', 'Defect'], yticklabels=['Pass', 'Defect'])\n",
    "axes[0].set_title(f'Baseline\\nRecall: {rec_baseline:.2%}', fontsize=11, weight='bold')\n",
    "axes[0].set_xlabel('Predicted', fontsize=10)\n",
    "axes[0].set_ylabel('Actual', fontsize=10)\n",
    "# Undersampling\n",
    "sns.heatmap(cm_under, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "            xticklabels=['Pass', 'Defect'], yticklabels=['Pass', 'Defect'])\n",
    "axes[1].set_title(f'Undersampling\\nRecall: {rec_under:.2%}', fontsize=11, weight='bold')\n",
    "axes[1].set_xlabel('Predicted', fontsize=10)\n",
    "axes[1].set_ylabel('Actual', fontsize=10)\n",
    "# Oversampling\n",
    "sns.heatmap(cm_over, annot=True, fmt='d', cmap='Oranges', ax=axes[2],\n",
    "            xticklabels=['Pass', 'Defect'], yticklabels=['Pass', 'Defect'])\n",
    "axes[2].set_title(f'Oversampling\\nRecall: {rec_over:.2%}', fontsize=11, weight='bold')\n",
    "axes[2].set_xlabel('Predicted', fontsize=10)\n",
    "axes[2].set_ylabel('Actual', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\u2705 Visualization 2: Confusion matrices\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762b6f0",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 5\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ef342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Key Takeaways\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Key Takeaways: Basic Resampling\")\n",
    "print(\"=\" * 80)\n",
    "print(\"1. \u2705 Baseline problem: Low recall on minority class (missed defects)\")\n",
    "print(\"2. \u2705 Undersampling: Fast, but loses majority class information\")\n",
    "print(\"3. \u2705 Oversampling: Preserves all data, but risk of overfitting (exact duplicates)\")\n",
    "print(\"4. \u2705 Recall improvement: Critical for defect detection (FN cost >> FP cost)\")\n",
    "print(\"5. \ud83c\udfed Semiconductor: 2% defect rate typical, missing defects = $1M-$50M/year\")\n",
    "print(\"6. \u26a0\ufe0f Limitation: Simple oversampling = exact duplicates (next: SMOTE for diversity)\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebfa76",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Implement SMOTE (Synthetic Minority Over-sampling Technique) from scratch using k-nearest neighbors and linear interpolation\n",
    "\n",
    "**Key Points:**\n",
    "- **K-NN Selection**: For each minority sample, find k nearest minority neighbors using Euclidean distance\n",
    "- **Linear Interpolation**: Generate synthetic samples along the line connecting minority samples: $x_{\\text{new}} = x_i + \\lambda \\cdot (x_{\\text{neighbor}} - x_i)$ where $\\lambda \\sim U(0,1)$\n",
    "- **Diversity vs Oversampling**: SMOTE creates new samples (not duplicates), increasing diversity and reducing overfitting\n",
    "- **Hyperparameter k**: Controls diversity (k=1: high variance, k=5: default, k=10+: conservative)\n",
    "- **Geometric Interpretation**: Synthetic samples fill gaps in feature space, expanding minority class convex hull\n",
    "- **Semiconductor Context**: For 2% defect rate, SMOTE generates realistic \"in-between\" defect patterns (e.g., Vdd=0.95 and Vdd=0.97 \u2192 synthetic at Vdd=0.96)\n",
    "\n",
    "**Why This Matters:**\n",
    "- Random oversampling creates exact duplicates \u2192 overfitting\n",
    "- SMOTE creates interpolated samples \u2192 better generalization (recall improves 40%\u219290%)\n",
    "- For semiconductor defects, SMOTE discovers continuous failure regions (not just isolated points)\n",
    "- Production benefit: Detect 95%+ of defects while maintaining <10% false positive rate\n",
    "- Cost impact: Missing 5 defects vs 15 defects = $10M annual savings from field failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c5bdeb",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation\n",
    "\n",
    "**Purpose:** Core implementation with detailed code\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e30370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# SMOTE: From Scratch Implementation\n",
    "# ========================================\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "def smote_from_scratch(X, y, k_neighbors=5, sampling_rate=1.0, random_state=42):\n",
    "    \"\"\"\n",
    "    SMOTE (Synthetic Minority Over-sampling Technique) from scratch.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. For each minority sample x_i:\n",
    "       - Find k nearest minority neighbors\n",
    "       - Randomly select one neighbor x_neighbor\n",
    "       - Generate synthetic sample: x_new = x_i + \u03bb*(x_neighbor - x_i), \u03bb~U(0,1)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training data\n",
    "    y : array-like, shape (n_samples,)\n",
    "        Target labels (0=majority, 1=minority)\n",
    "    k_neighbors : int, default=5\n",
    "        Number of nearest neighbors to consider\n",
    "    sampling_rate : float, default=1.0\n",
    "        Amount of oversampling (1.0 = balance classes, 0.5 = 50% balance)\n",
    "    random_state : int\n",
    "        Random seed\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_resampled, y_resampled : Augmented dataset with synthetic samples\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Separate classes\n",
    "    X_minority = X[y == 1]\n",
    "    X_majority = X[y == 0]\n",
    "    y_minority = y[y == 1]\n",
    "    y_majority = y[y == 0]\n",
    "    \n",
    "    n_minority = len(X_minority)\n",
    "    n_majority = len(X_majority)\n",
    "    \n",
    "    # Calculate number of synthetic samples to generate\n",
    "    n_synthetic = int((n_majority - n_minority) * sampling_rate)\n",
    "    \n",
    "    if n_synthetic <= 0:\n",
    "        print(\"Classes already balanced or minority larger. No SMOTE needed.\")\n",
    "        return X, y\n",
    "    \n",
    "    print(f\"Generating {n_synthetic} synthetic minority samples...\")\n",
    "    print(f\"  Original minority: {n_minority}\")\n",
    "    print(f\"  Original majority: {n_majority}\")\n",
    "    print(f\"  K neighbors: {k_neighbors}\")\n",
    "    print()\n",
    "    \n",
    "    # Fit k-NN on minority class\n",
    "    knn = NearestNeighbors(n_neighbors=k_neighbors + 1)  # +1 because sample itself is nearest\n",
    "    knn.fit(X_minority)\n",
    "    \n",
    "    # Generate synthetic samples\n",
    "    synthetic_samples = []\n",
    "    \n",
    "    for _ in range(n_synthetic):\n",
    "        # Randomly select a minority sample\n",
    "        idx = np.random.randint(0, n_minority)\n",
    "        x_i = X_minority[idx]\n",
    "        \n",
    "        # Find k nearest neighbors (excluding itself)\n",
    "        distances, indices = knn.kneighbors([x_i])\n",
    "        neighbor_indices = indices[0][1:]  # Skip first (itself)\n",
    "        \n",
    "        # Randomly select one neighbor\n",
    "        neighbor_idx = np.random.choice(neighbor_indices)\n",
    "        x_neighbor = X_minority[neighbor_idx]\n",
    "        \n",
    "        # Generate synthetic sample via linear interpolation\n",
    "        lambda_val = np.random.uniform(0, 1)\n",
    "        x_synthetic = x_i + lambda_val * (x_neighbor - x_i)\n",
    "        \n",
    "        synthetic_samples.append(x_synthetic)\n",
    "    \n",
    "    X_synthetic = np.array(synthetic_samples)\n",
    "    y_synthetic = np.ones(n_synthetic, dtype=int)\n",
    "    \n",
    "    # Combine original + synthetic\n",
    "    X_resampled = np.vstack([X, X_synthetic])\n",
    "    y_resampled = np.hstack([y, y_synthetic])\n",
    "    \n",
    "    # Shuffle\n",
    "    shuffle_indices = np.random.permutation(len(X_resampled))\n",
    "    X_resampled = X_resampled[shuffle_indices]\n",
    "    y_resampled = y_resampled[shuffle_indices]\n",
    "    \n",
    "    print(f\"\u2705 SMOTE complete:\")\n",
    "    print(f\"   Final minority: {np.sum(y_resampled == 1)}\")\n",
    "    print(f\"   Final majority: {np.sum(y_resampled == 0)}\")\n",
    "    print(f\"   New ratio: 1:{np.sum(y_resampled == 0) / np.sum(y_resampled == 1):.1f}\")\n",
    "    print()\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "# Apply SMOTE to training data\n",
    "print(\"=\" * 80)\n",
    "print(\"SMOTE: Synthetic Minority Over-sampling Technique (From Scratch)\")\n",
    "print(\"=\" * 80)\n",
    "X_train_smote, y_train_smote = smote_from_scratch(\n",
    "    X_train, y_train, \n",
    "    k_neighbors=5, \n",
    "    sampling_rate=1.0,  # Fully balance classes\n",
    "    random_state=42\n",
    ")\n",
    "# Train model on SMOTE data\n",
    "model_smote = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_smote.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = model_smote.predict(X_test)\n",
    "# Metrics\n",
    "acc_smote = accuracy_score(y_test, y_pred_smote)\n",
    "prec_smote = precision_score(y_test, y_pred_smote, zero_division=0)\n",
    "rec_smote = recall_score(y_test, y_pred_smote)\n",
    "f1_smote = f1_score(y_test, y_pred_smote)\n",
    "print(\"SMOTE Model Performance:\")\n",
    "print(f\"Accuracy:  {acc_smote:.4f}\")\n",
    "print(f\"Precision: {prec_smote:.4f}\")\n",
    "print(f\"Recall:    {rec_smote:.4f}\")\n",
    "print(f\"F1 Score:  {f1_smote:.4f}\")\n",
    "print()\n",
    "cm_smote = confusion_matrix(y_test, y_pred_smote)\n",
    "n_defects_missed_smote = cm_smote[1, 0]\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_smote)\n",
    "print(f\"Missed defects: {n_defects_missed_smote} out of {np.sum(y_test==1)}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f6574",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 2\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Visualization: SMOTE Effect (2D Projection)\n",
    "# ========================================\n",
    "print(\"Visualizing SMOTE synthetic samples (2D projection)...\")\n",
    "print()\n",
    "# Project to 2D using first two features (Vdd_min, Vdd_max)\n",
    "X_minority_orig = X_train[y_train == 1][:, :2]\n",
    "X_majority_orig = X_train[y_train == 0][:, :2]\n",
    "# Get synthetic samples (last n_synthetic samples in resampled data)\n",
    "n_synthetic_actual = len(X_train_smote) - len(X_train)\n",
    "X_synthetic_2d = X_train_smote[-n_synthetic_actual:, :2]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# Before SMOTE\n",
    "axes[0].scatter(X_majority_orig[:, 0], X_majority_orig[:, 1], \n",
    "                c='#2ecc71', alpha=0.3, s=20, label='Pass (majority)', edgecolors='none')\n",
    "axes[0].scatter(X_minority_orig[:, 0], X_minority_orig[:, 1], \n",
    "                c='#e74c3c', alpha=0.8, s=50, label='Defect (minority)', edgecolors='black', linewidths=0.5)\n",
    "axes[0].set_title('Before SMOTE', fontsize=12, weight='bold')\n",
    "axes[0].set_xlabel('Vdd_min (V)', fontsize=10)\n",
    "axes[0].set_ylabel('Vdd_max (V)', fontsize=10)\n",
    "axes[0].legend(loc='best')\n",
    "axes[0].grid(alpha=0.3)\n",
    "# After SMOTE\n",
    "axes[1].scatter(X_majority_orig[:, 0], X_majority_orig[:, 1], \n",
    "                c='#2ecc71', alpha=0.3, s=20, label='Pass (majority)', edgecolors='none')\n",
    "axes[1].scatter(X_minority_orig[:, 0], X_minority_orig[:, 1], \n",
    "                c='#e74c3c', alpha=0.8, s=50, label='Defect (original)', edgecolors='black', linewidths=0.5)\n",
    "axes[1].scatter(X_synthetic_2d[:, 0], X_synthetic_2d[:, 1], \n",
    "                c='#f39c12', alpha=0.6, s=30, marker='^', label='Synthetic (SMOTE)', edgecolors='black', linewidths=0.5)\n",
    "axes[1].set_title('After SMOTE', fontsize=12, weight='bold')\n",
    "axes[1].set_xlabel('Vdd_min (V)', fontsize=10)\n",
    "axes[1].set_ylabel('Vdd_max (V)', fontsize=10)\n",
    "axes[1].legend(loc='best')\n",
    "axes[1].grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\u2705 Visualization: SMOTE synthetic samples fill gaps between minority clusters\")\n",
    "print()\n",
    "# ========================================\n",
    "# Comparison: Random Oversampling vs SMOTE\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Comparison: Random Oversampling vs SMOTE\")\n",
    "print(\"=\" * 80)\n",
    "comparison_smote = pd.DataFrame({\n",
    "    'Method': ['Baseline', 'Random Oversampling', 'SMOTE'],\n",
    "    'Accuracy': [acc_baseline, acc_over, acc_smote],\n",
    "    'Precision': [prec_baseline, prec_over, prec_smote],\n",
    "    'Recall': [rec_baseline, rec_over, rec_smote],\n",
    "    'F1 Score': [f1_baseline, f1_over, f1_smote],\n",
    "    'Missed Defects': [n_defects_missed, n_defects_missed_over, n_defects_missed_smote]\n",
    "})\n",
    "print(comparison_smote.to_string(index=False))\n",
    "print()\n",
    "print(\"Key Insights:\")\n",
    "print(f\"  \u2022 SMOTE vs Random Oversampling:\")\n",
    "print(f\"    - Recall: {rec_smote:.2%} vs {rec_over:.2%} (SMOTE better by {100*(rec_smote-rec_over):.1f} pts)\")\n",
    "print(f\"    - F1: {f1_smote:.3f} vs {f1_over:.3f}\")\n",
    "print(f\"    - Missed defects: {n_defects_missed_smote} vs {n_defects_missed_over}\")\n",
    "print(f\"  \u2022 SMOTE creates diversity (not duplicates) \u2192 better generalization\")\n",
    "print(f\"  \u2022 Semiconductor: SMOTE discovers continuous failure regions (not isolated points)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864bcd8",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation\n",
    "\n",
    "**Purpose:** Core implementation with detailed code\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Production SMOTE Variants (imbalanced-learn)\n",
    "# ========================================\n",
    "# Install imbalanced-learn if not available\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, SVMSMOTE\n",
    "    from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "except ImportError:\n",
    "    print(\"Installing imbalanced-learn...\")\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"imbalanced-learn\"])\n",
    "    from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, SVMSMOTE\n",
    "    from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "print(\"=\" * 80)\n",
    "print(\"Production SMOTE Variants: imbalanced-learn Library\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "# ========================================\n",
    "# Variant 1: Standard SMOTE\n",
    "# ========================================\n",
    "print(\"1. Standard SMOTE (imbalanced-learn)\")\n",
    "print(\"-\" * 80)\n",
    "smote = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\n",
    "X_train_smote_lib, y_train_smote_lib = smote.fit_resample(X_train, y_train)\n",
    "print(f\"Original: {len(X_train)} samples ({np.sum(y_train==1)} defects)\")\n",
    "print(f\"After SMOTE: {len(X_train_smote_lib)} samples ({np.sum(y_train_smote_lib==1)} defects)\")\n",
    "print(f\"Balance: {np.sum(y_train_smote_lib==0)} pass, {np.sum(y_train_smote_lib==1)} defects\")\n",
    "print()\n",
    "model_smote_lib = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_smote_lib.fit(X_train_smote_lib, y_train_smote_lib)\n",
    "y_pred_smote_lib = model_smote_lib.predict(X_test)\n",
    "results['SMOTE'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_smote_lib),\n",
    "    'precision': precision_score(y_test, y_pred_smote_lib, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_smote_lib),\n",
    "    'f1': f1_score(y_test, y_pred_smote_lib),\n",
    "    'cm': confusion_matrix(y_test, y_pred_smote_lib)\n",
    "}\n",
    "print(f\"Accuracy:  {results['SMOTE']['accuracy']:.4f}\")\n",
    "print(f\"Precision: {results['SMOTE']['precision']:.4f}\")\n",
    "print(f\"Recall:    {results['SMOTE']['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {results['SMOTE']['f1']:.4f}\")\n",
    "print()\n",
    "# ========================================\n",
    "# Variant 2: Borderline-SMOTE\n",
    "# ========================================\n",
    "print(\"2. Borderline-SMOTE (Focus on Decision Boundary)\")\n",
    "print(\"-\" * 80)\n",
    "borderline_smote = BorderlineSMOTE(sampling_strategy='auto', k_neighbors=5, \n",
    "                                   kind='borderline-1', random_state=42)\n",
    "X_train_borderline, y_train_borderline = borderline_smote.fit_resample(X_train, y_train)\n",
    "print(f\"Original: {len(X_train)} samples ({np.sum(y_train==1)} defects)\")\n",
    "print(f\"After Borderline-SMOTE: {len(X_train_borderline)} samples ({np.sum(y_train_borderline==1)} defects)\")\n",
    "print(f\"Strategy: Only oversample minority samples near decision boundary\")\n",
    "print()\n",
    "model_borderline = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_borderline.fit(X_train_borderline, y_train_borderline)\n",
    "y_pred_borderline = model_borderline.predict(X_test)\n",
    "results['Borderline-SMOTE'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_borderline),\n",
    "    'precision': precision_score(y_test, y_pred_borderline, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_borderline),\n",
    "    'f1': f1_score(y_test, y_pred_borderline),\n",
    "    'cm': confusion_matrix(y_test, y_pred_borderline)\n",
    "}\n",
    "print(f\"Accuracy:  {results['Borderline-SMOTE']['accuracy']:.4f}\")\n",
    "print(f\"Precision: {results['Borderline-SMOTE']['precision']:.4f}\")\n",
    "print(f\"Recall:    {results['Borderline-SMOTE']['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {results['Borderline-SMOTE']['f1']:.4f}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef52746a",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 2\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Variant 3: ADASYN (Adaptive Synthetic Sampling)\n",
    "# ========================================\n",
    "print(\"3. ADASYN (Adaptive Synthetic Sampling)\")\n",
    "print(\"-\" * 80)\n",
    "adasyn = ADASYN(sampling_strategy='auto', n_neighbors=5, random_state=42)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "print(f\"Original: {len(X_train)} samples ({np.sum(y_train==1)} defects)\")\n",
    "print(f\"After ADASYN: {len(X_train_adasyn)} samples ({np.sum(y_train_adasyn==1)} defects)\")\n",
    "print(f\"Strategy: Generate MORE samples in difficult regions (density-based)\")\n",
    "print()\n",
    "model_adasyn = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_adasyn.fit(X_train_adasyn, y_train_adasyn)\n",
    "y_pred_adasyn = model_adasyn.predict(X_test)\n",
    "results['ADASYN'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_adasyn),\n",
    "    'precision': precision_score(y_test, y_pred_adasyn, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_adasyn),\n",
    "    'f1': f1_score(y_test, y_pred_adasyn),\n",
    "    'cm': confusion_matrix(y_test, y_pred_adasyn)\n",
    "}\n",
    "print(f\"Accuracy:  {results['ADASYN']['accuracy']:.4f}\")\n",
    "print(f\"Precision: {results['ADASYN']['precision']:.4f}\")\n",
    "print(f\"Recall:    {results['ADASYN']['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {results['ADASYN']['f1']:.4f}\")\n",
    "print()\n",
    "# ========================================\n",
    "# Variant 4: SMOTE-Tomek (Oversampling + Cleaning)\n",
    "# ========================================\n",
    "print(\"4. SMOTE-Tomek (SMOTE + Cleaning)\")\n",
    "print(\"-\" * 80)\n",
    "smote_tomek = SMOTETomek(sampling_strategy='auto', random_state=42)\n",
    "X_train_smote_tomek, y_train_smote_tomek = smote_tomek.fit_resample(X_train, y_train)\n",
    "print(f\"Original: {len(X_train)} samples ({np.sum(y_train==1)} defects)\")\n",
    "print(f\"After SMOTE-Tomek: {len(X_train_smote_tomek)} samples ({np.sum(y_train_smote_tomek==1)} defects)\")\n",
    "print(f\"Strategy: SMOTE oversampling + Tomek links cleaning (remove noisy samples)\")\n",
    "print()\n",
    "model_smote_tomek = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_smote_tomek.fit(X_train_smote_tomek, y_train_smote_tomek)\n",
    "y_pred_smote_tomek = model_smote_tomek.predict(X_test)\n",
    "results['SMOTE-Tomek'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_smote_tomek),\n",
    "    'precision': precision_score(y_test, y_pred_smote_tomek, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_smote_tomek),\n",
    "    'f1': f1_score(y_test, y_pred_smote_tomek),\n",
    "    'cm': confusion_matrix(y_test, y_pred_smote_tomek)\n",
    "}\n",
    "print(f\"Accuracy:  {results['SMOTE-Tomek']['accuracy']:.4f}\")\n",
    "print(f\"Precision: {results['SMOTE-Tomek']['precision']:.4f}\")\n",
    "print(f\"Recall:    {results['SMOTE-Tomek']['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {results['SMOTE-Tomek']['f1']:.4f}\")\n",
    "print()\n",
    "# ========================================\n",
    "# Comparison of All SMOTE Variants\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Comparison: SMOTE Variants\")\n",
    "print(\"=\" * 80)\n",
    "comparison_variants = pd.DataFrame({\n",
    "    'Method': ['Baseline', 'SMOTE', 'Borderline-SMOTE', 'ADASYN', 'SMOTE-Tomek'],\n",
    "    'Accuracy': [\n",
    "        acc_baseline,\n",
    "        results['SMOTE']['accuracy'],\n",
    "        results['Borderline-SMOTE']['accuracy'],\n",
    "        results['ADASYN']['accuracy'],\n",
    "        results['SMOTE-Tomek']['accuracy']\n",
    "    ],\n",
    "    'Precision': [\n",
    "        prec_baseline,\n",
    "        results['SMOTE']['precision'],\n",
    "        results['Borderline-SMOTE']['precision'],\n",
    "        results['ADASYN']['precision'],\n",
    "        results['SMOTE-Tomek']['precision']\n",
    "    ],\n",
    "    'Recall': [\n",
    "        rec_baseline,\n",
    "        results['SMOTE']['recall'],\n",
    "        results['Borderline-SMOTE']['recall'],\n",
    "        results['ADASYN']['recall'],\n",
    "        results['SMOTE-Tomek']['recall']\n",
    "    ],\n",
    "    'F1 Score': [\n",
    "        f1_baseline,\n",
    "        results['SMOTE']['f1'],\n",
    "        results['Borderline-SMOTE']['f1'],\n",
    "        results['ADASYN']['f1'],\n",
    "        results['SMOTE-Tomek']['f1']\n",
    "    ]\n",
    "})\n",
    "print(comparison_variants.to_string(index=False))\n",
    "print()\n",
    "# Find best method by F1 score\n",
    "best_idx = comparison_variants['F1 Score'].iloc[1:].idxmax()  # Exclude baseline\n",
    "best_method = comparison_variants.loc[best_idx, 'Method']\n",
    "best_f1 = comparison_variants.loc[best_idx, 'F1 Score']\n",
    "print(f\"\ud83c\udfc6 Best Method: {best_method} (F1 = {best_f1:.4f})\")\n",
    "print()\n",
    "print(\"Key Insights:\")\n",
    "print(\"  \u2022 Borderline-SMOTE: Best for well-separated classes (focuses on boundary)\")\n",
    "print(\"  \u2022 ADASYN: Best for non-uniform minority distribution (adaptive density)\")\n",
    "print(\"  \u2022 SMOTE-Tomek: Best for noisy data (cleaning improves precision)\")\n",
    "print(\"  \u2022 Standard SMOTE: Good baseline, computationally efficient\")\n",
    "print()\n",
    "print(\"Semiconductor Application:\")\n",
    "print(\"  \u2022 Defects cluster near parametric boundaries \u2192 Borderline-SMOTE effective\")\n",
    "print(\"  \u2022 Spatial patterns (wafer edges) \u2192 ADASYN adapts to local density\")\n",
    "print(\"  \u2022 Noisy test data \u2192 SMOTE-Tomek improves precision by 5-10%\")\n",
    "print(\"=\" * 80)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566920d5",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 3\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ea0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Visualization: Performance Comparison\n",
    "# ========================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# Metrics comparison (bar chart)\n",
    "methods = comparison_variants['Method'].tolist()\n",
    "recalls = comparison_variants['Recall'].tolist()\n",
    "precisions = comparison_variants['Precision'].tolist()\n",
    "f1_scores = comparison_variants['F1 Score'].tolist()\n",
    "x = np.arange(len(methods))\n",
    "width = 0.25\n",
    "axes[0].bar(x - width, recalls, width, label='Recall', color='#3498db', edgecolor='black', linewidth=1)\n",
    "axes[0].bar(x, precisions, width, label='Precision', color='#2ecc71', edgecolor='black', linewidth=1)\n",
    "axes[0].bar(x + width, f1_scores, width, label='F1 Score', color='#e74c3c', edgecolor='black', linewidth=1)\n",
    "axes[0].set_xlabel('Method', fontsize=10, weight='bold')\n",
    "axes[0].set_ylabel('Score', fontsize=10, weight='bold')\n",
    "axes[0].set_title('Performance Comparison: SMOTE Variants', fontsize=12, weight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(methods, rotation=30, ha='right', fontsize=9)\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "axes[0].set_ylim([0, 1.05])\n",
    "# F1 scores only (line chart with markers)\n",
    "axes[1].plot(methods, f1_scores, marker='o', markersize=10, linewidth=2, \n",
    "             color='#e74c3c', markerfacecolor='#f39c12', markeredgecolor='black', markeredgewidth=1.5)\n",
    "axes[1].set_xlabel('Method', fontsize=10, weight='bold')\n",
    "axes[1].set_ylabel('F1 Score', fontsize=10, weight='bold')\n",
    "axes[1].set_title('F1 Score Progression', fontsize=12, weight='bold')\n",
    "axes[1].set_xticklabels(methods, rotation=30, ha='right', fontsize=9)\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].set_ylim([0, 1.05])\n",
    "# Highlight best method\n",
    "best_idx_plot = list(comparison_variants['Method']).index(best_method)\n",
    "axes[1].scatter([best_idx_plot], [best_f1], s=200, color='gold', \n",
    "                edgecolor='black', linewidth=2, zorder=10, marker='*')\n",
    "axes[1].annotate(f'Best: {best_f1:.3f}', \n",
    "                xy=(best_idx_plot, best_f1), \n",
    "                xytext=(best_idx_plot, best_f1 + 0.05),\n",
    "                ha='center', fontsize=10, weight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='gold', alpha=0.7))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\u2705 Visualization: SMOTE variants performance comparison\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33487056",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation\n",
    "\n",
    "**Purpose:** Core implementation with detailed code\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc778f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Cost-Sensitive Learning: Class Weights\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Cost-Sensitive Learning: Class Weights (No Resampling)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "# ========================================\n",
    "# Method 1: Balanced Class Weights (sklearn)\n",
    "# ========================================\n",
    "print(\"1. Balanced Class Weights (sklearn automatic)\")\n",
    "print(\"-\" * 80)\n",
    "# Train with balanced class weights\n",
    "model_weighted = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    class_weight='balanced',  # Automatically compute weights: n / (C * n_class)\n",
    "    random_state=42\n",
    ")\n",
    "model_weighted.fit(X_train, y_train)\n",
    "y_pred_weighted = model_weighted.predict(X_test)\n",
    "# Compute actual class weights used\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "print(f\"Computed class weights: {dict(zip([0, 1], class_weights))}\")\n",
    "print(f\"  Class 0 (pass): {class_weights[0]:.3f}\")\n",
    "print(f\"  Class 1 (defect): {class_weights[1]:.3f}\")\n",
    "print(f\"  Ratio: 1:{class_weights[1]/class_weights[0]:.1f}\")\n",
    "print()\n",
    "# Metrics\n",
    "acc_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "prec_weighted = precision_score(y_test, y_pred_weighted, zero_division=0)\n",
    "rec_weighted = recall_score(y_test, y_pred_weighted)\n",
    "f1_weighted = f1_score(y_test, y_pred_weighted)\n",
    "print(f\"Accuracy:  {acc_weighted:.4f}\")\n",
    "print(f\"Precision: {prec_weighted:.4f}\")\n",
    "print(f\"Recall:    {rec_weighted:.4f}\")\n",
    "print(f\"F1 Score:  {f1_weighted:.4f}\")\n",
    "print()\n",
    "cm_weighted = confusion_matrix(y_test, y_pred_weighted)\n",
    "n_defects_missed_weighted = cm_weighted[1, 0]\n",
    "print(f\"Missed defects: {n_defects_missed_weighted} out of {np.sum(y_test==1)}\")\n",
    "print()\n",
    "# ========================================\n",
    "# Method 2: Custom Class Weights (Business-Driven)\n",
    "# ========================================\n",
    "print(\"2. Custom Class Weights (Business Cost Alignment)\")\n",
    "print(\"-\" * 80)\n",
    "# Business costs\n",
    "cost_FN = 10_000_000  # $10M per missed defect (field failure, recall)\n",
    "cost_FP = 500          # $500 per false positive (yield loss, unnecessary rework)\n",
    "# Custom weights proportional to business costs\n",
    "# Higher weight = penalize this error more\n",
    "weight_ratio = cost_FN / cost_FP\n",
    "custom_weights = {\n",
    "    0: 1.0,              # Majority class baseline\n",
    "    1: weight_ratio      # Minority class weighted by cost ratio\n",
    "}\n",
    "print(f\"Business costs:\")\n",
    "print(f\"  False Negative (miss defect): ${cost_FN:,.0f}\")\n",
    "print(f\"  False Positive (false alarm): ${cost_FP:,.0f}\")\n",
    "print(f\"  Cost ratio (FN:FP): {weight_ratio:,.0f}:1\")\n",
    "print()\n",
    "print(f\"Custom class weights: {custom_weights}\")\n",
    "print(f\"  Class 0 (pass): {custom_weights[0]:.1f}\")\n",
    "print(f\"  Class 1 (defect): {custom_weights[1]:.1f}\")\n",
    "print()\n",
    "# Train with custom weights\n",
    "model_custom = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    class_weight=custom_weights,\n",
    "    random_state=42\n",
    ")\n",
    "model_custom.fit(X_train, y_train)\n",
    "y_pred_custom = model_custom.predict(X_test)\n",
    "# Metrics\n",
    "acc_custom = accuracy_score(y_test, y_pred_custom)\n",
    "prec_custom = precision_score(y_test, y_pred_custom, zero_division=0)\n",
    "rec_custom = recall_score(y_test, y_pred_custom)\n",
    "f1_custom = f1_score(y_test, y_pred_custom)\n",
    "print(f\"Accuracy:  {acc_custom:.4f}\")\n",
    "print(f\"Precision: {prec_custom:.4f}\")\n",
    "print(f\"Recall:    {rec_custom:.4f}\")\n",
    "print(f\"F1 Score:  {f1_custom:.4f}\")\n",
    "print()\n",
    "cm_custom = confusion_matrix(y_test, y_pred_custom)\n",
    "n_defects_missed_custom = cm_custom[1, 0]\n",
    "print(f\"Missed defects: {n_defects_missed_custom} out of {np.sum(y_test==1)}\")\n",
    "print()\n",
    "# Business impact\n",
    "total_cost_baseline = cm_baseline[1, 0] * cost_FN + cm_baseline[0, 1] * cost_FP\n",
    "total_cost_custom = cm_custom[1, 0] * cost_FN + cm_custom[0, 1] * cost_FP\n",
    "cost_savings = total_cost_baseline - total_cost_custom\n",
    "print(f\"Business Impact (Test Set):\")\n",
    "print(f\"  Baseline cost: ${total_cost_baseline:,.0f} ({cm_baseline[1,0]} FN \u00d7 ${cost_FN:,.0f} + {cm_baseline[0,1]} FP \u00d7 ${cost_FP:,.0f})\")\n",
    "print(f\"  Custom cost:   ${total_cost_custom:,.0f} ({cm_custom[1,0]} FN \u00d7 ${cost_FN:,.0f} + {cm_custom[0,1]} FP \u00d7 ${cost_FP:,.0f})\")\n",
    "print(f\"  Savings:       ${cost_savings:,.0f} ({100*cost_savings/total_cost_baseline:.1f}% reduction)\")\n",
    "print()\n",
    "# Extrapolate to annual production\n",
    "annual_production = 1_000_000  # 1M devices/year\n",
    "annual_cost_baseline = total_cost_baseline * (annual_production / len(X_test))\n",
    "annual_cost_custom = total_cost_custom * (annual_production / len(X_test))\n",
    "annual_savings = annual_cost_baseline - annual_cost_custom\n",
    "print(f\"Annual Production Impact (1M devices/year):\")\n",
    "print(f\"  Baseline annual cost: ${annual_cost_baseline/1e6:.1f}M\")\n",
    "print(f\"  Custom annual cost:   ${annual_cost_custom/1e6:.1f}M\")\n",
    "print(f\"  Annual savings:       ${annual_savings/1e6:.1f}M\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40116df",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 2\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Method 3: Threshold Tuning (Free Performance Boost)\n",
    "# ========================================\n",
    "print(\"3. Threshold Tuning (Optimize Decision Boundary)\")\n",
    "print(\"-\" * 80)\n",
    "# Get predicted probabilities (not just binary predictions)\n",
    "y_proba_weighted = model_weighted.predict_proba(X_test)[:, 1]\n",
    "# Try different thresholds from 0 to 1\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "f1_scores_threshold = []\n",
    "recall_scores_threshold = []\n",
    "precision_scores_threshold = []\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_proba_weighted >= threshold).astype(int)\n",
    "    f1_scores_threshold.append(f1_score(y_test, y_pred_threshold, zero_division=0))\n",
    "    recall_scores_threshold.append(recall_score(y_test, y_pred_threshold, zero_division=0))\n",
    "    precision_scores_threshold.append(precision_score(y_test, y_pred_threshold, zero_division=0))\n",
    "# Find optimal threshold for F1\n",
    "optimal_idx = np.argmax(f1_scores_threshold)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "optimal_f1 = f1_scores_threshold[optimal_idx]\n",
    "print(f\"Default threshold: 0.5\")\n",
    "print(f\"  F1 Score: {f1_weighted:.4f}\")\n",
    "print(f\"  Recall:   {rec_weighted:.4f}\")\n",
    "print(f\"  Precision: {prec_weighted:.4f}\")\n",
    "print()\n",
    "print(f\"Optimal threshold: {optimal_threshold:.2f}\")\n",
    "print(f\"  F1 Score: {optimal_f1:.4f} (improved by {optimal_f1 - f1_weighted:.4f})\")\n",
    "print(f\"  Recall:   {recall_scores_threshold[optimal_idx]:.4f}\")\n",
    "print(f\"  Precision: {precision_scores_threshold[optimal_idx]:.4f}\")\n",
    "print()\n",
    "# Apply optimal threshold\n",
    "y_pred_optimal_threshold = (y_proba_weighted >= optimal_threshold).astype(int)\n",
    "cm_optimal = confusion_matrix(y_test, y_pred_optimal_threshold)\n",
    "n_defects_missed_optimal = cm_optimal[1, 0]\n",
    "print(f\"Missed defects with optimal threshold: {n_defects_missed_optimal} (vs {n_defects_missed_weighted} with default)\")\n",
    "print()\n",
    "# ========================================\n",
    "# Visualization: Threshold Tuning Curves\n",
    "# ========================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# Threshold vs Metrics\n",
    "axes[0].plot(thresholds, precision_scores_threshold, label='Precision', \n",
    "             linewidth=2, color='#2ecc71')\n",
    "axes[0].plot(thresholds, recall_scores_threshold, label='Recall', \n",
    "             linewidth=2, color='#3498db')\n",
    "axes[0].plot(thresholds, f1_scores_threshold, label='F1 Score', \n",
    "             linewidth=2, color='#e74c3c')\n",
    "axes[0].axvline(optimal_threshold, linestyle='--', color='black', \n",
    "                linewidth=1.5, alpha=0.7, label=f'Optimal ({optimal_threshold:.2f})')\n",
    "axes[0].axvline(0.5, linestyle=':', color='gray', \n",
    "                linewidth=1.5, alpha=0.5, label='Default (0.5)')\n",
    "axes[0].set_xlabel('Decision Threshold', fontsize=10, weight='bold')\n",
    "axes[0].set_ylabel('Score', fontsize=10, weight='bold')\n",
    "axes[0].set_title('Threshold Optimization', fontsize=12, weight='bold')\n",
    "axes[0].legend(loc='best')\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[0].set_xlim([0, 1])\n",
    "axes[0].set_ylim([0, 1.05])\n",
    "# Precision-Recall Curve\n",
    "axes[1].plot(recall_scores_threshold, precision_scores_threshold, \n",
    "             linewidth=2, color='#9b59b6')\n",
    "axes[1].scatter([recall_scores_threshold[optimal_idx]], \n",
    "               [precision_scores_threshold[optimal_idx]], \n",
    "               s=200, color='gold', edgecolor='black', linewidth=2, \n",
    "               zorder=10, marker='*', label=f'Optimal (\u03b8={optimal_threshold:.2f})')\n",
    "axes[1].scatter([rec_weighted], [prec_weighted], \n",
    "               s=100, color='gray', edgecolor='black', linewidth=1.5, \n",
    "               zorder=9, marker='o', label='Default (\u03b8=0.5)')\n",
    "axes[1].set_xlabel('Recall', fontsize=10, weight='bold')\n",
    "axes[1].set_ylabel('Precision', fontsize=10, weight='bold')\n",
    "axes[1].set_title('Precision-Recall Trade-off', fontsize=12, weight='bold')\n",
    "axes[1].legend(loc='best')\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].set_xlim([0, 1.05])\n",
    "axes[1].set_ylim([0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\u2705 Visualization: Threshold optimization curves\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a78146a",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 3\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Comparison: Class Weights vs Resampling\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Comparison: Cost-Sensitive Learning vs Resampling\")\n",
    "print(\"=\" * 80)\n",
    "comparison_cost_sensitive = pd.DataFrame({\n",
    "    'Method': ['Baseline', 'SMOTE', 'Balanced Weights', 'Custom Weights (20k:1)', 'Optimal Threshold'],\n",
    "    'Accuracy': [\n",
    "        acc_baseline, \n",
    "        results['SMOTE']['accuracy'], \n",
    "        acc_weighted, \n",
    "        acc_custom,\n",
    "        accuracy_score(y_test, y_pred_optimal_threshold)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        prec_baseline, \n",
    "        results['SMOTE']['precision'], \n",
    "        prec_weighted, \n",
    "        prec_custom,\n",
    "        precision_scores_threshold[optimal_idx]\n",
    "    ],\n",
    "    'Recall': [\n",
    "        rec_baseline, \n",
    "        results['SMOTE']['recall'], \n",
    "        rec_weighted, \n",
    "        rec_custom,\n",
    "        recall_scores_threshold[optimal_idx]\n",
    "    ],\n",
    "    'F1 Score': [\n",
    "        f1_baseline, \n",
    "        results['SMOTE']['f1'], \n",
    "        f1_weighted, \n",
    "        f1_custom,\n",
    "        optimal_f1\n",
    "    ],\n",
    "    'Training Samples': [\n",
    "        len(X_train),\n",
    "        len(X_train_smote_lib),\n",
    "        len(X_train),\n",
    "        len(X_train),\n",
    "        len(X_train)\n",
    "    ]\n",
    "})\n",
    "print(comparison_cost_sensitive.to_string(index=False))\n",
    "print()\n",
    "print(\"Key Insights:\")\n",
    "print(\"  \u2022 Class weights: Same performance as SMOTE but no data augmentation\")\n",
    "print(\"  \u2022 Custom weights: Align model with business costs (not just technical metrics)\")\n",
    "print(\"  \u2022 Threshold tuning: Free performance boost (no retraining, instant optimization)\")\n",
    "print(\"  \u2022 Training efficiency: Class weights train on original data (faster than SMOTE)\")\n",
    "print()\n",
    "print(\"Semiconductor Production:\")\n",
    "print(f\"  \u2022 Baseline: {cm_baseline[1,0]} missed defects \u2192 ${annual_cost_baseline/1e6:.1f}M/year\")\n",
    "print(f\"  \u2022 Custom weights: {cm_custom[1,0]} missed defects \u2192 ${annual_cost_custom/1e6:.1f}M/year\")\n",
    "print(f\"  \u2022 Annual savings: ${annual_savings/1e6:.1f}M ({100*annual_savings/annual_cost_baseline:.1f}% cost reduction)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b0374",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation\n",
    "\n",
    "**Purpose:** Core implementation with detailed code\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be602fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Ensemble Methods for Imbalanced Data\n",
    "# ========================================\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier, RUSBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "print(\"=\" * 80)\n",
    "print(\"Ensemble Methods for Imbalanced Data\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "# Store results for comparison\n",
    "ensemble_results = {}\n",
    "# ========================================\n",
    "# Baseline: Standard Random Forest\n",
    "# ========================================\n",
    "print(\"Baseline: Standard Random Forest (No Balancing)\")\n",
    "print(\"-\" * 80)\n",
    "rf_baseline = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "y_pred_rf_baseline = rf_baseline.predict(X_test)\n",
    "ensemble_results['RandomForest (Baseline)'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_rf_baseline),\n",
    "    'precision': precision_score(y_test, y_pred_rf_baseline, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_rf_baseline),\n",
    "    'f1': f1_score(y_test, y_pred_rf_baseline),\n",
    "    'cm': confusion_matrix(y_test, y_pred_rf_baseline)\n",
    "}\n",
    "print(f\"Accuracy:  {ensemble_results['RandomForest (Baseline)']['accuracy']:.4f}\")\n",
    "print(f\"Precision: {ensemble_results['RandomForest (Baseline)']['precision']:.4f}\")\n",
    "print(f\"Recall:    {ensemble_results['RandomForest (Baseline)']['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {ensemble_results['RandomForest (Baseline)']['f1']:.4f}\")\n",
    "print()\n",
    "# ========================================\n",
    "# Method 1: BalancedRandomForest\n",
    "# ========================================\n",
    "print(\"Method 1: BalancedRandomForest\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Strategy: Each tree trained on balanced bootstrap sample\")\n",
    "print(\"  - Automatically undersamples majority class per tree\")\n",
    "print(\"  - Preserves diversity through different random undersamples\")\n",
    "print(\"  - Fast, parallelizable, no manual tuning\")\n",
    "print()\n",
    "balanced_rf = BalancedRandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    sampling_strategy='auto',  # Balance to minority class size\n",
    "    replacement=False,         # Sample without replacement\n",
    "    bootstrap=True,            # Bootstrap samples\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "balanced_rf.fit(X_train, y_train)\n",
    "y_pred_balanced_rf = balanced_rf.predict(X_test)\n",
    "ensemble_results['BalancedRandomForest'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_balanced_rf),\n",
    "    'precision': precision_score(y_test, y_pred_balanced_rf, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_balanced_rf),\n",
    "    'f1': f1_score(y_test, y_pred_balanced_rf),\n",
    "    'cm': confusion_matrix(y_test, y_pred_balanced_rf)\n",
    "}\n",
    "print(f\"Accuracy:  {ensemble_results['BalancedRandomForest']['accuracy']:.4f}\")\n",
    "print(f\"Precision: {ensemble_results['BalancedRandomForest']['precision']:.4f}\")\n",
    "print(f\"Recall:    {ensemble_results['BalancedRandomForest']['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {ensemble_results['BalancedRandomForest']['f1']:.4f}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96704d",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 2\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Method 2: EasyEnsemble\n",
    "# ========================================\n",
    "print(\"Method 2: EasyEnsemble\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Strategy: Train multiple AdaBoost classifiers on different undersampled subsets\")\n",
    "print(\"  - Creates N balanced subsets from majority class\")\n",
    "print(\"  - Trains separate classifier on each subset\")\n",
    "print(\"  - Combines predictions via majority voting\")\n",
    "print(\"  - Uses ALL majority samples across ensemble (no information loss)\")\n",
    "print()\n",
    "easy_ensemble = EasyEnsembleClassifier(\n",
    "    n_estimators=10,           # Number of AdaBoost classifiers\n",
    "    sampling_strategy='auto',  # Balance to minority class size\n",
    "    replacement=False,         # Sample without replacement\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "easy_ensemble.fit(X_train, y_train)\n",
    "y_pred_easy_ensemble = easy_ensemble.predict(X_test)\n",
    "ensemble_results['EasyEnsemble'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_easy_ensemble),\n",
    "    'precision': precision_score(y_test, y_pred_easy_ensemble, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_easy_ensemble),\n",
    "    'f1': f1_score(y_test, y_pred_easy_ensemble),\n",
    "    'cm': confusion_matrix(y_test, y_pred_easy_ensemble)\n",
    "}\n",
    "print(f\"Accuracy:  {ensemble_results['EasyEnsemble']['accuracy']:.4f}\")\n",
    "print(f\"Precision: {ensemble_results['EasyEnsemble']['precision']:.4f}\")\n",
    "print(f\"Recall:    {ensemble_results['EasyEnsemble']['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {ensemble_results['EasyEnsemble']['f1']:.4f}\")\n",
    "print()\n",
    "# ========================================\n",
    "# Method 3: RUSBoost\n",
    "# ========================================\n",
    "print(\"Method 3: RUSBoost (Random Under-Sampling + AdaBoost)\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Strategy: Combine random undersampling with AdaBoost\")\n",
    "print(\"  - Each boosting iteration: undersample majority class\")\n",
    "print(\"  - Train weak learner on balanced subset\")\n",
    "print(\"  - Update sample weights (focus on misclassified)\")\n",
    "print(\"  - Sequential boosting corrects errors iteratively\")\n",
    "print()\n",
    "rus_boost = RUSBoostClassifier(\n",
    "    n_estimators=50,           # Number of boosting iterations\n",
    "    sampling_strategy='auto',  # Balance to minority class size\n",
    "    replacement=False,         # Sample without replacement\n",
    "    random_state=42\n",
    ")\n",
    "rus_boost.fit(X_train, y_train)\n",
    "y_pred_rus_boost = rus_boost.predict(X_test)\n",
    "ensemble_results['RUSBoost'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_rus_boost),\n",
    "    'precision': precision_score(y_test, y_pred_rus_boost, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_rus_boost),\n",
    "    'f1': f1_score(y_test, y_pred_rus_boost),\n",
    "    'cm': confusion_matrix(y_test, y_pred_rus_boost)\n",
    "}\n",
    "print(f\"Accuracy:  {ensemble_results['RUSBoost']['accuracy']:.4f}\")\n",
    "print(f\"Precision: {ensemble_results['RUSBoost']['precision']:.4f}\")\n",
    "print(f\"Recall:    {ensemble_results['RUSBoost']['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {ensemble_results['RUSBoost']['f1']:.4f}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d2537",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 3\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d335776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Comparison: All Ensemble Methods\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Comparison: Ensemble Methods for Imbalanced Data\")\n",
    "print(\"=\" * 80)\n",
    "comparison_ensemble = pd.DataFrame({\n",
    "    'Method': list(ensemble_results.keys()),\n",
    "    'Accuracy': [ensemble_results[m]['accuracy'] for m in ensemble_results.keys()],\n",
    "    'Precision': [ensemble_results[m]['precision'] for m in ensemble_results.keys()],\n",
    "    'Recall': [ensemble_results[m]['recall'] for m in ensemble_results.keys()],\n",
    "    'F1 Score': [ensemble_results[m]['f1'] for m in ensemble_results.keys()]\n",
    "})\n",
    "print(comparison_ensemble.to_string(index=False))\n",
    "print()\n",
    "# Find best method\n",
    "best_idx = comparison_ensemble['F1 Score'].idxmax()\n",
    "best_method = comparison_ensemble.loc[best_idx, 'Method']\n",
    "best_f1_ensemble = comparison_ensemble.loc[best_idx, 'F1 Score']\n",
    "print(f\"\ud83c\udfc6 Best Ensemble Method: {best_method} (F1 = {best_f1_ensemble:.4f})\")\n",
    "print()\n",
    "print(\"Key Insights:\")\n",
    "print(\"  \u2022 BalancedRandomForest: Best for large datasets (fast, parallelizable)\")\n",
    "print(\"  \u2022 EasyEnsemble: Best for maximizing majority class info (uses all samples)\")\n",
    "print(\"  \u2022 RUSBoost: Best for sequential error correction (focuses on hard cases)\")\n",
    "print(\"  \u2022 All methods significantly outperform standard RandomForest on recall\")\n",
    "print()\n",
    "# ========================================\n",
    "# Test Extreme Imbalance (1:100 ratio)\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Extreme Imbalance Test: 1:100 Ratio (0.99% Defect Rate)\")\n",
    "print(\"=\" * 80)\n",
    "# Generate extremely imbalanced data\n",
    "np.random.seed(42)\n",
    "n_samples_extreme = 10000\n",
    "defect_rate_extreme = 0.01  # 1% defect rate (1:100 ratio)\n",
    "# Features\n",
    "X_extreme = np.random.randn(n_samples_extreme, 6)\n",
    "# Labels (1% defects)\n",
    "n_defects_extreme = int(n_samples_extreme * defect_rate_extreme)\n",
    "y_extreme = np.zeros(n_samples_extreme, dtype=int)\n",
    "y_extreme[:n_defects_extreme] = 1\n",
    "# Shuffle\n",
    "shuffle_idx = np.random.permutation(n_samples_extreme)\n",
    "X_extreme = X_extreme[shuffle_idx]\n",
    "y_extreme = y_extreme[shuffle_idx]\n",
    "print(f\"Extreme imbalance dataset:\")\n",
    "print(f\"  Total samples: {n_samples_extreme}\")\n",
    "print(f\"  Pass (class 0): {np.sum(y_extreme==0)} ({100*np.mean(y_extreme==0):.2f}%)\")\n",
    "print(f\"  Defect (class 1): {np.sum(y_extreme==1)} ({100*np.mean(y_extreme==1):.2f}%)\")\n",
    "print(f\"  Imbalance ratio: 1:{int(np.sum(y_extreme==0)/np.sum(y_extreme==1))}\")\n",
    "print()\n",
    "# Split\n",
    "X_train_extreme, X_test_extreme, y_train_extreme, y_test_extreme = train_test_split(\n",
    "    X_extreme, y_extreme, test_size=0.2, random_state=42, stratify=y_extreme\n",
    ")\n",
    "# Test baseline vs BalancedRandomForest\n",
    "print(\"Baseline RandomForest:\")\n",
    "rf_extreme_baseline = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_extreme_baseline.fit(X_train_extreme, y_train_extreme)\n",
    "y_pred_extreme_baseline = rf_extreme_baseline.predict(X_test_extreme)\n",
    "print(f\"  Recall: {recall_score(y_test_extreme, y_pred_extreme_baseline):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test_extreme, y_pred_extreme_baseline, zero_division=0):.4f}\")\n",
    "print(f\"  F1 Score: {f1_score(y_test_extreme, y_pred_extreme_baseline):.4f}\")\n",
    "print()\n",
    "print(\"BalancedRandomForest:\")\n",
    "balanced_rf_extreme = BalancedRandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "balanced_rf_extreme.fit(X_train_extreme, y_train_extreme)\n",
    "y_pred_extreme_balanced = balanced_rf_extreme.predict(X_test_extreme)\n",
    "print(f\"  Recall: {recall_score(y_test_extreme, y_pred_extreme_balanced):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test_extreme, y_pred_extreme_balanced, zero_division=0):.4f}\")\n",
    "print(f\"  F1 Score: {f1_score(y_test_extreme, y_pred_extreme_balanced):.4f}\")\n",
    "print()\n",
    "recall_improvement = recall_score(y_test_extreme, y_pred_extreme_balanced) - recall_score(y_test_extreme, y_pred_extreme_baseline)\n",
    "print(f\"\u2705 Recall improvement: {100*recall_improvement:.1f} percentage points\")\n",
    "print(f\"   (BalancedRandomForest handles extreme imbalance much better)\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d91b3",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 4\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Visualization: Ensemble Performance\n",
    "# ========================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# Bar chart: Recall comparison\n",
    "methods = comparison_ensemble['Method'].tolist()\n",
    "recalls = comparison_ensemble['Recall'].tolist()\n",
    "f1_scores_ensemble = comparison_ensemble['F1 Score'].tolist()\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "bars1 = axes[0].bar(x - width/2, recalls, width, label='Recall', \n",
    "                     color='#3498db', edgecolor='black', linewidth=1.5)\n",
    "bars2 = axes[0].bar(x + width/2, f1_scores_ensemble, width, label='F1 Score', \n",
    "                     color='#e74c3c', edgecolor='black', linewidth=1.5)\n",
    "# Highlight best method\n",
    "axes[0].bar(best_idx - width/2, recalls[best_idx], width, \n",
    "            color='gold', edgecolor='black', linewidth=2, alpha=0.7)\n",
    "axes[0].bar(best_idx + width/2, f1_scores_ensemble[best_idx], width, \n",
    "            color='gold', edgecolor='black', linewidth=2, alpha=0.7)\n",
    "axes[0].set_xlabel('Method', fontsize=10, weight='bold')\n",
    "axes[0].set_ylabel('Score', fontsize=10, weight='bold')\n",
    "axes[0].set_title('Ensemble Methods: Recall & F1 Comparison', fontsize=12, weight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(methods, rotation=20, ha='right', fontsize=9)\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "axes[0].set_ylim([0, 1.05])\n",
    "# Confusion matrices for best method\n",
    "cm_best = ensemble_results[best_method]['cm']\n",
    "sns.heatmap(cm_best, annot=True, fmt='d', cmap='RdYlGn', ax=axes[1],\n",
    "            xticklabels=['Pass', 'Defect'], yticklabels=['Pass', 'Defect'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "axes[1].set_title(f'Best Method: {best_method}\\nRecall: {ensemble_results[best_method][\"recall\"]:.2%}', \n",
    "                  fontsize=12, weight='bold')\n",
    "axes[1].set_xlabel('Predicted', fontsize=10)\n",
    "axes[1].set_ylabel('Actual', fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\u2705 Visualization: Ensemble methods performance\")\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"Semiconductor Application: Ensemble Methods\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\ud83c\udfed Production Recommendations:\")\n",
    "print(\"  \u2022 Wafer-level testing (1-5% defects): BalancedRandomForest\")\n",
    "print(\"  \u2022 Die-level testing (0.1-1% defects): EasyEnsemble or RUSBoost\")\n",
    "print(\"  \u2022 Field reliability (<0.1% defects): EasyEnsemble + SMOTE-Tomek\")\n",
    "print()\n",
    "print(\"\ud83d\udca1 Key Advantages:\")\n",
    "print(\"  \u2022 Handles extreme imbalance (1:100, 1:1000+)\")\n",
    "print(\"  \u2022 Robust to distribution shift (new failure modes)\")\n",
    "print(\"  \u2022 Parallelizable (BalancedRandomForest)\")\n",
    "print(\"  \u2022 High recall (detect 90-95% of defects)\")\n",
    "print()\n",
    "print(\"\ud83d\udcb0 Business Impact:\")\n",
    "print(f\"  \u2022 Baseline: {cm_baseline[1,0]} missed defects, {ensemble_results['RandomForest (Baseline)']['recall']:.1%} recall\")\n",
    "print(f\"  \u2022 {best_method}: {cm_best[1,0]} missed defects, {ensemble_results[best_method]['recall']:.1%} recall\")\n",
    "print(f\"  \u2022 Improvement: {cm_baseline[1,0] - cm_best[1,0]} fewer missed defects\")\n",
    "print(f\"  \u2022 Cost savings: ${(cm_baseline[1,0] - cm_best[1,0]) * 1e6 * 365 * 1000 / len(X_test) / 1e6:.1f}M/year\")\n",
    "print(\"=\" * 80)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2ad29",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation\n",
    "\n",
    "**Purpose:** Core implementation with detailed code\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Production Pipeline: SMOTE + Preprocessing + Classification\n",
    "# ========================================\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "print(\"=\" * 80)\n",
    "print(\"Production Pipeline: End-to-End Imbalanced Learning\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "# ========================================\n",
    "# Build Production Pipeline\n",
    "# ========================================\n",
    "print(\"Building Production Pipeline...\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Pipeline Steps:\")\n",
    "print(\"  1. SMOTE (oversample minority class)\")\n",
    "print(\"  2. StandardScaler (normalize features)\")\n",
    "print(\"  3. LogisticRegression (with class weights)\")\n",
    "print()\n",
    "# Create pipeline (use imblearn.pipeline.Pipeline, not sklearn.pipeline.Pipeline)\n",
    "production_pipeline = ImbPipeline([\n",
    "    ('smote', SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "])\n",
    "print(\"\u2705 Pipeline created\")\n",
    "print()\n",
    "# ========================================\n",
    "# Train Pipeline\n",
    "# ========================================\n",
    "print(\"Training Production Pipeline...\")\n",
    "print(\"-\" * 80)\n",
    "# Train on original imbalanced data (SMOTE applied internally)\n",
    "production_pipeline.fit(X_train, y_train)\n",
    "print(\"\u2705 Pipeline trained successfully\")\n",
    "print()\n",
    "# Predict\n",
    "y_pred_pipeline = production_pipeline.predict(X_test)\n",
    "y_proba_pipeline = production_pipeline.predict_proba(X_test)[:, 1]\n",
    "# Metrics\n",
    "acc_pipeline = accuracy_score(y_test, y_pred_pipeline)\n",
    "prec_pipeline = precision_score(y_test, y_pred_pipeline, zero_division=0)\n",
    "rec_pipeline = recall_score(y_test, y_pred_pipeline)\n",
    "f1_pipeline = f1_score(y_test, y_pred_pipeline)\n",
    "print(\"Pipeline Performance:\")\n",
    "print(f\"  Accuracy:  {acc_pipeline:.4f}\")\n",
    "print(f\"  Precision: {prec_pipeline:.4f}\")\n",
    "print(f\"  Recall:    {rec_pipeline:.4f}\")\n",
    "print(f\"  F1 Score:  {f1_pipeline:.4f}\")\n",
    "print()\n",
    "# ========================================\n",
    "# Cross-Validation (Correct Way)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e0338",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 2\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc8b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "print(\"Cross-Validation (5-fold, stratified)...\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\u26a0\ufe0f IMPORTANT: SMOTE applied INSIDE each fold (on training fold only, not validation)\")\n",
    "print()\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Cross-validate (SMOTE applied inside each fold automatically)\n",
    "cv_scores = cross_val_score(production_pipeline, X_train, y_train, \n",
    "                            cv=cv, scoring='f1', n_jobs=-1)\n",
    "print(f\"Cross-Validation F1 Scores: {cv_scores}\")\n",
    "print(f\"  Mean: {cv_scores.mean():.4f}\")\n",
    "print(f\"  Std:  {cv_scores.std():.4f}\")\n",
    "print()\n",
    "print(\"\u2705 Correct pipeline order prevents data leakage\")\n",
    "print(\"   (SMOTE on training fold \u2192 validate on original imbalanced validation fold)\")\n",
    "print()\n",
    "# ========================================\n",
    "# Serialize Pipeline for Deployment\n",
    "# ========================================\n",
    "print(\"Serializing Pipeline for Production Deployment...\")\n",
    "print(\"-\" * 80)\n",
    "# Save pipeline\n",
    "pipeline_filename = 'imbalanced_defect_pipeline.pkl'\n",
    "joblib.dump(production_pipeline, pipeline_filename)\n",
    "print(f\"\u2705 Pipeline saved to: {pipeline_filename}\")\n",
    "print(f\"   File size: {os.path.getsize(pipeline_filename) / 1024:.1f} KB\")\n",
    "print()\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'model_type': 'imbalanced_learning_pipeline',\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'training_samples': len(X_train),\n",
    "    'defect_rate': float(np.mean(y_train)),\n",
    "    'imbalance_ratio': f\"1:{int(np.sum(y_train==0)/np.sum(y_train==1))}\",\n",
    "    'smote_k_neighbors': 5,\n",
    "    'performance': {\n",
    "        'accuracy': float(acc_pipeline),\n",
    "        'precision': float(prec_pipeline),\n",
    "        'recall': float(rec_pipeline),\n",
    "        'f1_score': float(f1_pipeline)\n",
    "    },\n",
    "    'cv_f1_mean': float(cv_scores.mean()),\n",
    "    'cv_f1_std': float(cv_scores.std()),\n",
    "    'feature_names': ['Vdd_min', 'Vdd_max', 'Idd_active', 'Idd_standby', 'freq_max', 'temp'],\n",
    "    'class_names': ['Pass', 'Defect']\n",
    "}\n",
    "metadata_filename = 'imbalanced_defect_pipeline_metadata.json'\n",
    "with open(metadata_filename, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"\u2705 Metadata saved to: {metadata_filename}\")\n",
    "print()\n",
    "# ========================================\n",
    "# Load and Test Pipeline (Simulate Deployment)\n",
    "# ========================================\n",
    "print(\"Loading Pipeline for Production Inference...\")\n",
    "print(\"-\" * 80)\n",
    "# Load pipeline\n",
    "loaded_pipeline = joblib.load(pipeline_filename)\n",
    "print(\"\u2705 Pipeline loaded successfully\")\n",
    "print()\n",
    "# Load metadata\n",
    "with open(metadata_filename, 'r') as f:\n",
    "    loaded_metadata = json.load(f)\n",
    "print(\"Pipeline Metadata:\")\n",
    "print(f\"  Model Type: {loaded_metadata['model_type']}\")\n",
    "print(f\"  Training Date: {loaded_metadata['training_date']}\")\n",
    "print(f\"  Training Samples: {loaded_metadata['training_samples']}\")\n",
    "print(f\"  Defect Rate: {loaded_metadata['defect_rate']:.2%}\")\n",
    "print(f\"  Imbalance Ratio: {loaded_metadata['imbalance_ratio']}\")\n",
    "print(f\"  F1 Score (CV): {loaded_metadata['cv_f1_mean']:.4f} \u00b1 {loaded_metadata['cv_f1_std']:.4f}\")\n",
    "print()\n",
    "# Test inference on new sample\n",
    "print(\"Testing Inference on New Samples...\")\n",
    "print(\"-\" * 80)\n",
    "# Simulate new device test data (5 devices)\n",
    "new_devices = np.array([\n",
    "    [0.95, 1.18, 55, 1.2, 1950, 87],  # Likely defect (low Vdd_min, high Idd)\n",
    "    [1.02, 1.22, 48, 0.9, 2050, 83],  # Likely pass (normal parameters)\n",
    "    [0.98, 1.20, 52, 1.0, 2000, 85],  # Borderline\n",
    "    [1.05, 1.25, 45, 0.8, 2100, 80],  # Likely pass\n",
    "    [0.92, 1.15, 60, 1.5, 1900, 90]   # Likely defect (extreme parameters)\n",
    "])\n",
    "# Predict\n",
    "predictions = loaded_pipeline.predict(new_devices)\n",
    "probabilities = loaded_pipeline.predict_proba(new_devices)\n",
    "print(f\"{'Device':<10} {'Prediction':<12} {'Probability (Defect)':<25} {'Status':<10}\")\n",
    "print(\"-\" * 70)\n",
    "for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "    status = 'DEFECT' if pred == 1 else 'PASS'\n",
    "    prob_defect = prob[1]\n",
    "    print(f\"Device {i+1:<3} {status:<12} {prob_defect:.4f} ({prob_defect*100:.1f}%)          {'\u26a0\ufe0f' if status == 'DEFECT' else '\u2705'}\")\n",
    "print()\n",
    "print(\"\u2705 Real-time inference successful\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd5199",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd Implementation Part 3\n",
    "\n",
    "**Purpose:** Continue implementation\n",
    "\n",
    "**Key implementation details below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Production Monitoring Simulation\n",
    "# ========================================\n",
    "print(\"Production Monitoring: Detecting Distribution Drift...\")\n",
    "print(\"-\" * 80)\n",
    "# Simulate production data with drift (defect rate increases from 2% to 5%)\n",
    "np.random.seed(123)\n",
    "n_production = 1000\n",
    "defect_rate_production = 0.05  # Drift from 2% to 5%\n",
    "X_production = np.random.randn(n_production, 6)\n",
    "n_defects_prod = int(n_production * defect_rate_production)\n",
    "y_production = np.zeros(n_production, dtype=int)\n",
    "y_production[:n_defects_prod] = 1\n",
    "# Shuffle\n",
    "shuffle_idx = np.random.permutation(n_production)\n",
    "X_production = X_production[shuffle_idx]\n",
    "y_production = y_production[shuffle_idx]\n",
    "# Predict on production data\n",
    "y_pred_production = loaded_pipeline.predict(X_production)\n",
    "# Metrics on production data\n",
    "rec_production = recall_score(y_production, y_pred_production)\n",
    "prec_production = precision_score(y_production, y_pred_production, zero_division=0)\n",
    "f1_production = f1_score(y_production, y_pred_production)\n",
    "print(\"Training Data:\")\n",
    "print(f\"  Defect rate: {np.mean(y_train):.2%}\")\n",
    "print(f\"  Recall: {rec_pipeline:.4f}\")\n",
    "print(f\"  F1 Score: {f1_pipeline:.4f}\")\n",
    "print()\n",
    "print(\"Production Data (with drift):\")\n",
    "print(f\"  Defect rate: {np.mean(y_production):.2%} (\u2191 increased from 2% to 5%)\")\n",
    "print(f\"  Recall: {rec_production:.4f}\")\n",
    "print(f\"  F1 Score: {f1_production:.4f}\")\n",
    "print()\n",
    "# Drift detection\n",
    "defect_rate_change = abs(np.mean(y_production) - loaded_metadata['defect_rate'])\n",
    "performance_degradation = loaded_metadata['performance']['f1_score'] - f1_production\n",
    "print(\"Drift Detection:\")\n",
    "if defect_rate_change > 0.01:  # 1% threshold\n",
    "    print(f\"  \u26a0\ufe0f ALERT: Class distribution drift detected!\")\n",
    "    print(f\"     Defect rate changed by {100*defect_rate_change:.1f} percentage points\")\n",
    "    print(f\"     Recommendation: Retrain model with recent production data\")\n",
    "else:\n",
    "    print(f\"  \u2705 No significant distribution drift\")\n",
    "if performance_degradation > 0.05:  # 5% F1 drop threshold\n",
    "    print(f\"  \u26a0\ufe0f ALERT: Model performance degradation detected!\")\n",
    "    print(f\"     F1 score dropped by {performance_degradation:.4f}\")\n",
    "    print(f\"     Recommendation: Investigate and retrain model\")\n",
    "else:\n",
    "    print(f\"  \u2705 Model performance stable\")\n",
    "print()\n",
    "# ========================================\n",
    "# Production Checklist\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Production Deployment Checklist\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "checklist = [\n",
    "    (\"Pipeline Serialization\", \"\u2705\", \"Model saved with joblib\"),\n",
    "    (\"Metadata Tracking\", \"\u2705\", \"JSON metadata for version control\"),\n",
    "    (\"Cross-Validation\", \"\u2705\", \"5-fold CV, SMOTE inside folds\"),\n",
    "    (\"Inference Testing\", \"\u2705\", \"New samples tested successfully\"),\n",
    "    (\"Monitoring Setup\", \"\u2705\", \"Distribution drift detection\"),\n",
    "    (\"Performance Baseline\", \"\u2705\", f\"F1={f1_pipeline:.3f}, Recall={rec_pipeline:.3f}\"),\n",
    "    (\"API Endpoint\", \"\ud83d\udea7\", \"Deploy to Flask/FastAPI (next step)\"),\n",
    "    (\"Logging\", \"\ud83d\udea7\", \"Implement prediction logging (next step)\"),\n",
    "    (\"Alerting\", \"\ud83d\udea7\", \"Set up Slack/email alerts (next step)\"),\n",
    "    (\"A/B Testing\", \"\ud83d\udea7\", \"Compare with baseline model (next step)\")\n",
    "]\n",
    "print(f\"{'Task':<30} {'Status':<10} {'Details':<40}\")\n",
    "print(\"-\" * 80)\n",
    "for task, status, details in checklist:\n",
    "    print(f\"{task:<30} {status:<10} {details:<40}\")\n",
    "print()\n",
    "print(\"\ud83c\udfed Semiconductor Production Recommendations:\")\n",
    "print(\"  \u2022 Deploy pipeline to REST API (Flask/FastAPI)\")\n",
    "print(\"  \u2022 Batch scoring: Process overnight test data (1M devices/night)\")\n",
    "print(\"  \u2022 Real-time scoring: Inline wafer test (<50ms latency)\")\n",
    "print(\"  \u2022 Monitor defect rate weekly, retrain if >10% drift\")\n",
    "print(\"  \u2022 Log all predictions for audit trail (FDA/ISO compliance)\")\n",
    "print(\"  \u2022 A/B test new models before full deployment\")\n",
    "print()\n",
    "print(\"\ud83d\udcb0 Production Impact:\")\n",
    "print(f\"  \u2022 Baseline defect detection: {rec_baseline:.1%} recall\")\n",
    "print(f\"  \u2022 Production pipeline: {rec_pipeline:.1%} recall\")\n",
    "print(f\"  \u2022 Improvement: {100*(rec_pipeline - rec_baseline):.1f} percentage points\")\n",
    "print(f\"  \u2022 Annual savings: ${(cm_baseline[1,0] - cm_weighted[1,0]) * 1e6 * 365 * 1000 / len(X_test) / 1e6:.1f}M\")\n",
    "print(\"=\" * 80)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f08df95",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Real-World Projects: Imbalanced Data Handling\n",
    "\n",
    "Apply imbalanced learning techniques to production scenarios with clear business impact.\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfed **Semiconductor & Post-Silicon Validation Projects**\n",
    "\n",
    "#### **Project 1: Wafer-Level Defect Prediction System**\n",
    "**Objective:** Predict systematic wafer defects from parametric test data (1-5% defect rate)\n",
    "\n",
    "**Business Value:** Reduce field failures by 90%, saving $10M-$50M annually from recalls and warranty claims\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Features: Vdd_min/max, Idd_active/standby, frequency, power, temperature (6-20 parametric tests)\n",
    "- Spatial: wafer_id, die_x, die_y (for wafer map clustering)\n",
    "- Temporal: lot_number, test_date, equipment_id (for drift detection)\n",
    "- Labels: pass/fail, bin_category (electrical, functional, reliability)\n",
    "- Imbalance: 1-5% defect rate typical for systematic issues\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# 1. Exploratory Analysis\n",
    "#    - Visualize wafer maps (spatial patterns)\n",
    "#    - Check defect rate by lot/equipment (temporal patterns)\n",
    "#    - Analyze parametric distributions (normal vs defect)\n",
    "\n",
    "# 2. Feature Engineering\n",
    "#    - Parametric deltas: Vdd_max - Vdd_min\n",
    "#    - Spatial features: distance from wafer center\n",
    "#    - Interaction terms: Vdd * frequency (power proxy)\n",
    "\n",
    "# 3. Model Selection\n",
    "#    - Try: SMOTE + Logistic Regression (baseline)\n",
    "#    - Try: BalancedRandomForest (handles spatial patterns)\n",
    "#    - Try: Custom class weights (FN cost = $10M, FP cost = $500)\n",
    "#    - Optimize threshold for F-beta (\u03b2=2-5, prioritize recall)\n",
    "\n",
    "# 4. Validation\n",
    "#    - Stratified K-Fold (preserve defect rate)\n",
    "#    - Wafer-level split (prevent data leakage)\n",
    "#    - Temporal validation (train on old lots, test on new lots)\n",
    "\n",
    "# 5. Production Deployment\n",
    "#    - Real-time API for inline test (< 50ms latency)\n",
    "#    - Batch scoring for overnight data (1M devices)\n",
    "#    - Monitor defect rate drift (retrain if > 10% change)\n",
    "```\n",
    "\n",
    "**Success Metrics:**\n",
    "- Recall > 95% (detect 95% of defects)\n",
    "- Precision > 80% (minimize false alarms)\n",
    "- F1 > 0.87\n",
    "- Cost savings > $10M/year\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 2: Die-Level Reliability Prediction (Extreme Imbalance)**\n",
    "**Objective:** Predict early-life failures from burn-in test data (0.1-0.5% failure rate, 1:200-1:1000 imbalance)\n",
    "\n",
    "**Business Value:** Improve reliability screening, reduce field returns by 80%, save $20M-$100M annually\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Features: Burn-in voltage, current, temperature stress, duration\n",
    "- Electrical: Vdd_max shift, Idd_max shift, frequency degradation\n",
    "- Spatial: die location, wafer lot, fab location\n",
    "- Labels: pass/fail after 168 hours, early-life failure flag\n",
    "- Imbalance: 0.1-0.5% failure rate (extreme imbalance)\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# 1. Handle Extreme Imbalance\n",
    "#    - Use EasyEnsemble or BalancedRandomForest\n",
    "#    - Try ADASYN (adaptive to difficult regions)\n",
    "#    - Custom class weights (FN:FP = 10000:1 or higher)\n",
    "\n",
    "# 2. Time-Series Features\n",
    "#    - Voltage shift over time (\u0394Vdd per hour)\n",
    "#    - Current ramp rate (\u0394Idd per hour)\n",
    "#    - Temperature excursion frequency\n",
    "\n",
    "# 3. Anomaly Detection Hybrid\n",
    "#    - Combine supervised (SMOTE) + unsupervised (Isolation Forest)\n",
    "#    - Flag outliers in parametric space\n",
    "#    - Ensemble voting (multiple models)\n",
    "\n",
    "# 4. Production Pipeline\n",
    "#    - Pipeline: ADASYN \u2192 StandardScaler \u2192 EasyEnsemble\n",
    "#    - Threshold tuning for 99.5%+ recall (critical safety)\n",
    "#    - Monitor for distribution shift (new failure modes)\n",
    "```\n",
    "\n",
    "**Success Metrics:**\n",
    "- Recall > 99% (detect 99% of early failures)\n",
    "- Precision > 50% (acceptable for extreme imbalance)\n",
    "- Cost per miss: $100K-$1M (field failure cost)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 3: Test-Time Optimization (Adaptive Sampling)**\n",
    "**Objective:** Reduce test time by 30% while maintaining 99%+ defect detection using adaptive test strategies\n",
    "\n",
    "**Business Value:** Save $5M-$20M annually from reduced test time ($50-$200 per device-hour)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Features: Sequential test results (test1, test2, ..., testN)\n",
    "- Test order: Critical tests first, optional tests later\n",
    "- Time: Cumulative test time per stage\n",
    "- Labels: Final pass/fail, early stop decision\n",
    "- Imbalance: 1-5% defect rate, but adaptive stopping changes distribution\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# 1. Sequential Decision Making\n",
    "#    - Train model after each test stage (cumulative features)\n",
    "#    - Predict defect probability after stage N\n",
    "#    - Early stop if P(defect) > 0.95 (high confidence)\n",
    "\n",
    "# 2. Cost-Sensitive Stopping\n",
    "#    - Stop cost: test_time_remaining * $50/hour\n",
    "#    - Miss cost: field_failure_cost * P(defect missed)\n",
    "#    - Optimal stopping rule: argmin(stop_cost + miss_cost)\n",
    "\n",
    "# 3. Imbalanced Learning per Stage\n",
    "#    - Stage 1-3: High imbalance (few defects caught)\n",
    "#    - Stage 4-6: Medium imbalance (most defects caught)\n",
    "#    - SMOTE or class weights per stage\n",
    "\n",
    "# 4. Production Deployment\n",
    "#    - Real-time inference at each test stage\n",
    "#    - Dynamic threshold adjustment (conservative early, aggressive late)\n",
    "#    - A/B test savings vs quality trade-off\n",
    "```\n",
    "\n",
    "**Success Metrics:**\n",
    "- Test time reduction: 30%\n",
    "- Defect escape rate: < 0.1% (maintain quality)\n",
    "- Cost savings: $5M-$20M/year\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 4: Spatial Defect Clustering for Yield Analysis**\n",
    "**Objective:** Identify spatial defect patterns on wafers to trace root causes (equipment, contamination, process drift)\n",
    "\n",
    "**Business Value:** Improve yield by 2-5%, worth $50M-$200M annually for high-volume manufacturing\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Features: Parametric test results per die\n",
    "- Spatial: die_x, die_y, wafer_id, lot_id\n",
    "- Labels: pass/fail, defect_type (electrical, functional, physical)\n",
    "- Imbalance: 1-5% defect rate, but clustered spatially\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# 1. Spatial Feature Engineering\n",
    "#    - Distance from wafer center: sqrt(x\u00b2 + y\u00b2)\n",
    "#    - Quadrant: top-left, top-right, bottom-left, bottom-right\n",
    "#    - Edge flag: distance from edge < 5mm\n",
    "#    - Neighbor defect count (5x5 die window)\n",
    "\n",
    "# 2. Clustering + Classification Hybrid\n",
    "#    - First: Cluster defects (DBSCAN, spatial coordinates)\n",
    "#    - Second: Classify each cluster's root cause\n",
    "#    - Use cluster labels as features for imbalanced classification\n",
    "\n",
    "# 3. Imbalanced Learning with Spatial Context\n",
    "#    - BalancedRandomForest (handles non-linear spatial patterns)\n",
    "#    - SMOTE with spatial neighbors (k-NN in spatial + parametric space)\n",
    "\n",
    "# 4. Visualization & Root Cause\n",
    "#    - Wafer maps colored by defect probability\n",
    "#    - Identify systematic patterns (edge defects, quadrant bias)\n",
    "#    - Trace to equipment/process issues\n",
    "```\n",
    "\n",
    "**Success Metrics:**\n",
    "- Defect localization accuracy: > 90%\n",
    "- Root cause identification: > 80%\n",
    "- Yield improvement: 2-5%\n",
    "- Annual value: $50M-$200M\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\ude80 **General AI/ML Projects**\n",
    "\n",
    "#### **Project 5: Credit Card Fraud Detection (Real-Time Scoring)**\n",
    "**Objective:** Detect fraudulent transactions in real-time (0.1-0.5% fraud rate, extreme imbalance)\n",
    "\n",
    "**Business Value:** Prevent $30B+ annual fraud losses, improve customer trust, reduce false positives by 50%\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Features: Transaction amount, merchant category, time, location, device fingerprint\n",
    "- User history: Avg transaction size, frequency, typical merchants\n",
    "- Anomaly features: Deviation from user baseline\n",
    "- Labels: Fraud/legitimate (0.1-0.5% fraud rate)\n",
    "- Imbalance: 1:200 to 1:1000 ratio\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# 1. Feature Engineering\n",
    "#    - Time features: Hour of day, day of week, holiday flag\n",
    "#    - User features: Transaction deviation from 30-day avg\n",
    "#    - Velocity features: # transactions in last hour\n",
    "#    - Geo features: Distance from last transaction\n",
    "\n",
    "# 2. Extreme Imbalance Handling\n",
    "#    - EasyEnsemble (handles 1:1000 ratio)\n",
    "#    - SMOTE-Tomek (clean noisy samples)\n",
    "#    - Custom class weights (fraud_miss_cost = $500, false_alarm = $10)\n",
    "\n",
    "# 3. Real-Time Constraints\n",
    "#    - Latency < 100ms (payment authorization)\n",
    "#    - Use lightweight model (Logistic Regression, LightGBM)\n",
    "#    - Threshold tuning for 99%+ recall (minimize fraud escapes)\n",
    "\n",
    "# 4. Production Monitoring\n",
    "#    - Track fraud rate drift (seasonal patterns)\n",
    "#    - Monitor false positive rate (customer friction)\n",
    "#    - A/B test new models on 1% traffic\n",
    "```\n",
    "\n",
    "**Success Metrics:**\n",
    "- Recall > 99% (detect 99% of fraud)\n",
    "- Precision > 80% (minimize false alarms)\n",
    "- Latency < 100ms\n",
    "- Cost savings: $100M+/year\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 6: Medical Diagnosis (Rare Disease Detection)**\n",
    "**Objective:** Detect rare diseases from medical imaging/lab results (0.1-2% disease prevalence)\n",
    "\n",
    "**Business Value:** Save lives, improve early detection by 50%, reduce diagnostic errors by 40%\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Features: Lab test results, vital signs, medical imaging features\n",
    "- Demographics: Age, gender, family history, risk factors\n",
    "- Clinical: Symptoms, medical history, medications\n",
    "- Labels: Disease present/absent (0.1-2% prevalence)\n",
    "- Imbalance: 1:50 to 1:1000 ratio\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# 1. Handle Extreme Imbalance\n",
    "#    - SMOTE for minority augmentation\n",
    "#    - Custom class weights (FN_cost >> FP_cost for life-critical)\n",
    "#    - Threshold optimization for 99.5%+ recall (patient safety)\n",
    "\n",
    "# 2. Feature Engineering\n",
    "#    - Normalize by age/gender baselines\n",
    "#    - Temporal trends (lab results over time)\n",
    "#    - Risk score aggregation\n",
    "\n",
    "# 3. Ensemble Approach\n",
    "#    - BalancedRandomForest (robust, interpretable)\n",
    "#    - EasyEnsemble for extreme imbalance\n",
    "#    - Combine with expert rules (clinical guidelines)\n",
    "\n",
    "# 4. Regulatory Compliance\n",
    "#    - Explainable predictions (SHAP, feature importance)\n",
    "#    - Audit trail for all predictions\n",
    "#    - FDA 510(k) validation requirements\n",
    "```\n",
    "\n",
    "**Success Metrics:**\n",
    "- Recall > 99.5% (critical for patient safety)\n",
    "- Precision > 70% (minimize unnecessary follow-ups)\n",
    "- AUC-PR > 0.85\n",
    "- Lives saved: 1000+/year\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 7: Customer Churn Prediction (Subscription Business)**\n",
    "**Objective:** Predict customer churn 30 days in advance (5-10% monthly churn rate)\n",
    "\n",
    "**Business Value:** Reduce churn by 20%, worth $10M-$50M annually in retained revenue\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Features: Usage frequency, session duration, feature adoption\n",
    "- Engagement: Last login, days since last activity, support tickets\n",
    "- Demographics: Age, plan type, tenure, payment history\n",
    "- Labels: Churned within 30 days (5-10% churn rate)\n",
    "- Imbalance: 1:10 to 1:20 ratio\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# 1. Feature Engineering\n",
    "#    - Engagement trends: Usage drop over last 30 days\n",
    "#    - Activity decay: Days since last login\n",
    "#    - Support indicators: # tickets, resolution time\n",
    "\n",
    "# 2. Imbalanced Learning\n",
    "#    - SMOTE or ADASYN (moderate imbalance)\n",
    "#    - Class weights (churn_cost = $500 LTV, retention_cost = $50)\n",
    "#    - Threshold tuning for optimal ROI\n",
    "\n",
    "# 3. Proactive Intervention\n",
    "#    - Predict 30 days ahead (time for retention campaign)\n",
    "#    - Prioritize high-value customers (LTV > $1000)\n",
    "#    - Personalized retention offers\n",
    "\n",
    "# 4. A/B Testing\n",
    "#    - Test retention campaigns on high-risk segment\n",
    "#    - Measure churn reduction vs control group\n",
    "#    - Optimize campaign cost vs retention benefit\n",
    "```\n",
    "\n",
    "**Success Metrics:**\n",
    "- Recall > 80% (identify 80% of churners)\n",
    "- Precision > 60% (efficient retention spend)\n",
    "- Churn reduction: 20%\n",
    "- Revenue saved: $10M-$50M/year\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 8: Anomaly Detection in Manufacturing (Predictive Maintenance)**\n",
    "**Objective:** Predict equipment failures before they occur (0.5-2% failure rate)\n",
    "\n",
    "**Business Value:** Reduce unplanned downtime by 50%, save $5M-$20M annually from avoided production losses\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Features: Sensor data (temperature, vibration, pressure, current)\n",
    "- Time-series: Trends, moving averages, rate of change\n",
    "- Equipment: Age, maintenance history, usage hours\n",
    "- Labels: Failure within 24 hours (0.5-2% failure rate)\n",
    "- Imbalance: 1:50 to 1:200 ratio\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# 1. Time-Series Feature Engineering\n",
    "#    - Rolling statistics: Mean, std, min, max over 1-hour window\n",
    "#    - Trend features: Linear regression slope over last 24 hours\n",
    "#    - Anomaly indicators: Values > 3 std from baseline\n",
    "\n",
    "# 2. Imbalanced Learning\n",
    "#    - SMOTE for minority augmentation\n",
    "#    - BalancedRandomForest (handles non-linear sensor patterns)\n",
    "#    - Custom weights (downtime_cost = $100K/hour, maintenance_cost = $5K)\n",
    "\n",
    "# 3. Real-Time Monitoring\n",
    "#    - Stream processing (Kafka, Spark Streaming)\n",
    "#    - Real-time scoring (< 1 second latency)\n",
    "#    - Alert operators 24 hours before failure\n",
    "\n",
    "# 4. Continuous Learning\n",
    "#    - Retrain weekly with new failure data\n",
    "#    - Monitor sensor drift (calibration changes)\n",
    "#    - Update thresholds based on production schedule\n",
    "```\n",
    "\n",
    "**Success Metrics:**\n",
    "- Recall > 90% (predict 90% of failures)\n",
    "- Precision > 70% (minimize false alarms)\n",
    "- Downtime reduction: 50%\n",
    "- Cost savings: $5M-$20M/year\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udf93 **Project Selection Guide**\n",
    "\n",
    "**For Beginners:**\n",
    "- Start with Project 7 (Customer Churn) - moderate imbalance, clear business value\n",
    "- Then try Project 5 (Fraud Detection) - more extreme imbalance\n",
    "\n",
    "**For Intermediate:**\n",
    "- Try Project 1 (Wafer Defect) - spatial patterns, real-world complexity\n",
    "- Or Project 8 (Predictive Maintenance) - time-series features\n",
    "\n",
    "**For Advanced:**\n",
    "- Tackle Project 2 (Die Reliability) - extreme imbalance, multi-modal approach\n",
    "- Or Project 3 (Test Optimization) - sequential decision making, adaptive systems\n",
    "\n",
    "**For Maximum Impact:**\n",
    "- Project 4 (Spatial Clustering) - highest ROI ($50M-$200M annually)\n",
    "- Project 6 (Medical Diagnosis) - highest social impact (saves lives)\n",
    "\n",
    "---\n",
    "\n",
    "**Common Pitfalls to Avoid:**\n",
    "1. \u274c Applying SMOTE before train-test split (data leakage!)\n",
    "2. \u274c Using accuracy as primary metric (misleading for imbalanced data)\n",
    "3. \u274c Ignoring business costs (optimize for F1, but real goal is $ savings)\n",
    "4. \u274c Not monitoring production drift (models degrade over time)\n",
    "5. \u274c Oversampling to 50:50 (often unnecessary, 70:30 or 80:20 sufficient)\n",
    "\n",
    "**Best Practices:**\n",
    "1. \u2705 Start with class weights (fast, effective baseline)\n",
    "2. \u2705 Try SMOTE variants if resampling needed\n",
    "3. \u2705 Use ensemble methods for extreme imbalance (1:100+)\n",
    "4. \u2705 Always optimize threshold for business objective\n",
    "5. \u2705 Monitor and retrain regularly (quarterly or when drift > 10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e4e03",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Key Takeaways: Imbalanced Data Handling\n",
    "\n",
    "### **Core Principles**\n",
    "\n",
    "#### **1. When to Use Each Technique**\n",
    "\n",
    "| **Scenario** | **Recommended Approach** | **Why** |\n",
    "|-------------|-------------------------|---------|\n",
    "| **Moderate imbalance (1:10 to 1:50)** | Class weights or SMOTE | Fast, effective, no data augmentation complexity |\n",
    "| **Extreme imbalance (1:100+)** | BalancedRandomForest or EasyEnsemble | Handles severe imbalance, robust to noise |\n",
    "| **Large datasets (1M+ samples)** | Class weights or undersampling | Fast training, no memory overhead |\n",
    "| **Small datasets (<10K samples)** | SMOTE or ADASYN | Generates synthetic data to expand minority class |\n",
    "| **High cost asymmetry (FN >> FP)** | Custom class weights or threshold tuning | Aligns model with business objectives |\n",
    "| **Real-time inference (<100ms)** | Class weights + lightweight model | No resampling overhead, fast prediction |\n",
    "| **Non-uniform minority distribution** | ADASYN or Borderline-SMOTE | Adapts to local difficulty, focuses on boundary |\n",
    "| **Noisy data** | SMOTE-Tomek or SMOTE-ENN | Cleans overlapping regions after oversampling |\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Limitations & Solutions**\n",
    "\n",
    "| **Limitation** | **Impact** | **Solution** |\n",
    "|---------------|-----------|--------------|\n",
    "| **SMOTE overfitting** | Creates samples in overlapping regions \u2192 high variance | Use Borderline-SMOTE or SMOTE-Tomek (cleaning) |\n",
    "| **Undersampling information loss** | Discards majority samples \u2192 underfitting | Use ensemble methods (EasyEnsemble) to utilize all data |\n",
    "| **Class weights convergence issues** | Extreme weights (10000:1) \u2192 training instability | Cap weights at 100:1, use threshold tuning for rest |\n",
    "| **Pipeline data leakage** | SMOTE before split \u2192 inflated validation metrics | Use imblearn.pipeline, SMOTE inside CV folds |\n",
    "| **Distribution shift** | Production data differs from training \u2192 model degradation | Monitor defect rate, retrain if drift > 10% |\n",
    "| **Threshold sensitivity** | Default 0.5 suboptimal for imbalanced data | Always optimize threshold on validation set |\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Choosing Metrics**\n",
    "\n",
    "**Avoid:**\n",
    "- \u274c **Accuracy** (misleading for imbalanced data, e.g., 99% accuracy with 0% recall)\n",
    "- \u274c **ROC-AUC** (ignores class imbalance, dominated by majority class)\n",
    "\n",
    "**Use:**\n",
    "- \u2705 **Recall** (critical when FN cost >> FP cost, e.g., defect detection, fraud, medical)\n",
    "- \u2705 **Precision** (important when FP cost matters, e.g., spam filtering, marketing)\n",
    "- \u2705 **F1-Score** (harmonic mean, balances precision/recall)\n",
    "- \u2705 **F-beta** (\u03b2 > 1: prioritize recall, \u03b2 < 1: prioritize precision)\n",
    "- \u2705 **PR-AUC** (Precision-Recall AUC, better than ROC-AUC for imbalanced data)\n",
    "- \u2705 **G-Mean** (geometric mean of recalls, balances both classes)\n",
    "- \u2705 **Business Cost** (true objective: minimize $ losses, not just technical metrics)\n",
    "\n",
    "**Semiconductor Example:**\n",
    "```\n",
    "FN cost = $10M (field failure)\n",
    "FP cost = $500 (unnecessary rework)\n",
    "\u2192 Optimize for recall (99%+), accept precision 70-80%\n",
    "\u2192 Use F-beta with \u03b2=2-5 (heavily weight recall)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Common Pitfalls**\n",
    "\n",
    "1. **Data Leakage:**\n",
    "   ```python\n",
    "   # \u274c WRONG: SMOTE before split\n",
    "   X_smote, y_smote = SMOTE().fit_resample(X, y)\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote)\n",
    "   \n",
    "   # \u2705 CORRECT: SMOTE after split, only on training data\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "   X_train_smote, y_train_smote = SMOTE().fit_resample(X_train, y_train)\n",
    "   # Or use imblearn.pipeline.Pipeline (handles automatically)\n",
    "   ```\n",
    "\n",
    "2. **Over-Balancing:**\n",
    "   ```python\n",
    "   # \u274c WRONG: Balance to 50:50 (unnecessary, wastes computation)\n",
    "   SMOTE(sampling_strategy=1.0)  # Forces 1:1 ratio\n",
    "   \n",
    "   # \u2705 CORRECT: Partial balancing often sufficient\n",
    "   SMOTE(sampling_strategy=0.5)  # Balance to 1:2 ratio\n",
    "   # Or use class_weight='balanced' (no resampling needed)\n",
    "   ```\n",
    "\n",
    "3. **Ignoring Business Context:**\n",
    "   ```python\n",
    "   # \u274c WRONG: Optimize for F1 (equal weight to precision/recall)\n",
    "   threshold = argmax_f1(y_proba)\n",
    "   \n",
    "   # \u2705 CORRECT: Optimize for business cost\n",
    "   cost_fn = 10_000_000  # $10M per missed defect\n",
    "   cost_fp = 500          # $500 per false alarm\n",
    "   beta = sqrt(cost_fn / cost_fp)  # \u03b2 = 141\n",
    "   threshold = argmax_fbeta(y_proba, beta=min(beta, 5))\n",
    "   ```\n",
    "\n",
    "4. **Not Monitoring Production:**\n",
    "   ```python\n",
    "   # \u274c WRONG: Deploy model and forget\n",
    "   model.fit(X_train, y_train)\n",
    "   joblib.dump(model, 'model.pkl')\n",
    "   # ... 6 months later, model silently degrades\n",
    "   \n",
    "   # \u2705 CORRECT: Monitor and retrain\n",
    "   if abs(defect_rate_prod - defect_rate_train) > 0.01:\n",
    "       print(\"\u26a0\ufe0f Distribution drift detected, retraining...\")\n",
    "       model.fit(X_prod_recent, y_prod_recent)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Best Practices for Production**\n",
    "\n",
    "**Pre-Deployment:**\n",
    "1. \u2705 **Start simple:** Try class weights first (fastest baseline)\n",
    "2. \u2705 **Iterate:** If class weights insufficient, try SMOTE \u2192 BalancedRandomForest\n",
    "3. \u2705 **Validate properly:** Stratified K-Fold, temporal validation, wafer-level splits\n",
    "4. \u2705 **Optimize threshold:** Don't use default 0.5, optimize for business metric\n",
    "5. \u2705 **Document assumptions:** Defect rate, cost asymmetry, acceptable FP rate\n",
    "\n",
    "**During Deployment:**\n",
    "1. \u2705 **Use imblearn.pipeline:** Prevents data leakage, simplifies deployment\n",
    "2. \u2705 **Serialize pipeline:** Save entire pipeline (SMOTE + scaler + model) with joblib\n",
    "3. \u2705 **Version metadata:** Track training date, defect rate, hyperparameters, performance\n",
    "4. \u2705 **A/B test:** Compare new model with baseline on 1-10% traffic before full rollout\n",
    "5. \u2705 **Monitor latency:** Ensure real-time inference meets SLA (< 50ms for semiconductor)\n",
    "\n",
    "**Post-Deployment:**\n",
    "1. \u2705 **Track defect rate:** Weekly monitoring, alert if > 10% drift\n",
    "2. \u2705 **Track model performance:** Log predictions, compare with ground truth\n",
    "3. \u2705 **Retrain regularly:** Quarterly or when drift detected\n",
    "4. \u2705 **Update thresholds:** Business costs change (e.g., new warranty policies)\n",
    "5. \u2705 **Audit predictions:** Maintain logs for compliance (FDA, ISO, internal audit)\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Algorithm Selection Flowchart**\n",
    "\n",
    "```\n",
    "START\n",
    "  \u2502\n",
    "  \u251c\u2500 Imbalance ratio 1:10 to 1:50?\n",
    "  \u2502   \u251c\u2500 YES \u2192 Try class_weight='balanced' (fastest)\n",
    "  \u2502   \u2502         If insufficient \u2192 Try SMOTE\n",
    "  \u2502   \u2514\u2500 NO \u2192 Extreme imbalance (1:100+)\n",
    "  \u2502\n",
    "  \u251c\u2500 Extreme imbalance (1:100+)?\n",
    "  \u2502   \u251c\u2500 YES \u2192 Try BalancedRandomForest or EasyEnsemble\n",
    "  \u2502   \u2514\u2500 NO \u2192 Continue\n",
    "  \u2502\n",
    "  \u251c\u2500 Real-time inference (<100ms)?\n",
    "  \u2502   \u251c\u2500 YES \u2192 Use class weights (no resampling overhead)\n",
    "  \u2502   \u2502         Optimize threshold for business metric\n",
    "  \u2502   \u2514\u2500 NO \u2192 SMOTE or ensemble acceptable\n",
    "  \u2502\n",
    "  \u251c\u2500 High cost asymmetry (FN >> FP)?\n",
    "  \u2502   \u251c\u2500 YES \u2192 Custom class weights based on business costs\n",
    "  \u2502   \u2502         Then optimize threshold for F-beta (\u03b2=2-5)\n",
    "  \u2502   \u2514\u2500 NO \u2192 Balanced weights or SMOTE\n",
    "  \u2502\n",
    "  \u251c\u2500 Noisy data (overlapping classes)?\n",
    "  \u2502   \u251c\u2500 YES \u2192 SMOTE-Tomek or SMOTE-ENN (cleaning)\n",
    "  \u2502   \u2514\u2500 NO \u2192 Standard SMOTE or Borderline-SMOTE\n",
    "  \u2502\n",
    "  \u251c\u2500 Non-uniform minority distribution?\n",
    "  \u2502   \u251c\u2500 YES \u2192 ADASYN (adaptive sampling)\n",
    "  \u2502   \u2514\u2500 NO \u2192 Standard SMOTE\n",
    "  \u2502\n",
    "  \u2514\u2500 Final step: ALWAYS optimize threshold\n",
    "      \u2192 Use validation set to find optimal \u03b8 for business objective\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Semiconductor-Specific Recommendations**\n",
    "\n",
    "| **Test Stage** | **Defect Rate** | **Imbalance Ratio** | **Recommended Approach** |\n",
    "|---------------|----------------|-------------------|------------------------|\n",
    "| **Wafer Probe** | 1-5% | 1:20 to 1:100 | BalancedRandomForest + threshold tuning |\n",
    "| **Final Test** | 0.5-2% | 1:50 to 1:200 | SMOTE + Logistic Regression or EasyEnsemble |\n",
    "| **Burn-In** | 0.1-0.5% | 1:200 to 1:1000 | EasyEnsemble + ADASYN + custom weights |\n",
    "| **Field Returns** | 0.01-0.1% | 1:1000 to 1:10000 | Anomaly detection + EasyEnsemble hybrid |\n",
    "\n",
    "**Critical Considerations:**\n",
    "- **Real-time latency:** Wafer probe (<50ms), final test (<100ms), burn-in (batch OK)\n",
    "- **Cost asymmetry:** FN cost $10M-$100M (field failures), FP cost $100-$500 (yield loss)\n",
    "- **Spatial patterns:** Use die_x, die_y features, wafer-level cross-validation\n",
    "- **Temporal drift:** Retrain monthly or when equipment maintenance occurs\n",
    "- **Regulatory:** Maintain audit logs (automotive ISO 26262, medical FDA 510(k))\n",
    "\n",
    "---\n",
    "\n",
    "#### **8. Resource Recommendations**\n",
    "\n",
    "**Papers:**\n",
    "1. **SMOTE:** Chawla et al. (2002) - \"SMOTE: Synthetic Minority Over-sampling Technique\"\n",
    "2. **ADASYN:** He et al. (2008) - \"ADASYN: Adaptive Synthetic Sampling Approach\"\n",
    "3. **Cost-Sensitive Learning:** Elkan (2001) - \"The Foundations of Cost-Sensitive Learning\"\n",
    "4. **Imbalanced Learning Survey:** Haixiang et al. (2017) - \"Learning from class-imbalanced data\"\n",
    "\n",
    "**Libraries:**\n",
    "- **imbalanced-learn:** https://imbalanced-learn.org/ (SMOTE, ensemble methods)\n",
    "- **scikit-learn:** https://scikit-learn.org/ (class weights, pipelines)\n",
    "- **XGBoost/LightGBM:** scale_pos_weight parameter (built-in class weighting)\n",
    "\n",
    "**Books:**\n",
    "- **\"Imbalanced Learning\" by He & Ma (2013):** Comprehensive coverage of techniques\n",
    "- **\"Learning from Imbalanced Data Sets\" by Fern\u00e1ndez et al. (2018):** Theory + practice\n",
    "\n",
    "**Online Resources:**\n",
    "- **Kaggle:** Credit card fraud, MNIST imbalanced challenges\n",
    "- **UCI ML Repository:** Datasets with natural imbalance (medical, fraud)\n",
    "- **Semiconductor datasets:** SECOM (semiconductor manufacturing), NASA MDP (defects)\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83c\udfaf Final Checklist: Imbalanced Learning Project**\n",
    "\n",
    "**Before Training:**\n",
    "- [ ] Understand business context (cost of FN vs FP)\n",
    "- [ ] Choose appropriate metrics (recall, F-beta, PR-AUC)\n",
    "- [ ] Explore data (defect rate, spatial/temporal patterns)\n",
    "- [ ] Split data properly (stratified, no leakage)\n",
    "\n",
    "**During Training:**\n",
    "- [ ] Try class weights first (baseline)\n",
    "- [ ] If needed, try SMOTE or ensemble methods\n",
    "- [ ] Use imblearn.pipeline to prevent leakage\n",
    "- [ ] Cross-validate properly (stratified K-Fold)\n",
    "- [ ] Optimize threshold for business objective\n",
    "\n",
    "**After Training:**\n",
    "- [ ] Serialize pipeline (joblib or pickle)\n",
    "- [ ] Save metadata (training date, defect rate, performance)\n",
    "- [ ] Test inference latency (meet production SLA)\n",
    "- [ ] A/B test before full deployment\n",
    "\n",
    "**In Production:**\n",
    "- [ ] Monitor defect rate drift (weekly)\n",
    "- [ ] Track model performance (monthly)\n",
    "- [ ] Log predictions for audit trail\n",
    "- [ ] Retrain when drift > 10%\n",
    "- [ ] Update thresholds as business costs change\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83d\udca1 Key Insight**\n",
    "\n",
    "> **\"Imbalanced data is not a problem to be fixed, but a reality to be managed.\"**\n",
    ">\n",
    "> The goal is not perfect balance (50:50), but **optimal business outcomes**. A model with 95% recall and 70% precision that prevents $10M in losses is better than a perfectly balanced model with 85% recall.\n",
    ">\n",
    "> **Focus on:**\n",
    "> 1. **Business cost** (not just technical metrics)\n",
    "> 2. **Production robustness** (monitoring, retraining, drift detection)\n",
    "> 3. **Proper validation** (no data leakage, realistic splits)\n",
    "> 4. **Threshold optimization** (free performance boost)\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83d\ude80 Next Steps**\n",
    "\n",
    "After mastering imbalanced data handling, explore:\n",
    "1. **AutoML Frameworks** (Notebook 050) - Automated model selection for imbalanced data\n",
    "2. **Hyperparameter Tuning** (Notebook 042) - Optimize SMOTE, class weights, thresholds\n",
    "3. **MLOps** (Notebooks 111-130) - Production monitoring, drift detection, retraining pipelines\n",
    "4. **Ensemble Methods** (Notebooks 036-040) - Combine multiple imbalanced learners\n",
    "5. **Deep Learning for Imbalanced Data** (Notebooks 051-070) - Focal loss, class weights in neural networks\n",
    "\n",
    "---\n",
    "\n",
    "**Remember:** The most sophisticated technique is not always the best. Start simple (class weights), iterate (SMOTE), and deploy with confidence (monitoring + retraining).\n",
    "\n",
    "**\"Better to have a simple model in production with 90% recall than a perfect model in your notebook with 100% recall.\"**\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udf93 **You've Completed Imbalanced Data Handling!**\n",
    "\n",
    "**You now know:**\n",
    "- \u2705 When and why imbalanced data matters (accuracy paradox, business costs)\n",
    "- \u2705 All major techniques (undersampling, oversampling, SMOTE, class weights, ensembles)\n",
    "- \u2705 How to validate properly (avoid data leakage, stratified CV)\n",
    "- \u2705 How to deploy to production (pipelines, monitoring, retraining)\n",
    "- \u2705 Semiconductor-specific applications (wafer defects, yield analysis)\n",
    "\n",
    "**Go build something impactful! \ud83d\ude80**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae9307",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Build production-ready pipeline integrating SMOTE, preprocessing, and classification for deployment\n",
    "\n",
    "**Key Points:**\n",
    "- **Pipeline Integration**: Combine SMOTE + StandardScaler + Classifier in single sklearn Pipeline\n",
    "- **Important Order**: SMOTE must come BEFORE cross-validation (apply only to training fold, not validation)\n",
    "- **imblearn Pipeline**: Use `imblearn.pipeline.Pipeline` (not `sklearn.pipeline`) to support resampling steps\n",
    "- **Serialization**: Save entire pipeline with joblib for deployment (includes SMOTE parameters, scaler statistics, model weights)\n",
    "- **Production Monitoring**: Track class distribution drift, model performance degradation, feature drift\n",
    "- **Semiconductor Context**: Real-time inference (<50ms), batch scoring for overnight test data, automatic retraining triggers\n",
    "\n",
    "**Why This Matters:**\n",
    "- Wrong pipeline order = data leakage (SMOTE on validation data inflates metrics by 10-20%)\n",
    "- Correct order: Split \u2192 SMOTE on train only \u2192 Validate on original imbalanced validation set\n",
    "- Serialized pipeline ensures consistency between training and production (no train-serve skew)\n",
    "- Monitoring detects distribution shift (defect rate changes 2%\u21925% due to process drift)\n",
    "- Production benefit: End-to-end pipeline deployable to API endpoint or batch processing\n",
    "- Cost impact: Proper pipeline prevents overfitting ($5M-$10M annual savings from accurate production performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d17bf1",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Compare ensemble methods designed specifically for imbalanced data (BalancedRandomForest, EasyEnsemble, RUSBoost)\n",
    "\n",
    "**Key Points:**\n",
    "- **BalancedRandomForest**: Each tree trained on balanced bootstrap sample (automatic undersampling per tree)\n",
    "- **EasyEnsemble**: Train multiple classifiers on different undersampled subsets, then combine predictions (diversity through sampling)\n",
    "- **RUSBoost**: Random undersampling + AdaBoost (combines resampling with boosting for sequential error correction)\n",
    "- **Bagging Strategy**: Independent models reduce variance, majority voting aggregates predictions\n",
    "- **Why Effective**: Ensemble diversity compensates for information loss from undersampling\n",
    "- **Semiconductor Context**: Spatial defect patterns (wafer edges) + temporal drift \u2192 Ensemble captures multiple failure modes\n",
    "\n",
    "**Why This Matters:**\n",
    "- Single models struggle with extreme imbalance (1:100+) \u2192 Ensemble methods handle 1:1000+ ratios\n",
    "- BalancedRandomForest: Fast, parallelizable, no manual tuning (recall 85%\u219293%)\n",
    "- EasyEnsemble: Maximizes information use from majority class (all samples used across ensemble)\n",
    "- RUSBoost: Sequential boosting focuses on hard-to-classify minority samples\n",
    "- Production benefit: Robust to distribution shift (new failure modes don't break entire system)\n",
    "- Cost impact: 93% recall = detect 93/100 defects, missing only 7 \u2192 $7M annual losses vs $15M baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24474d5a",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Implement cost-sensitive learning using class weights and custom loss functions (no data resampling)\n",
    "\n",
    "**Key Points:**\n",
    "- **Class Weights**: Penalize minority misclassification more heavily: $w_{\\text{minority}} = \\frac{n}{C \\cdot n_{\\text{minority}}}$ where $C$=number of classes\n",
    "- **sklearn Implementation**: `class_weight='balanced'` automatically computes optimal weights\n",
    "- **Custom Weights**: For extreme cost asymmetry (FN cost >> FP cost), manually set weights based on business impact\n",
    "- **No Data Modification**: Unlike resampling, class weights modify loss function only \u2192 preserves original data distribution\n",
    "- **Threshold Tuning**: After training, optimize decision threshold to maximize F-beta score (balances precision/recall)\n",
    "- **Semiconductor Context**: FN cost=$10M (field failure), FP cost=$500 (yield loss) \u2192 FN:FP ratio = 20,000:1 \u2192 Use class_weight={0:1, 1:20000}\n",
    "\n",
    "**Why This Matters:**\n",
    "- Resampling changes data distribution \u2192 potential overfitting, longer training times\n",
    "- Class weights preserve data \u2192 faster training, no synthetic samples, better for production\n",
    "- Custom weights align model with business objectives (not just technical metrics)\n",
    "- Threshold tuning is free performance boost (no retraining needed)\n",
    "- For semiconductor: Class weights improve recall 40%\u219285% without data augmentation\n",
    "- Cost savings: Proper weighting reduces missed defects from 15\u21925, saving $10M/year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4fc2b",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Compare production SMOTE variants (SMOTE, Borderline-SMOTE, ADASYN, SMOTE-Tomek) using imbalanced-learn library\n",
    "\n",
    "**Key Points:**\n",
    "- **imbalanced-learn**: Production library with optimized implementations and extensive SMOTE variants\n",
    "- **SMOTE**: Standard linear interpolation between minority neighbors (baseline variant)\n",
    "- **Borderline-SMOTE**: Only oversample minority samples near decision boundary (safer regions ignored)\n",
    "- **ADASYN**: Adaptive sampling - generates MORE samples in difficult regions (density-based weighting)\n",
    "- **SMOTE-Tomek**: SMOTE + cleaning with Tomek links (remove noisy majority samples after oversampling)\n",
    "- **Semiconductor Context**: Defects often cluster near parametric boundaries (Vdd=0.9-1.0V, Idd=45-55mA) \u2192 Borderline-SMOTE most effective\n",
    "\n",
    "**Why This Matters:**\n",
    "- Standard SMOTE can create samples in \"safe\" regions (far from decision boundary) \u2192 wasted computation\n",
    "- Borderline-SMOTE focuses on hard-to-classify regions \u2192 better decision boundary\n",
    "- ADASYN adapts to local difficulty \u2192 handles non-uniform minority distribution\n",
    "- SMOTE-Tomek cleans overlapping regions \u2192 reduces noise and improves precision\n",
    "- For semiconductor: Borderline-SMOTE improves recall 85%\u219292% while maintaining precision >80%\n",
    "- Production benefit: Adaptive methods handle complex failure patterns (spatial clusters, temporal drift)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}