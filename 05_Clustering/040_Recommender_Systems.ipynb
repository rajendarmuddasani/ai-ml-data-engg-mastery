{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b117f1c",
   "metadata": {},
   "source": [
    "## üßÆ Mathematical Foundation\n",
    "\n",
    "### 1. User-Item Matrix\n",
    "\n",
    "**Matrix R**: Users √ó Items, entries = ratings (or 1/0 for implicit feedback)\n",
    "\n",
    "$$R = \\begin{bmatrix}\n",
    "r_{11} & r_{12} & \\cdots & r_{1m} \\\\\n",
    "r_{21} & ? & \\cdots & r_{2m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "r_{n1} & r_{n2} & \\cdots & ?\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "**Goal**: Predict missing entries (marked as ?)\n",
    "\n",
    "**Sparsity**: Typically >99% missing (users rate <1% of items)\n",
    "\n",
    "### 2. Similarity Metrics\n",
    "\n",
    "**Cosine Similarity** (angle between vectors):\n",
    "\n",
    "$$\\text{sim}(u, v) = \\frac{\\mathbf{r}_u \\cdot \\mathbf{r}_v}{||\\mathbf{r}_u|| \\cdot ||\\mathbf{r}_v||} = \\frac{\\sum_{i \\in I_{uv}} r_{ui} r_{vi}}{\\sqrt{\\sum_{i} r_{ui}^2} \\sqrt{\\sum_{i} r_{vi}^2}}$$\n",
    "\n",
    "where $I_{uv}$ = items rated by both users u and v\n",
    "\n",
    "**Pearson Correlation** (centered cosine):\n",
    "\n",
    "$$\\text{sim}(u, v) = \\frac{\\sum_{i \\in I_{uv}} (r_{ui} - \\bar{r}_u)(r_{vi} - \\bar{r}_v)}{\\sqrt{\\sum_{i} (r_{ui} - \\bar{r}_u)^2} \\sqrt{\\sum_{i} (r_{vi} - \\bar{r}_v)^2}}$$\n",
    "\n",
    "**Interpretation**: Pearson handles user bias (some users rate higher on average)\n",
    "\n",
    "### 3. User-Based Collaborative Filtering\n",
    "\n",
    "**Prediction** for user u on item i:\n",
    "\n",
    "$$\\hat{r}_{ui} = \\bar{r}_u + \\frac{\\sum_{v \\in N(u)} \\text{sim}(u,v) \\cdot (r_{vi} - \\bar{r}_v)}{\\sum_{v \\in N(u)} |\\text{sim}(u,v)|}$$\n",
    "\n",
    "where $N(u)$ = k nearest neighbors of user u who rated item i\n",
    "\n",
    "**Intuition**: Weighted average of neighbors' ratings, adjusted for their bias\n",
    "\n",
    "### 4. Matrix Factorization (SVD)\n",
    "\n",
    "**Decompose** R into user and item latent factors:\n",
    "\n",
    "$$R \\approx U \\times V^T$$\n",
    "\n",
    "where:\n",
    "- $U \\in \\mathbb{R}^{n \\times k}$: User factor matrix (n users, k latent features)\n",
    "- $V \\in \\mathbb{R}^{m \\times k}$: Item factor matrix (m items, k latent features)\n",
    "- $k \\ll \\min(n, m)$: Latent dimensionality (e.g., 50-100)\n",
    "\n",
    "**Prediction**:\n",
    "\n",
    "$$\\hat{r}_{ui} = \\mu + b_u + b_i + \\mathbf{u}_u^T \\mathbf{v}_i$$\n",
    "\n",
    "where:\n",
    "- $\\mu$: Global mean rating\n",
    "- $b_u$: User bias (user u rates higher/lower than average)\n",
    "- $b_i$: Item bias (item i is rated higher/lower than average)\n",
    "- $\\mathbf{u}_u^T \\mathbf{v}_i$: Interaction between user and item latent factors\n",
    "\n",
    "**Objective** (regularized squared error):\n",
    "\n",
    "$$\\min_{U,V,b} \\sum_{(u,i) \\in \\text{known}} (r_{ui} - \\hat{r}_{ui})^2 + \\lambda(||U||^2 + ||V||^2 + ||b||^2)$$\n",
    "\n",
    "**Optimization**: Stochastic Gradient Descent (SGD) or Alternating Least Squares (ALS)\n",
    "\n",
    "### 5. Content-Based Filtering\n",
    "\n",
    "**Item Profile**: Feature vector $\\mathbf{x}_i \\in \\mathbb{R}^d$ (e.g., genre, keywords, test parameters)\n",
    "\n",
    "**User Profile**: Weighted average of liked items:\n",
    "\n",
    "$$\\mathbf{p}_u = \\frac{\\sum_{i \\in I_u} r_{ui} \\cdot \\mathbf{x}_i}{\\sum_{i \\in I_u} r_{ui}}$$\n",
    "\n",
    "**Prediction**: Similarity between user profile and item:\n",
    "\n",
    "$$\\hat{r}_{ui} = \\text{cosine}(\\mathbf{p}_u, \\mathbf{x}_i) = \\frac{\\mathbf{p}_u \\cdot \\mathbf{x}_i}{||\\mathbf{p}_u|| \\cdot ||\\mathbf{x}_i||}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2d7cb",
   "metadata": {},
   "source": [
    "## üíª Implementation from Scratch\n",
    "\n",
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Build user-based and item-based collaborative filtering from scratch\n",
    "\n",
    "**Key Points:**\n",
    "- **UserBasedCF**: Find similar users via Pearson correlation, predict with weighted average\n",
    "- **ItemBasedCF**: Precompute item similarity matrix, predict with weighted sum\n",
    "- **Pearson**: Centers ratings (handles user bias)\n",
    "- **k neighbors**: Limit to top-k most similar (reduces noise)\n",
    "- **Fallback**: If no neighbors, use user/item mean\n",
    "\n",
    "**Why This Matters:** \n",
    "- Understanding similarity metrics clarifies when each approach works\n",
    "- Item-based often better for sparse data (items change less than users)\n",
    "- Implementation shows computational bottlenecks (similarity computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8eca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "class UserBasedCF:\n",
    "    \"\"\"User-based collaborative filtering.\"\"\"\n",
    "    \n",
    "    def __init__(self, k=10, min_overlap=2):\n",
    "        self.k = k  # Number of neighbors\n",
    "        self.min_overlap = min_overlap  # Minimum co-rated items\n",
    "        \n",
    "    def fit(self, R):\n",
    "        \"\"\"R: user-item matrix (n_users √ó n_items), NaN for missing.\"\"\"\n",
    "        self.R = R\n",
    "        self.user_means = np.nanmean(R, axis=1)\n",
    "        return self\n",
    "    \n",
    "    def _pearson_similarity(self, u, v):\n",
    "        \"\"\"Pearson correlation between users u and v.\"\"\"\n",
    "        # Find co-rated items\n",
    "        mask = ~np.isnan(self.R[u]) & ~np.isnan(self.R[v])\n",
    "        if np.sum(mask) < self.min_overlap:\n",
    "            return 0.0\n",
    "        \n",
    "        r_u = self.R[u, mask] - self.user_means[u]\n",
    "        r_v = self.R[v, mask] - self.user_means[v]\n",
    "        \n",
    "        if np.std(r_u) == 0 or np.std(r_v) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return np.corrcoef(r_u, r_v)[0, 1]\n",
    "    \n",
    "    def predict(self, u, i):\n",
    "        \"\"\"Predict rating for user u on item i.\"\"\"\n",
    "        # Find users who rated item i\n",
    "        rated_users = np.where(~np.isnan(self.R[:, i]))[0]\n",
    "        if len(rated_users) == 0:\n",
    "            return self.user_means[u]\n",
    "        \n",
    "        # Compute similarities\n",
    "        sims = [(v, self._pearson_similarity(u, v)) for v in rated_users if v != u]\n",
    "        sims = [(v, s) for v, s in sims if s > 0]  # Keep positive correlations\n",
    "        \n",
    "        if len(sims) == 0:\n",
    "            return self.user_means[u]\n",
    "        \n",
    "        # Top-k neighbors\n",
    "        sims = sorted(sims, key=lambda x: x[1], reverse=True)[:self.k]\n",
    "        \n",
    "        # Weighted average\n",
    "        numerator = sum(s * (self.R[v, i] - self.user_means[v]) for v, s in sims)\n",
    "        denominator = sum(abs(s) for _, s in sims)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return self.user_means[u]\n",
    "        \n",
    "        return self.user_means[u] + numerator / denominator\n",
    "\n",
    "\n",
    "class ItemBasedCF:\n",
    "    \"\"\"Item-based collaborative filtering.\"\"\"\n",
    "    \n",
    "    def __init__(self, k=10, min_overlap=2):\n",
    "        self.k = k\n",
    "        self.min_overlap = min_overlap\n",
    "        \n",
    "    def fit(self, R):\n",
    "        \"\"\"Precompute item similarity matrix.\"\"\"\n",
    "        self.R = R\n",
    "        self.item_means = np.nanmean(R, axis=0)\n",
    "        self.n_items = R.shape[1]\n",
    "        \n",
    "        # Compute item similarity matrix\n",
    "        self.sim_matrix = np.zeros((self.n_items, self.n_items))\n",
    "        for i in range(self.n_items):\n",
    "            for j in range(i+1, self.n_items):\n",
    "                sim = self._cosine_similarity(i, j)\n",
    "                self.sim_matrix[i, j] = sim\n",
    "                self.sim_matrix[j, i] = sim\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _cosine_similarity(self, i, j):\n",
    "        \"\"\"Cosine similarity between items i and j.\"\"\"\n",
    "        # Find users who rated both\n",
    "        mask = ~np.isnan(self.R[:, i]) & ~np.isnan(self.R[:, j])\n",
    "        if np.sum(mask) < self.min_overlap:\n",
    "            return 0.0\n",
    "        \n",
    "        r_i = self.R[mask, i]\n",
    "        r_j = self.R[mask, j]\n",
    "        \n",
    "        if np.linalg.norm(r_i) == 0 or np.linalg.norm(r_j) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return np.dot(r_i, r_j) / (np.linalg.norm(r_i) * np.linalg.norm(r_j))\n",
    "    \n",
    "    def predict(self, u, i):\n",
    "        \"\"\"Predict rating for user u on item i.\"\"\"\n",
    "        # Find items rated by user u\n",
    "        rated_items = np.where(~np.isnan(self.R[u, :]))[0]\n",
    "        if len(rated_items) == 0:\n",
    "            return self.item_means[i]\n",
    "        \n",
    "        # Get similarities\n",
    "        sims = [(j, self.sim_matrix[i, j]) for j in rated_items if j != i]\n",
    "        sims = [(j, s) for j, s in sims if s > 0]\n",
    "        \n",
    "        if len(sims) == 0:\n",
    "            return self.item_means[i]\n",
    "        \n",
    "        # Top-k similar items\n",
    "        sims = sorted(sims, key=lambda x: x[1], reverse=True)[:self.k]\n",
    "        \n",
    "        # Weighted sum\n",
    "        numerator = sum(s * self.R[u, j] for j, s in sims)\n",
    "        denominator = sum(s for _, s in sims)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return self.item_means[i]\n",
    "        \n",
    "        return numerator / denominator\n",
    "\n",
    "\n",
    "print(\"‚úÖ Collaborative filtering implementations complete!\")\n",
    "print(\"   - User-based: Find similar users (Pearson correlation)\")\n",
    "print(\"   - Item-based: Precompute item similarities (Cosine)\")\n",
    "print(\"   - Both use k-nearest neighbors for prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb972ba",
   "metadata": {},
   "source": [
    "## üß™ Test on MovieLens-style Data\n",
    "\n",
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Validate implementations on synthetic rating data\n",
    "\n",
    "**Key Points:**\n",
    "- **Synthetic ratings**: 100 users, 50 items, ~80% sparsity\n",
    "- **Latent factors**: Users/items with 3 hidden preferences (genre-like)\n",
    "- **Train/test split**: Hold out 20% for evaluation\n",
    "- **MAE/RMSE**: Standard recommendation metrics\n",
    "- **Comparison**: User-based vs item-based performance\n",
    "\n",
    "**Why This Matters:** \n",
    "- Synthetic data with known structure validates algorithm\n",
    "- Shows which approach works better for this sparsity level\n",
    "- Establishes baseline before production library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb1665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic rating data with latent factors\n",
    "n_users = 100\n",
    "n_items = 50\n",
    "n_factors = 3\n",
    "sparsity = 0.8  # 80% missing\n",
    "\n",
    "# Latent factor matrices\n",
    "U_true = np.random.randn(n_users, n_factors)\n",
    "V_true = np.random.randn(n_items, n_factors)\n",
    "\n",
    "# Generate ratings R = U √ó V^T + noise\n",
    "R_true = U_true @ V_true.T + np.random.randn(n_users, n_items) * 0.5\n",
    "R_true = np.clip(R_true, 1, 5)  # Ratings 1-5\n",
    "\n",
    "# Create sparse matrix\n",
    "R = R_true.copy()\n",
    "mask = np.random.rand(n_users, n_items) < sparsity\n",
    "R[mask] = np.nan\n",
    "\n",
    "print(f\"üìä Synthetic Rating Matrix:\")\n",
    "print(f\"   Shape: {R.shape}\")\n",
    "print(f\"   Sparsity: {np.isnan(R).mean()*100:.1f}%\")\n",
    "print(f\"   Rating range: [{np.nanmin(R):.2f}, {np.nanmax(R):.2f}]\")\n",
    "\n",
    "# Split train/test\n",
    "observed = ~np.isnan(R)\n",
    "indices = np.argwhere(observed)\n",
    "np.random.shuffle(indices)\n",
    "n_test = int(0.2 * len(indices))\n",
    "test_indices = indices[:n_test]\n",
    "\n",
    "R_train = R.copy()\n",
    "R_test_values = []\n",
    "for u, i in test_indices:\n",
    "    R_test_values.append((u, i, R_train[u, i]))\n",
    "    R_train[u, i] = np.nan\n",
    "\n",
    "print(f\"\\n   Train ratings: {(~np.isnan(R_train)).sum()}\")\n",
    "print(f\"   Test ratings: {len(R_test_values)}\")\n",
    "\n",
    "# Train models\n",
    "print(\"\\nüîß Training models...\")\n",
    "user_cf = UserBasedCF(k=15).fit(R_train)\n",
    "item_cf = ItemBasedCF(k=15).fit(R_train)\n",
    "\n",
    "# Evaluate\n",
    "def evaluate(model, test_data):\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    for u, i, r_true in test_data:\n",
    "        r_pred = model.predict(u, i)\n",
    "        predictions.append(r_pred)\n",
    "        actuals.append(r_true)\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    mae = np.mean(np.abs(predictions - actuals))\n",
    "    rmse = np.sqrt(np.mean((predictions - actuals)**2))\n",
    "    \n",
    "    return mae, rmse, predictions, actuals\n",
    "\n",
    "mae_user, rmse_user, preds_user, actuals_user = evaluate(user_cf, R_test_values)\n",
    "mae_item, rmse_item, preds_item, actuals_item = evaluate(item_cf, R_test_values)\n",
    "\n",
    "print(f\"\\nüìä Evaluation Results:\")\n",
    "print(f\"\\n   User-Based CF:\")\n",
    "print(f\"      MAE:  {mae_user:.3f}\")\n",
    "print(f\"      RMSE: {rmse_user:.3f}\")\n",
    "print(f\"\\n   Item-Based CF:\")\n",
    "print(f\"      MAE:  {mae_item:.3f}\")\n",
    "print(f\"      RMSE: {rmse_item:.3f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Prediction vs Actual (User-based)\n",
    "ax = axes[0]\n",
    "ax.scatter(actuals_user, preds_user, alpha=0.3, s=10)\n",
    "ax.plot([1, 5], [1, 5], 'r--', linewidth=2, label='Perfect prediction')\n",
    "ax.set_xlabel('Actual Rating')\n",
    "ax.set_ylabel('Predicted Rating')\n",
    "ax.set_title(f'User-Based CF\\nRMSE={rmse_user:.3f}')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction vs Actual (Item-based)\n",
    "ax = axes[1]\n",
    "ax.scatter(actuals_item, preds_item, alpha=0.3, s=10, color='orange')\n",
    "ax.plot([1, 5], [1, 5], 'r--', linewidth=2, label='Perfect prediction')\n",
    "ax.set_xlabel('Actual Rating')\n",
    "ax.set_ylabel('Predicted Rating')\n",
    "ax.set_title(f'Item-Based CF\\nRMSE={rmse_item:.3f}')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Error distribution\n",
    "ax = axes[2]\n",
    "errors_user = preds_user - actuals_user\n",
    "errors_item = preds_item - actuals_item\n",
    "ax.hist(errors_user, bins=30, alpha=0.5, label='User-based', color='blue')\n",
    "ax.hist(errors_item, bins=30, alpha=0.5, label='Item-based', color='orange')\n",
    "ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero error')\n",
    "ax.set_xlabel('Prediction Error')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Error Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3dfe93",
   "metadata": {},
   "source": [
    "## üè≠ Post-Silicon Application: Test Failure Prediction\n",
    "\n",
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Predict which tests will fail for new devices (skip likely passing tests)\n",
    "\n",
    "**Key Points:**\n",
    "- **Matrix R**: Devices √ó Tests (1=fail, 0=pass, NaN=not run)\n",
    "- **Collaborative insight**: Devices with similar past failures likely fail same tests\n",
    "- **Business value**: Test time reduction by skipping likely-passing tests\n",
    "- **Risk**: Must not skip tests that will fail (false negatives costly)\n",
    "- **Threshold tuning**: Predict fail if score > 0.5 (adjustable for precision/recall)\n",
    "\n",
    "**Why This Matters:** \n",
    "- Reduces ATE time (expensive resource)\n",
    "- Enables adaptive test flows (device-specific)\n",
    "- Maintains quality (catch all failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate semiconductor test failure data\n",
    "n_devices = 500\n",
    "n_tests = 30\n",
    "sparsity = 0.7  # 70% tests not run yet\n",
    "\n",
    "# Ground truth failure patterns (3 failure modes)\n",
    "failure_mode_1 = [1, 2, 5, 8, 12]  # Process defect\n",
    "failure_mode_2 = [3, 7, 11, 15, 20]  # Frequency issue\n",
    "failure_mode_3 = [4, 9, 13, 18, 25]  # Thermal issue\n",
    "\n",
    "R_psv = np.zeros((n_devices, n_tests))\n",
    "for device in range(n_devices):\n",
    "    # Assign to failure mode(s) or none\n",
    "    if np.random.rand() < 0.10:\n",
    "        R_psv[device, failure_mode_1] = 1\n",
    "    if np.random.rand() < 0.08:\n",
    "        R_psv[device, failure_mode_2] = 1\n",
    "    if np.random.rand() < 0.05:\n",
    "        R_psv[device, failure_mode_3] = 1\n",
    "    \n",
    "    # Random failures (noise)\n",
    "    n_random = np.random.poisson(0.5)\n",
    "    random_tests = np.random.choice(n_tests, min(n_random, 5), replace=False)\n",
    "    R_psv[device, random_tests] = 1\n",
    "\n",
    "# Create sparse matrix (only some tests run)\n",
    "R_psv_observed = R_psv.copy()\n",
    "mask = np.random.rand(n_devices, n_tests) < sparsity\n",
    "R_psv_observed[mask] = np.nan\n",
    "\n",
    "print(f\"üî¨ Test Failure Matrix:\")\n",
    "print(f\"   Devices: {n_devices}, Tests: {n_tests}\")\n",
    "print(f\"   Sparsity: {np.isnan(R_psv_observed).mean()*100:.1f}% (tests not run)\")\n",
    "print(f\"   Overall failure rate: {R_psv.mean()*100:.1f}%\")\n",
    "\n",
    "# Split: first 400 devices for training, last 100 for testing\n",
    "R_train_psv = R_psv_observed[:400, :].copy()\n",
    "R_test_psv = R_psv_observed[400:, :].copy()\n",
    "R_test_ground_truth = R_psv[400:, :]\n",
    "\n",
    "print(f\"\\n   Training devices: 400\")\n",
    "print(f\"   Test devices: 100\")\n",
    "\n",
    "# Train item-based model (items=tests)\n",
    "print(\"\\nüîß Training test failure predictor...\")\n",
    "model_psv = ItemBasedCF(k=10, min_overlap=5).fit(R_train_psv)\n",
    "\n",
    "# Predict for test devices\n",
    "predictions_psv = []\n",
    "actuals_psv = []\n",
    "for device_id in range(100):\n",
    "    for test_id in range(n_tests):\n",
    "        if ~np.isnan(R_test_psv[device_id, test_id]):\n",
    "            continue  # Already ran\n",
    "        \n",
    "        pred = model_psv.predict(device_id + 400, test_id)  # Adjust index\n",
    "        actual = R_test_ground_truth[device_id, test_id]\n",
    "        \n",
    "        predictions_psv.append(pred)\n",
    "        actuals_psv.append(actual)\n",
    "\n",
    "predictions_psv = np.array(predictions_psv)\n",
    "actuals_psv = np.array(actuals_psv)\n",
    "\n",
    "# Binary classification metrics (threshold=0.5)\n",
    "pred_binary = (predictions_psv > 0.5).astype(int)\n",
    "accuracy = np.mean(pred_binary == actuals_psv)\n",
    "precision = np.sum((pred_binary == 1) & (actuals_psv == 1)) / max(np.sum(pred_binary == 1), 1)\n",
    "recall = np.sum((pred_binary == 1) & (actuals_psv == 1)) / max(np.sum(actuals_psv == 1), 1)\n",
    "f1 = 2 * precision * recall / max(precision + recall, 1e-10)\n",
    "\n",
    "print(f\"\\nüìä Test Failure Prediction:\")\n",
    "print(f\"   Accuracy:  {accuracy*100:.1f}%\")\n",
    "print(f\"   Precision: {precision*100:.1f}% (predicted fails that are actual fails)\")\n",
    "print(f\"   Recall:    {recall*100:.1f}% (actual fails that were predicted)\")\n",
    "print(f\"   F1 Score:  {f1:.3f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# ROC-like curve (vary threshold)\n",
    "ax = axes[0]\n",
    "thresholds = np.linspace(0, 1, 50)\n",
    "precisions = []\n",
    "recalls = []\n",
    "for thresh in thresholds:\n",
    "    pred_bin = (predictions_psv > thresh).astype(int)\n",
    "    tp = np.sum((pred_bin == 1) & (actuals_psv == 1))\n",
    "    fp = np.sum((pred_bin == 1) & (actuals_psv == 0))\n",
    "    fn = np.sum((pred_bin == 0) & (actuals_psv == 1))\n",
    "    \n",
    "    prec = tp / max(tp + fp, 1)\n",
    "    rec = tp / max(tp + fn, 1)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "ax.plot(recalls, precisions, linewidth=2, marker='o', markersize=3)\n",
    "ax.set_xlabel('Recall (Catch Failures)')\n",
    "ax.set_ylabel('Precision (Avoid False Alarms)')\n",
    "ax.set_title('Precision-Recall Curve\\n(Test Failure Prediction)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Confusion matrix\n",
    "ax = axes[1]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(actuals_psv, pred_binary)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "           xticklabels=['Pass', 'Fail'], yticklabels=['Pass', 'Fail'])\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_title(f'Confusion Matrix\\n(Threshold=0.5)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Business Insights:\")\n",
    "print(f\"   - High recall ({recall*100:.1f}%) means we catch most failures\")\n",
    "print(f\"   - Precision {precision*100:.1f}% indicates false positive rate\")\n",
    "print(f\"   - Can skip predicted-passing tests to reduce ATE time\")\n",
    "print(f\"   - Tune threshold based on cost of missed failures vs unnecessary tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45811c5e",
   "metadata": {},
   "source": [
    "## üîß Matrix Factorization with Surprise Library\n",
    "\n",
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Use production-ready SVD implementation from Surprise library\n",
    "\n",
    "**Key Points:**\n",
    "- **SVD**: Decomposes rating matrix into user/item latent factors\n",
    "- **Biases**: Models global, user, and item biases\n",
    "- **SGD optimization**: Efficient learning with regularization\n",
    "- **Cross-validation**: 5-fold CV for robust evaluation\n",
    "- **Comparison**: SVD vs KNN (collaborative filtering)\n",
    "\n",
    "**Why This Matters:** \n",
    "- Production systems use matrix factorization (scales to millions)\n",
    "- SVD captures latent preferences (user taste, item genres)\n",
    "- Surprise library handles sparse data efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e91acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD, KNNBasic\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Convert to Surprise format\n",
    "ratings_list = []\n",
    "for u in range(n_users):\n",
    "    for i in range(n_items):\n",
    "        if ~np.isnan(R[u, i]):\n",
    "            ratings_list.append((u, i, R[u, i]))\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(pd.DataFrame(ratings_list, columns=['userID', 'itemID', 'rating']), reader)\n",
    "\n",
    "print(f\"üìä Loaded {len(ratings_list)} ratings into Surprise\")\n",
    "\n",
    "# Train SVD model\n",
    "print(\"\\nüîß Training SVD (Matrix Factorization)...\")\n",
    "svd = SVD(n_factors=10, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=42)\n",
    "cv_results_svd = cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=False)\n",
    "\n",
    "print(f\"\\n   SVD Results (5-fold CV):\")\n",
    "print(f\"      RMSE: {cv_results_svd['test_rmse'].mean():.3f} ¬± {cv_results_svd['test_rmse'].std():.3f}\")\n",
    "print(f\"      MAE:  {cv_results_svd['test_mae'].mean():.3f} ¬± {cv_results_svd['test_mae'].std():.3f}\")\n",
    "\n",
    "# Compare with KNN\n",
    "print(\"\\nüîß Training KNN (User-Based CF)...\")\n",
    "knn = KNNBasic(k=15, sim_options={'name': 'pearson', 'user_based': True})\n",
    "cv_results_knn = cross_validate(knn, data, measures=['RMSE', 'MAE'], cv=5, verbose=False)\n",
    "\n",
    "print(f\"\\n   KNN Results (5-fold CV):\")\n",
    "print(f\"      RMSE: {cv_results_knn['test_rmse'].mean():.3f} ¬± {cv_results_knn['test_rmse'].std():.3f}\")\n",
    "print(f\"      MAE:  {cv_results_knn['test_mae'].mean():.3f} ¬± {cv_results_knn['test_mae'].std():.3f}\")\n",
    "\n",
    "# Visualize latent factors (train full SVD)\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Extract user and item factors\n",
    "user_factors = svd.pu  # n_users √ó n_factors\n",
    "item_factors = svd.qi  # n_items √ó n_factors\n",
    "\n",
    "print(f\"\\nüìä Learned Latent Factors:\")\n",
    "print(f\"   User factors: {user_factors.shape}\")\n",
    "print(f\"   Item factors: {item_factors.shape}\")\n",
    "\n",
    "# Visualize first 2 latent dimensions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# User embeddings\n",
    "ax = axes[0]\n",
    "ax.scatter(user_factors[:, 0], user_factors[:, 1], alpha=0.5, s=30)\n",
    "ax.set_xlabel('Latent Factor 1')\n",
    "ax.set_ylabel('Latent Factor 2')\n",
    "ax.set_title('User Embeddings (First 2 Factors)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Item embeddings\n",
    "ax = axes[1]\n",
    "ax.scatter(item_factors[:, 0], item_factors[:, 1], alpha=0.5, s=30, color='orange')\n",
    "ax.set_xlabel('Latent Factor 1')\n",
    "ax.set_ylabel('Latent Factor 2')\n",
    "ax.set_title('Item Embeddings (First 2 Factors)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Surprise Library Results:\")\n",
    "print(\"   - SVD: Matrix factorization with latent factors\")\n",
    "print(\"   - KNN: Neighborhood-based collaborative filtering\")\n",
    "print(\"   - Production-ready implementations with cross-validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d2915a",
   "metadata": {},
   "source": [
    "## üéØ Real-World Project Ideas\n",
    "\n",
    "### Post-Silicon Validation Projects\n",
    "\n",
    "1. **Adaptive Test Flow Recommender** üí∞ $15M+ Test Efficiency\n",
    "   - **Objective**: Predict per-device test sequence, skip likely-passing tests\n",
    "   - **Features**: Device parametric signature + historical test results\n",
    "   - **Success Metric**: 30% test time reduction, 99.9% defect capture\n",
    "   - **Implementation**: Item-based CF (tests=items), predict failure prob, adaptive thresholds\n",
    "\n",
    "2. **Failure Analysis Strategy Recommender** üí∞ $10M+ Debug Acceleration\n",
    "   - **Objective**: Suggest FA techniques based on similar failure signatures\n",
    "   - **Features**: Parametric test results + wafer spatial + lot context\n",
    "   - **Success Metric**: 40% FA time reduction, 95% root cause match\n",
    "   - **Implementation**: Hybrid (content-based on params + collaborative on past FA success)\n",
    "\n",
    "3. **Equipment Health Predictor** üí∞ $20M+ Downtime Prevention\n",
    "   - **Objective**: Recommend maintenance based on tool parameter drift\n",
    "   - **Features**: 100+ tool sensors + recipe parameters + chamber usage\n",
    "   - **Success Metric**: 7-day advance warning, <5% false alarms\n",
    "   - **Implementation**: SVD on tool√óparameter matrix, detect abnormal latent factors\n",
    "\n",
    "4. **Cross-Product Yield Transfer** üí∞ $50M+ Ramp Acceleration\n",
    "   - **Objective**: Recommend initial test limits for new product based on similar products\n",
    "   - **Features**: Product specs + package type + process node + test results\n",
    "   - **Success Metric**: 50% faster yield learning, 90% limit accuracy\n",
    "   - **Implementation**: Content-based (product similarity) + transfer learning\n",
    "\n",
    "### General AI/ML Projects\n",
    "\n",
    "5. **E-Commerce Product Recommender** üí∞ $100M+ Revenue\n",
    "   - **Objective**: Personalized product recommendations\n",
    "   - **Features**: Purchase history + browsing + demographics + product attributes\n",
    "   - **Success Metric**: 25% conversion rate increase, 20% AOV lift\n",
    "   - **Implementation**: Hybrid (CF for personalization + content for cold-start)\n",
    "\n",
    "6. **Video Streaming Recommender** üí∞ $200M+ Engagement\n",
    "   - **Objective**: Recommend movies/shows to increase watch time\n",
    "   - **Features**: Viewing history + ratings + genres + actors + descriptions\n",
    "   - **Success Metric**: 30% more watch time, 50% click-through rate\n",
    "   - **Implementation**: Deep learning hybrid (embeddings + sequence models)\n",
    "\n",
    "7. **Job-Candidate Matching** üí∞ $50M+ Placement Success\n",
    "   - **Objective**: Recommend candidates to jobs and vice versa\n",
    "   - **Features**: Skills + experience + education + company culture + job descriptions\n",
    "   - **Success Metric**: 40% placement rate increase, 80% 1-year retention\n",
    "   - **Implementation**: Two-way recommendations (candidates+jobs as users+items)\n",
    "\n",
    "8. **News Article Recommender** üí∞ $80M+ Ad Revenue\n",
    "   - **Objective**: Personalized news feed with diversity and timeliness\n",
    "   - **Features**: Reading history + click behavior + article topics + recency\n",
    "   - **Success Metric**: 50% more engagement, 30% session time increase\n",
    "   - **Implementation**: Contextual bandits + explore-exploit for fresh content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614def0d",
   "metadata": {},
   "source": [
    "## üîç Key Takeaways\n",
    "\n",
    "### ‚úÖ When to Use Recommender Systems\n",
    "- **Sparse interactions**: Users rate/interact with <1% of items\n",
    "- **Implicit feedback**: Clicks, views, purchases (not just explicit ratings)\n",
    "- **Personalization**: Each user has unique preferences\n",
    "- **Large item catalogs**: Millions of products/videos/articles\n",
    "- **Cold-start problem**: New users/items with no history (use content-based)\n",
    "\n",
    "### ‚ùå Limitations\n",
    "- **Cold-start**: New users/items hard to recommend\n",
    "- **Popularity bias**: Tends to recommend popular items\n",
    "- **Filter bubble**: Users only see similar items (lack diversity)\n",
    "- **Data sparsity**: Need sufficient interactions (>5 per user)\n",
    "- **No explanations**: Matrix factorization latent factors not interpretable\n",
    "\n",
    "### üîß Best Practices\n",
    "1. **Start with item-based CF**: Works well for sparse data, more stable than user-based\n",
    "2. **Use matrix factorization for scale**: SVD/ALS handles millions of users\n",
    "3. **Hybrid approaches**: Combine CF + content-based for cold-start\n",
    "4. **Implicit feedback**: Use clicks/views (not just ratings) for more data\n",
    "5. **Diversity**: Add exploration (not just exploitation) to avoid filter bubbles\n",
    "6. **A/B testing**: Always test recommendations with real users\n",
    "\n",
    "### üìä Approach Comparison\n",
    "\n",
    "| Approach | Pros | Cons | Use Case |\n",
    "|----------|------|------|----------|\n",
    "| **User-Based CF** | Simple, explainable | Scalability, user sparsity | Small datasets |\n",
    "| **Item-Based CF** | Stable, scalable | Item cold-start | Large catalogs |\n",
    "| **Matrix Factorization** | Handles sparsity, scalable | Black box, cold-start | Millions of users |\n",
    "| **Content-Based** | No cold-start, explainable | Overspecialization | Rich item metadata |\n",
    "| **Hybrid** | Best of both worlds | Complex, tuning needed | Production systems |\n",
    "\n",
    "### üöÄ Next Steps\n",
    "- **Deep learning**: Neural collaborative filtering, autoencoders\n",
    "- **Contextual bandits**: Exploration-exploitation for fresh content\n",
    "- **Graph neural networks**: User-item-context graphs\n",
    "- **Sequential models**: RNNs for session-based recommendations\n",
    "\n",
    "### üî¨ Production Considerations\n",
    "- **Online learning**: Update models incrementally with new interactions\n",
    "- **Latency**: Precompute similarities, cache predictions\n",
    "- **Diversity**: Add randomness, novelty, serendipity\n",
    "- **Bias mitigation**: Fair recommendations across demographics\n",
    "- **Evaluation**: Use online metrics (CTR, conversion) not just RMSE"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
