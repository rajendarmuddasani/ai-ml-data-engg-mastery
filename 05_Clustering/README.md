# 05 - Clustering

**Purpose:** Master unsupervised learning for pattern discovery and dimensionality reduction

## Notebooks

- **026_K_Means_Clustering.ipynb** - K-Means, Lloyd's algorithm, K-Means++, elbow method, silhouette analysis
- **027_Hierarchical_Clustering.ipynb** - Agglomerative/divisive, linkage methods, dendrogram, cophenetic correlation
- **028_DBSCAN.ipynb** - Density-based clustering, core/border/noise points, eps-neighborhood, arbitrary shapes
- **029_Gaussian_Mixture_Models.ipynb** - GMM, EM algorithm, soft clustering, BIC/AIC model selection
- **030_Dimensionality_Reduction.ipynb** - PCA, t-SNE, UMAP, explained variance, manifold learning

## Key Learning Outcomes

- Discover patterns in unlabeled data
- Reduce 1000D STDF data to 50D (20Ã— ML speedup)
- Visualize high-dimensional data in 2D/3D
- Apply to wafer defect pattern detection ($5M+ yield recovery)
- Understand when to use centroid vs density vs probabilistic clustering

## Prerequisites

- **03_Tree_Based_Models** (feature importance understanding)
- Linear algebra (eigendecomposition for PCA)
- Distance metrics and similarity measures

## Next Steps

Proceed to **06_Time_Series** for temporal data modeling.
