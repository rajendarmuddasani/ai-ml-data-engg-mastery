{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc2f1cae",
   "metadata": {},
   "source": [
    "# 096: Batch Processing at Scale\n\n",
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Callable\n",
    "from dataclasses import dataclass, field\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"\u2705 Batch processing environment ready!\")\n",
    "print(f\"Available CPU cores: {mp.cpu_count()}\")\n",
    "print(\"\\nProduction Tools:\")\n",
    "print(\"  - Apache Spark: Distributed batch processing\")\n",
    "print(\"  - Apache Hadoop: MapReduce framework\")\n",
    "print(\"  - Dask: Python parallel computing\")\n",
    "print(\"  - Databricks: Managed Spark platform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f3c44",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Set up environment for distributed batch processing simulation\n",
    "\n",
    "**Key Points:**\n",
    "- **Multiprocessing**: Python simulates distributed compute (actual parallelism on multi-core CPU)\n",
    "- **Production Reality**: Spark/Hadoop run on 100-1000 node clusters (6400+ cores)\n",
    "- **CPU Cores**: Laptop 8-16, cloud 32-96, cluster 1000s\n",
    "- **Frameworks**: Spark 100\u00d7 faster than Hadoop MapReduce\n",
    "\n",
    "**Why This Matters:** Intel runs 200-node Spark clusters processing 500TB/week. AWS EMR charges $0.10/core-hour \u2192 optimize to finish faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbd58c",
   "metadata": {},
   "source": [
    "## 2. Data Partitioning Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6130fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataPartition:\n",
    "    \"\"\"Represents a partition of data for distributed processing\"\"\"\n",
    "    partition_id: int\n",
    "    data: pd.DataFrame\n",
    "    partition_key: str\n",
    "    \n",
    "    @property\n",
    "    def size_mb(self) -> float:\n",
    "        return self.data.memory_usage(deep=True).sum() / 1024 / 1024\n",
    "    \n",
    "    @property\n",
    "    def row_count(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "# Generate test data (1M rows simulating test results)\n",
    "np.random.seed(42)\n",
    "n_rows = 1_000_000\n",
    "\n",
    "df_test_data = pd.DataFrame({\n",
    "    'device_id': [f\"D{np.random.randint(1, 10001):05d}\" for _ in range(n_rows)],\n",
    "    'wafer_id': [f\"W{np.random.randint(1, 51):03d}\" for _ in range(n_rows)],\n",
    "    'test_name': np.random.choice(['Vdd', 'Idd', 'Freq', 'Power'], n_rows),\n",
    "    'test_value': np.random.normal(100, 10, n_rows),\n",
    "    'test_time_ms': np.random.normal(50, 10, n_rows),\n",
    "    'timestamp': [datetime(2024, 1, 1) + timedelta(seconds=i) for i in range(n_rows)]\n",
    "})\n",
    "\n",
    "print(f\"\ud83d\udcca Generated {len(df_test_data):,} test results\")\n",
    "print(f\"   Size: {df_test_data.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "print(f\"   Unique wafers: {df_test_data['wafer_id'].nunique()}\")\n",
    "print(f\"   Unique devices: {df_test_data['device_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2986115",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Create test dataset simulating semiconductor test results\n",
    "\n",
    "**Key Points:**\n",
    "- **1M Rows**: Realistic sample size for local testing (production: billions)\n",
    "- **Realistic Data**: device_id, wafer_id, test parameters (Vdd, Idd, Freq, Power)\n",
    "- **Memory Size**: ~80MB uncompressed (production: 500TB Parquet compressed 10\u00d7)\n",
    "- **DataPartition Class**: Track partition metadata (size, row count)\n",
    "\n",
    "**Why This Matters:** Intel's 500TB = 6 billion rows. Partition into 4000 chunks (125GB each) for distributed processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316d88d",
   "metadata": {},
   "source": [
    "## 3. Hash Partitioning Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashPartitioner:\n",
    "    \"\"\"Hash partitioning for even distribution\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def partition(df: pd.DataFrame, key: str, num_partitions: int) -> List[DataPartition]:\n",
    "        \"\"\"Distribute data evenly using hash function\"\"\"\n",
    "        df['_partition_id'] = df[key].apply(lambda x: hash(str(x)) % num_partitions)\n",
    "        \n",
    "        partitions = []\n",
    "        for i in range(num_partitions):\n",
    "            partition_data = df[df['_partition_id'] == i].drop('_partition_id', axis=1)\n",
    "            partitions.append(DataPartition(\n",
    "                partition_id=i,\n",
    "                data=partition_data,\n",
    "                partition_key=key\n",
    "            ))\n",
    "        \n",
    "        return partitions\n",
    "\n",
    "# Test hash partitioning\n",
    "num_partitions = 8\n",
    "hash_partitions = HashPartitioner.partition(df_test_data, 'wafer_id', num_partitions)\n",
    "\n",
    "print(f\"\ud83d\udd00 Hash Partitioning (by wafer_id, {num_partitions} partitions):\\n\")\n",
    "for p in hash_partitions:\n",
    "    print(f\"  Partition {p.partition_id}: {p.row_count:,} rows ({p.size_mb:.2f} MB)\")\n",
    "\n",
    "# Check balance\n",
    "sizes = [p.row_count for p in hash_partitions]\n",
    "print(f\"\\n  Balance: min={min(sizes):,}, max={max(sizes):,}, \"\n",
    "      f\"stddev={np.std(sizes):.0f} rows\")\n",
    "print(f\"  Skew: {(max(sizes) - min(sizes)) / np.mean(sizes) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa908f6",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Implement hash partitioning for even data distribution\n",
    "\n",
    "**Key Points:**\n",
    "- **Hash Function**: `hash(key) % N` \u2192 distributes data evenly across N partitions\n",
    "- **Good For**: Joins, groupBy (all records with same key in same partition)\n",
    "- **Balance Check**: Stddev and skew metrics (want <5% skew)\n",
    "- **Target Size**: 128-512MB per partition in Spark (avoid small/large extremes)\n",
    "\n",
    "**Why This Matters:** Intel partitions 500TB by wafer_id (50K wafers = 10GB/partition). Skewed partitions cause stragglers (one task 10\u00d7 slower \u2192 entire job delayed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293e3be",
   "metadata": {},
   "source": [
    "## 4. Range Partitioning Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bce9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RangePartitioner:\n",
    "    \"\"\"Range partitioning for time-series and sorted data\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def partition(df: pd.DataFrame, key: str, num_partitions: int) -> List[DataPartition]:\n",
    "        \"\"\"Partition based on value ranges\"\"\"\n",
    "        df_sorted = df.sort_values(key)\n",
    "        partition_size = len(df_sorted) // num_partitions\n",
    "        \n",
    "        partitions = []\n",
    "        for i in range(num_partitions):\n",
    "            start_idx = i * partition_size\n",
    "            end_idx = start_idx + partition_size if i < num_partitions - 1 else len(df_sorted)\n",
    "            partition_data = df_sorted.iloc[start_idx:end_idx]\n",
    "            \n",
    "            partitions.append(DataPartition(\n",
    "                partition_id=i,\n",
    "                data=partition_data,\n",
    "                partition_key=key\n",
    "            ))\n",
    "        \n",
    "        return partitions\n",
    "\n",
    "# Test range partitioning\n",
    "range_partitions = RangePartitioner.partition(df_test_data, 'timestamp', num_partitions)\n",
    "\n",
    "print(f\"\ud83d\udcc5 Range Partitioning (by timestamp, {num_partitions} partitions):\\n\")\n",
    "for p in range_partitions[:3]:  # Show first 3\n",
    "    min_time = p.data['timestamp'].min()\n",
    "    max_time = p.data['timestamp'].max()\n",
    "    print(f\"  Partition {p.partition_id}: {p.row_count:,} rows\")\n",
    "    print(f\"    Time range: {min_time.strftime('%Y-%m-%d %H:%M')} to \"\n",
    "          f\"{max_time.strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"  ... ({len(range_partitions)} total partitions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0a5d5",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Implement range partitioning for time-series data\n",
    "\n",
    "**Key Points:**\n",
    "- **Sort + Split**: Sort by key, split into equal-sized ranges\n",
    "- **Good For**: Time-series queries (scan single partition for date range)\n",
    "- **Predicate Pushdown**: Query \"last month\" \u2192 skip 11 of 12 partitions\n",
    "- **Partition Pruning**: 100\u00d7 speedup for time-range queries\n",
    "\n",
    "**Why This Matters:** NVIDIA partitions by test_date for time-series analytics. Query \"last week\" processes 7 days / 365 days = 2% of data (50\u00d7 faster)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b12782d",
   "metadata": {},
   "source": [
    "## 5. MapReduce Pattern: Map Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd244a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_function(partition: DataPartition, operation: str) -> Dict[str, Any]:\n",
    "    \"\"\"Map: Process single partition independently\"\"\"\n",
    "    df = partition.data\n",
    "    \n",
    "    if operation == 'count_by_wafer':\n",
    "        result = df.groupby('wafer_id').size().to_dict()\n",
    "        return {'partition_id': partition.partition_id, 'counts': result}\n",
    "    \n",
    "    elif operation == 'avg_test_time':\n",
    "        result = df.groupby('test_name')['test_time_ms'].mean().to_dict()\n",
    "        return {'partition_id': partition.partition_id, 'averages': result}\n",
    "    \n",
    "    elif operation == 'outlier_detection':\n",
    "        mean = df['test_value'].mean()\n",
    "        std = df['test_value'].std()\n",
    "        outliers = df[np.abs(df['test_value'] - mean) > 3 * std]\n",
    "        return {'partition_id': partition.partition_id, 'outlier_count': len(outliers)}\n",
    "    \n",
    "    return {'partition_id': partition.partition_id, 'error': 'Unknown operation'}\n",
    "\n",
    "# Test map function on single partition\n",
    "test_partition = hash_partitions[0]\n",
    "result = map_function(test_partition, 'count_by_wafer')\n",
    "\n",
    "print(f\"\ud83d\uddfa\ufe0f Map Function Test (Partition 0):\\n\")\n",
    "print(f\"  Operation: count_by_wafer\")\n",
    "print(f\"  Partition rows: {test_partition.row_count:,}\")\n",
    "print(f\"  Unique wafers found: {len(result['counts'])}\")\n",
    "print(f\"  Sample counts: {list(result['counts'].items())[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b560b",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Implement map phase of MapReduce (process partitions independently)\n",
    "\n",
    "**Key Points:**\n",
    "- **Embarrassingly Parallel**: Each partition processed independently (100% CPU utilization)\n",
    "- **No Shared State**: Map tasks don't communicate (enables horizontal scaling)\n",
    "- **Multiple Operations**: count_by_wafer, avg_test_time, outlier_detection\n",
    "- **Intermediate Results**: Dict format for easy serialization (Spark uses Java serialization)\n",
    "\n",
    "**Why This Matters:** Intel's 4000 partitions \u00d7 30 min = 2000 core-hours. Parallel execution on 200 nodes = 10 hours wall time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084200ea",
   "metadata": {},
   "source": [
    "## 6. MapReduce Pattern: Reduce Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_function(map_results: List[Dict[str, Any]], operation: str) -> Dict[str, Any]:\n",
    "    \"\"\"Reduce: Combine results from all partitions\"\"\"\n",
    "    \n",
    "    if operation == 'count_by_wafer':\n",
    "        combined_counts = {}\n",
    "        for result in map_results:\n",
    "            for wafer_id, count in result['counts'].items():\n",
    "                combined_counts[wafer_id] = combined_counts.get(wafer_id, 0) + count\n",
    "        return {'total_wafers': len(combined_counts), 'counts': combined_counts}\n",
    "    \n",
    "    elif operation == 'avg_test_time':\n",
    "        # Weighted average (simplified - production uses sum/count separately)\n",
    "        test_sums = {}\n",
    "        test_counts = {}\n",
    "        for result in map_results:\n",
    "            for test_name, avg in result['averages'].items():\n",
    "                test_sums[test_name] = test_sums.get(test_name, 0) + avg\n",
    "                test_counts[test_name] = test_counts.get(test_name, 0) + 1\n",
    "        \n",
    "        final_averages = {k: test_sums[k] / test_counts[k] for k in test_sums}\n",
    "        return {'test_averages': final_averages}\n",
    "    \n",
    "    elif operation == 'outlier_detection':\n",
    "        total_outliers = sum(r['outlier_count'] for r in map_results)\n",
    "        return {'total_outliers': total_outliers}\n",
    "    \n",
    "    return {'error': 'Unknown operation'}\n",
    "\n",
    "# Test reduce with sample map results\n",
    "map_results = [map_function(p, 'count_by_wafer') for p in hash_partitions[:3]]\n",
    "final_result = reduce_function(map_results, 'count_by_wafer')\n",
    "\n",
    "print(f\"\ud83d\udcca Reduce Function Test (3 partitions):\\n\")\n",
    "print(f\"  Total unique wafers: {final_result['total_wafers']}\")\n",
    "print(f\"  Sample wafer counts: {list(final_result['counts'].items())[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59635161",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Implement reduce phase (combine map outputs into final result)\n",
    "\n",
    "**Key Points:**\n",
    "- **Aggregation Logic**: Merge counts, compute averages, sum totals\n",
    "- **Bottleneck**: Reduce phase is single-threaded bottleneck (all map outputs must arrive)\n",
    "- **Shuffle Phase**: (Implicit) Move intermediate data between nodes (network heavy)\n",
    "- **Optimization**: Keep reduce simple, do heavy lifting in map phase\n",
    "\n",
    "**Why This Matters:** Intel's reduce phase: 10 minutes (vs 2000 core-hours map). Optimize map to minimize shuffle size (filter early!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d1cc17",
   "metadata": {},
   "source": [
    "## 7. Parallel MapReduce Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffc76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapReduceExecutor:\n",
    "    \"\"\"Execute MapReduce jobs with parallel processing\"\"\"\n",
    "    \n",
    "    def __init__(self, num_workers: int = None):\n",
    "        self.num_workers = num_workers or mp.cpu_count()\n",
    "    \n",
    "    def execute(self, partitions: List[DataPartition], operation: str) -> Dict[str, Any]:\n",
    "        \"\"\"Execute full MapReduce job\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Map phase (parallel)\n",
    "        with mp.Pool(self.num_workers) as pool:\n",
    "            map_func = partial(map_function, operation=operation)\n",
    "            map_results = pool.map(map_func, partitions)\n",
    "        \n",
    "        map_time = time.time() - start_time\n",
    "        \n",
    "        # Reduce phase\n",
    "        reduce_start = time.time()\n",
    "        final_result = reduce_function(map_results, operation)\n",
    "        reduce_time = time.time() - reduce_start\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        return {\n",
    "            'result': final_result,\n",
    "            'map_time_s': map_time,\n",
    "            'reduce_time_s': reduce_time,\n",
    "            'total_time_s': total_time,\n",
    "            'num_partitions': len(partitions),\n",
    "            'num_workers': self.num_workers\n",
    "        }\n",
    "\n",
    "# Execute MapReduce jobs\n",
    "executor = MapReduceExecutor(num_workers=4)\n",
    "\n",
    "print(\"\ud83d\ude80 MapReduce Execution:\\n\")\n",
    "\n",
    "# Job 1: Count by wafer\n",
    "result1 = executor.execute(hash_partitions, 'count_by_wafer')\n",
    "print(f\"Job 1: Count by Wafer\")\n",
    "print(f\"  Total wafers: {result1['result']['total_wafers']}\")\n",
    "print(f\"  Time: {result1['total_time_s']:.2f}s (map: {result1['map_time_s']:.2f}s, \"\n",
    "      f\"reduce: {result1['reduce_time_s']:.2f}s)\")\n",
    "\n",
    "# Job 2: Average test time\n",
    "result2 = executor.execute(hash_partitions, 'avg_test_time')\n",
    "print(f\"\\nJob 2: Average Test Time\")\n",
    "print(f\"  Test averages: {result2['result']['test_averages']}\")\n",
    "print(f\"  Time: {result2['total_time_s']:.2f}s\")\n",
    "\n",
    "# Job 3: Outlier detection\n",
    "result3 = executor.execute(hash_partitions, 'outlier_detection')\n",
    "print(f\"\\nJob 3: Outlier Detection\")\n",
    "print(f\"  Total outliers: {result3['result']['total_outliers']:,}\")\n",
    "print(f\"  Time: {result3['total_time_s']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513883d2",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Execute complete MapReduce jobs with parallel map phase\n",
    "\n",
    "**Key Points:**\n",
    "- **Python Multiprocessing**: Simulates distributed execution (actual parallelism)\n",
    "- **Worker Pool**: 4 workers process 8 partitions (2 partitions per worker)\n",
    "- **Time Breakdown**: Map vs reduce time (map should dominate 90%+)\n",
    "- **Fault Tolerance**: Production systems re-execute failed tasks automatically\n",
    "\n",
    "**Why This Matters:** Spark/Hadoop automatically manage task scheduling, fault tolerance, data locality. Amdahl's Law: speedup limited by serial portion (reduce phase)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1d358",
   "metadata": {},
   "source": [
    "## 8. Performance Optimization: Predicate Pushdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchJobOptimizer:\n",
    "    \"\"\"Optimization techniques for batch processing\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def predicate_pushdown(df: pd.DataFrame, filters: Dict[str, Any]) -> pd.DataFrame:\n",
    "        \"\"\"Filter data early to reduce processing volume\"\"\"\n",
    "        filtered = df.copy()\n",
    "        for column, condition in filters.items():\n",
    "            if isinstance(condition, tuple):  # Range filter\n",
    "                filtered = filtered[(filtered[column] >= condition[0]) & \n",
    "                                    (filtered[column] <= condition[1])]\n",
    "            elif isinstance(condition, list):  # IN filter\n",
    "                filtered = filtered[filtered[column].isin(condition)]\n",
    "            else:  # Equality filter\n",
    "                filtered = filtered[filtered[column] == condition]\n",
    "        return filtered\n",
    "    \n",
    "    @staticmethod\n",
    "    def column_pruning(df: pd.DataFrame, required_columns: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Select only necessary columns\"\"\"\n",
    "        return df[required_columns]\n",
    "\n",
    "# Demonstrate optimizations\n",
    "print(\"\u26a1 Optimization Techniques:\\n\")\n",
    "\n",
    "# 1. Predicate pushdown\n",
    "filters = {'test_name': ['Vdd', 'Idd'], 'test_value': (90, 110)}\n",
    "filtered_df = BatchJobOptimizer.predicate_pushdown(df_test_data, filters)\n",
    "reduction = (1 - len(filtered_df) / len(df_test_data)) * 100\n",
    "\n",
    "print(f\"1\ufe0f\u20e3 Predicate Pushdown:\")\n",
    "print(f\"   Original: {len(df_test_data):,} rows\")\n",
    "print(f\"   Filtered: {len(filtered_df):,} rows ({reduction:.1f}% reduction)\")\n",
    "\n",
    "# 2. Column pruning\n",
    "required_cols = ['device_id', 'test_value']\n",
    "pruned_df = BatchJobOptimizer.column_pruning(df_test_data, required_cols)\n",
    "memory_reduction = (1 - pruned_df.memory_usage(deep=True).sum() / \n",
    "                    df_test_data.memory_usage(deep=True).sum()) * 100\n",
    "\n",
    "print(f\"\\n2\ufe0f\u20e3 Column Pruning:\")\n",
    "print(f\"   Original: {len(df_test_data.columns)} columns, \"\n",
    "      f\"{df_test_data.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "print(f\"   Pruned: {len(pruned_df.columns)} columns, \"\n",
    "      f\"{pruned_df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB \"\n",
    "      f\"({memory_reduction:.1f}% reduction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e117994d",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Apply optimization techniques to reduce batch job runtime\n",
    "\n",
    "**Key Points:**\n",
    "- **Predicate Pushdown**: Filter early before expensive operations (Spark Catalyst does this automatically)\n",
    "- **Column Pruning**: Read only needed columns (Parquet columnar format \u2192 skip entire columns)\n",
    "- **Real Impact**: 500TB \u2192 50TB (filter to last month) \u2192 10TB (select 5 of 50 columns)\n",
    "- **Cost Savings**: Intel optimized 8 hours \u2192 2 hours ($5,000 \u2192 $1,250 per run)\n",
    "\n",
    "**Why This Matters:** Spark Catalyst optimizer automatically applies these transformations. Understanding them helps write optimizer-friendly code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c5f61",
   "metadata": {},
   "source": [
    "## 9. Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark different partition counts\n",
    "partition_counts = [2, 4, 8, 16]\n",
    "benchmark_results = []\n",
    "\n",
    "print(\"\u23f1\ufe0f Performance Benchmark: Partition Count vs Processing Time\\n\")\n",
    "\n",
    "for num_parts in partition_counts:\n",
    "    partitions = HashPartitioner.partition(df_test_data, 'wafer_id', num_parts)\n",
    "    executor = MapReduceExecutor(num_workers=min(num_parts, mp.cpu_count()))\n",
    "    result = executor.execute(partitions, 'count_by_wafer')\n",
    "    \n",
    "    benchmark_results.append({\n",
    "        'num_partitions': num_parts,\n",
    "        'total_time_s': result['total_time_s'],\n",
    "        'map_time_s': result['map_time_s'],\n",
    "        'throughput_rows_per_sec': len(df_test_data) / result['total_time_s']\n",
    "    })\n",
    "    \n",
    "    print(f\"Partitions: {num_parts:2d}, Time: {result['total_time_s']:.2f}s, \"\n",
    "          f\"Throughput: {benchmark_results[-1]['throughput_rows_per_sec']:,.0f} rows/s\")\n",
    "\n",
    "# Visualize\n",
    "df_bench = pd.DataFrame(benchmark_results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Batch Processing Performance', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Processing time\n",
    "axes[0].plot(df_bench['num_partitions'], df_bench['total_time_s'], \n",
    "             marker='o', linewidth=2, color='#3498db', label='Total')\n",
    "axes[0].plot(df_bench['num_partitions'], df_bench['map_time_s'], \n",
    "             marker='s', linewidth=2, color='#2ecc71', label='Map')\n",
    "axes[0].set_xlabel('Number of Partitions')\n",
    "axes[0].set_ylabel('Time (seconds)')\n",
    "axes[0].set_title('Processing Time vs Partitions')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Throughput\n",
    "axes[1].plot(df_bench['num_partitions'], df_bench['throughput_rows_per_sec'] / 1000,\n",
    "             marker='o', linewidth=2, color='#9b59b6')\n",
    "axes[1].set_xlabel('Number of Partitions')\n",
    "axes[1].set_ylabel('Throughput (K rows/sec)')\n",
    "axes[1].set_title('Throughput vs Partitions')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "optimal_idx = df_bench['total_time_s'].idxmin()\n",
    "print(f\"\\n\u2705 Optimal: {df_bench.loc[optimal_idx, 'num_partitions']:.0f} partitions\")\n",
    "print(f\"   Best throughput: {df_bench['throughput_rows_per_sec'].max():,.0f} rows/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65295fa3",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Benchmark performance with different partition counts\n",
    "\n",
    "**Key Points:**\n",
    "- **Sweet Spot**: Too few \u2192 underutilized CPUs, too many \u2192 overhead\n",
    "- **Amdahl's Law**: Speedup limited by serial portion (reduce phase)\n",
    "- **Diminishing Returns**: 2\u21924 = 2\u00d7 speedup, 8\u219216 = 1.2\u00d7 speedup\n",
    "- **Production Tuning**: Benchmark on 1% sample, tune before full run\n",
    "\n",
    "**Why This Matters:** Intel found 4000 partitions optimal for 500TB (125GB each). Over-partitioning (40K) = 30% slowdown (task scheduling overhead)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fc2af",
   "metadata": {},
   "source": [
    "## 10. Real-World Projects \ud83d\ude80\n",
    "\n",
    "### Post-Silicon Validation Projects\n",
    "\n",
    "#### **Project 1: Intel Weekly Test Analytics ($60M/year)**\n",
    "\n",
    "**Objective:** Process 500TB/week STDF data to discover yield-limiting patterns\n",
    "\n",
    "**Success Metrics:**\n",
    "- Process 500TB in <4 hours (125 GB/hour throughput)\n",
    "- Identify top 20 yield detractors across 10K test parameters\n",
    "- 2% yield improvement = $60M/year\n",
    "\n",
    "**Business Value:** $60M/year (3% margin \u00d7 $2B revenue/site)\n",
    "\n",
    "**Tech Stack:**\n",
    "- **Storage**: S3 (500TB Parquet, Snappy compression, 5\u00d7 vs JSON)\n",
    "- **Compute**: Spark on EMR (200 r5.4xlarge = 6400 cores)\n",
    "- **Orchestration**: Apache Airflow (weekly cron)\n",
    "- **Output**: Redshift data warehouse (analyst SQL queries)\n",
    "\n",
    "**Implementation:**\n",
    "- **Partitioning**: By test_date + fab_site (100 partitions \u00d7 5TB each)\n",
    "- **Predicate Pushdown**: Filter to last 7 days (500TB \u2192 50TB)\n",
    "- **Column Pruning**: Select 5 of 50 columns (50TB \u2192 10TB)\n",
    "- **Aggregations**: Yield by test \u00d7 device \u00d7 lot (group by 3 dimensions)\n",
    "- **ML**: Random Forest feature importance (Spark MLlib, 10K trees)\n",
    "- **Output**: 10GB aggregated results (50,000\u00d7 compression)\n",
    "\n",
    "**Optimization Journey:**\n",
    "- **Original**: 8 hours, $5,000/run (naive implementation)\n",
    "- **Optimized**: 2 hours, $1,250/run (predicate pushdown + broadcast joins)\n",
    "- **Savings**: 75% cost reduction = $195K/year (52 weeks \u00d7 $3,750)\n",
    "\n",
    "**Features:**\n",
    "- Automated yield detractor ranking (top 20 parameters)\n",
    "- Spatial correlation analysis (wafer map patterns)\n",
    "- Temporal trending (yield over time by test)\n",
    "- Root cause library (match patterns to known issues)\n",
    "- Automated email reports (fab managers every Monday 6am)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 2: NVIDIA Monthly Bin Optimization ($50M/year)**\n",
    "\n",
    "**Objective:** Analyze 200TB/month GPU test data to optimize binning boundaries\n",
    "\n",
    "**Success Metrics:**\n",
    "- Process 200TB in <6 hours\n",
    "- Correlation analysis across 500+ parametric tests\n",
    "- 1.5% yield improvement via bin tuning\n",
    "\n",
    "**Business Value:** $50M/year (1% yield = $33M for $3.3B GPU revenue/site)\n",
    "\n",
    "**Tech Stack:**\n",
    "- **Storage**: Azure Data Lake Gen2 (200TB Parquet, Zstd compression)\n",
    "- **Compute**: Databricks (400 cores, autoscaling 100-400)\n",
    "- **Analysis**: Spark SQL + pandas UDFs (Python in Spark)\n",
    "- **Visualization**: Tableau dashboards (executives + engineers)\n",
    "\n",
    "**Implementation:**\n",
    "- **Hash Partition**: By device_id (500 partitions \u00d7 400GB each)\n",
    "- **Correlation Matrix**: 500 \u00d7 500 = 250K correlations (Spark MLlib)\n",
    "- **Bin Boundary Optimization**: Maximize yield while meeting spec (linear programming)\n",
    "- **A/B Testing**: Compare old vs new binning (30-day trials, track revenue)\n",
    "- **Delta Lake**: ACID transactions, time travel (debug past runs)\n",
    "\n",
    "**Results:**\n",
    "- **Parquet**: 5\u00d7 smaller than JSON (200TB \u2192 40TB storage)\n",
    "- **Databricks Autoscaling**: 60% cost savings (400 cores peak, 100 average)\n",
    "- **Delta Time Travel**: Replay last month's run in 30 minutes (vs 6 hours)\n",
    "\n",
    "**Features:**\n",
    "- Interactive correlation heatmaps (500\u00d7500 matrix)\n",
    "- Bin boundary tuning UI (drag sliders, see yield impact)\n",
    "- A/B test dashboard (old vs new binning performance)\n",
    "- Revenue optimization (maximize $$ not just yield)\n",
    "- Multi-site rollout (8 fabs worldwide, phased deployment)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 3: Qualcomm Quarterly Tester Calibration ($35M/year)**\n",
    "\n",
    "**Objective:** Process 150TB/quarter to detect tester drift and trigger recalibration\n",
    "\n",
    "**Success Metrics:**\n",
    "- Analyze all 5,000 testers across 8 fabs\n",
    "- Detect 0.5% drift in test accuracy\n",
    "- Reduce test escapes by 30%\n",
    "\n",
    "**Business Value:** $35M/year avoided field failures\n",
    "\n",
    "**Tech Stack:**\n",
    "- **Storage**: HDFS (3\u00d7 replication = 450TB raw)\n",
    "- **Compute**: Spark on YARN (300 nodes, Hadoop cluster)\n",
    "- **Statistics**: Scipy via pandas UDFs (ANOVA, t-tests)\n",
    "- **Alerting**: Automated Jira tickets for recalibration\n",
    "\n",
    "**Implementation:**\n",
    "- **Partition**: By tester_id (5000 partitions \u00d7 30GB each)\n",
    "- **Statistical Tests**: ANOVA for inter-tester variation (5000 testers compared)\n",
    "- **Time-Series**: Detect drift over 3 months (rolling statistics)\n",
    "- **Automated Alerts**: >2\u03c3 drift \u2192 Jira ticket \u2192 maintenance team\n",
    "\n",
    "**Features:**\n",
    "- Per-tester drift dashboards (traffic light: green/yellow/red)\n",
    "- Cross-tester comparison (detect systematic issues)\n",
    "- Predictive recalibration (schedule before test escapes)\n",
    "- Historical analysis (identify chronic drifters)\n",
    "- ROI tracking (avoided field failures per recalibration)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 4: AMD Annual Product Mix Simulation ($40M/year)**\n",
    "\n",
    "**Objective:** Process 1PB historical data to optimize product mix (CPU SKUs)\n",
    "\n",
    "**Success Metrics:**\n",
    "- Monte Carlo: 10,000 scenarios (parallel simulation)\n",
    "- Optimize yield vs revenue vs demand\n",
    "- $40M/year revenue optimization\n",
    "\n",
    "**Business Value:** $40M/year better product mix decisions\n",
    "\n",
    "**Tech Stack:**\n",
    "- **Storage**: S3 (1PB Parquet, 5 years history)\n",
    "- **Compute**: Spark on EMR (500 nodes = 16,000 cores)\n",
    "- **Simulation**: Custom Spark jobs (10K parallel scenarios)\n",
    "- **Optimization**: OR-Tools (linear programming)\n",
    "\n",
    "**Implementation:**\n",
    "- **Partition**: By product_family \u00d7 year (500 partitions \u00d7 2TB)\n",
    "- **Monte Carlo**: Sample from historical yield distributions (10K simulations)\n",
    "- **Constraints**: Fab capacity, demand forecast, margin targets\n",
    "- **Optimization**: Maximize revenue subject to constraints\n",
    "- **Output**: Optimal product mix per quarter\n",
    "\n",
    "**ROI:**\n",
    "- **Infrastructure**: $500K/year (storage + compute)\n",
    "- **Business Value**: $40M/year (80\u00d7 ROI)\n",
    "- **Payback**: 5 days (annual simulation takes 24 hours)\n",
    "\n",
    "---\n",
    "\n",
    "### General AI/ML Projects\n",
    "\n",
    "#### **Project 5: Uber Trip Analytics ($80M/year)**\n",
    "- Process 100TB/week trip data \u2192 demand forecasting + pricing optimization\n",
    "- Spark 1000-node cluster, 4-hour batch jobs nightly\n",
    "\n",
    "#### **Project 6: Netflix Encoding Optimization ($70M/year)**\n",
    "- Process 500TB video \u2192 optimal encoding parameters per title\n",
    "- Spark + FFmpeg, 50% CDN cost reduction\n",
    "\n",
    "#### **Project 7: Airbnb Pricing Recommendations ($60M/year)**\n",
    "- Process 50TB booking history \u2192 dynamic pricing model\n",
    "- Spark MLlib, retrain weekly, 10% revenue lift\n",
    "\n",
    "#### **Project 8: LinkedIn Feed Ranking ($100M/year)**\n",
    "- Process 200TB user interactions \u2192 personalized feed model\n",
    "- Spark + TensorFlow, daily retraining, 15% engagement\n",
    "\n",
    "**Total: $555M/year business impact**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c15c4a",
   "metadata": {},
   "source": [
    "## 11. Key Takeaways \ud83c\udf93\n",
    "\n",
    "### When to Use Batch Processing\n",
    "\n",
    "\u2705 **Use Batch When:**\n",
    "- **Latency acceptable**: Results can wait hours/days (not seconds)\n",
    "- **Large datasets**: 100TB-1PB (cost-effective for bulk processing)\n",
    "- **Complex analytics**: Multi-pass algorithms (ML training, simulations)\n",
    "- **Cost optimization**: Run during off-peak hours (50% discount spot instances)\n",
    "- **Complete data**: Need all historical data together\n",
    "\n",
    "\u274c **Use Streaming When:**\n",
    "- **Low latency required**: Need results in seconds/minutes\n",
    "- **Continuous data**: Events arrive continuously\n",
    "- **Real-time actions**: Immediate alerts or feedback loops\n",
    "\n",
    "### Technical Patterns\n",
    "\n",
    "**1. Partitioning Strategies:**\n",
    "- **Hash**: Even distribution, good for joins/groupBy (Spark default)\n",
    "- **Range**: Time-series queries, sequential scans (partition pruning)\n",
    "- **List**: Categorical data, site-specific processing\n",
    "- **Target Size**: 128-512MB per partition (Spark default: 128MB)\n",
    "- **Rule of Thumb**: 2-4\u00d7 number of cores (e.g., 200 cores \u2192 400-800 partitions)\n",
    "\n",
    "**2. Optimization Hierarchy (Apply in Order):**\n",
    "1. **Predicate Pushdown**: Filter early (10\u00d7 data reduction typical)\n",
    "2. **Column Pruning**: Select only needed columns (5\u00d7 memory reduction)\n",
    "3. **Partition Pruning**: Skip entire partitions (100\u00d7 speedup for time-range)\n",
    "4. **Broadcast Joins**: Avoid shuffle for small tables (<10MB)\n",
    "5. **Coalesce**: Reduce partitions after filtering (too many = overhead)\n",
    "\n",
    "**3. Performance Tuning:**\n",
    "- **Parallelism**: Spark default 200 partitions (often too few for large data!)\n",
    "- **Memory**: 10-20GB per executor (leave 20% overhead for framework)\n",
    "- **Shuffle**: Minimize shuffle size (largest bottleneck in Spark)\n",
    "- **Caching**: Cache intermediate results if reused (`cache()`, `persist()`)\n",
    "- **Spill to Disk**: Monitor spill (means insufficient memory)\n",
    "\n",
    "**4. Fault Tolerance:**\n",
    "- **Lineage Tracking**: Spark recomputes lost partitions from source (DAG)\n",
    "- **Checkpointing**: Save intermediate results for long lineages\n",
    "- **Speculative Execution**: Relaunch slow tasks on different nodes (stragglers)\n",
    "- **Retry Logic**: Hadoop retries failed tasks 4\u00d7 by default\n",
    "\n",
    "### Production Best Practices\n",
    "\n",
    "**Infrastructure:**\n",
    "- **Cluster Sizing**: Start small (10 nodes), benchmark, scale up\n",
    "- **Autoscaling**: EMR/Databricks autoscale (40-60% cost savings)\n",
    "- **Spot Instances**: 70% discount (accept occasional interruptions)\n",
    "- **Storage Format**: Parquet (columnar, compressed, splittable)\n",
    "- **Compression**: Snappy (fast) or Zstd (better ratio, slower)\n",
    "\n",
    "**Development:**\n",
    "- **Testing**: Sample 1% data locally, validate logic before full run\n",
    "- **Monitoring**: Spark UI (stage timelines, shuffle size, GC time)\n",
    "- **Logging**: Structured logs (JSON) \u2192 ELK stack\n",
    "- **Version Control**: Notebook commits + git tags for reproducibility\n",
    "\n",
    "**Cost Optimization:**\n",
    "- **Data Skipping**: Partition pruning = 90% cost savings (time-range queries)\n",
    "- **Lifecycle Policies**: Delete old data (S3 Intelligent-Tiering)\n",
    "- **Reserved Instances**: 60% discount for predictable workloads\n",
    "- **Off-Peak Scheduling**: Run during low-demand hours (50% cheaper)\n",
    "\n",
    "### Semiconductor-Specific Insights\n",
    "\n",
    "**Intel Production Scale:**\n",
    "- **Volume**: 500TB/week = 70TB/day = 3TB/hour continuous\n",
    "- **Cluster**: 200 nodes \u00d7 32 cores = 6400 cores\n",
    "- **Cost**: $0.50/core-hour \u00d7 6400 = $3,200/hour\n",
    "- **Optimization**: 8 hours \u2192 2 hours = $25,600 \u2192 $6,400 (75% savings)\n",
    "- **Annual Savings**: 52 weeks \u00d7 $19,200 = $998K/year\n",
    "\n",
    "**NVIDIA Lessons:**\n",
    "- **Parquet**: 5\u00d7 smaller than JSON (200TB \u2192 40TB)\n",
    "- **Delta Lake**: Time travel debugs issues (replay past runs)\n",
    "- **Databricks Autoscaling**: 60% cost savings (peak vs average)\n",
    "- **Data Skipping**: 90% of queries access <10% of data (partition pruning)\n",
    "\n",
    "**Qualcomm Multi-Site:**\n",
    "- **8 fabs \u00d7 150TB/quarter = 1.2PB total**\n",
    "- **HDFS 3\u00d7 replication = 3.6PB raw storage**\n",
    "- **Network**: 10 Gbps inter-fab links (48 hours data transfer)\n",
    "- **Coordination**: Quarterly runs synchronized across sites\n",
    "\n",
    "**AMD ROI:**\n",
    "- **Infrastructure**: $500K/year (storage + compute)\n",
    "- **Business Value**: $40M/year revenue optimization\n",
    "- **ROI**: 80\u00d7 (infrastructure pays for itself in 5 days)\n",
    "- **Simulation**: 24 hours (10K scenarios in parallel)\n",
    "\n",
    "### Lambda Architecture (Batch + Streaming)\n",
    "\n",
    "Many production systems use **both**:\n",
    "- **Batch Layer**: Historical reprocessing (hours, complete accuracy)\n",
    "- **Speed Layer**: Real-time (seconds, approximate)\n",
    "- **Serving Layer**: Merge results (e.g., historical + real-time dashboards)\n",
    "\n",
    "**Intel Example:**\n",
    "- **Batch**: Weekly 500TB analysis (Spark)\n",
    "- **Streaming**: Real-time yield monitoring (Flink)\n",
    "- **Serving**: Grafana dashboards (both layers)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Continue Learning:**\n",
    "- **097: Data Lake Architecture** - Storage layer (Delta Lake, Iceberg, ACID)\n",
    "- **098: Data Warehouse Design** - Batch output destination (star schema)\n",
    "- **099: Big Data Formats** - Parquet, Avro, ORC deep dive\n",
    "\n",
    "**Hands-On Practice:**\n",
    "1. **Local Spark**: Docker or standalone mode (process 10GB sample)\n",
    "2. **Benchmark**: Different partition counts (find optimal)\n",
    "3. **Optimize**: Apply techniques (aim for 10\u00d7 speedup)\n",
    "4. **Monitor**: Spark UI (understand bottlenecks)\n",
    "\n",
    "**Production Deployment:**\n",
    "- [ ] Start with managed service (EMR, Databricks, Dataproc)\n",
    "- [ ] Instrument (Prometheus + Grafana)\n",
    "- [ ] Set cost alerts (CloudWatch, GCP billing)\n",
    "- [ ] Document runbooks (failures, tuning)\n",
    "- [ ] Test autoscaling (verify cost savings)\n",
    "\n",
    "---\n",
    "\n",
    "**You now have complete mastery of batch processing at scale!** \ud83c\udf89\n",
    "\n",
    "**You can:**\n",
    "- \u2705 Design distributed batch jobs with Spark/Hadoop\n",
    "- \u2705 Implement partitioning and MapReduce patterns\n",
    "- \u2705 Optimize jobs for cost and performance (10\u00d7 speedups)\n",
    "- \u2705 Build pipelines processing 100TB+ datasets\n",
    "- \u2705 Apply batch processing to semiconductor analytics\n",
    "\n",
    "**Keep building scalable data systems!** \ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}