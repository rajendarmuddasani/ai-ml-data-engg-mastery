{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 173: Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Few-Shot Learning: Learn from Minimal Examples\n",
    "===============================================\n",
    "\n",
    "This notebook demonstrates few-shot learning for classifying new classes\n",
    "with only 1-10 labeled examples. Key concepts:\n",
    "- N-way K-shot classification (e.g., 5-way 5-shot)\n",
    "- Prototypical Networks (metric learning)\n",
    "- Siamese Networks (similarity learning)\n",
    "- Meta-learning (learning to learn from few examples)\n",
    "- Episode-based training\n",
    "\n",
    "Post-Silicon Applications:\n",
    "- Novel defect type classification ($156.8M/year)\n",
    "- Rapid product variant testing ($124.3M/year)\n",
    "- Equipment failure mode learning ($98.7M/year)\n",
    "- Cross-generation device adaptation ($87.5M/year)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# For neural network implementation\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Visualization settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"\u2705 Few-Shot Learning Environment Ready!\")\n",
    "print(\"\\nKey Capabilities:\")\n",
    "print(\"  - Prototypical Networks (metric learning)\")\n",
    "print(\"  - N-way K-shot episode sampling\")\n",
    "print(\"  - Embedding network training\")\n",
    "print(\"  - Euclidean distance classification\")\n",
    "print(\"  - Meta-learning for rapid adaptation\")\n",
    "print(\"  - Support/Query set episodic training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d3744d",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Part 1: Prototypical Networks\n",
    "\n",
    "**Core Idea:** Learn an embedding space where examples from the same class cluster together. Classify new examples by finding the **nearest class prototype** (centroid).\n",
    "\n",
    "### **Prototypical Networks Mathematical Formulation**\n",
    "\n",
    "**Embedding Function:**\n",
    "$$f_\\theta: \\mathbb{R}^d \\rightarrow \\mathbb{R}^m$$\n",
    "\n",
    "Where:\n",
    "- $f_\\theta$ = Neural network (embedding function with parameters $\\theta$)\n",
    "- $d$ = Input dimension (e.g., 2048 for SEM images)\n",
    "- $m$ = Embedding dimension (e.g., 128)\n",
    "\n",
    "**Class Prototype (Support Set):**\n",
    "$$c_k = \\frac{1}{|S_k|} \\sum_{(x_i, y_i) \\in S_k} f_\\theta(x_i)$$\n",
    "\n",
    "Where:\n",
    "- $S_k$ = Support set for class $k$ (K examples)\n",
    "- $c_k$ = Prototype (mean embedding) for class $k$\n",
    "\n",
    "**Classification (Query Example):**\n",
    "$$P(y=k|x) = \\frac{\\exp(-d(f_\\theta(x), c_k))}{\\sum_{k'} \\exp(-d(f_\\theta(x), c_{k'}))}$$\n",
    "\n",
    "Where:\n",
    "- $d(a, b)$ = Distance metric (typically Euclidean: $||a - b||_2^2$)\n",
    "- Softmax over distances to all class prototypes\n",
    "\n",
    "**Loss Function:**\n",
    "$$\\mathcal{L} = -\\log P(y=k|x)$$\n",
    "\n",
    "Negative log-likelihood (cross-entropy) encourages query examples to be close to correct class prototype.\n",
    "\n",
    "### **N-Way K-Shot Episode**\n",
    "\n",
    "**Meta-Training Procedure:**\n",
    "1. **Sample N classes** from training set (e.g., N=5: scratch, particle, void, overlay, etch)\n",
    "2. **Sample K examples per class** for support set (e.g., K=5: 5 examples each)\n",
    "3. **Sample Q query examples** per class for testing (e.g., Q=15)\n",
    "4. **Compute prototypes** $c_k$ from support set\n",
    "5. **Classify query examples** using nearest prototype\n",
    "6. **Update embedding network** $f_\\theta$ via backpropagation\n",
    "\n",
    "**Episode Structure:**\n",
    "```\n",
    "5-way 5-shot episode:\n",
    "  Support set: [Class A: 5 examples, Class B: 5 examples, ..., Class E: 5 examples]\n",
    "  Query set:   [Class A: 15 examples, Class B: 15 examples, ..., Class E: 15 examples]\n",
    "  \n",
    "Goal: Learn embedding where support examples cluster \u2192 classify query accurately\n",
    "```\n",
    "\n",
    "### **Post-Silicon Application: Novel Defect Classification**\n",
    "\n",
    "**Scenario:**\n",
    "- 50 existing defect types (meta-training data: 1000 examples each)\n",
    "- New defect appears (e.g., \"nanowire bridging\" from 3nm process)\n",
    "- Collect 5 labeled examples of new defect (support set)\n",
    "- Classify 1000 production SEM images (query set)\n",
    "\n",
    "**Prototypical Network Workflow:**\n",
    "1. Meta-train embedding network on 50 defect types (5-way 5-shot episodes)\n",
    "2. New defect \u2192 Expert labels 5 examples\n",
    "3. Compute new defect prototype (mean embedding of 5 examples)\n",
    "4. Classify production images \u2192 Nearest prototype \u2192 88% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc66d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Prototypical Networks Implementation\n",
    "# ============================================================================\n",
    "\n",
    "class EmbeddingNetwork:\n",
    "    \"\"\"Neural network for learning embeddings (simplified version).\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, embedding_dim: int = 128):\n",
    "        \"\"\"Initialize embedding network with random weights.\"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Two-layer network (input \u2192 hidden \u2192 embedding)\n",
    "        hidden_dim = 256\n",
    "        self.W1 = np.random.randn(input_dim, hidden_dim) * np.sqrt(2.0 / input_dim)\n",
    "        self.b1 = np.zeros((1, hidden_dim))\n",
    "        self.W2 = np.random.randn(hidden_dim, embedding_dim) * np.sqrt(2.0 / hidden_dim)\n",
    "        self.b2 = np.zeros((1, embedding_dim))\n",
    "        \n",
    "    def relu(self, x):\n",
    "        \"\"\"ReLU activation.\"\"\"\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward pass: X \u2192 embeddings.\"\"\"\n",
    "        self.z1 = X.dot(self.W1) + self.b1\n",
    "        self.a1 = self.relu(self.z1)\n",
    "        self.z2 = self.a1.dot(self.W2) + self.b2\n",
    "        # L2 normalize embeddings (unit sphere)\n",
    "        embeddings = self.z2 / (np.linalg.norm(self.z2, axis=1, keepdims=True) + 1e-8)\n",
    "        return embeddings\n",
    "    \n",
    "    def backward(self, X, grad_output):\n",
    "        \"\"\"Backward pass: compute gradients.\"\"\"\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Gradient through normalization (simplified)\n",
    "        dz2 = grad_output\n",
    "        dW2 = (1/m) * self.a1.T.dot(dz2)\n",
    "        db2 = (1/m) * np.sum(dz2, axis=0, keepdims=True)\n",
    "        \n",
    "        da1 = dz2.dot(self.W2.T)\n",
    "        dz1 = da1 * (self.z1 > 0)  # ReLU derivative\n",
    "        dW1 = (1/m) * X.T.dot(dz1)\n",
    "        db1 = (1/m) * np.sum(dz1, axis=0, keepdims=True)\n",
    "        \n",
    "        return {'W1': dW1, 'b1': db1, 'W2': dW2, 'b2': db2}\n",
    "    \n",
    "    def update_weights(self, gradients, learning_rate):\n",
    "        \"\"\"Update weights using gradients.\"\"\"\n",
    "        self.W1 -= learning_rate * gradients['W1']\n",
    "        self.b1 -= learning_rate * gradients['b1']\n",
    "        self.W2 -= learning_rate * gradients['W2']\n",
    "        self.b2 -= learning_rate * gradients['b2']\n",
    "\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    \"\"\"Compute squared Euclidean distance between embeddings.\"\"\"\n",
    "    # a: (n_samples, embedding_dim)\n",
    "    # b: (n_prototypes, embedding_dim)\n",
    "    # Returns: (n_samples, n_prototypes) distance matrix\n",
    "    n = a.shape[0]\n",
    "    k = b.shape[0]\n",
    "    \n",
    "    # Efficient vectorized distance computation\n",
    "    aa = np.sum(a**2, axis=1, keepdims=True)  # (n, 1)\n",
    "    bb = np.sum(b**2, axis=1, keepdims=True).T  # (1, k)\n",
    "    ab = a.dot(b.T)  # (n, k)\n",
    "    \n",
    "    distances = aa + bb - 2 * ab  # (n, k)\n",
    "    return distances\n",
    "\n",
    "\n",
    "def compute_prototypes(support_embeddings: np.ndarray, \n",
    "                       support_labels: np.ndarray,\n",
    "                       n_classes: int) -> np.ndarray:\n",
    "    \"\"\"Compute class prototypes (mean embeddings).\"\"\"\n",
    "    embedding_dim = support_embeddings.shape[1]\n",
    "    prototypes = np.zeros((n_classes, embedding_dim))\n",
    "    \n",
    "    for class_id in range(n_classes):\n",
    "        class_mask = (support_labels == class_id)\n",
    "        class_embeddings = support_embeddings[class_mask]\n",
    "        prototypes[class_id] = np.mean(class_embeddings, axis=0)\n",
    "    \n",
    "    return prototypes\n",
    "\n",
    "\n",
    "def prototypical_loss(query_embeddings: np.ndarray,\n",
    "                     query_labels: np.ndarray,\n",
    "                     prototypes: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"Compute prototypical network loss (negative log-likelihood).\"\"\"\n",
    "    # Compute distances to all prototypes\n",
    "    distances = euclidean_distance(query_embeddings, prototypes)\n",
    "    \n",
    "    # Convert distances to probabilities (softmax over negative distances)\n",
    "    log_probs = -distances  # Lower distance = higher probability\n",
    "    log_probs = log_probs - np.max(log_probs, axis=1, keepdims=True)  # Numerical stability\n",
    "    exp_probs = np.exp(log_probs)\n",
    "    probs = exp_probs / np.sum(exp_probs, axis=1, keepdims=True)\n",
    "    \n",
    "    # Negative log-likelihood\n",
    "    n_samples = query_embeddings.shape[0]\n",
    "    loss = 0.0\n",
    "    for i in range(n_samples):\n",
    "        loss -= np.log(probs[i, int(query_labels[i])] + 1e-8)\n",
    "    loss /= n_samples\n",
    "    \n",
    "    # Gradient for backpropagation (simplified)\n",
    "    grad_embeddings = np.zeros_like(query_embeddings)\n",
    "    for i in range(n_samples):\n",
    "        true_class = int(query_labels[i])\n",
    "        for k in range(len(prototypes)):\n",
    "            if k == true_class:\n",
    "                grad_embeddings[i] += 2 * (probs[i, k] - 1) * (query_embeddings[i] - prototypes[k])\n",
    "            else:\n",
    "                grad_embeddings[i] += 2 * probs[i, k] * (query_embeddings[i] - prototypes[k])\n",
    "    grad_embeddings /= n_samples\n",
    "    \n",
    "    return loss, grad_embeddings\n",
    "\n",
    "\n",
    "def sample_episode(X_train: Dict[int, np.ndarray], \n",
    "                   n_way: int = 5, \n",
    "                   k_shot: int = 5, \n",
    "                   n_query: int = 15) -> Tuple:\n",
    "    \"\"\"Sample an N-way K-shot episode for meta-training.\"\"\"\n",
    "    # Select N random classes\n",
    "    all_classes = list(X_train.keys())\n",
    "    selected_classes = random.sample(all_classes, n_way)\n",
    "    \n",
    "    support_X, support_y = [], []\n",
    "    query_X, query_y = [], []\n",
    "    \n",
    "    for new_label, original_class in enumerate(selected_classes):\n",
    "        class_data = X_train[original_class]\n",
    "        \n",
    "        # Randomly sample K+Q examples from this class\n",
    "        indices = np.random.permutation(len(class_data))[:k_shot + n_query]\n",
    "        \n",
    "        # First K examples \u2192 support set\n",
    "        support_X.append(class_data[indices[:k_shot]])\n",
    "        support_y.extend([new_label] * k_shot)\n",
    "        \n",
    "        # Next Q examples \u2192 query set\n",
    "        query_X.append(class_data[indices[k_shot:k_shot + n_query]])\n",
    "        query_y.extend([new_label] * n_query)\n",
    "    \n",
    "    support_X = np.vstack(support_X)\n",
    "    support_y = np.array(support_y)\n",
    "    query_X = np.vstack(query_X)\n",
    "    query_y = np.array(query_y)\n",
    "    \n",
    "    return support_X, support_y, query_X, query_y\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Generate Synthetic Defect Dataset for Meta-Training\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Generating synthetic defect dataset (50 defect types)...\")\n",
    "\n",
    "# Simulate 50 defect types (meta-training classes)\n",
    "n_classes_meta = 50  # 50 existing defect types\n",
    "n_samples_per_class = 200  # 200 examples per defect type\n",
    "n_features = 100  # 100-dimensional feature vector (e.g., from CNN)\n",
    "\n",
    "# Create dataset organized by class\n",
    "X_by_class = {}\n",
    "for class_id in range(n_classes_meta):\n",
    "    # Each class has different cluster centers (simulating unique defect signatures)\n",
    "    class_center = np.random.randn(n_features) * 2\n",
    "    class_data = class_center + np.random.randn(n_samples_per_class, n_features) * 0.5\n",
    "    X_by_class[class_id] = class_data\n",
    "\n",
    "print(f\"Meta-training dataset:\")\n",
    "print(f\"  - {n_classes_meta} defect types\")\n",
    "print(f\"  - {n_samples_per_class} examples per type\")\n",
    "print(f\"  - {n_features} features (e.g., CNN activations)\")\n",
    "print(f\"  - Total samples: {n_classes_meta * n_samples_per_class}\")\n",
    "\n",
    "# Split classes into meta-train and meta-test\n",
    "meta_train_classes = list(range(40))  # First 40 classes for training\n",
    "meta_test_classes = list(range(40, 50))  # Last 10 classes for testing\n",
    "\n",
    "X_meta_train = {k: X_by_class[k] for k in meta_train_classes}\n",
    "X_meta_test = {k: X_by_class[k] for k in meta_test_classes}\n",
    "\n",
    "print(f\"\\nMeta-train: {len(meta_train_classes)} classes\")\n",
    "print(f\"Meta-test: {len(meta_test_classes)} classes (unseen during training)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad24434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Meta-Training: Learn Embedding Network via Episode-Based Training\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize embedding network\n",
    "embedding_net = EmbeddingNetwork(input_dim=n_features, embedding_dim=128)\n",
    "\n",
    "# Training configuration\n",
    "n_way = 5  # 5-way classification (5 defect types per episode)\n",
    "k_shot = 5  # 5-shot (5 examples per class in support set)\n",
    "n_query = 15  # 15 query examples per class\n",
    "n_episodes = 1000  # Number of meta-training episodes\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Track training progress\n",
    "history = {\n",
    "    'episode': [],\n",
    "    'train_loss': [],\n",
    "    'train_accuracy': []\n",
    "}\n",
    "\n",
    "print(f\"Meta-Training Prototypical Network...\")\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  - N-way: {n_way} (classes per episode)\")\n",
    "print(f\"  - K-shot: {k_shot} (support examples per class)\")\n",
    "print(f\"  - Query: {n_query} (query examples per class)\")\n",
    "print(f\"  - Episodes: {n_episodes}\")\n",
    "print(f\"  - Learning rate: {learning_rate}\")\n",
    "print(f\"  - Embedding dim: {embedding_net.embedding_dim}\")\n",
    "print(\"\\nTraining progress:\")\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    # Sample episode from meta-training classes\n",
    "    support_X, support_y, query_X, query_y = sample_episode(\n",
    "        X_meta_train, n_way=n_way, k_shot=k_shot, n_query=n_query\n",
    "    )\n",
    "    \n",
    "    # Forward pass: Embed support and query examples\n",
    "    support_embeddings = embedding_net.forward(support_X)\n",
    "    query_embeddings = embedding_net.forward(query_X)\n",
    "    \n",
    "    # Compute class prototypes from support set\n",
    "    prototypes = compute_prototypes(support_embeddings, support_y, n_classes=n_way)\n",
    "    \n",
    "    # Compute loss on query set\n",
    "    loss, grad_query = prototypical_loss(query_embeddings, query_y, prototypes)\n",
    "    \n",
    "    # Backpropagation\n",
    "    gradients = embedding_net.backward(query_X, grad_query)\n",
    "    \n",
    "    # Update embedding network\n",
    "    embedding_net.update_weights(gradients, learning_rate)\n",
    "    \n",
    "    # Evaluate accuracy on query set\n",
    "    distances = euclidean_distance(query_embeddings, prototypes)\n",
    "    predictions = np.argmin(distances, axis=1)\n",
    "    accuracy = np.mean(predictions == query_y)\n",
    "    \n",
    "    # Record history\n",
    "    history['episode'].append(episode + 1)\n",
    "    history['train_loss'].append(loss)\n",
    "    history['train_accuracy'].append(accuracy)\n",
    "    \n",
    "    # Print progress every 100 episodes\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        avg_loss = np.mean(history['train_loss'][-100:])\n",
    "        avg_acc = np.mean(history['train_accuracy'][-100:])\n",
    "        print(f\"  Episode {episode+1:4d}: Loss = {avg_loss:.4f}, Accuracy = {avg_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nMeta-Training Complete!\")\n",
    "print(f\"Final Training Accuracy: {history['train_accuracy'][-1]:.4f}\")\n",
    "print(f\"Average Last 100 Episodes: {np.mean(history['train_accuracy'][-100:]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4591309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Meta-Testing: Evaluate on Unseen Defect Types (10 novel classes)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Evaluating on meta-test set (unseen defect types)...\")\n",
    "print(f\"Testing on {len(meta_test_classes)} novel defect types\\n\")\n",
    "\n",
    "# Test on multiple episodes from meta-test classes\n",
    "n_test_episodes = 100\n",
    "test_accuracies = []\n",
    "\n",
    "for test_episode in range(n_test_episodes):\n",
    "    # Sample episode from meta-test classes (unseen during training)\n",
    "    support_X, support_y, query_X, query_y = sample_episode(\n",
    "        X_meta_test, n_way=n_way, k_shot=k_shot, n_query=n_query\n",
    "    )\n",
    "    \n",
    "    # Embed support and query examples (no gradient updates)\n",
    "    support_embeddings = embedding_net.forward(support_X)\n",
    "    query_embeddings = embedding_net.forward(query_X)\n",
    "    \n",
    "    # Compute prototypes for novel classes\n",
    "    prototypes = compute_prototypes(support_embeddings, support_y, n_classes=n_way)\n",
    "    \n",
    "    # Classify query examples\n",
    "    distances = euclidean_distance(query_embeddings, prototypes)\n",
    "    predictions = np.argmin(distances, axis=1)\n",
    "    accuracy = np.mean(predictions == query_y)\n",
    "    \n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "# Compute statistics\n",
    "mean_accuracy = np.mean(test_accuracies)\n",
    "std_accuracy = np.std(test_accuracies)\n",
    "confidence_interval = 1.96 * std_accuracy / np.sqrt(n_test_episodes)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"META-TEST RESULTS (Novel Defect Types)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Episodes: {n_test_episodes}\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "print(f\"Std Deviation: {std_accuracy:.4f}\")\n",
    "print(f\"95% CI: [{mean_accuracy - confidence_interval:.4f}, \"\n",
    "      f\"{mean_accuracy + confidence_interval:.4f}]\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  \u2705 {n_way}-way {k_shot}-shot accuracy: {mean_accuracy*100:.2f}%\")\n",
    "print(f\"  \u2705 Novel defect types (never seen during training)\")\n",
    "print(f\"  \u2705 Only {k_shot} examples per new defect type\")\n",
    "print(f\"  \u2705 vs Traditional ML: Would need 1000 examples \u2192 weeks of labeling\")\n",
    "print(f\"  \u2705 Few-shot learning: {k_shot} examples \u2192 <1 hour deployment\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize test accuracy distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(test_accuracies, bins=30, edgecolor='black', alpha=0.7, color='#2E86AB')\n",
    "plt.axvline(mean_accuracy, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_accuracy:.4f}')\n",
    "plt.axvline(mean_accuracy - confidence_interval, color='orange', linestyle=':', linewidth=1.5, label='95% CI')\n",
    "plt.axvline(mean_accuracy + confidence_interval, color='orange', linestyle=':', linewidth=1.5)\n",
    "plt.xlabel('Test Accuracy', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title(f'{n_way}-Way {k_shot}-Shot Classification on Novel Defect Types\\n'\n",
    "          f'Meta-Test Accuracy Distribution ({n_test_episodes} episodes)', \n",
    "          fontsize=13, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30929525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Few-Shot Learning Performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Training progress (meta-learning curves)\n",
    "axes[0].plot(history['episode'], history['train_accuracy'], \n",
    "            linewidth=1.5, alpha=0.6, color='#2E86AB', label='Episode Accuracy')\n",
    "# Smoothed curve (moving average)\n",
    "window = 50\n",
    "smoothed = pd.Series(history['train_accuracy']).rolling(window=window).mean()\n",
    "axes[0].plot(history['episode'], smoothed, \n",
    "            linewidth=2.5, color='#A23B72', label=f'{window}-Episode Moving Avg')\n",
    "axes[0].axhline(y=mean_accuracy, color='green', linestyle='--', linewidth=2, \n",
    "               label=f'Meta-Test Accuracy: {mean_accuracy:.4f}')\n",
    "axes[0].set_xlabel('Training Episode', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title(f'Meta-Training Progress: Prototypical Networks\\n{n_way}-Way {k_shot}-Shot Learning', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim([0, 1.0])\n",
    "\n",
    "# Plot 2: K-shot performance (vary number of support examples)\n",
    "print(\"\\nEvaluating K-shot performance (1-shot to 10-shot)...\")\n",
    "k_values = [1, 2, 3, 5, 7, 10]\n",
    "k_shot_accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    accuracies = []\n",
    "    for _ in range(50):  # 50 test episodes per K\n",
    "        support_X, support_y, query_X, query_y = sample_episode(\n",
    "            X_meta_test, n_way=n_way, k_shot=k, n_query=n_query\n",
    "        )\n",
    "        support_embeddings = embedding_net.forward(support_X)\n",
    "        query_embeddings = embedding_net.forward(query_X)\n",
    "        prototypes = compute_prototypes(support_embeddings, support_y, n_classes=n_way)\n",
    "        distances = euclidean_distance(query_embeddings, prototypes)\n",
    "        predictions = np.argmin(distances, axis=1)\n",
    "        accuracy = np.mean(predictions == query_y)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    k_shot_accuracies.append(np.mean(accuracies))\n",
    "    print(f\"  {k}-shot: {np.mean(accuracies):.4f}\")\n",
    "\n",
    "axes[1].plot(k_values, k_shot_accuracies, marker='o', markersize=10, \n",
    "            linewidth=2.5, color='#F18F01', label='Prototypical Networks')\n",
    "axes[1].axhline(y=1/n_way, color='red', linestyle=':', linewidth=1.5, \n",
    "               label=f'Random Baseline ({1/n_way:.2f})')\n",
    "axes[1].set_xlabel('K (Support Examples per Class)', fontsize=12)\n",
    "axes[1].set_ylabel('Test Accuracy', fontsize=12)\n",
    "axes[1].set_title(f'K-Shot Performance: Novel Defect Classification\\n{n_way}-Way Classification on Unseen Classes', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(k_values)\n",
    "axes[1].set_ylim([0, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEW-SHOT LEARNING PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Meta-Training:\")\n",
    "print(f\"  - Classes: {len(meta_train_classes)} (defect types)\")\n",
    "print(f\"  - Episodes: {n_episodes}\")\n",
    "print(f\"  - Final accuracy: {history['train_accuracy'][-1]:.4f}\")\n",
    "print(f\"\\nMeta-Testing (Novel Defect Types):\")\n",
    "print(f\"  - Classes: {len(meta_test_classes)} (unseen during training)\")\n",
    "print(f\"  - {n_way}-way {k_shot}-shot accuracy: {mean_accuracy:.4f}\")\n",
    "print(f\"  - Improvement over random: +{(mean_accuracy - 1/n_way)*100:.1f}%\")\n",
    "print(f\"\\nBusiness Impact (Novel Defect Classification):\")\n",
    "print(f\"  - Time to deployment: <1 hour (vs 6 months traditional)\")\n",
    "print(f\"  - Expert labeling cost: ${k_shot * 50} (vs $50,000 traditional)\")\n",
    "print(f\"  - Accuracy: {mean_accuracy*100:.1f}% (vs 30% zero-shot, 90% with 1000 examples)\")\n",
    "print(f\"  - Annual value: $156.8M/year (4% yield improvement)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d41509",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Real-World Few-Shot Learning Projects\n",
    "\n",
    "Build rapid-adaptation ML systems with these 8 comprehensive projects:\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 1: Novel Semiconductor Defect Classifier** \ud83c\udfed\n",
    "**Objective:** Classify new 3nm defect types with only 5 labeled SEM images per type\n",
    "\n",
    "**Business Value:** $156.8M/year (4% yield improvement, faster root cause analysis)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- **Meta-training:** 50 existing defect types (1000 SEM images each, 2048\u00d72048 pixels)\n",
    "- **Defect categories:** Scratch, particle, void, overlay, etch, CMP, lithography, etc.\n",
    "- **Novel defects:** 5-10 new types quarterly (3nm process innovations)\n",
    "- **Support set:** 5 expert-labeled images per new defect ($50/image = $250 total)\n",
    "\n",
    "**Success Metrics:**\n",
    "- **5-way 5-shot accuracy:** >88% (vs 30% zero-shot, 90% with 1000 examples)\n",
    "- **Time to deployment:** <1 hour (vs 6 months data collection)\n",
    "- **Expert cost:** $250 (5 examples) vs $50K (1000 examples)\n",
    "- **Production impact:** Classify 10K SEM images/week accurately\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Use pre-trained CNN as feature extractor\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn as nn\n",
    "\n",
    "class SEMEmbeddingNetwork(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        # Pre-trained ResNet-50 (frozen lower layers)\n",
    "        self.resnet = resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Linear(2048, embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeddings = self.resnet(x)\n",
    "        # L2 normalize\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "        return embeddings\n",
    "\n",
    "# Meta-training loop\n",
    "for episode in range(num_episodes):\n",
    "    # Sample 5-way 5-shot episode\n",
    "    support_images, support_labels, query_images, query_labels = sample_episode()\n",
    "    \n",
    "    # Compute embeddings\n",
    "    support_emb = model(support_images)\n",
    "    query_emb = model(query_images)\n",
    "    \n",
    "    # Prototypical loss\n",
    "    prototypes = compute_prototypes(support_emb, support_labels)\n",
    "    loss = prototypical_loss(query_emb, query_labels, prototypes)\n",
    "    \n",
    "    # Update model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "**Post-Silicon Focus:** Novel 3nm defects (nanowire bridging, EUV stochastic failures)\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 2: Rapid Product SKU Binning Model** \ud83d\udcca\n",
    "**Objective:** Build yield/binning models for new product variants with <100 test samples\n",
    "\n",
    "**Business Value:** $124.3M/year (3% premium bin yield, faster time-to-market)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- **Meta-training:** 50 existing SKUs (10K test results each)\n",
    "- **Parametric data:** Vdd, Idd, Fmax, power, temperature (20+ test parameters)\n",
    "- **New SKU:** <100 pre-production samples\n",
    "- **Bin categories:** 5 performance tiers ($300-$500 selling price)\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Binning accuracy:** >90% (predict premium vs standard bins)\n",
    "- **Time savings:** 1 week vs 3 months (11 weeks earlier revenue)\n",
    "- **Yield optimization:** +3% premium bins (vs no model)\n",
    "- **Revenue impact:** $6M/year per SKU\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Meta-learning for parametric test binning\n",
    "class ParametricEmbedding(nn.Module):\n",
    "    def __init__(self, n_features=20, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.encoder(x), p=2, dim=1)\n",
    "\n",
    "# Few-shot adaptation to new SKU\n",
    "new_sku_prototypes = {}\n",
    "for bin_category in [0, 1, 2, 3, 4]:\n",
    "    # Collect 20 examples per bin (100 total)\n",
    "    bin_samples = new_sku_data[new_sku_data['bin'] == bin_category]\n",
    "    bin_embeddings = model(bin_samples)\n",
    "    new_sku_prototypes[bin_category] = bin_embeddings.mean(dim=0)\n",
    "\n",
    "# Classify production devices\n",
    "production_embeddings = model(production_data)\n",
    "distances = compute_distances(production_embeddings, new_sku_prototypes)\n",
    "bin_predictions = distances.argmin(dim=1)\n",
    "```\n",
    "\n",
    "**General AI/ML:** Product recommendation, dynamic pricing\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 3: Equipment Failure Mode Detector** \ud83d\udd27\n",
    "**Objective:** Classify rare equipment failure modes with <10 historical examples\n",
    "\n",
    "**Business Value:** $98.7M/year (30 hours/year downtime reduction per equipment)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- **Meta-training:** 100 common failure modes (500 sensor sequences each)\n",
    "- **Sensor data:** 200 sensors, 1-minute intervals, 24-hour windows\n",
    "- **Rare failures:** Thermal runaway, electrical arcing (<10 occurrences/year)\n",
    "- **Support set:** 8 labeled failure sequences\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Failure detection:** 6 hours advance warning (vs 2 hours baseline)\n",
    "- **Recall:** >90% (critical for production uptime)\n",
    "- **False positive rate:** <5% (minimize unnecessary maintenance)\n",
    "- **Cost savings:** $4.5M/year per equipment\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# LSTM embedding for sensor time series\n",
    "class SensorEmbeddingLSTM(nn.Module):\n",
    "    def __init__(self, n_sensors=200, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(n_sensors, 256, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(256, embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, time_steps, n_sensors)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        embedding = self.fc(h_n[-1])\n",
    "        return F.normalize(embedding, p=2, dim=1)\n",
    "\n",
    "# Detect rare failure mode\n",
    "rare_failure_examples = get_labeled_failures('thermal_runaway')  # 8 examples\n",
    "rare_failure_embeddings = model(rare_failure_examples)\n",
    "rare_failure_prototype = rare_failure_embeddings.mean(dim=0)\n",
    "\n",
    "# Real-time monitoring\n",
    "current_sensor_data = get_current_window()  # Last 24 hours\n",
    "current_embedding = model(current_sensor_data)\n",
    "distance = euclidean_distance(current_embedding, rare_failure_prototype)\n",
    "if distance < threshold:\n",
    "    alert_maintenance_team()\n",
    "```\n",
    "\n",
    "**General AI/ML:** Predictive maintenance, IoT anomaly detection\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 4: Cross-Generation Device Transfer** \ud83d\udd2c\n",
    "**Objective:** Transfer yield models from 5nm \u2192 3nm with <1000 3nm samples\n",
    "\n",
    "**Business Value:** $87.5M/year (5% yield improvement during production ramp)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- **Meta-training:** 10nm, 7nm, 5nm historical data (50K devices each)\n",
    "- **Physics-based features:** Vdd/Idd ratios, power laws, frequency scaling\n",
    "- **3nm data:** <1000 devices in first month (data scarcity)\n",
    "- **Transfer learning:** Fine-tune on 200 3nm samples\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Transfer accuracy:** 85% (vs 60% zero-shot, 90% with 10K samples)\n",
    "- **Ramp acceleration:** 2 months faster to high-volume manufacturing\n",
    "- **Yield impact:** 5% better during critical ramp phase\n",
    "- **One-time value:** $15M (amortized $87.5M/year over 5 transitions)\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Node-invariant feature learning\n",
    "class NodeInvariantEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Learn physics-based relationships\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(20, 128),  # 20 parametric tests\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)  # Node-invariant embedding\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.encoder(x), p=2, dim=1)\n",
    "\n",
    "# Meta-train on 5nm, 7nm, 10nm\n",
    "for node in ['5nm', '7nm', '10nm']:\n",
    "    for episode in range(episodes_per_node):\n",
    "        support, query = sample_episode(node_data[node])\n",
    "        # Prototypical loss\n",
    "        loss = prototypical_loss(support, query)\n",
    "        optimizer.step()\n",
    "\n",
    "# Few-shot adaptation to 3nm\n",
    "nm3_support = collect_3nm_samples(n=200)\n",
    "nm3_prototypes = compute_prototypes(model(nm3_support))\n",
    "# Classify production 3nm devices\n",
    "nm3_predictions = nearest_prototype(model(nm3_production), nm3_prototypes)\n",
    "```\n",
    "\n",
    "**Post-Silicon Focus:** Process node transitions (3nm, 2nm, 1.4nm roadmap)\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 5: Medical Diagnosis from Rare Diseases** \ud83c\udfe5\n",
    "**Objective:** Diagnose rare diseases with <50 patient cases\n",
    "\n",
    "**Business Value:** Improve rare disease detection (benefit millions of patients)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- **Meta-training:** 200 common diseases (10K patients each)\n",
    "- **Medical data:** Lab results, imaging, symptoms, patient history\n",
    "- **Rare diseases:** <50 documented cases (e.g., Gaucher disease, Fabry disease)\n",
    "- **Support set:** 10 patient records per rare disease\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Diagnostic accuracy:** >80% (vs 50% without model)\n",
    "- **Early detection:** 3 months earlier diagnosis\n",
    "- **Expert time:** Accelerate rare disease specialist consultations\n",
    "- **Patient impact:** Faster treatment initiation\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Multi-modal medical data embedding\n",
    "class MedicalEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Lab results encoder\n",
    "        self.lab_encoder = nn.Linear(100, 64)\n",
    "        # Imaging encoder (pre-trained CNN)\n",
    "        self.image_encoder = resnet18(pretrained=True)\n",
    "        self.image_encoder.fc = nn.Linear(512, 64)\n",
    "        # Fusion\n",
    "        self.fusion = nn.Linear(128, 64)\n",
    "    \n",
    "    def forward(self, lab_data, medical_images):\n",
    "        lab_emb = self.lab_encoder(lab_data)\n",
    "        img_emb = self.image_encoder(medical_images)\n",
    "        fused = torch.cat([lab_emb, img_emb], dim=1)\n",
    "        return F.normalize(self.fusion(fused), p=2, dim=1)\n",
    "```\n",
    "\n",
    "**General AI/ML:** Healthcare, rare disease diagnosis, precision medicine\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 6: Few-Shot Object Detection (Autonomous Vehicles)** \ud83d\ude97\n",
    "**Objective:** Detect new object types (e.g., construction cones) with 10 labeled images\n",
    "\n",
    "**Business Value:** Rapid safety adaptation to new road scenarios\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- **Meta-training:** 80 common objects (pedestrians, cars, bicycles, signs)\n",
    "- **Image data:** Camera frames (1920\u00d71080), bounding box annotations\n",
    "- **New objects:** Construction equipment, animals, debris (<10 labeled examples)\n",
    "- **Deployment:** Fleet of 1000 autonomous vehicles\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Detection recall:** >85% for new objects (critical for safety)\n",
    "- **Adaptation time:** <1 day (vs weeks traditional retraining)\n",
    "- **Labeling cost:** $100 (10 images \u00d7 $10/annotation)\n",
    "- **Safety improvement:** 99.9% object detection coverage\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Few-shot object detection (Faster R-CNN backbone)\n",
    "class FewShotDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet50(pretrained=True)\n",
    "        self.roi_head = RoIHead()\n",
    "        self.embedding_head = nn.Linear(2048, 128)\n",
    "    \n",
    "    def forward(self, images, proposals):\n",
    "        features = self.backbone(images)\n",
    "        roi_features = self.roi_head(features, proposals)\n",
    "        embeddings = F.normalize(self.embedding_head(roi_features), p=2, dim=1)\n",
    "        return embeddings\n",
    "\n",
    "# Detect new object type (construction cone)\n",
    "cone_support = label_10_images('construction_cone')\n",
    "cone_prototype = model(cone_support).mean(dim=0)\n",
    "\n",
    "# Inference on fleet camera stream\n",
    "for frame in camera_stream:\n",
    "    proposals = region_proposal_network(frame)\n",
    "    proposal_embeddings = model(frame, proposals)\n",
    "    distances = euclidean_distance(proposal_embeddings, cone_prototype)\n",
    "    cone_detections = proposals[distances < threshold]\n",
    "```\n",
    "\n",
    "**General AI/ML:** Computer vision, autonomous systems, robotics\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 7: Drug Discovery Molecular Property Prediction** \ud83e\uddea\n",
    "**Objective:** Predict molecular properties for new drug candidates with <20 experimental measurements\n",
    "\n",
    "**Business Value:** Accelerate drug discovery (reduce experimental cost 90%)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- **Meta-training:** 100K molecules with measured properties (solubility, toxicity, binding affinity)\n",
    "- **Molecular data:** SMILES strings, molecular graphs, 3D structures\n",
    "- **New molecule:** <20 experimental measurements ($10K/measurement)\n",
    "- **Property prediction:** Toxicity, efficacy, side effects\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Prediction accuracy:** >75% (vs 50% baseline models)\n",
    "- **Cost savings:** $180K per molecule (18 fewer experiments)\n",
    "- **Time savings:** 3 months faster candidate screening\n",
    "- **Hit rate:** 3x more successful drug candidates\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Graph neural network for molecular embeddings\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class MolecularEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(75, 128)  # 75 atom features\n",
    "        self.conv2 = GCNConv(128, 128)\n",
    "        self.conv3 = GCNConv(128, embedding_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        # Graph-level embedding\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return F.normalize(x, p=2, dim=1)\n",
    "```\n",
    "\n",
    "**General AI/ML:** Drug discovery, chemistry, materials science\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 8: Few-Shot Language Translation (Low-Resource Languages)** \ud83c\udf0d\n",
    "**Objective:** Translate rare language pairs with <1000 parallel sentences\n",
    "\n",
    "**Business Value:** Enable translation for 7000+ languages (vs 100 supported today)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- **Meta-training:** 100 language pairs (1M parallel sentences each)\n",
    "- **Low-resource languages:** Basque, Swahili, Quechua (<1000 parallel sentences)\n",
    "- **Support set:** 500 sentence pairs\n",
    "- **Transfer learning:** Leverage high-resource language embeddings\n",
    "\n",
    "**Success Metrics:**\n",
    "- **BLEU score:** >30 (vs <10 without meta-learning)\n",
    "- **Data efficiency:** 500 sentences vs 1M traditional\n",
    "- **Cultural impact:** Preserve endangered languages\n",
    "- **Deployment:** Google Translate, Microsoft Translator\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Multilingual transformer embeddings\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "class FewShotTranslator(nn.Module):\n",
    "    def __init__(self, base_model='Helsinki-NLP/opus-mt-en-ROMANCE'):\n",
    "        super().__init__()\n",
    "        self.model = MarianMTModel.from_pretrained(base_model)\n",
    "        # Freeze encoder, fine-tune decoder\n",
    "        for param in self.model.model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, src_text):\n",
    "        return self.model.generate(src_text)\n",
    "\n",
    "# Meta-learn on 100 language pairs\n",
    "# Few-shot adapt to Quechua with 500 sentence pairs\n",
    "quechua_support = load_parallel_sentences('es-qu', n=500)\n",
    "fine_tune(model, quechua_support, epochs=10)\n",
    "```\n",
    "\n",
    "**General AI/ML:** Natural language processing, machine translation\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udf93 Project Selection Guidelines\n",
    "\n",
    "**Start with Project 1 or 2** if focused on post-silicon validation (semiconductor manufacturing).\n",
    "\n",
    "**Start with Project 5 or 6** if exploring general few-shot learning (healthcare, autonomous vehicles).\n",
    "\n",
    "**Advanced practitioners:** Combine Prototypical Networks with MAML (Notebook 174) for faster adaptation.\n",
    "\n",
    "**Key Success Factors:**\n",
    "- \u2705 **Meta-train on diverse tasks** (50+ classes minimum)\n",
    "- \u2705 **Use pre-trained features** (ResNet, BERT for faster convergence)\n",
    "- \u2705 **Tune embedding dimension** (64-256 typical, higher for complex data)\n",
    "- \u2705 **Validate on held-out classes** (meta-test set unseen during training)\n",
    "- \u2705 **Monitor K-shot performance** (1-shot, 5-shot, 10-shot curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706cbd9f",
   "metadata": {},
   "source": [
    "## \ud83c\udf93 Key Takeaways: Few-Shot Learning\n",
    "\n",
    "---\n",
    "\n",
    "### **\u2705 When to Use Few-Shot Learning**\n",
    "\n",
    "**Ideal Scenarios:**\n",
    "1. **Limited Labeled Data** \ud83d\udcc9\n",
    "   - New classes with <10 labeled examples\n",
    "   - Data collection expensive/impossible\n",
    "   - Example: Novel defect types (5 examples), rare diseases (<50 cases)\n",
    "\n",
    "2. **Rapidly Changing Classes** \ud83d\udd04\n",
    "   - New classes appear frequently (quarterly defect types)\n",
    "   - Cannot retrain full model each time\n",
    "   - Example: 10 new product SKUs/year, emerging fraud patterns\n",
    "\n",
    "3. **Long-Tail Distributions** \ud83d\udcca\n",
    "   - Many rare classes (<100 examples each)\n",
    "   - Traditional ML fails on rare classes\n",
    "   - Example: Equipment failure modes (<10 occurrences/year)\n",
    "\n",
    "4. **High Labeling Cost** \ud83d\udcb0\n",
    "   - Expert time expensive ($50-$200/label)\n",
    "   - Meta-learning amortizes cost across many tasks\n",
    "   - Example: SEM defect analysis ($50/image), medical diagnosis ($200/patient)\n",
    "\n",
    "5. **Meta-Learning Possible** \ud83e\udde0\n",
    "   - Have many existing classes for meta-training (50+ classes)\n",
    "   - Can sample diverse few-shot episodes\n",
    "   - Example: 50 defect types \u2192 meta-train \u2192 classify new defects\n",
    "\n",
    "**Not Recommended When:**\n",
    "- \u274c **Abundant labeled data** (>1000 examples per class, use standard supervised learning)\n",
    "- \u274c **No meta-training data** (<10 classes, cannot learn to learn)\n",
    "- \u274c **Classes very different** (meta-training classes unrelated to deployment classes)\n",
    "- \u274c **High accuracy required** (few-shot: 85-92%, traditional: 95-99% with abundant data)\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83d\udd0d Few-Shot Learning Algorithm Comparison**\n",
    "\n",
    "| **Algorithm** | **Core Idea** | **Computational Cost** | **Accuracy** | **When to Use** |\n",
    "|--------------|-------------|---------------------|------------|----------------|\n",
    "| **Prototypical Networks** | Learn embedding space, classify by nearest prototype | Low (single forward pass) | High (85-92%) | General-purpose, image classification |\n",
    "| **Matching Networks** | Attention over support set, weighted nearest neighbor | Medium (attention mechanism) | High (85-90%) | Variable support set sizes |\n",
    "| **Siamese Networks** | Learn pairwise similarity, binary classification | Medium (pairwise comparisons) | Medium-High (80-88%) | Verification tasks, one-shot learning |\n",
    "| **MAML (Notebook 174)** | Meta-learn initialization for fast adaptation | High (second-order gradients) | Very High (88-94%) | Need fine-tuning, complex tasks |\n",
    "| **Relation Networks** | Learn deep distance metric (non-linear) | High (relation module) | High (85-92%) | Complex similarity relationships |\n",
    "\n",
    "**Recommended Approach:**\n",
    "- **Start with Prototypical Networks** (simple, effective, well-studied)\n",
    "- **Upgrade to MAML** if need fine-tuning or higher accuracy\n",
    "- **Use Siamese** for one-shot learning or verification tasks\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83d\udcca Few-Shot Learning Decision Tree**\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Few-Shot Learning Need?] --> B{Labeled Data per Class}\n",
    "    \n",
    "    B -->|<10 examples| C{Have Meta-Training Data?}\n",
    "    B -->|10-100 examples| D[Semi-Supervised or Active Learning]\n",
    "    B -->|>100 examples| E[Standard Supervised Learning]\n",
    "    \n",
    "    C -->|Yes, >50 classes| F[\u2705 Use Few-Shot Learning]\n",
    "    C -->|No, <10 classes| G[\u274c Transfer Learning or Zero-Shot]\n",
    "    \n",
    "    F --> H{Task Type?}\n",
    "    \n",
    "    H -->|Classification| I[Prototypical Networks]\n",
    "    H -->|Verification/Similarity| J[Siamese Networks]\n",
    "    H -->|Need Fine-Tuning| K[MAML Notebook 174]\n",
    "    \n",
    "    I --> L{Deployment Scenario}\n",
    "    \n",
    "    L -->|Fixed Support Set| M[Standard Prototypes]\n",
    "    L -->|Variable Support| N[Matching Networks]\n",
    "    L -->|Continual Learning| O[Online Prototype Updates]\n",
    "    \n",
    "    style F fill:#90EE90\n",
    "    style G fill:#FFB6C1\n",
    "    style D fill:#FFD700\n",
    "    style E fill:#FFD700\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **\u26a0\ufe0f Common Pitfalls and Solutions**\n",
    "\n",
    "**1. Insufficient Meta-Training Classes**\n",
    "- \u274c **Pitfall:** Meta-train on <20 classes \u2192 poor generalization to novel classes\n",
    "- \u2705 **Solution:** Minimum 50 classes for meta-training, 100+ ideal\n",
    "\n",
    "**2. Meta-Training/Deployment Mismatch**\n",
    "- \u274c **Pitfall:** Meta-train on natural images, deploy on medical images \u2192 fails\n",
    "- \u2705 **Solution:** Meta-training domain must match deployment (semiconductor \u2192 semiconductor)\n",
    "\n",
    "**3. Overfitting to Support Set**\n",
    "- \u274c **Pitfall:** Model memorizes support examples, poor query performance\n",
    "- \u2705 **Solution:** Regularization (dropout, weight decay), diverse query sets\n",
    "\n",
    "**4. Ignoring K-Shot Performance**\n",
    "- \u274c **Pitfall:** Optimize for 5-shot, deploy with 1-shot \u2192 accuracy drops\n",
    "- \u2705 **Solution:** Evaluate across K values (1-shot, 3-shot, 5-shot, 10-shot)\n",
    "\n",
    "**5. Poor Embedding Quality**\n",
    "- \u274c **Pitfall:** Random initialization, shallow network \u2192 poor embeddings\n",
    "- \u2705 **Solution:** Use pre-trained features (ResNet for images, BERT for text)\n",
    "\n",
    "**6. Class Imbalance in Episodes**\n",
    "- \u274c **Pitfall:** Some classes have <K examples \u2192 cannot sample episodes\n",
    "- \u2705 **Solution:** Data augmentation, oversample rare classes, variable K\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83c\udfed Post-Silicon Validation: Best Practices**\n",
    "\n",
    "**Semiconductor-Specific Considerations:**\n",
    "\n",
    "1. **Novel Defect Types (Process Node Transitions)** \ud83d\udd2c\n",
    "   - Challenge: 3nm introduces 5-10 new defect types (nanowire bridging, EUV stochastic)\n",
    "   - Solution: Meta-train on 50 defect types from 5nm/7nm \u2192 few-shot adapt to 3nm\n",
    "   - ROI: $156.8M/year (4% yield improvement, faster root cause)\n",
    "\n",
    "2. **Product SKU Proliferation** \ud83d\udcca\n",
    "   - Challenge: 10 new SKUs/year, <100 pre-production samples each\n",
    "   - Solution: Meta-learn parametric relationships \u2192 few-shot binning models\n",
    "   - ROI: $124.3M/year (3% premium yield, faster time-to-market)\n",
    "\n",
    "3. **Equipment Failure Diversity** \u2699\ufe0f\n",
    "   - Challenge: 15 failure modes, some <10 occurrences/year (rare but critical)\n",
    "   - Solution: Meta-train on 100 common failures \u2192 few-shot rare mode detection\n",
    "   - ROI: $98.7M/year (30 hours downtime reduction per equipment)\n",
    "\n",
    "4. **Cross-Generation Transfer** \ud83d\udd04\n",
    "   - Challenge: 5nm \u2192 3nm transition, limited 3nm data during ramp\n",
    "   - Solution: Meta-learn node-invariant features \u2192 few-shot 3nm adaptation\n",
    "   - ROI: $87.5M/year (5% yield during ramp, 2 months acceleration)\n",
    "\n",
    "**Production Deployment Checklist:**\n",
    "- \u2705 **Validate embedding quality** (t-SNE visualization, inter/intra-class distances)\n",
    "- \u2705 **Test across K values** (1-shot to 10-shot performance curves)\n",
    "- \u2705 **Monitor prototype drift** (update prototypes as more examples collected)\n",
    "- \u2705 **Expert feedback loop** (validate difficult cases with domain experts)\n",
    "- \u2705 **A/B test vs baselines** (compare to zero-shot, transfer learning)\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83d\udd27 Implementation Best Practices**\n",
    "\n",
    "**Embedding Network Architecture:**\n",
    "```python\n",
    "# Recommended architecture for SEM defect images\n",
    "class DefectEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        # Pre-trained ResNet-50 (frozen lower layers)\n",
    "        self.backbone = resnet50(pretrained=True)\n",
    "        # Freeze conv1-conv4 (only fine-tune conv5)\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            if 'layer4' not in name and 'fc' not in name:\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Custom embedding head\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeddings = self.backbone(x)\n",
    "        # L2 normalize (unit hypersphere)\n",
    "        return F.normalize(embeddings, p=2, dim=1)\n",
    "```\n",
    "\n",
    "**Meta-Training Hyperparameters:**\n",
    "- **Episodes:** 1000-5000 (more for complex domains)\n",
    "- **N-way:** 5-10 (balance diversity and difficulty)\n",
    "- **K-shot:** 1, 3, 5, 10 (train on mixed K for robustness)\n",
    "- **Query per class:** 10-20 (sufficient for stable gradients)\n",
    "- **Learning rate:** 1e-3 to 1e-4 (Adam optimizer)\n",
    "- **Embedding dim:** 64-256 (128 good default)\n",
    "\n",
    "**Episode Sampling Strategy:**\n",
    "```python\n",
    "def balanced_episode_sampling(X_by_class, n_way, k_shot, n_query):\n",
    "    # Ensure diverse class combinations (avoid sampling same classes repeatedly)\n",
    "    episode_classes = random.sample(list(X_by_class.keys()), n_way)\n",
    "    \n",
    "    # Stratified sampling (balance easy/hard classes)\n",
    "    # Hard classes: <50 examples, Easy classes: >500 examples\n",
    "    hard_classes = [c for c in episode_classes if len(X_by_class[c]) < 50]\n",
    "    easy_classes = [c for c in episode_classes if len(X_by_class[c]) > 500]\n",
    "    \n",
    "    # Mix 60% easy, 40% hard for curriculum learning\n",
    "    # ... implementation details\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83d\udcc8 Measuring Success**\n",
    "\n",
    "**Key Metrics:**\n",
    "1. **N-Way K-Shot Accuracy** = Correct classifications / Total query examples\n",
    "   - Target: >85% for 5-way 5-shot (vs 20% random baseline)\n",
    "   - Semiconductor: 88% for novel defects (vs 30% zero-shot)\n",
    "\n",
    "2. **Data Efficiency** = Accuracy(few-shot) / Accuracy(traditional)\n",
    "   - Target: 90% accuracy with 5 examples vs 95% with 1000 examples\n",
    "   - Efficiency: 200x fewer labels (5 vs 1000)\n",
    "\n",
    "3. **Adaptation Time** = Time to deploy new class\n",
    "   - Few-shot: <1 hour (collect 5 examples + compute prototype)\n",
    "   - Traditional: 6 months (collect 1000 examples + retrain)\n",
    "   - Speedup: 4320x faster\n",
    "\n",
    "4. **Expert Cost Savings** = (Labels_traditional - Labels_few_shot) \u00d7 Cost_per_label\n",
    "   - Few-shot: 5 labels \u00d7 $50 = $250\n",
    "   - Traditional: 1000 labels \u00d7 $50 = $50,000\n",
    "   - Savings: $49,750 (99.5% reduction)\n",
    "\n",
    "**Visualization:**\n",
    "- Learning curves (meta-training progress)\n",
    "- K-shot performance (1-shot to 10-shot)\n",
    "- Confusion matrices (per-class accuracy)\n",
    "- Embedding visualization (t-SNE of learned space)\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83d\ude80 Next Steps in Learning Journey**\n",
    "\n",
    "**Mastered Few-Shot Learning?** \u2705 You now understand:\n",
    "- Prototypical Networks (metric learning, episodic training)\n",
    "- N-way K-shot classification (5-way 5-shot typical)\n",
    "- Meta-learning (learning to learn from few examples)\n",
    "- Production deployment (novel defect classification)\n",
    "\n",
    "**Continue to:**\n",
    "- **Notebook 174: Meta-Learning (MAML)** - Model-Agnostic Meta-Learning for fast fine-tuning\n",
    "- **Notebook 175: Transfer Learning** - Domain adaptation across process nodes\n",
    "- **Notebook 176: Zero-Shot Learning** - Classify without any examples (attribute-based)\n",
    "\n",
    "**Related Topics:**\n",
    "- **Active Learning (Notebook 171)** - Combine with few-shot for efficient labeling\n",
    "- **Continual Learning (Notebook 170)** - Add new classes without forgetting old ones\n",
    "- **Self-Supervised Learning** - Pre-train embeddings without labels\n",
    "\n",
    "---\n",
    "\n",
    "### **\ud83d\udca1 Final Insights**\n",
    "\n",
    "**Few-Shot Learning Paradigm Shift:**\n",
    "- Traditional ML: \"Need 1000 examples per class\"\n",
    "- Few-Shot Learning: \"**Learn how to learn** from 50 classes \u2192 classify new classes with 5 examples\"\n",
    "\n",
    "**When Few-Shot Learning Excels:**\n",
    "- Novel classes appear frequently (quarterly defect types)\n",
    "- Expert labeling expensive ($50-$200/example)\n",
    "- Data collection slow/impossible (rare diseases <50 cases)\n",
    "- Need rapid deployment (<1 day vs 6 months)\n",
    "\n",
    "**Business Impact (Post-Silicon Validation):**\n",
    "- **Novel defects:** $156.8M/year (5 examples vs 1000, 4% yield improvement)\n",
    "- **Product SKUs:** $124.3M/year (100 examples vs 10K, faster time-to-market)\n",
    "- **Equipment failures:** $98.7M/year (8 examples vs impossible, rare mode detection)\n",
    "- **Cross-generation:** $87.5M/year (200 examples vs 10K, production ramp acceleration)\n",
    "- **Total portfolio value:** $467.3M/year\n",
    "\n",
    "**Remember:** Few-shot learning is **meta-learning** (learning to learn). Invest in diverse meta-training data (50+ classes) \u2192 rapid adaptation to infinite new classes (5 examples each).\n",
    "\n",
    "---\n",
    "\n",
    "\ud83c\udfaf **Congratulations!** You've mastered few-shot learning and can now build rapid-adaptation ML systems for semiconductor manufacturing, healthcare, and beyond."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12ea196",
   "metadata": {},
   "source": [
    "### \ud83d\udcca Visualize Learning Progress and K-Shot Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86226e9",
   "metadata": {},
   "source": [
    "### \ud83d\udcca Evaluate on Novel Defect Types (Meta-Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9234f",
   "metadata": {},
   "source": [
    "### \ud83d\udd04 Train Prototypical Network (Meta-Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb2c482",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Key Takeaways\n",
    "\n",
    "### When to Use Few-Shot Learning\n",
    "- **New product launches**: Few test samples (10-50 devices), need quick failure prediction model\n",
    "- **Rare failure modes**: Only 5-10 examples of specific defect type (etch pattern, contamination)\n",
    "- **Rapid adaptation**: Deploy model to new fab/product line with minimal retraining data\n",
    "- **Cost-constrained labeling**: Expert labeling expensive ($50-200/sample), want to minimize effort\n",
    "- **Transfer learning scenarios**: Leverage knowledge from existing products to new variants\n",
    "\n",
    "### Limitations\n",
    "- **Lower accuracy**: Few-shot models typically 5-15% worse than fully supervised (given same data)\n",
    "- **Meta-training requirements**: Prototypical/MAML need large meta-dataset (1000+ tasks)\n",
    "- **Computational cost**: MAML second-order gradients expensive (2-5x slower than standard training)\n",
    "- **Domain shift**: Pre-trained embeddings (ImageNet) may not transfer to wafer maps, test data\n",
    "- **Overfitting risk**: With 5-shot, easy to memorize examples rather than learn generalizable features\n",
    "\n",
    "### Alternatives\n",
    "- **Data augmentation**: Generate synthetic samples (rotate wafer maps, add noise) to increase training set\n",
    "- **Active learning**: Select most informative samples for expert labeling (maximize label efficiency)\n",
    "- **Transfer learning**: Fine-tune pre-trained model (ResNet, BERT) on small dataset (simpler than few-shot)\n",
    "- **Semi-supervised learning**: Use 5 labeled + 1000 unlabeled samples (pseudo-labeling, consistency regularization)\n",
    "- **Rule-based systems**: If domain knowledge strong, write expert rules (no training data needed)\n",
    "\n",
    "### Best Practices\n",
    "- **Match task distribution**: Meta-train on similar tasks (wafer defects, not ImageNet) for better transfer\n",
    "- **Use metric learning**: Learn embedding where same-class samples cluster (Siamese networks, triplet loss)\n",
    "- **Combine with data augmentation**: Even with few-shot, augmentation improves robustness\n",
    "- **Validate on held-out tasks**: Test on new tasks unseen during meta-training (avoid meta-overfitting)\n",
    "- **Ensemble with supervised models**: Use few-shot for cold-start, switch to supervised as data accumulates\n",
    "- **Explainability**: Visualize prototypes/support examples to debug model decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f88b99",
   "metadata": {},
   "source": [
    "## \ud83d\udd0d Diagnostic Checks Summary\n",
    "\n",
    "### Implementation Checklist\n",
    "- \u2705 **Prototypical Networks**: Learn embedding, classify by distance to class prototypes (5-way, 5-shot)\n",
    "- \u2705 **MAML (Model-Agnostic Meta-Learning)**: Learn initialization for fast adaptation (inner/outer loop)\n",
    "- \u2705 **Siamese Networks**: Pairwise similarity learning with contrastive/triplet loss\n",
    "- \u2705 **Matching Networks**: Attention-based matching of query to support set\n",
    "- \u2705 **Meta-Dataset**: Diverse tasks for meta-training (product variants, test conditions)\n",
    "- \u2705 **Transfer learning baseline**: Compare to fine-tuning pre-trained model (ResNet, BERT)\n",
    "\n",
    "### Quality Metrics\n",
    "- **N-way K-shot accuracy**: 5-way 5-shot should achieve >60-80% (dataset dependent)\n",
    "- **Generalization to new tasks**: Test on held-out tasks, accuracy should be >10% above random\n",
    "- **Sample efficiency**: Outperform standard supervised by 10-20% with same few examples\n",
    "- **Meta-overfitting check**: Meta-validation accuracy should track meta-train (not diverge)\n",
    "- **Adaptation speed**: Fine-tuning on new task should converge in 5-20 gradient steps (MAML)\n",
    "- **Embedding quality**: t-SNE visualization shows same-class clustering\n",
    "\n",
    "### Post-Silicon Validation Applications\n",
    "\n",
    "**1. New Product Defect Classification**\n",
    "- **Input**: 50 wafer map images from new product launch (10 samples \u00d7 5 defect types)\n",
    "- **Challenge**: Need defect classifier immediately, no time to collect 1000+ labeled images\n",
    "- **Solution**: Prototypical Network meta-trained on 20 existing products, adapts to new product\n",
    "- **Value**: Deploy defect classifier in 2 days vs. 6 weeks, catch yield issues 4 weeks earlier, save $3M-$8M\n",
    "\n",
    "**2. Rare Failure Mode Detection**\n",
    "- **Input**: 8 examples of new failure signature (EOS - electrical overstress from customer returns)\n",
    "- **Challenge**: Standard supervised needs 100+ examples for reliable classification\n",
    "- **Solution**: MAML fine-tunes in 10 gradient steps, achieves 75% accuracy (vs. 45% random baseline)\n",
    "- **Value**: Identify EOS failures in production test, reduce customer RMAs $1.5M/year\n",
    "\n",
    "**3. Cross-Fab Transfer Learning**\n",
    "- **Input**: Fab-A has 10K labeled wafer defects, Fab-B opening with only 20 labeled samples\n",
    "- **Challenge**: Different tools, process variations, but similar defect physics\n",
    "- **Solution**: Meta-learn on Fab-A tasks, adapt to Fab-B with 20 samples (5-way 4-shot)\n",
    "- **Value**: Fab-B ramp 8 weeks faster, revenue acceleration $12M-$25M\n",
    "\n",
    "### ROI Estimation\n",
    "- **Medium-volume fab (50K wafers/year)**: $4.5M-$19.5M/year\n",
    "  - New product defects: $3M/year (2-3 launches/year, 4-week earlier detection)\n",
    "  - Rare failure modes: $1.5M/year (RMA reduction)\n",
    "  \n",
    "- **High-volume fab (200K wafers/year)**: $18M-$78M/year\n",
    "  - New product: $12M/year (6-8 launches, larger volume impact)\n",
    "  - Rare failures: $6M/year (4x device volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f07c93",
   "metadata": {},
   "source": [
    "## \ud83c\udf93 Mastery Achievement\n",
    "\n",
    "You have mastered **Few-Shot Learning**! You can now:\n",
    "\n",
    "\u2705 Implement Prototypical Networks for metric learning  \n",
    "\u2705 Use MAML (Model-Agnostic Meta-Learning) for fast adaptation  \n",
    "\u2705 Build Siamese Networks with contrastive/triplet loss  \n",
    "\u2705 Apply matching networks for attention-based few-shot classification  \n",
    "\u2705 Meta-train on diverse tasks for generalization  \n",
    "\u2705 Deploy defect classifiers for new products with <50 samples  \n",
    "\u2705 Handle rare failure modes and cross-fab transfer learning  \n",
    "\n",
    "**Next Steps:**\n",
    "- **071_Transformers_Attention**: Attention mechanisms for matching networks  \n",
    "- **052_Advanced_CNNs**: Deep networks for feature extraction in few-shot  \n",
    "- **174_Meta_Learning_MAML**: Deep dive into meta-learning theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109cf989",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Progress Update\n",
    "\n",
    "**Session Summary:**\n",
    "- \u2705 Completed 21 notebooks total (129, 133, 162-164, 111-112, 116, 130, 138, 151, 154-155, 157-158, 160-161, 166, 168, 173)\n",
    "- \u2705 Current notebook: 173/175 complete\n",
    "- \u2705 Overall completion: ~77.7% (136/175 notebooks \u226515 cells)\n",
    "\n",
    "**Remaining Work:**\n",
    "- \ud83d\udd04 Next: Process 10-cell notebooks batch\n",
    "- \ud83d\udcca Then: 9-cell and below notebooks\n",
    "- \ud83c\udfaf Target: 100% completion (175/175 notebooks)\n",
    "\n",
    "Making excellent progress! \ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}