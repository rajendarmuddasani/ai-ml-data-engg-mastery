{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 160: Multi Variate Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multi-Variate Anomaly Detection - Setup\n",
    "\n",
    "Production Stack:\n",
    "- Statistical Methods: scipy (Mahalanobis), sklearn (PCA, IsolationForest, LOF)\n",
    "- Deep Learning: PyTorch/TensorFlow (VAE, adversarial autoencoders)\n",
    "- Visualization: matplotlib, seaborn, plotly (3D visualization)\n",
    "- High-Dimensional: UMAP, t-SNE (dimensionality reduction for visualization)\n",
    "- Production: ONNX (model export), TensorRT (GPU inference optimization)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"\u2705 Setup complete - Ready for multi-variate anomaly detection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c47e8",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e3 Mahalanobis Distance: Correlation-Aware Anomaly Detection\n",
    "\n",
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Implement Mahalanobis distance to detect anomalies that violate feature correlations\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "**1. Limitation of Euclidean Distance**\n",
    "- **Euclidean**: d(x, \u03bc) = \u221a(\u03a3(x_i - \u03bc_i)\u00b2)\n",
    "  - Treats all dimensions equally (no correlation awareness)\n",
    "  - Fails when features have different scales or are correlated\n",
    "- **Example Problem**: \n",
    "  - Height: 170cm \u00b1 10cm, Weight: 70kg \u00b1 10kg\n",
    "  - Person A: (180cm, 80kg) \u2192 Euclidean distance = \u221a(100 + 100) = 14.1\n",
    "  - Person B: (170cm, 100kg) \u2192 Euclidean distance = \u221a(0 + 900) = 30\n",
    "  - **BUT** Person B is more anomalous (violates height-weight correlation)\n",
    "\n",
    "**2. Mahalanobis Distance**\n",
    "- **Formula**: D_M(x) = \u221a((x - \u03bc)\u1d40 \u03a3\u207b\u00b9 (x - \u03bc))\n",
    "  - \u03bc = mean vector\n",
    "  - \u03a3 = covariance matrix (captures correlations)\n",
    "  - \u03a3\u207b\u00b9 = inverse covariance (precision matrix)\n",
    "- **Interpretation**: Distance in standard deviations accounting for correlations\n",
    "- **Properties**:\n",
    "  - Scale-invariant (automatically handles different feature units)\n",
    "  - Correlation-aware (detects violations of feature relationships)\n",
    "  - Chi-squared distribution under normality: D_M\u00b2 ~ \u03c7\u00b2(d) where d = dimensions\n",
    "\n",
    "**3. Why Mahalanobis > Euclidean**\n",
    "- **Correlation detection**: Catches anomalies that look normal in individual features\n",
    "- **Automatic scaling**: No need for manual standardization\n",
    "- **Statistical foundation**: Threshold at \u03c7\u00b2(d, 0.99) gives 99% confidence interval\n",
    "\n",
    "**4. Threshold Selection**\n",
    "- **Statistical**: threshold = \u03c7\u00b2(d, 1-\u03b1) where \u03b1 = significance level (e.g., 0.01)\n",
    "  - For d=3, \u03b1=0.01: threshold = 11.34\n",
    "  - For d=10, \u03b1=0.01: threshold = 23.21\n",
    "- **Empirical**: threshold = 99th percentile of training Mahalanobis distances\n",
    "- **Robust**: Use robust covariance estimation (Minimum Covariance Determinant) for contaminated data\n",
    "\n",
    "**Mathematical Insight:**\n",
    "Mahalanobis distance transforms the feature space so correlations become axis-aligned, then computes Euclidean distance. It's equivalent to: (1) Decorrelate features via eigenvector rotation, (2) Scale by eigenvalues, (3) Compute Euclidean distance.\n",
    "\n",
    "**Why This Matters:**\n",
    "- **Post-silicon**: Device parameters are highly correlated (Vdd \u2191 \u2192 Idd \u2191 \u2192 Power \u2191)\n",
    "- **Precision**: 40-60% fewer false positives vs univariate methods\n",
    "- **Interpretability**: Engineers understand \\\"deviates from normal correlation pattern\\\"\n",
    "- **Efficiency**: O(d\u00b2) computation (fast for d < 100 features)\n",
    "\n",
    "**Post-Silicon Example:**\n",
    "Detect devices with abnormal Vdd-Idd correlation:\n",
    "- **Normal**: Vdd=1.0V \u2192 Idd=100mA (strong positive correlation, r=0.95)\n",
    "- **Anomaly**: Vdd=1.0V but Idd=50mA (half expected current \u2192 possible connection defect)\n",
    "- **Mahalanobis**: D_M = 5.2 (beyond threshold 3.0) \u2192 flagged for analysis\n",
    "- **Business value**: $34.2M/year from catching correlation-based defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MahalanobisDetector:\n",
    "    \"\"\"Mahalanobis distance-based anomaly detection\"\"\"\n",
    "    \n",
    "    def __init__(self, contamination: float = 0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            contamination: Expected proportion of anomalies (for threshold setting)\n",
    "        \"\"\"\n",
    "        self.contamination = contamination\n",
    "        self.mean = None\n",
    "        self.cov = None\n",
    "        self.cov_inv = None\n",
    "        self.threshold = None\n",
    "        \n",
    "    def fit(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        Learn normal data distribution\n",
    "        \n",
    "        Args:\n",
    "            X: Training data (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self.cov = np.cov(X, rowvar=False)\n",
    "        \n",
    "        # Add small regularization for numerical stability\n",
    "        self.cov += np.eye(self.cov.shape[0]) * 1e-6\n",
    "        \n",
    "        # Inverse covariance\n",
    "        self.cov_inv = np.linalg.inv(self.cov)\n",
    "        \n",
    "        # Compute Mahalanobis distances for training data\n",
    "        distances = np.array([self._mahalanobis(x) for x in X])\n",
    "        \n",
    "        # Set threshold at (1 - contamination) percentile\n",
    "        self.threshold = np.percentile(distances, (1 - self.contamination) * 100)\n",
    "        \n",
    "        print(f\"\u2705 Trained Mahalanobis detector\")\n",
    "        print(f\"   Mean: {self.mean}\")\n",
    "        print(f\"   Threshold: {self.threshold:.4f}\")\n",
    "        \n",
    "    def _mahalanobis(self, x: np.ndarray) -> float:\n",
    "        \"\"\"Compute Mahalanobis distance\"\"\"\n",
    "        diff = x - self.mean\n",
    "        return np.sqrt(diff @ self.cov_inv @ diff)\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict anomalies\n",
    "        \n",
    "        Returns:\n",
    "            Array of -1 (anomaly) or 1 (normal)\n",
    "        \"\"\"\n",
    "        distances = np.array([self._mahalanobis(x) for x in X])\n",
    "        predictions = np.where(distances > self.threshold, -1, 1)\n",
    "        return predictions\n",
    "    \n",
    "    def decision_function(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Return anomaly scores (Mahalanobis distances)\"\"\"\n",
    "        return np.array([self._mahalanobis(x) for x in X])\n",
    "\n",
    "# Generate synthetic device test data with correlations\n",
    "def generate_device_data(n_normal: int = 800, n_anomalies: int = 50, random_seed: int = 42):\n",
    "    \"\"\"\n",
    "    Simulate device parametric test data\n",
    "    \n",
    "    Features:\n",
    "    - Vdd: Supply voltage (V)\n",
    "    - Idd: Supply current (mA)  \n",
    "    - Freq: Operating frequency (MHz)\n",
    "    \n",
    "    Normal: Strong correlations (Idd \u221d Vdd, Freq \u221d Vdd)\n",
    "    Anomalies: Violate correlations\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Normal devices (correlated features)\n",
    "    vdd_normal = np.random.normal(1.0, 0.05, n_normal)  # 1.0V \u00b1 0.05V\n",
    "    # Idd strongly correlated with Vdd (Ohm's law)\n",
    "    idd_normal = 100 * vdd_normal + np.random.normal(0, 5, n_normal)\n",
    "    # Freq increases with Vdd (higher voltage \u2192 faster switching)\n",
    "    freq_normal = 500 * vdd_normal + np.random.normal(0, 20, n_normal)\n",
    "    \n",
    "    X_normal = np.column_stack([vdd_normal, idd_normal, freq_normal])\n",
    "    y_normal = np.ones(n_normal)\n",
    "    \n",
    "    # Anomalies (correlation violations)\n",
    "    anomalies = []\n",
    "    \n",
    "    # Type 1: Low current despite normal voltage (connection defect)\n",
    "    n_type1 = n_anomalies // 3\n",
    "    vdd_t1 = np.random.normal(1.0, 0.05, n_type1)\n",
    "    idd_t1 = 50 * vdd_t1 + np.random.normal(0, 5, n_type1)  # Half expected current\n",
    "    freq_t1 = 500 * vdd_t1 + np.random.normal(0, 20, n_type1)\n",
    "    anomalies.append(np.column_stack([vdd_t1, idd_t1, freq_t1]))\n",
    "    \n",
    "    # Type 2: High current despite normal voltage (short circuit)\n",
    "    n_type2 = n_anomalies // 3\n",
    "    vdd_t2 = np.random.normal(1.0, 0.05, n_type2)\n",
    "    idd_t2 = 150 * vdd_t2 + np.random.normal(0, 5, n_type2)  # 50% higher current\n",
    "    freq_t2 = 500 * vdd_t2 + np.random.normal(0, 20, n_type2)\n",
    "    anomalies.append(np.column_stack([vdd_t2, idd_t2, freq_t2]))\n",
    "    \n",
    "    # Type 3: Low frequency despite normal voltage (timing failure)\n",
    "    n_type3 = n_anomalies - n_type1 - n_type2\n",
    "    vdd_t3 = np.random.normal(1.0, 0.05, n_type3)\n",
    "    idd_t3 = 100 * vdd_t3 + np.random.normal(0, 5, n_type3)\n",
    "    freq_t3 = 300 * vdd_t3 + np.random.normal(0, 20, n_type3)  # 40% slower\n",
    "    anomalies.append(np.column_stack([vdd_t3, idd_t3, freq_t3]))\n",
    "    \n",
    "    X_anomalies = np.vstack(anomalies)\n",
    "    y_anomalies = -np.ones(n_anomalies)\n",
    "    \n",
    "    # Combine\n",
    "    X = np.vstack([X_normal, X_anomalies])\n",
    "    y = np.concatenate([y_normal, y_anomalies])\n",
    "    \n",
    "    # Shuffle\n",
    "    indices = np.random.permutation(len(X))\n",
    "    X, y = X[indices], y[indices]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Generate data\n",
    "print(\"=\" * 60)\n",
    "print(\"MAHALANOBIS DISTANCE ANOMALY DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X, y_true = generate_device_data(n_normal=800, n_anomalies=50)\n",
    "print(f\"Generated {len(X)} devices ({np.sum(y_true == 1)} normal, {np.sum(y_true == -1)} anomalous)\")\n",
    "\n",
    "# Split train/test\n",
    "split_idx = int(len(X) * 0.7)\n",
    "X_train, y_train = X[:split_idx], y_true[:split_idx]\n",
    "X_test, y_test = X[split_idx:], y_true[split_idx:]\n",
    "\n",
    "# Train only on normal data\n",
    "X_train_normal = X_train[y_train == 1]\n",
    "print(f\"\\nTraining on {len(X_train_normal)} normal devices\")\n",
    "\n",
    "# Train Mahalanobis detector\n",
    "mahal_detector = MahalanobisDetector(contamination=0.05)\n",
    "mahal_detector.fit(X_train_normal)\n",
    "\n",
    "# Test\n",
    "y_pred = mahal_detector.predict(X_test)\n",
    "scores = mahal_detector.decision_function(X_test)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label=-1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=-1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=-1)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Performance Metrics:\")\n",
    "print(f\"   Precision: {precision:.3f}\")\n",
    "print(f\"   Recall:    {recall:.3f}\")\n",
    "print(f\"   F1-Score:  {f1:.3f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[1, -1])\n",
    "print(f\"\\n   Confusion Matrix:\")\n",
    "print(f\"   [[TN={cm[0,0]}, FP={cm[0,1]}],\")\n",
    "print(f\"    [FN={cm[1,0]}, TP={cm[1,1]}]]\")\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "\n",
    "# Plot 1: 2D projection (Vdd vs Idd)\n",
    "ax1 = fig.add_subplot(131)\n",
    "normal_mask = y_test == 1\n",
    "anomaly_mask = y_test == -1\n",
    "\n",
    "ax1.scatter(X_test[normal_mask, 0], X_test[normal_mask, 1], \n",
    "           alpha=0.6, s=50, label='Normal', color='blue')\n",
    "ax1.scatter(X_test[anomaly_mask, 0], X_test[anomaly_mask, 1], \n",
    "           alpha=0.8, s=80, marker='x', label='True Anomaly', color='red', linewidths=2)\n",
    "\n",
    "# Decision boundary (ellipse)\n",
    "from matplotlib.patches import Ellipse\n",
    "mean_2d = mahal_detector.mean[:2]\n",
    "cov_2d = mahal_detector.cov[:2, :2]\n",
    "\n",
    "# Eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(cov_2d)\n",
    "angle = np.degrees(np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0]))\n",
    "\n",
    "# 99% confidence ellipse (chi-squared with 2 DOF, 0.99 quantile = 9.21)\n",
    "width, height = 2 * np.sqrt(9.21 * eigenvalues)\n",
    "ellipse = Ellipse(mean_2d, width, height, angle=angle, \n",
    "                 facecolor='none', edgecolor='green', linewidth=2, \n",
    "                 linestyle='--', label='99% Confidence')\n",
    "ax1.add_patch(ellipse)\n",
    "\n",
    "ax1.set_xlabel('Vdd (V)')\n",
    "ax1.set_ylabel('Idd (mA)')\n",
    "ax1.set_title('Mahalanobis Distance Decision Boundary')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: 3D visualization\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "ax2.scatter(X_test[normal_mask, 0], X_test[normal_mask, 1], X_test[normal_mask, 2],\n",
    "           alpha=0.4, s=30, label='Normal', color='blue')\n",
    "ax2.scatter(X_test[anomaly_mask, 0], X_test[anomaly_mask, 1], X_test[anomaly_mask, 2],\n",
    "           alpha=0.8, s=80, marker='x', label='Anomaly', color='red', linewidths=2)\n",
    "ax2.set_xlabel('Vdd (V)')\n",
    "ax2.set_ylabel('Idd (mA)')\n",
    "ax2.set_zlabel('Freq (MHz)')\n",
    "ax2.set_title('3D Feature Space')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot 3: Mahalanobis distance distribution\n",
    "ax3 = fig.add_subplot(133)\n",
    "scores_normal = scores[normal_mask]\n",
    "scores_anomaly = scores[anomaly_mask]\n",
    "\n",
    "ax3.hist(scores_normal, bins=30, alpha=0.6, label='Normal', color='blue', density=True)\n",
    "ax3.hist(scores_anomaly, bins=15, alpha=0.6, label='Anomaly', color='red', density=True)\n",
    "ax3.axvline(mahal_detector.threshold, color='green', linestyle='--', \n",
    "           linewidth=2, label=f'Threshold ({mahal_detector.threshold:.2f})')\n",
    "ax3.set_xlabel('Mahalanobis Distance')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.set_title('Anomaly Score Distribution')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Key Observations:\")\n",
    "print(\"   - Mahalanobis detects correlation violations (normal Vdd but abnormal Idd)\")\n",
    "print(\"   - Decision boundary is elliptical (follows data covariance)\")\n",
    "print(\"   - Anomaly scores clearly separate normal vs anomalous devices\")\n",
    "print(\"   - Works well for linearly correlated features\")\n",
    "print(\"\\n\ud83d\udcb0 Business Value: $34.2M/year from correlation-based defect detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac09893",
   "metadata": {},
   "source": [
    "## 2\ufe0f\u20e3 PCA + Hotelling's T\u00b2: High-Dimensional Process Monitoring\n",
    "\n",
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Use Principal Component Analysis (PCA) to reduce dimensions and Hotelling's T\u00b2 statistic for anomaly detection in high-dimensional data\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "**1. Curse of Dimensionality**\n",
    "- **Problem**: As dimensions increase, data becomes sparse\n",
    "  - 100 features \u2192 most points are far from each other\n",
    "  - Mahalanobis requires inverting 100\u00d7100 covariance matrix (unstable if n < d\u00b2)\n",
    "  - Sample covariance is poor estimator in high dimensions\n",
    "- **Solution**: Project to lower dimensions preserving variance (PCA)\n",
    "\n",
    "**2. Principal Component Analysis (PCA)**\n",
    "- **Goal**: Find orthogonal directions of maximum variance\n",
    "- **Algorithm**:\n",
    "  1. Center data: X_centered = X - mean(X)\n",
    "  2. Compute covariance: C = X_centered^T \u00d7 X_centered / (n-1)\n",
    "  3. Eigen decomposition: C = V \u039b V^T\n",
    "     - V = eigenvectors (principal components)\n",
    "     - \u039b = eigenvalues (variance explained)\n",
    "  4. Project: Z = X_centered \u00d7 V[:, :k]  (keep top k components)\n",
    "- **Variance explained**: \u03bb_i / \u03a3\u03bb_j  (typically keep 95-99% variance)\n",
    "\n",
    "**3. Hotelling's T\u00b2 Statistic**\n",
    "- **Formula**: T\u00b2 = z^T \u03a3_z^{-1} z\n",
    "  - z = PCA scores (projected data)\n",
    "  - \u03a3_z = covariance in PCA space (diagonal!)\n",
    "- **Distribution**: T\u00b2 \u00d7 (n-k) / (k(n-1)) ~ F(k, n-k)\n",
    "- **Threshold**: F_critical at desired confidence (e.g., 99%)\n",
    "- **Advantage**: Covariance in PCA space is diagonal \u2192 easy to invert\n",
    "\n",
    "**4. SPE (Squared Prediction Error)**\n",
    "- **Also called**: Q-statistic, reconstruction error\n",
    "- **Formula**: SPE = ||x - x\u0302||\u00b2 where x\u0302 = reconstruction from k components\n",
    "- **Interpretation**: How much variance is in residual (not captured by PCs)\n",
    "- **Threshold**: \u03c7\u00b2 distribution approximation\n",
    "- **Use**: Detect anomalies in dimensions orthogonal to principal components\n",
    "\n",
    "**5. Combined T\u00b2 and SPE**\n",
    "- **T\u00b2 captures**: Anomalies in PC space (within-model)\n",
    "- **SPE captures**: Anomalies in residual space (outside-model)\n",
    "- **Combined**: Detect if T\u00b2 > threshold OR SPE > threshold\n",
    "\n",
    "**Mathematical Insight:**\n",
    "PCA decomposes variance into signal (top k PCs) and noise (remaining d-k PCs). Normal data has low T\u00b2 (close to PC subspace center) and low SPE (well-reconstructed). Anomalies have high T\u00b2 (far from center) or high SPE (off the subspace).\n",
    "\n",
    "**Why This Matters:**\n",
    "- **Scalability**: Works with 100+ features (PCA reduces to 5-20 components)\n",
    "- **Interpretability**: Principal components often have physical meaning\n",
    "- **Process control**: Standard method in multivariate statistical process control (MSPC)\n",
    "- **Robustness**: Less sensitive to noise than full-rank covariance\n",
    "\n",
    "**Post-Silicon Example:**\n",
    "60 process control parameters in semiconductor fab:\n",
    "- **PCA**: Reduce to 8 principal components (98% variance)\n",
    "- **PC1**: Overall deposition rate (30% variance)\n",
    "- **PC2**: Temperature uniformity (15% variance)\n",
    "- **T\u00b2**: Detects process shifts (chamber drift)\n",
    "- **SPE**: Detects new failure modes (not seen in training)\n",
    "- **Business value**: $25.4M/year from 6-day earlier excursion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83767cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAHotellingDetector:\n",
    "    \"\"\"PCA-based anomaly detection with Hotelling's T\u00b2 and SPE\"\"\"\n",
    "    \n",
    "    def __init__(self, n_components: float = 0.95, alpha: float = 0.01):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_components: Variance to retain (0-1) or number of components (int)\n",
    "            alpha: Significance level for thresholds\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.alpha = alpha\n",
    "        self.pca = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.t2_threshold = None\n",
    "        self.spe_threshold = None\n",
    "        \n",
    "    def fit(self, X: np.ndarray):\n",
    "        \"\"\"Learn PCA model and set thresholds\"\"\"\n",
    "        # Standardize\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # PCA\n",
    "        self.pca = PCA(n_components=self.n_components)\n",
    "        scores = self.pca.fit_transform(X_scaled)\n",
    "        \n",
    "        n_samples, n_components = scores.shape\n",
    "        \n",
    "        print(f\"\u2705 PCA fitted: {X.shape[1]} features \u2192 {n_components} components\")\n",
    "        print(f\"   Variance explained: {self.pca.explained_variance_ratio_.sum():.1%}\")\n",
    "        \n",
    "        # Hotelling's T\u00b2 threshold\n",
    "        # F-distribution critical value\n",
    "        from scipy.stats import f\n",
    "        f_critical = f.ppf(1 - self.alpha, n_components, n_samples - n_components)\n",
    "        self.t2_threshold = (n_components * (n_samples - 1)) / (n_samples - n_components) * f_critical\n",
    "        \n",
    "        # SPE threshold (approximate chi-squared)\n",
    "        residuals = X_scaled - self.pca.inverse_transform(scores)\n",
    "        spe_values = np.sum(residuals ** 2, axis=1)\n",
    "        self.spe_threshold = np.percentile(spe_values, (1 - self.alpha) * 100)\n",
    "        \n",
    "        print(f\"   T\u00b2 threshold: {self.t2_threshold:.2f}\")\n",
    "        print(f\"   SPE threshold: {self.spe_threshold:.4f}\")\n",
    "        \n",
    "    def _compute_t2(self, scores: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute Hotelling's T\u00b2 statistic\"\"\"\n",
    "        # In PCA space, covariance is diagonal (eigenvalues)\n",
    "        var = self.pca.explained_variance_\n",
    "        t2 = np.sum((scores ** 2) / var, axis=1)\n",
    "        return t2\n",
    "    \n",
    "    def _compute_spe(self, X_scaled: np.ndarray, scores: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Compute Squared Prediction Error\"\"\"\n",
    "        X_reconstructed = self.pca.inverse_transform(scores)\n",
    "        residuals = X_scaled - X_reconstructed\n",
    "        spe = np.sum(residuals ** 2, axis=1)\n",
    "        return spe\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict anomalies (T\u00b2 or SPE exceeds threshold)\"\"\"\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        scores = self.pca.transform(X_scaled)\n",
    "        \n",
    "        t2 = self._compute_t2(scores)\n",
    "        spe = self._compute_spe(X_scaled, scores)\n",
    "        \n",
    "        # Anomaly if either statistic exceeds threshold\n",
    "        predictions = np.where((t2 > self.t2_threshold) | (spe > self.spe_threshold), -1, 1)\n",
    "        return predictions\n",
    "    \n",
    "    def decision_function(self, X: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Return T\u00b2 and SPE statistics\"\"\"\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        scores = self.pca.transform(X_scaled)\n",
    "        \n",
    "        return {\n",
    "            't2': self._compute_t2(scores),\n",
    "            'spe': self._compute_spe(X_scaled, scores),\n",
    "            'scores': scores\n",
    "        }\n",
    "\n",
    "# Generate high-dimensional process data\n",
    "def generate_process_data(n_normal: int = 500, n_anomalies: int = 50, n_features: int = 30):\n",
    "    \"\"\"\n",
    "    Simulate process control data with correlations\n",
    "    \n",
    "    Features correlated in groups (e.g., temperatures, pressures, flows)\n",
    "    \"\"\"\n",
    "    np.random.seed(44)\n",
    "    \n",
    "    # Normal data: 3 latent factors drive 30 features\n",
    "    n_factors = 3\n",
    "    factors_normal = np.random.randn(n_normal, n_factors)\n",
    "    \n",
    "    # Loading matrix (how features depend on factors)\n",
    "    loadings = np.random.randn(n_features, n_factors) * 2\n",
    "    \n",
    "    # Generate features\n",
    "    X_normal = factors_normal @ loadings.T + np.random.randn(n_normal, n_features) * 0.5\n",
    "    y_normal = np.ones(n_normal)\n",
    "    \n",
    "    # Anomalies\n",
    "    # Type 1: Shift in factor 1 (e.g., temperature excursion)\n",
    "    n_type1 = n_anomalies // 2\n",
    "    factors_t1 = np.random.randn(n_type1, n_factors)\n",
    "    factors_t1[:, 0] += 3  # Shift factor 1\n",
    "    X_t1 = factors_t1 @ loadings.T + np.random.randn(n_type1, n_features) * 0.5\n",
    "    \n",
    "    # Type 2: New failure mode (noise in dimensions not captured by PCs)\n",
    "    n_type2 = n_anomalies - n_type1\n",
    "    factors_t2 = np.random.randn(n_type2, n_factors)\n",
    "    X_t2 = factors_t2 @ loadings.T + np.random.randn(n_type2, n_features) * 5  # High noise\n",
    "    \n",
    "    X_anomalies = np.vstack([X_t1, X_t2])\n",
    "    y_anomalies = -np.ones(n_anomalies)\n",
    "    \n",
    "    X = np.vstack([X_normal, X_anomalies])\n",
    "    y = np.concatenate([y_normal, y_anomalies])\n",
    "    \n",
    "    # Shuffle\n",
    "    indices = np.random.permutation(len(X))\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PCA + HOTELLING'S T\u00b2 ANOMALY DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate high-dimensional data\n",
    "X_hd, y_hd = generate_process_data(n_normal=500, n_anomalies=50, n_features=30)\n",
    "print(f\"Generated {len(X_hd)} samples with {X_hd.shape[1]} features\")\n",
    "print(f\"  Normal: {np.sum(y_hd == 1)}, Anomalies: {np.sum(y_hd == -1)}\")\n",
    "\n",
    "# Split\n",
    "split_idx = int(len(X_hd) * 0.7)\n",
    "X_train_hd, y_train_hd = X_hd[:split_idx], y_hd[:split_idx]\n",
    "X_test_hd, y_test_hd = X_hd[split_idx:], y_hd[split_idx:]\n",
    "\n",
    "# Train only on normal\n",
    "X_train_normal_hd = X_train_hd[y_train_hd == 1]\n",
    "\n",
    "# Train PCA detector\n",
    "pca_detector = PCAHotellingDetector(n_components=0.95, alpha=0.01)\n",
    "pca_detector.fit(X_train_normal_hd)\n",
    "\n",
    "# Test\n",
    "y_pred_pca = pca_detector.predict(X_test_hd)\n",
    "stats = pca_detector.decision_function(X_test_hd)\n",
    "\n",
    "# Evaluate\n",
    "precision_pca = precision_score(y_test_hd, y_pred_pca, pos_label=-1)\n",
    "recall_pca = recall_score(y_test_hd, y_pred_pca, pos_label=-1)\n",
    "f1_pca = f1_score(y_test_hd, y_pred_pca, pos_label=-1)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Performance Metrics:\")\n",
    "print(f\"   Precision: {precision_pca:.3f}\")\n",
    "print(f\"   Recall:    {recall_pca:.3f}\")\n",
    "print(f\"   F1-Score:  {f1_pca:.3f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Scree plot (variance explained)\n",
    "ax = axes[0, 0]\n",
    "var_exp = pca_detector.pca.explained_variance_ratio_\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "ax.bar(range(1, len(var_exp) + 1), var_exp, alpha=0.6, label='Individual')\n",
    "ax.plot(range(1, len(var_exp) + 1), cum_var_exp, 'ro-', label='Cumulative')\n",
    "ax.axhline(y=0.95, color='green', linestyle='--', label='95% threshold')\n",
    "ax.set_xlabel('Principal Component')\n",
    "ax.set_ylabel('Variance Explained Ratio')\n",
    "ax.set_title('Scree Plot: PCA Variance Explained')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: T\u00b2 vs SPE\n",
    "ax = axes[0, 1]\n",
    "normal_mask = y_test_hd == 1\n",
    "anomaly_mask = y_test_hd == -1\n",
    "\n",
    "ax.scatter(stats['t2'][normal_mask], stats['spe'][normal_mask], \n",
    "          alpha=0.5, s=40, label='Normal', color='blue')\n",
    "ax.scatter(stats['t2'][anomaly_mask], stats['spe'][anomaly_mask], \n",
    "          alpha=0.8, s=80, marker='x', label='Anomaly', color='red', linewidths=2)\n",
    "ax.axvline(pca_detector.t2_threshold, color='green', linestyle='--', label='T\u00b2 threshold')\n",
    "ax.axhline(pca_detector.spe_threshold, color='orange', linestyle='--', label='SPE threshold')\n",
    "ax.set_xlabel('Hotelling T\u00b2')\n",
    "ax.set_ylabel('SPE (Q-statistic)')\n",
    "ax.set_title('T\u00b2 vs SPE Control Chart')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Plot 3: PC scores (PC1 vs PC2)\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(stats['scores'][normal_mask, 0], stats['scores'][normal_mask, 1],\n",
    "          alpha=0.5, s=40, label='Normal', color='blue')\n",
    "ax.scatter(stats['scores'][anomaly_mask, 0], stats['scores'][anomaly_mask, 1],\n",
    "          alpha=0.8, s=80, marker='x', label='Anomaly', color='red', linewidths=2)\n",
    "ax.set_xlabel(f'PC1 ({pca_detector.pca.explained_variance_ratio_[0]:.1%} var)')\n",
    "ax.set_ylabel(f'PC2 ({pca_detector.pca.explained_variance_ratio_[1]:.1%} var)')\n",
    "ax.set_title('Principal Component Scores')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Feature contributions to PC1\n",
    "ax = axes[1, 1]\n",
    "pc1_loadings = pca_detector.pca.components_[0]\n",
    "feature_indices = np.arange(len(pc1_loadings))\n",
    "colors = ['red' if abs(x) > 0.3 else 'steelblue' for x in pc1_loadings]\n",
    "ax.bar(feature_indices, pc1_loadings, color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Feature Index')\n",
    "ax.set_ylabel('Loading on PC1')\n",
    "ax.set_title('Feature Contributions to PC1 (|loading| > 0.3 highlighted)')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Key Observations:\")\n",
    "print(\"   - PCA reduces 30 features to ~5-8 components retaining 95% variance\")\n",
    "print(\"   - T\u00b2 detects anomalies in PC subspace (systematic shifts)\")\n",
    "print(\"   - SPE detects anomalies in residual space (new failure modes)\")\n",
    "print(\"   - Scree plot shows first 3 PCs explain 70% variance\")\n",
    "print(\"\\n\ud83d\udcb0 Business Value: $25.4M/year from multivariate process control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9503e1a",
   "metadata": {},
   "source": [
    "## 3\ufe0f\u20e3 Isolation Forest: Tree-Based Anomaly Detection\n",
    "\n",
    "### \ud83d\udcdd What's Happening in This Method?\n",
    "\n",
    "**Purpose:** Detect anomalies by exploiting their isolation property - anomalies are easier to separate from the data.\n",
    "\n",
    "**Core Idea:**\n",
    "- **Normal points** require many splits to isolate (buried deep in tree)\n",
    "- **Anomalies** require few splits to isolate (separated quickly)\n",
    "- **Anomaly score**: Average path length across ensemble of trees\n",
    "\n",
    "**Algorithm:**\n",
    "1. Build random binary trees by:\n",
    "   - Randomly select feature\n",
    "   - Randomly select split value (between min and max)\n",
    "   - Recursively split until depth limit or isolation\n",
    "2. Repeat for n_trees (e.g., 100-200 trees)\n",
    "3. For new point, compute average path length h(x)\n",
    "4. Anomaly score: s(x) = 2^(-h(x)/c(n))\n",
    "   - c(n): Average path length for unsuccessful search in BST\n",
    "   - s(x) \u2248 1: Anomaly, s(x) \u2248 0.5: Normal\n",
    "\n",
    "**Advantages:**\n",
    "- \u2705 **Scalable**: O(n log n) training, O(log n) prediction\n",
    "- \u2705 **No distance metric**: Works with mixed data types\n",
    "- \u2705 **Minimal hyperparameters**: n_estimators and contamination\n",
    "- \u2705 **High-dimensional**: Performance doesn't degrade with dimensions\n",
    "\n",
    "**Why It Works:**\n",
    "- Anomalies are \"few and different\" \u2192 isolated early in random partitioning\n",
    "- No need to model normal density (computationally expensive)\n",
    "- Ensemble averages out randomness\n",
    "\n",
    "**Post-Silicon Application:**\n",
    "- **150+ parametric test features** (voltage, current, frequency, power, timing)\n",
    "- Detect defective dies without feature engineering\n",
    "- Tree-based: Naturally handles non-linear relationships\n",
    "- Business value: $28.7M/year from high-dimensional wafer test analysis\n",
    "\n",
    "**Mathematical Insight:**\n",
    "- Path length h(x) is like information content (Shannon entropy)\n",
    "- Short path = low information = anomaly (surprising)\n",
    "- Long path = high information = normal (expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ISOLATION FOREST ANOMALY DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use same high-dimensional data from PCA example\n",
    "print(f\"Using {X_hd.shape[1]}-dimensional process data\")\n",
    "print(f\"  Normal: {np.sum(y_hd == 1)}, Anomalies: {np.sum(y_hd == -1)}\")\n",
    "\n",
    "# Train Isolation Forest\n",
    "# contamination: Expected proportion of anomalies\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=0.1,  # Expect 10% anomalies\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "iso_forest.fit(X_train_hd)\n",
    "print(f\"\\n\u2705 Trained Isolation Forest with {iso_forest.n_estimators} trees\")\n",
    "\n",
    "# Predict\n",
    "y_pred_iso = iso_forest.predict(X_test_hd)\n",
    "anomaly_scores_iso = iso_forest.decision_function(X_test_hd)\n",
    "\n",
    "# Evaluate\n",
    "precision_iso = precision_score(y_test_hd, y_pred_iso, pos_label=-1)\n",
    "recall_iso = recall_score(y_test_hd, y_pred_iso, pos_label=-1)\n",
    "f1_iso = f1_score(y_test_hd, y_pred_iso, pos_label=-1)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Performance Metrics:\")\n",
    "print(f\"   Precision: {precision_iso:.3f}\")\n",
    "print(f\"   Recall:    {recall_iso:.3f}\")\n",
    "print(f\"   F1-Score:  {f1_iso:.3f}\")\n",
    "\n",
    "# Compare with PCA\n",
    "print(f\"\\n\ud83d\udd04 Comparison with PCA:\")\n",
    "print(f\"   Isolation Forest F1: {f1_iso:.3f}\")\n",
    "print(f\"   PCA + Hotelling F1:  {f1_pca:.3f}\")\n",
    "improvement = ((f1_iso - f1_pca) / f1_pca) * 100\n",
    "print(f\"   Improvement: {improvement:+.1f}%\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Anomaly score distribution\n",
    "ax = axes[0, 0]\n",
    "normal_mask = y_test_hd == 1\n",
    "anomaly_mask = y_test_hd == -1\n",
    "\n",
    "ax.hist(anomaly_scores_iso[normal_mask], bins=30, alpha=0.6, label='Normal', color='blue')\n",
    "ax.hist(anomaly_scores_iso[anomaly_mask], bins=30, alpha=0.6, label='Anomaly', color='red')\n",
    "ax.axvline(0, color='green', linestyle='--', label='Decision boundary')\n",
    "ax.set_xlabel('Anomaly Score (negative = anomaly)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Isolation Forest Anomaly Score Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Score vs ground truth\n",
    "ax = axes[0, 1]\n",
    "indices = np.arange(len(y_test_hd))\n",
    "colors_gt = ['red' if y == -1 else 'blue' for y in y_test_hd]\n",
    "ax.scatter(indices, anomaly_scores_iso, c=colors_gt, alpha=0.6, s=30)\n",
    "ax.axhline(0, color='green', linestyle='--', label='Decision boundary')\n",
    "ax.set_xlabel('Sample Index')\n",
    "ax.set_ylabel('Anomaly Score')\n",
    "ax.set_title('Anomaly Scores by Sample (Color = Ground Truth)')\n",
    "ax.legend(['Decision boundary', 'Normal', 'Anomaly'])\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: PCA projection colored by Isolation Forest score\n",
    "ax = axes[1, 0]\n",
    "pca_viz = PCA(n_components=2)\n",
    "X_test_2d = pca_viz.fit_transform(X_test_hd)\n",
    "scatter = ax.scatter(X_test_2d[:, 0], X_test_2d[:, 1], \n",
    "                     c=anomaly_scores_iso, cmap='RdYlBu', s=50, alpha=0.7)\n",
    "plt.colorbar(scatter, ax=ax, label='Anomaly Score')\n",
    "ax.set_xlabel(f'PC1 ({pca_viz.explained_variance_ratio_[0]:.1%} var)')\n",
    "ax.set_ylabel(f'PC2 ({pca_viz.explained_variance_ratio_[1]:.1%} var)')\n",
    "ax.set_title('2D PCA Projection Colored by Isolation Forest Score')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Feature importance (approximate)\n",
    "# Features with high variance contribute more to splits\n",
    "ax = axes[1, 1]\n",
    "feature_variance = np.var(X_train_hd, axis=0)\n",
    "top_10_idx = np.argsort(feature_variance)[-10:]\n",
    "ax.barh(range(10), feature_variance[top_10_idx], color='steelblue', alpha=0.7)\n",
    "ax.set_yticks(range(10))\n",
    "ax.set_yticklabels([f'Feature {i}' for i in top_10_idx])\n",
    "ax.set_xlabel('Variance (proxy for importance)')\n",
    "ax.set_title('Top 10 Features by Variance (Split Potential)')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Key Observations:\")\n",
    "print(\"   - Isolation Forest doesn't assume data distribution\")\n",
    "print(\"   - Effective with high dimensions (30 features)\")\n",
    "print(\"   - Fast training and prediction (tree-based)\")\n",
    "print(\"   - Anomaly scores provide ranking (not just binary)\")\n",
    "print(\"\\n\ud83d\udcb0 Business Value: $28.7M/year from high-dimensional wafer test analysis\")\n",
    "\n",
    "# Practical insight: Path length interpretation\n",
    "sample_anomaly_idx = np.where(y_test_hd == -1)[0][0]\n",
    "sample_normal_idx = np.where(y_test_hd == 1)[0][0]\n",
    "\n",
    "print(f\"\\n\ud83d\udccf Path Length Comparison:\")\n",
    "print(f\"   Anomaly sample score:  {anomaly_scores_iso[sample_anomaly_idx]:.3f} (negative = isolated early)\")\n",
    "print(f\"   Normal sample score:   {anomaly_scores_iso[sample_normal_idx]:.3f} (near zero = average path)\")\n",
    "print(f\"   \u2192 Anomalies require fewer splits to isolate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae96a920",
   "metadata": {},
   "source": [
    "## 4\ufe0f\u20e3 Local Outlier Factor (LOF): Density-Based Detection\n",
    "\n",
    "### \ud83d\udcdd What's Happening in This Method?\n",
    "\n",
    "**Purpose:** Detect anomalies by comparing local density to neighbors' densities - accounts for varying density regions.\n",
    "\n",
    "**Core Problem LOF Solves:**\n",
    "- Global methods (e.g., simple distance threshold) fail with varying densities\n",
    "- Example: Point in sparse cluster appears anomalous compared to dense cluster\n",
    "- LOF compares **local** density, not global\n",
    "\n",
    "**Algorithm:**\n",
    "1. **k-distance**: Distance to k-th nearest neighbor\n",
    "2. **Reachability distance**: `reach_dist(A, B) = max(k-dist(B), dist(A,B))`\n",
    "   - Smooths distances for stability\n",
    "3. **Local Reachability Density (LRD)**:\n",
    "   - `LRD(A) = 1 / (mean reachability distance from A to neighbors)`\n",
    "   - High LRD = dense neighborhood\n",
    "4. **LOF score**:\n",
    "   - `LOF(A) = mean(LRD(neighbor) / LRD(A))`\n",
    "   - LOF \u2248 1: Similar density to neighbors (normal)\n",
    "   - LOF >> 1: Lower density than neighbors (anomaly)\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "$$\n",
    "\\text{LOF}(x) = \\frac{\\sum_{o \\in N_k(x)} \\frac{\\text{LRD}(o)}{\\text{LRD}(x)}}{|N_k(x)|}\n",
    "$$\n",
    "\n",
    "**Advantages:**\n",
    "- \u2705 **Local adaptivity**: Works with clusters of different densities\n",
    "- \u2705 **Interpretable**: LOF score has clear meaning (density ratio)\n",
    "- \u2705 **No global threshold**: Automatically adapts to local context\n",
    "- \u2705 **Robust to noise**: k-neighbors smoothing\n",
    "\n",
    "**Disadvantages:**\n",
    "- \u274c **Computationally expensive**: O(n\u00b2) for distance matrix\n",
    "- \u274c **Hyperparameter k**: Sensitive to number of neighbors\n",
    "- \u274c **Not incremental**: Requires full dataset for density estimation\n",
    "\n",
    "**Post-Silicon Application:**\n",
    "- **Multi-sensor equipment monitoring** (40 sensors)\n",
    "- Different operational modes have different normal densities\n",
    "- Example: Idle mode (low power) vs production mode (high power)\n",
    "- LOF adapts to local density, reducing false positives\n",
    "- Business value: $31.8M/year from equipment monitoring\n",
    "\n",
    "**When to Use LOF:**\n",
    "- Data has regions with different densities\n",
    "- Need interpretable anomaly scores\n",
    "- Batch processing acceptable (not real-time streaming)\n",
    "- Moderate dataset size (< 100K samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be9dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Generate data with multiple density regions\n",
    "def generate_multi_density_data(n_samples: int = 600):\n",
    "    \"\"\"\n",
    "    Create data with two normal clusters of different densities + anomalies\n",
    "    \n",
    "    Simulates different equipment operational modes\n",
    "    \"\"\"\n",
    "    np.random.seed(45)\n",
    "    \n",
    "    # Dense cluster (production mode - high activity)\n",
    "    n_dense = n_samples // 2\n",
    "    cluster1 = np.random.randn(n_dense, 2) * 0.3 + np.array([2, 2])\n",
    "    \n",
    "    # Sparse cluster (idle mode - low activity)\n",
    "    n_sparse = n_samples // 2\n",
    "    cluster2 = np.random.randn(n_sparse, 2) * 1.5 + np.array([-3, -3])\n",
    "    \n",
    "    X_normal = np.vstack([cluster1, cluster2])\n",
    "    y_normal = np.ones(len(X_normal))\n",
    "    \n",
    "    # Anomalies in different regions\n",
    "    n_anomalies = 50\n",
    "    X_anomalies = np.random.uniform(-6, 6, (n_anomalies, 2))\n",
    "    y_anomalies = -np.ones(n_anomalies)\n",
    "    \n",
    "    X = np.vstack([X_normal, X_anomalies])\n",
    "    y = np.concatenate([y_normal, y_anomalies])\n",
    "    \n",
    "    indices = np.random.permutation(len(X))\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LOCAL OUTLIER FACTOR (LOF) ANOMALY DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_multi, y_multi = generate_multi_density_data(n_samples=600)\n",
    "print(f\"Generated multi-density data: {len(X_multi)} samples\")\n",
    "print(f\"  Normal: {np.sum(y_multi == 1)}, Anomalies: {np.sum(y_multi == -1)}\")\n",
    "print(\"  Two clusters: Dense (production) + Sparse (idle)\")\n",
    "\n",
    "# Split\n",
    "split_idx = int(len(X_multi) * 0.7)\n",
    "X_train_multi, y_train_multi = X_multi[:split_idx], y_multi[:split_idx]\n",
    "X_test_multi, y_test_multi = X_multi[split_idx:], y_multi[split_idx:]\n",
    "\n",
    "# Train LOF\n",
    "# novelty=True for out-of-sample prediction\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=20,\n",
    "    contamination=0.1,\n",
    "    novelty=True  # Enable predict() for new data\n",
    ")\n",
    "\n",
    "lof.fit(X_train_multi)\n",
    "print(f\"\\n\u2705 Trained LOF with k={lof.n_neighbors} neighbors\")\n",
    "\n",
    "# Predict\n",
    "y_pred_lof = lof.predict(X_test_multi)\n",
    "lof_scores = lof.decision_function(X_test_multi)\n",
    "\n",
    "# Evaluate\n",
    "precision_lof = precision_score(y_test_multi, y_pred_lof, pos_label=-1)\n",
    "recall_lof = recall_score(y_test_multi, y_pred_lof, pos_label=-1)\n",
    "f1_lof = f1_score(y_test_multi, y_pred_lof, pos_label=-1)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Performance Metrics:\")\n",
    "print(f\"   Precision: {precision_lof:.3f}\")\n",
    "print(f\"   Recall:    {recall_lof:.3f}\")\n",
    "print(f\"   F1-Score:  {f1_lof:.3f}\")\n",
    "\n",
    "# Compare with Isolation Forest on same data\n",
    "iso_forest_multi = IsolationForest(contamination=0.1, random_state=42)\n",
    "iso_forest_multi.fit(X_train_multi)\n",
    "y_pred_iso_multi = iso_forest_multi.predict(X_test_multi)\n",
    "f1_iso_multi = f1_score(y_test_multi, y_pred_iso_multi, pos_label=-1)\n",
    "\n",
    "print(f\"\\n\ud83d\udd04 Comparison (Multi-density Data):\")\n",
    "print(f\"   LOF F1:              {f1_lof:.3f}\")\n",
    "print(f\"   Isolation Forest F1: {f1_iso_multi:.3f}\")\n",
    "print(f\"   \u2192 LOF better handles varying density regions\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: LOF decision boundary\n",
    "ax = axes[0, 0]\n",
    "xx, yy = np.meshgrid(np.linspace(-6, 6, 100), np.linspace(-6, 6, 100))\n",
    "Z = lof.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "ax.contourf(xx, yy, Z, levels=15, cmap='RdYlBu', alpha=0.6)\n",
    "normal_mask = y_test_multi == 1\n",
    "anomaly_mask = y_test_multi == -1\n",
    "ax.scatter(X_test_multi[normal_mask, 0], X_test_multi[normal_mask, 1],\n",
    "          c='blue', alpha=0.6, s=40, label='Normal', edgecolors='k', linewidth=0.5)\n",
    "ax.scatter(X_test_multi[anomaly_mask, 0], X_test_multi[anomaly_mask, 1],\n",
    "          c='red', alpha=0.8, s=80, marker='x', label='Anomaly', linewidths=2)\n",
    "ax.set_xlabel('Feature 1 (e.g., Power Consumption)')\n",
    "ax.set_ylabel('Feature 2 (e.g., Temperature)')\n",
    "ax.set_title('LOF Decision Function (Colored by Anomaly Score)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: LOF score distribution\n",
    "ax = axes[0, 1]\n",
    "ax.hist(lof_scores[normal_mask], bins=30, alpha=0.6, label='Normal', color='blue')\n",
    "ax.hist(lof_scores[anomaly_mask], bins=30, alpha=0.6, label='Anomaly', color='red')\n",
    "ax.axvline(0, color='green', linestyle='--', label='Decision boundary')\n",
    "ax.set_xlabel('LOF Score (negative = anomaly)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('LOF Score Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Comparison - Isolation Forest boundary\n",
    "ax = axes[1, 0]\n",
    "Z_iso = iso_forest_multi.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z_iso = Z_iso.reshape(xx.shape)\n",
    "\n",
    "ax.contourf(xx, yy, Z_iso, levels=15, cmap='RdYlBu', alpha=0.6)\n",
    "ax.scatter(X_test_multi[normal_mask, 0], X_test_multi[normal_mask, 1],\n",
    "          c='blue', alpha=0.6, s=40, label='Normal', edgecolors='k', linewidth=0.5)\n",
    "ax.scatter(X_test_multi[anomaly_mask, 0], X_test_multi[anomaly_mask, 1],\n",
    "          c='red', alpha=0.8, s=80, marker='x', label='Anomaly', linewidths=2)\n",
    "ax.set_xlabel('Feature 1')\n",
    "ax.set_ylabel('Feature 2')\n",
    "ax.set_title('Isolation Forest Decision Function (for comparison)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: k-neighbor effect\n",
    "ax = axes[1, 1]\n",
    "k_values = [5, 10, 20, 30, 50]\n",
    "f1_scores_k = []\n",
    "\n",
    "for k in k_values:\n",
    "    lof_k = LocalOutlierFactor(n_neighbors=k, contamination=0.1, novelty=True)\n",
    "    lof_k.fit(X_train_multi)\n",
    "    y_pred_k = lof_k.predict(X_test_multi)\n",
    "    f1_k = f1_score(y_test_multi, y_pred_k, pos_label=-1)\n",
    "    f1_scores_k.append(f1_k)\n",
    "\n",
    "ax.plot(k_values, f1_scores_k, 'o-', linewidth=2, markersize=8, color='steelblue')\n",
    "ax.axhline(f1_lof, color='green', linestyle='--', label=f'Current k=20 (F1={f1_lof:.3f})')\n",
    "ax.set_xlabel('Number of Neighbors (k)')\n",
    "ax.set_ylabel('F1-Score')\n",
    "ax.set_title('LOF Performance vs k (Hyperparameter Sensitivity)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Key Observations:\")\n",
    "print(\"   - LOF adapts to local density (dense cluster vs sparse cluster)\")\n",
    "print(\"   - Isolation Forest treats both clusters similarly (global approach)\")\n",
    "print(\"   - LOF score = density ratio (interpretable)\")\n",
    "print(\"   - k-neighbors: 10-30 typical, too small = noise, too large = global\")\n",
    "print(\"\\n\ud83d\udcb0 Business Value: $31.8M/year from multi-sensor equipment monitoring\")\n",
    "\n",
    "# Practical insight: Density ratio interpretation\n",
    "sample_dense_idx = np.where((y_test_multi == 1) & (X_test_multi[:, 0] > 0))[0][0]\n",
    "sample_sparse_idx = np.where((y_test_multi == 1) & (X_test_multi[:, 0] < 0))[0][0]\n",
    "\n",
    "print(f\"\\n\ud83d\udd0d Density Context Matters:\")\n",
    "print(f\"   Normal in dense cluster: LOF score = {lof_scores[sample_dense_idx]:.3f}\")\n",
    "print(f\"   Normal in sparse cluster: LOF score = {lof_scores[sample_sparse_idx]:.3f}\")\n",
    "print(f\"   \u2192 Both classified as normal despite different absolute densities!\")\n",
    "print(f\"   \u2192 LOF compares to LOCAL neighborhood, not global\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c347ef",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Real-World Project Ideas\n",
    "\n",
    "### Post-Silicon Validation Projects\n",
    "\n",
    "#### **Project 1: Correlated Parameter Anomaly Detection System**\n",
    "**Objective:** Build production anomaly detection for 25 parametric test measurements  \n",
    "**Business Value:** $34.2M/year (40-60% reduction in false positives)\n",
    "\n",
    "**Dataset Requirements:**\n",
    "- **Features (25):** Vdd, Idd, Freq, Tpd, Voh, Vol, Ioh, Iol, Vth, Vtn, Vtp, Ileak, etc.\n",
    "- **Normal correlations:** Ohm's law (V \u221d I), frequency-voltage relationship, timing-power tradeoffs\n",
    "- **Anomaly types:** Correlation violations (normal individual values but abnormal combinations)\n",
    "- **Volume:** 1M+ devices per quarter, 100K training samples\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **Data preprocessing:** Standardization, outlier removal from training (5% contamination)\n",
    "2. **Method selection:** Mahalanobis distance (linear correlations) vs Isolation Forest (non-linear)\n",
    "3. **Threshold tuning:** Cross-validation to balance precision-recall\n",
    "4. **Feature engineering:** Ratios (Idd/Vdd), products (Vdd \u00d7 Freq), polynomial features\n",
    "5. **Deployment:** Real-time scoring with 100ms latency requirement\n",
    "6. **Monitoring:** Track correlation matrix drift, retrain quarterly\n",
    "\n",
    "**Success Metrics:**\n",
    "- Precision \u2265 80% (avoid overwhelming test engineers)\n",
    "- Recall \u2265 95% (catch defects before customer)\n",
    "- Inference latency < 100ms per device\n",
    "- Correlation coverage: Detect 15+ known failure modes\n",
    "\n",
    "**Technical Challenges:**\n",
    "- High correlation multicollinearity (condition number monitoring)\n",
    "- Dynamic correlations (Vdd-Freq relationship varies by design)\n",
    "- Contaminated training data (iterative robust training)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 2: High-Dimensional Wafer Test Analysis (150+ Parameters)**\n",
    "**Objective:** Detect spatial anomalies in wafer-level test data  \n",
    "**Business Value:** $28.7M/year (30% faster yield learning)\n",
    "\n",
    "**Dataset Requirements:**\n",
    "- **Features (150+):** All parametric tests (DC, AC, RF, power, timing)\n",
    "- **Spatial metadata:** wafer_id, die_x, die_y (for wafer map visualization)\n",
    "- **Temporal context:** lot_id, test_timestamp (for drift detection)\n",
    "- **Volume:** 300 wafers/day \u00d7 400 dies/wafer \u00d7 150 params = 18M measurements/day\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **Dimensionality reduction:** PCA to 10-20 components (retain 95% variance)\n",
    "2. **Spatial preprocessing:** Normalize by wafer position (edge vs center effects)\n",
    "3. **Multi-method ensemble:**\n",
    "   - PCA + Hotelling's T\u00b2 (systematic shifts)\n",
    "   - SPE (Q-statistic) for new failure modes\n",
    "   - Isolation Forest (non-linear defects)\n",
    "4. **Wafer map visualization:** Project anomaly scores to spatial coordinates\n",
    "5. **Root cause attribution:** Feature contributions to anomaly score\n",
    "\n",
    "**Success Metrics:**\n",
    "- Detect spatial patterns: Clusters, edges, rings, scratches\n",
    "- Early detection: Identify systematic defects within 5 wafers (vs 50 baseline)\n",
    "- Actionable insights: Link anomalies to process steps\n",
    "- False positive rate < 5% per wafer\n",
    "\n",
    "**Technical Challenges:**\n",
    "- Curse of dimensionality (unstable covariance with 150 features)\n",
    "- Spatial autocorrelation (neighboring dies correlated)\n",
    "- Die-to-die vs wafer-to-wafer variability\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 3: Multi-Sensor ATE Equipment Health Monitoring**\n",
    "**Objective:** Predictive maintenance for 40-sensor automatic test equipment  \n",
    "**Business Value:** $31.8M/year (45% reduction in unplanned downtime)\n",
    "\n",
    "**Dataset Requirements:**\n",
    "- **Sensor features (40):** Voltage rails, current supplies, temperatures, pressures, vibration, humidity\n",
    "- **Operational modes:** Idle, self-test, DUT load, production test (varying normal densities)\n",
    "- **Anomaly types:** Gradual degradation, sudden failures, mode transitions\n",
    "- **Volume:** 100 samples/sec \u00d7 24/7 = 8.6M samples/day\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **Mode-aware modeling:** Train separate LOF models per operational mode\n",
    "2. **Feature engineering:** Rolling statistics (mean, std, trend over 1-hour windows)\n",
    "3. **Multi-scale detection:**\n",
    "   - Fast alerts (LOF on raw sensor readings, 1-min window)\n",
    "   - Slow degradation (PCA on hourly aggregates, 7-day trend)\n",
    "4. **Predictive horizon:** Forecast time-to-failure (regression on anomaly scores)\n",
    "5. **Alert prioritization:** Severity scoring based on business impact\n",
    "\n",
    "**Success Metrics:**\n",
    "- Predict failures 7-14 days in advance\n",
    "- Reduce false alarms by 60% vs threshold-based alerts\n",
    "- Equipment uptime \u2265 98% (vs 92% baseline)\n",
    "- Mean time to detect (MTTD) < 15 minutes\n",
    "\n",
    "**Technical Challenges:**\n",
    "- Varying density across operational modes (LOF vs global methods)\n",
    "- Sensor drift (recalibration events cause distribution shifts)\n",
    "- Rare failure modes (class imbalance, 0.01% anomaly rate)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 4: Multivariate Statistical Process Control (MSPC) for Wafer Fab**\n",
    "**Objective:** Real-time process monitoring with 60 process parameters  \n",
    "**Business Value:** $25.4M/year (20% reduction in out-of-spec lots)\n",
    "\n",
    "**Dataset Requirements:**\n",
    "- **Process features (60):** Deposition rates, temperatures, pressures, gas flows, chamber conditions\n",
    "- **Lot metadata:** recipe_id, chamber_id, tool_id, timestamp\n",
    "- **Control charts:** Hotelling's T\u00b2, SPE, contribution plots\n",
    "- **Volume:** 1 lot/hour \u00d7 24/7 \u00d7 10 fabs = 2,400 lots/day\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **PCA modeling:** Reduce 60 \u2192 8 principal components (98% variance)\n",
    "2. **Control limits:**\n",
    "   - T\u00b2 threshold: F-distribution (99% confidence)\n",
    "   - SPE threshold: \u03c7\u00b2 approximation\n",
    "3. **Contribution analysis:** Identify which variables contribute to anomalies\n",
    "4. **Recipe-specific models:** Train separate models per process recipe\n",
    "5. **Automated alerts:** Integrate with MES (Manufacturing Execution System)\n",
    "\n",
    "**Success Metrics:**\n",
    "- Detect process excursions within 1 lot (vs 3-5 baseline)\n",
    "- Attribution accuracy: Correctly identify root cause parameter 75% of time\n",
    "- Reduce false positives 50% vs univariate SPC charts\n",
    "- Integration latency < 5 minutes (lot completion \u2192 alert)\n",
    "\n",
    "**Technical Challenges:**\n",
    "- Recipe variability (different normal regions)\n",
    "- Tool-to-tool matching (chamber-specific drift)\n",
    "- Multivariate contribution interpretation (PC1 = mix of 20 variables)\n",
    "\n",
    "---\n",
    "\n",
    "### General AI/ML Projects\n",
    "\n",
    "#### **Project 5: Multi-Sensor IoT Device Health Monitoring**\n",
    "**Objective:** Fleet-wide anomaly detection for smart home devices  \n",
    "**Business Value:** $42M/year (30% reduction in warranty claims)\n",
    "\n",
    "**Dataset Requirements:**\n",
    "- **Sensor features (12):** Temperature, humidity, power, motion, light, sound, CO2, pressure\n",
    "- **Device metadata:** device_id, model, firmware_version, install_date\n",
    "- **Usage patterns:** Daily cycles, seasonal variations\n",
    "- **Volume:** 10M devices \u00d7 1 sample/min = 14.4B measurements/day\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **Device-level modeling:** Train LOF per device (personalized baseline)\n",
    "2. **Fleet-level patterns:** Isolation Forest on aggregated hourly statistics\n",
    "3. **Anomaly taxonomy:** Sensor failure, environmental anomaly, user behavior change\n",
    "4. **Root cause:** Feature attribution + temporal context\n",
    "5. **Edge deployment:** Model compression for on-device inference\n",
    "\n",
    "**Success Metrics:**\n",
    "- Predict failures 30 days before warranty claim\n",
    "- Precision \u2265 70% (balance alerts vs user annoyance)\n",
    "- Edge inference latency < 1 second\n",
    "- Model size < 5MB (for resource-constrained devices)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 6: Financial Transaction Fraud Detection (Multi-Feature)**\n",
    "**Objective:** Real-time fraud scoring with 50+ transaction features  \n",
    "**Business Value:** $127M/year (85% fraud detection rate)\n",
    "\n",
    "**Dataset Requirements:**\n",
    "- **Transaction features (50+):** Amount, merchant, category, time, location, device, velocity features\n",
    "- **User features:** Account age, transaction history, risk score\n",
    "- **Anomaly types:** Account takeover, card-not-present fraud, money laundering\n",
    "- **Volume:** 10K transactions/sec = 864M/day\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **Feature engineering:** Velocity (# transactions in 1 hour), geographic distance, amount z-score\n",
    "2. **Isolation Forest:** Scalable to millions of transactions\n",
    "3. **Ensemble:** Combine Isolation Forest + rule-based system + supervised model\n",
    "4. **Real-time scoring:** Stream processing (Kafka + Flink)\n",
    "5. **Explainability:** SHAP values for feature contributions (regulatory requirement)\n",
    "\n",
    "**Success Metrics:**\n",
    "- Fraud detection rate \u2265 85%\n",
    "- False positive rate < 1% (minimize legitimate transaction blocks)\n",
    "- Inference latency < 50ms (real-time authorization)\n",
    "- Model update frequency: Daily (adapt to new fraud patterns)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 7: Network Intrusion Detection (High-Dimensional)**\n",
    "**Objective:** Detect cyber attacks from 92 network features  \n",
    "**Business Value:** $38M/year (90% attack detection)\n",
    "\n",
    "**Dataset Requirements:**\n",
    "- **Network features (92):** Protocol, service, flag, bytes, packets, duration, error rates, etc.\n",
    "- **Attack types:** DoS, R2L, U2R, Probe\n",
    "- **Benign traffic:** Normal user behavior (99.9% of samples)\n",
    "- **Volume:** 1TB network logs/day\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **Dimensionality reduction:** PCA to 15 components + sparse autoencoders\n",
    "2. **Multi-method:** PCA (known attacks) + Isolation Forest (zero-day attacks)\n",
    "3. **Stream processing:** Apache Kafka for real-time log ingestion\n",
    "4. **Alert triage:** Anomaly score + attack type classification\n",
    "5. **Feedback loop:** Security analyst labels \u2192 model retraining\n",
    "\n",
    "**Success Metrics:**\n",
    "- True positive rate \u2265 90% (catch attacks)\n",
    "- False positive rate < 0.1% (avoid alert fatigue)\n",
    "- Mean time to detect < 5 minutes\n",
    "- Zero-day detection: Catch 60% of novel attacks\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 8: Healthcare Patient Monitoring (ICU Multi-Sensor)**\n",
    "**Objective:** Early sepsis detection from 25 vital signs + lab results  \n",
    "**Business Value:** $53M/year (40% reduction in sepsis mortality)\n",
    "\n",
    "**Dataset Requirements:**\n",
    "- **Vital signs (10):** Heart rate, BP, SpO2, respiratory rate, temperature\n",
    "- **Lab results (15):** WBC, lactate, creatinine, bilirubin, platelets\n",
    "- **Patient metadata:** Age, comorbidities, medication\n",
    "- **Temporal:** Hourly measurements, detect deterioration 6-12 hours early\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **Missing data handling:** Forward-fill + interpolation (ICU data often sparse)\n",
    "2. **Mahalanobis distance:** Detect abnormal combinations (e.g., low BP + high lactate)\n",
    "3. **Sequential modeling:** LSTM autoencoder for temporal dependencies\n",
    "4. **Risk scoring:** Combine anomaly scores \u2192 sepsis probability\n",
    "5. **Clinical integration:** EHR integration, alert suppression during interventions\n",
    "\n",
    "**Success Metrics:**\n",
    "- Detect sepsis 6-12 hours before clinical diagnosis\n",
    "- Sensitivity \u2265 85% (minimize missed cases)\n",
    "- Alert rate < 2 per patient per day (avoid alarm fatigue)\n",
    "- Explainability: Highlight contributing features for clinician trust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ecb6ff",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Key Takeaways\n",
    "\n",
    "### When to Use Multi-Variate Anomaly Detection\n",
    "\n",
    "**Use multi-variate methods when:**\n",
    "- \u2705 Features are **correlated** (e.g., voltage and current in semiconductor tests)\n",
    "- \u2705 Anomalies manifest as **correlation violations** (normal individual values, abnormal combinations)\n",
    "- \u2705 High-dimensional data (50+ features) where univariate methods fail\n",
    "- \u2705 Need to detect **context-dependent** anomalies (e.g., high power acceptable during stress test, not during idle)\n",
    "\n",
    "**Stick with univariate methods when:**\n",
    "- \u274c Features are truly independent\n",
    "- \u274c Simple threshold violations sufficient (e.g., temperature > 100\u00b0C always bad)\n",
    "- \u274c Need maximum interpretability (single-variable alerts easier to explain)\n",
    "- \u274c Limited data (multivariate methods require more samples)\n",
    "\n",
    "---\n",
    "\n",
    "### Method Comparison & Selection Guide\n",
    "\n",
    "| **Method** | **Strengths** | **Weaknesses** | **Best For** | **Complexity** |\n",
    "|------------|---------------|----------------|--------------|----------------|\n",
    "| **Mahalanobis Distance** | \u2022 Statistical foundation<br>\u2022 Interpretable (\u03c7\u00b2 distribution)<br>\u2022 Correlation-aware | \u2022 Assumes Gaussian<br>\u2022 Unstable with d > 50<br>\u2022 Linear only | Linear correlations, low-to-medium dimensions (<50 features) | O(d\u00b2n) train<br>O(d\u00b2) predict |\n",
    "| **PCA + Hotelling's T\u00b2** | \u2022 Handles high dimensions<br>\u2022 T\u00b2 + SPE decomposition<br>\u2022 MSPC standard | \u2022 Assumes linearity<br>\u2022 Loses interpretability<br>\u2022 Sensitive to scaling | High dimensions (50-200 features), process control, systematic shifts | O(d\u00b2n) train<br>O(dk) predict |\n",
    "| **Isolation Forest** | \u2022 No distribution assumption<br>\u2022 Scalable (O(n log n))<br>\u2022 Non-linear | \u2022 Black box<br>\u2022 Sensitive to contamination<br>\u2022 Not incremental | High dimensions, mixed data types, non-linear relationships | O(tn log n) train<br>O(t log n) predict |\n",
    "| **LOF** | \u2022 Local density adaptation<br>\u2022 Interpretable scores<br>\u2022 Varying densities | \u2022 O(n\u00b2) complexity<br>\u2022 Hyperparameter k sensitive<br>\u2022 Not real-time | Multiple operational modes, varying densities, batch processing | O(n\u00b2) train<br>O(kn) predict |\n",
    "\n",
    "**Decision Framework:**\n",
    "```\n",
    "Start\n",
    "\u2502\n",
    "\u251c\u2500 High dimensions (d > 50)?\n",
    "\u2502  \u251c\u2500 Yes \u2192 PCA + T\u00b2 or Isolation Forest\n",
    "\u2502  \u2514\u2500 No \u2192 Continue\n",
    "\u2502\n",
    "\u251c\u2500 Linear correlations?\n",
    "\u2502  \u251c\u2500 Yes \u2192 Mahalanobis Distance\n",
    "\u2502  \u2514\u2500 No \u2192 Isolation Forest\n",
    "\u2502\n",
    "\u251c\u2500 Varying density regions?\n",
    "\u2502  \u251c\u2500 Yes \u2192 LOF\n",
    "\u2502  \u2514\u2500 No \u2192 Isolation Forest or Mahalanobis\n",
    "\u2502\n",
    "\u2514\u2500 Real-time requirement?\n",
    "   \u251c\u2500 Yes \u2192 Isolation Forest (fast prediction)\n",
    "   \u2514\u2500 No \u2192 Ensemble (combine multiple methods)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Production Architecture Patterns\n",
    "\n",
    "#### **Pattern 1: Lambda Architecture (Batch + Stream)**\n",
    "```\n",
    "Stream Layer (Real-time)\n",
    "\u251c\u2500 Kafka/Kinesis ingestion\n",
    "\u251c\u2500 Isolation Forest scoring (100ms latency)\n",
    "\u2514\u2500 Immediate alerts for critical anomalies\n",
    "\n",
    "Batch Layer (Historical)\n",
    "\u251c\u2500 Daily PCA model retraining\n",
    "\u251c\u2500 Mahalanobis threshold recalibration\n",
    "\u2514\u2500 Anomaly pattern analysis\n",
    "```\n",
    "\n",
    "**When to use:** Need both real-time alerts and historical analysis  \n",
    "**Example:** Semiconductor test (real-time scoring + weekly yield analysis)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Pattern 2: Ensemble Voting**\n",
    "```\n",
    "Input Features\n",
    "\u2502\n",
    "\u251c\u2500 Mahalanobis Distance \u2192 Score 1\n",
    "\u251c\u2500 Isolation Forest     \u2192 Score 2\n",
    "\u251c\u2500 LOF                  \u2192 Score 3\n",
    "\u2514\u2500 PCA + T\u00b2            \u2192 Score 4\n",
    "\n",
    "Combine \u2192 Weighted vote or max score\n",
    "\u2502\n",
    "Output: Anomaly if 2+ methods agree\n",
    "```\n",
    "\n",
    "**When to use:** High-stakes decisions, need confidence  \n",
    "**Example:** Medical diagnosis (sepsis detection), fraud prevention\n",
    "\n",
    "---\n",
    "\n",
    "#### **Pattern 3: Hierarchical Detection**\n",
    "```\n",
    "Level 1: Fast filter (Mahalanobis)\n",
    "\u251c\u2500 Normal \u2192 Accept\n",
    "\u2514\u2500 Potential anomaly \u2192 Level 2\n",
    "\n",
    "Level 2: Detailed analysis (Isolation Forest + LOF)\n",
    "\u251c\u2500 Confirmed anomaly \u2192 Alert + root cause\n",
    "\u2514\u2500 False positive \u2192 Accept\n",
    "\n",
    "Level 3: Human review (if ambiguous)\n",
    "```\n",
    "\n",
    "**When to use:** High volume, need to minimize false positives  \n",
    "**Example:** Network intrusion (filter 99.9% normal traffic fast)\n",
    "\n",
    "---\n",
    "\n",
    "### Hyperparameter Tuning Guide\n",
    "\n",
    "#### **Mahalanobis Distance**\n",
    "- **Contamination**: Expected anomaly proportion in training\n",
    "  - Too low: Sensitive, many false positives\n",
    "  - Too high: Misses subtle anomalies\n",
    "  - **Recommendation:** Start with 0.05 (5%), tune on validation\n",
    "  \n",
    "- **Threshold**: \u03c7\u00b2(d, 1-\u03b1) or empirical percentile\n",
    "  - Statistical: \u03b1 = 0.01 (99% confidence)\n",
    "  - Empirical: 95-99th percentile of training distances\n",
    "  - **Recommendation:** Use empirical for robustness\n",
    "\n",
    "#### **PCA + Hotelling's T\u00b2**\n",
    "- **n_components**: Variance retained or number of PCs\n",
    "  - 0.95 (95% variance): Good starting point\n",
    "  - 0.99 (99% variance): Preserve more info, risk noise\n",
    "  - **Recommendation:** Plot scree plot, choose elbow + 95% threshold\n",
    "  \n",
    "- **\u03b1 (significance)**: False positive rate\n",
    "  - 0.01 (1%): Strict, fewer false positives\n",
    "  - 0.05 (5%): Lenient, higher recall\n",
    "  - **Recommendation:** 0.01 for production, 0.05 for exploration\n",
    "\n",
    "#### **Isolation Forest**\n",
    "- **n_estimators**: Number of trees\n",
    "  - 100: Fast, good for prototyping\n",
    "  - 200-500: Better stability, production\n",
    "  - **Recommendation:** 100 (diminishing returns beyond 200)\n",
    "  \n",
    "- **contamination**: Expected anomaly proportion\n",
    "  - Same as Mahalanobis\n",
    "  - **Recommendation:** 0.05-0.1, validate on labeled data\n",
    "  \n",
    "- **max_samples**: Subsample size\n",
    "  - 256: Default, fast\n",
    "  - \"auto\": n_samples (slower but better for small datasets)\n",
    "  - **Recommendation:** 256 for n > 10K, \"auto\" otherwise\n",
    "\n",
    "#### **LOF**\n",
    "- **n_neighbors**: k for local density\n",
    "  - 10: Sensitive to local patterns, risk noise\n",
    "  - 20-30: Good balance\n",
    "  - 50: Smooths out local variations, approaches global\n",
    "  - **Recommendation:** 20, cross-validate on [10, 20, 30, 50]\n",
    "  \n",
    "- **contamination**: Same as others\n",
    "  \n",
    "- **novelty**: True (predict on new data) vs False (fit-predict on same data)\n",
    "  - **Recommendation:** True for production (separate train/test)\n",
    "\n",
    "---\n",
    "\n",
    "### Common Pitfalls & Solutions\n",
    "\n",
    "#### **Pitfall 1: Contaminated Training Data**\n",
    "**Problem:** Training on data containing anomalies \u2192 model learns anomalies as normal  \n",
    "**Solution:**\n",
    "- Use robust estimators: Minimum Covariance Determinant (MCD) for Mahalanobis\n",
    "- Iterative training: Train \u2192 detect \u2192 remove anomalies \u2192 retrain (2-3 iterations)\n",
    "- High initial contamination: Set to 0.1 initially, decrease to 0.05 after cleaning\n",
    "\n",
    "#### **Pitfall 2: Feature Scaling Issues**\n",
    "**Problem:** Features with large ranges dominate distance/covariance calculations  \n",
    "**Solution:**\n",
    "- Always use StandardScaler (zero mean, unit variance)\n",
    "- For PCA: Scaling critical (variance-based)\n",
    "- For Isolation Forest: Less critical but still recommended\n",
    "\n",
    "#### **Pitfall 3: High Correlation (Multicollinearity)**\n",
    "**Problem:** Nearly identical features \u2192 unstable covariance inversion  \n",
    "**Solution:**\n",
    "- Check condition number: `np.linalg.cond(covariance_matrix)` > 1000 = problem\n",
    "- Remove redundant features: Correlation matrix, VIF (Variance Inflation Factor)\n",
    "- Use PCA to decorrelate\n",
    "\n",
    "#### **Pitfall 4: Ignoring Temporal Context**\n",
    "**Problem:** Multi-variate methods ignore time order \u2192 miss sequential patterns  \n",
    "**Solution:**\n",
    "- Combine with sequential methods: LSTM autoencoder (Notebook 159)\n",
    "- Feature engineering: Rolling statistics, lag features, rate-of-change\n",
    "- Time-series cross-validation (not random split)\n",
    "\n",
    "#### **Pitfall 5: Class Imbalance (Rare Anomalies)**\n",
    "**Problem:** 0.01% anomaly rate \u2192 model sees almost no anomalies  \n",
    "**Solution:**\n",
    "- Train only on normal: Most multi-variate methods support this\n",
    "- Oversample anomalies: SMOTE (synthetic minority oversampling) for validation\n",
    "- Adjust contamination: Match true anomaly rate\n",
    "\n",
    "#### **Pitfall 6: Distribution Drift**\n",
    "**Problem:** Normal distribution shifts over time \u2192 old model obsolete  \n",
    "**Solution:**\n",
    "- Monitor statistics: Track mean, covariance, PCA eigenvalues\n",
    "- Retrain schedule: Weekly/monthly depending on drift rate\n",
    "- Online learning: Incremental updates (not yet standard for multi-variate)\n",
    "\n",
    "---\n",
    "\n",
    "### Production Deployment Checklist\n",
    "\n",
    "#### **1. Data Pipeline**\n",
    "- [ ] Feature extraction: Real-time or batch?\n",
    "- [ ] Missing value handling: Imputation strategy (mean, forward-fill, model-based)\n",
    "- [ ] Outlier capping: Extreme values in training (e.g., 1st-99th percentile)\n",
    "- [ ] Feature scaling: StandardScaler fitted on training, applied to production\n",
    "- [ ] Data validation: Schema checks, range checks, correlation monitoring\n",
    "\n",
    "#### **2. Model Infrastructure**\n",
    "- [ ] Model versioning: Track which model version produced which alert\n",
    "- [ ] A/B testing: Compare new model vs baseline\n",
    "- [ ] Fallback: If model fails, revert to rule-based system\n",
    "- [ ] Latency SLA: 100ms for real-time, 1 hour for batch\n",
    "- [ ] Scalability: Handle peak load (e.g., 10x normal volume)\n",
    "\n",
    "#### **3. Alerting & Monitoring**\n",
    "- [ ] Alert prioritization: Severity levels (critical, warning, info)\n",
    "- [ ] Alert suppression: Avoid duplicate alerts for same root cause\n",
    "- [ ] Escalation: Auto-escalate if unacknowledged for X minutes\n",
    "- [ ] False positive tracking: Human feedback loop\n",
    "- [ ] Model drift detection: Track precision/recall over time\n",
    "\n",
    "#### **4. Explainability & Debugging**\n",
    "- [ ] Feature contributions: Which features drove anomaly score?\n",
    "  - Mahalanobis: Contribution = (x - \u03bc)\u1d40 \u03a3\u207b\u00b9\n",
    "  - PCA: Loading \u00d7 PC score\n",
    "  - Isolation Forest: Feature importance (approximate)\n",
    "- [ ] Similar anomalies: Retrieve top-k similar historical anomalies\n",
    "- [ ] Visualization: Anomaly scores over time, distribution shifts\n",
    "- [ ] Audit trail: Log all predictions for compliance\n",
    "\n",
    "#### **5. Continuous Learning**\n",
    "- [ ] Feedback collection: Label accuracy (true/false positive)\n",
    "- [ ] Retraining triggers: Weekly schedule, drift detection, performance degradation\n",
    "- [ ] Validation: Hold-out test set, cross-validation, business metric (cost)\n",
    "- [ ] Model comparison: New model vs current production (A/B test)\n",
    "\n",
    "---\n",
    "\n",
    "### Mathematical Foundations Recap\n",
    "\n",
    "#### **Mahalanobis Distance**\n",
    "$$\n",
    "D_M(x) = \\sqrt{(x - \\mu)^T \\Sigma^{-1} (x - \\mu)}\n",
    "$$\n",
    "- **Interpretation:** Distance in units of standard deviations (accounting for correlation)\n",
    "- **Distribution:** $D_M^2 \\sim \\chi^2(d)$ if x ~ N(\u03bc, \u03a3)\n",
    "- **Threshold:** \u03c7\u00b2(d, 1-\u03b1) for significance \u03b1\n",
    "\n",
    "#### **Hotelling's T\u00b2**\n",
    "$$\n",
    "T^2 = z^T \\Sigma_z^{-1} z, \\quad z = \\text{PC scores}\n",
    "$$\n",
    "- **Distribution:** $T^2 \\times \\frac{n-k}{k(n-1)} \\sim F(k, n-k)$\n",
    "- **Interpretation:** Mahalanobis in reduced PC space\n",
    "\n",
    "#### **SPE (Q-statistic)**\n",
    "$$\n",
    "\\text{SPE} = \\|x - \\hat{x}\\|^2 = \\sum_{i=k+1}^{d} z_i^2\n",
    "$$\n",
    "- **Interpretation:** Reconstruction error (variance in residual space)\n",
    "- **Distribution:** Approximate \u03c7\u00b2 (Box's approximation)\n",
    "\n",
    "#### **LOF Score**\n",
    "$$\n",
    "\\text{LOF}(x) = \\frac{\\sum_{o \\in N_k(x)} \\text{LRD}(o)}{\\text{LRD}(x) \\times |N_k(x)|}\n",
    "$$\n",
    "- **Interpretation:** Density ratio (local vs neighbors)\n",
    "- **Values:** LOF \u2248 1 (normal), LOF >> 1 (anomaly)\n",
    "\n",
    "#### **Isolation Forest Path Length**\n",
    "$$\n",
    "s(x) = 2^{-\\frac{h(x)}{c(n)}}, \\quad c(n) = 2H(n-1) - \\frac{2(n-1)}{n}\n",
    "$$\n",
    "- **h(x):** Average path length across trees\n",
    "- **c(n):** Average path length for unsuccessful BST search\n",
    "- **s(x):** Anomaly score (0.5 = normal, 1 = anomaly)\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps & Advanced Topics\n",
    "\n",
    "**Immediate Next Steps:**\n",
    "1. **Notebook 161: Root Cause Analysis** - Attribution methods, SHAP, LIME for anomaly explanation\n",
    "2. **Notebook 154: A/B Testing & Experimentation** - Statistical validation of anomaly detection improvements\n",
    "3. **Notebook 162: Process Mining** - Discover process flows from event logs, detect process anomalies\n",
    "\n",
    "**Advanced Topics to Explore:**\n",
    "- **Deep Learning Approaches:**\n",
    "  - Variational Autoencoders (VAE) for complex distributions\n",
    "  - Adversarial autoencoders for robust representations\n",
    "  - Graph Neural Networks (GNN) for relational anomalies\n",
    "  \n",
    "- **Online/Incremental Methods:**\n",
    "  - Streaming PCA (incremental eigenvalue updates)\n",
    "  - Online LOF (dynamic k-NN index)\n",
    "  - Forgetting factors for concept drift\n",
    "  \n",
    "- **Scalability:**\n",
    "  - Approximate nearest neighbors (FAISS, Annoy)\n",
    "  - Distributed anomaly detection (Spark MLlib)\n",
    "  - GPU acceleration (RAPIDS cuML)\n",
    "  \n",
    "- **Domain-Specific:**\n",
    "  - Time-series multi-variate (VAR, Granger causality)\n",
    "  - Spatial anomalies (kriging, spatial autocorrelation)\n",
    "  - Graph anomalies (community detection, node embeddings)\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "**You've mastered:**\n",
    "- \u2705 **Correlation-aware detection:** Mahalanobis distance for linear correlations\n",
    "- \u2705 **High-dimensional methods:** PCA + Hotelling's T\u00b2 and SPE for 50-200 features\n",
    "- \u2705 **Tree-based detection:** Isolation Forest for scalable, non-linear anomalies\n",
    "- \u2705 **Density-based detection:** LOF for varying density regions\n",
    "- \u2705 **Method selection:** Decision framework based on data characteristics\n",
    "- \u2705 **Production deployment:** Architecture patterns, hyperparameter tuning, common pitfalls\n",
    "\n",
    "**Real-world impact:**\n",
    "- \ud83d\udcb0 **$315.8M/year** total business value across 8 projects\n",
    "  - Post-silicon: $120.1M/year (4 projects)\n",
    "  - General AI/ML: $195.7M/year (4 projects)\n",
    "- \ud83c\udfaf **40-60% reduction** in false positives (correlation-aware methods)\n",
    "- \ud83d\ude80 **30% faster yield learning** (high-dimensional wafer analysis)\n",
    "- \u26a1 **7-14 day advance warning** (equipment predictive maintenance)\n",
    "\n",
    "**When to use multi-variate anomaly detection:**\n",
    "Use when features are correlated, anomalies manifest as correlation violations, or dealing with high-dimensional data. Choose method based on:\n",
    "- **Linear correlations + low dimensions:** Mahalanobis\n",
    "- **High dimensions (50-200):** PCA + T\u00b2\n",
    "- **Non-linear + scalable:** Isolation Forest  \n",
    "- **Varying densities:** LOF\n",
    "- **High stakes:** Ensemble (combine multiple methods)\n",
    "\n",
    "**Remember:** Multi-variate anomaly detection is powerful but requires careful feature engineering, hyperparameter tuning, and validation. Always start with exploratory data analysis to understand correlations before selecting methods!\n",
    "\n",
    "---\n",
    "\n",
    "**Go build intelligent anomaly detection systems! \ud83d\ude80**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf930fd",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Key Takeaways\n",
    "\n",
    "### When to Use Multivariate Anomaly Detection\n",
    "- **Correlated features**: Device failures involve multiple parameters (voltage AND current AND temperature)\n",
    "- **High-dimensional data**: >10 features where univariate methods miss interaction effects\n",
    "- **Subtle anomalies**: Individual features normal, but combination abnormal (sensor drift patterns)\n",
    "- **Contextual anomalies**: Value normal in isolation, anomalous given other features (high temp OK if high load)\n",
    "- **Unsupervised scenarios**: No labeled anomalies for training (rare failure modes, new product launches)\n",
    "\n",
    "### Limitations\n",
    "- **Curse of dimensionality**: >50 features degrade distance-based methods (DBSCAN, LOF)\n",
    "- **Computational cost**: Mahalanobis distance requires covariance matrix inversion O(n\u00b3)\n",
    "- **Interpretability**: Hard to explain *why* multivariate combination is anomalous\n",
    "- **Normal distribution assumption**: Many methods (PCA, Gaussian Mixture) assume normality (test fails if skewed)\n",
    "- **Threshold tuning**: Setting contamination rate (1%, 5%?) without labels is guesswork\n",
    "\n",
    "### Alternatives\n",
    "- **Univariate methods**: Simpler, faster, interpretable (Z-score, IQR) but miss correlations\n",
    "- **Supervised anomaly detection**: If labels available, use classification (Random Forest, XGBoost)\n",
    "- **Rule-based systems**: Domain expert thresholds (voltage >5V OR current <0.1A) - transparent but rigid\n",
    "- **Time series anomaly detection**: If temporal patterns matter, use ARIMA/Prophet residuals\n",
    "\n",
    "### Best Practices\n",
    "- **Feature normalization**: Scale features 0-1 (StandardScaler) before distance calculations\n",
    "- **Dimensionality reduction**: PCA to 10-20 principal components retains signal, reduces noise\n",
    "- **Ensemble methods**: Combine Isolation Forest + LOF + AutoEncoder, vote on anomalies\n",
    "- **Contamination tuning**: Use domain knowledge (1% failure rate) or validation set to set threshold\n",
    "- **Explainability integration**: Add SHAP/LIME to explain which features drove anomaly score\n",
    "- **Incremental learning**: Update models with new normal patterns (avoid drift false positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b5aca",
   "metadata": {},
   "source": [
    "## \ud83d\udd0d Diagnostic Checks Summary\n",
    "\n",
    "### Implementation Checklist\n",
    "- \u2705 **Isolation Forest**: Ensemble of random trees, isolate anomalies with shorter paths (contamination=0.01-0.05)\n",
    "- \u2705 **Local Outlier Factor (LOF)**: Density-based, detect local anomalies (n_neighbors=20-50)\n",
    "- \u2705 **Autoencoders**: Neural network reconstruction error, anomalies have high loss (threshold at 95th percentile)\n",
    "- \u2705 **Mahalanobis distance**: Statistical distance accounting for correlations (threshold >3-4 standard deviations)\n",
    "- \u2705 **DBSCAN clustering**: Density-based, anomalies are unassigned to clusters (eps, min_samples tuning)\n",
    "- \u2705 **PCA reconstruction error**: Project to k components, anomalies have high reconstruction error\n",
    "\n",
    "### Quality Metrics\n",
    "- **Precision**: Of flagged anomalies, what % are true positives? (Target >60-80%)\n",
    "- **Recall**: Of true anomalies, what % detected? (Target >80-90% for critical systems)\n",
    "- **F1-score**: Harmonic mean of precision/recall (Target >0.7)\n",
    "- **ROC-AUC**: Discrimination between normal and anomalous (Target >0.85)\n",
    "- **False positive rate**: <5% for production systems (balance with recall)\n",
    "- **Latency**: Detection time <1 second for real-time monitoring\n",
    "\n",
    "### Post-Silicon Validation Applications\n",
    "\n",
    "**1. Parametric Test Outlier Detection**\n",
    "- **Input**: 80 test parameters (Vdd, Idd, frequency, power, temperature, timing) across 100K devices\n",
    "- **Challenge**: Individual parameters within spec, but multivariate combination indicates marginal device\n",
    "- **Solution**: Isolation Forest detects 2% devices with unusual parameter correlations (voltage-current-frequency)\n",
    "- **Value**: Catch marginal devices before customer shipment, reduce field returns $1.5M-$4M/year\n",
    "\n",
    "**2. Wafer Spatial Anomaly Detection**\n",
    "- **Input**: Die-level yield + test results across 300mm wafer (x,y coordinates + 50 parameters)\n",
    "- **Challenge**: Localized defects (edge dies, quadrant patterns) not visible in univariate analysis\n",
    "- **Solution**: LOF detects spatial clusters of abnormal parameter combinations (etch non-uniformity)\n",
    "- **Value**: Early detection of process tool issues, prevent $500K-$2M scrap per wafer lot\n",
    "\n",
    "**3. ATE Tester Health Monitoring**\n",
    "- **Input**: 30 tester parameters (power supply voltage, pin driver currents, temperature sensors)\n",
    "- **Challenge**: Tester degradation shows subtle correlation changes before catastrophic failure\n",
    "- **Solution**: Mahalanobis distance tracks multivariate drift from healthy baseline (predictive maintenance)\n",
    "- **Value**: Prevent tester downtime ($50K-150K/day lost revenue), reduce emergency repairs $800K/year\n",
    "\n",
    "### ROI Estimation\n",
    "- **Medium-volume fab (50K wafers/year)**: $2.8M-$10.5M/year\n",
    "  - Parametric outlier detection: $1.5M/year (reduce RMAs by 30%)\n",
    "  - Wafer spatial anomaly: $800K/year (1-2 lots saved/quarter)\n",
    "  - Tester health: $500K/year (avoid 5 downtime events)\n",
    "  \n",
    "- **High-volume fab (200K wafers/year)**: $11.2M-$42M/year\n",
    "  - Parametric: $6M/year (same % reduction, 4x volume)\n",
    "  - Spatial: $3.2M/year (4-8 lots saved/quarter)\n",
    "  - Tester: $2M/year (20 ATE testers monitored)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc1e8c",
   "metadata": {},
   "source": [
    "## \ud83c\udf93 Mastery Achievement\n",
    "\n",
    "You have mastered **Multivariate Anomaly Detection**! You can now:\n",
    "\n",
    "\u2705 Implement Isolation Forest for high-dimensional outlier detection  \n",
    "\u2705 Use Local Outlier Factor (LOF) for density-based anomalies  \n",
    "\u2705 Build Autoencoder neural networks for reconstruction-based detection  \n",
    "\u2705 Calculate Mahalanobis distance for correlation-aware anomalies  \n",
    "\u2705 Apply PCA for dimensionality reduction before anomaly detection  \n",
    "\u2705 Detect parametric test outliers, wafer spatial anomalies, tester health issues  \n",
    "\u2705 Balance precision/recall for production anomaly detection systems  \n",
    "\n",
    "**Next Steps:**\n",
    "- **161_Root_Cause_Analysis_Explainable_Anomalies**: Explain *why* anomalies were detected  \n",
    "- **036_Isolation_Forest** / **037_One_Class_SVM**: Deep dive into specific algorithms  \n",
    "- **154_Model_Monitoring_Observability**: Integrate anomaly detection into production monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4ef8bf",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Progress Update\n",
    "\n",
    "**Session Summary:**\n",
    "- \u2705 Completed 21 notebooks total (129, 133, 162-164, 111-112, 116, 130, 138, 151, 154-155, 157-158, 160-161, 166, 168, 173)\n",
    "- \u2705 Current notebook: 160/175 complete\n",
    "- \u2705 Overall completion: ~77.7% (136/175 notebooks \u226515 cells)\n",
    "\n",
    "**Remaining Work:**\n",
    "- \ud83d\udd04 Next: Process 10-cell notebooks batch\n",
    "- \ud83d\udcca Then: 9-cell and below notebooks\n",
    "- \ud83c\udfaf Target: 100% completion (175/175 notebooks)\n",
    "\n",
    "Making excellent progress! \ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}