{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 169: Real Time Streaming Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb44208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Real-Time Streaming Forecasting - Production Setup\n",
    "\n",
    "This notebook uses streaming and online learning libraries:\n",
    "- River: Online machine learning (incremental models, drift detection)\n",
    "- scikit-multiflow: Stream learning algorithms (legacy, now merged into River)\n",
    "- statsmodels: Time series models (adapted for streaming)\n",
    "- collections.deque: Efficient sliding windows (O(1) append/pop)\n",
    "\n",
    "Key Concepts:\n",
    "1. Online Learning: Models learn one sample at a time (incremental updates)\n",
    "2. Sliding Windows: Fixed-size buffers for recent data (FIFO)\n",
    "3. Concept Drift: Distribution changes over time (detect and adapt)\n",
    "4. Bounded Memory: Constant memory usage regardless of stream length\n",
    "\n",
    "Streaming Processing Frameworks (optional for large-scale):\n",
    "- Apache Kafka: Event streaming platform (producer/consumer)\n",
    "- Apache Flink: Stream processing (windowing, state management)\n",
    "- Redis Streams: Lightweight message broker\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import deque\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Online learning library\n",
    "try:\n",
    "    from river import linear_model, preprocessing, drift, metrics, tree\n",
    "    from river.stream import iter_pandas\n",
    "    RIVER_AVAILABLE = True\n",
    "    print(\"\u2705 River library loaded (online learning)\")\n",
    "except ImportError:\n",
    "    RIVER_AVAILABLE = False\n",
    "    print(\"\u26a0\ufe0f River not available (install: pip install river)\")\n",
    "\n",
    "# Time series\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Sklearn for comparison\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"\\n\ud83d\ude80 Real-Time Streaming Forecasting Setup Complete\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Key Capabilities:\")\n",
    "print(\"  \u2022 Online learning: Incremental model updates\")\n",
    "print(\"  \u2022 Sliding windows: Fixed-size FIFO buffers\")\n",
    "print(\"  \u2022 Drift detection: ADWIN, Page-Hinkley, DDM\")\n",
    "print(\"  \u2022 Bounded memory: O(1) memory per observation\")\n",
    "print(\"  \u2022 Low latency: <100ms predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef4b3d",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Part 1: Online Learning Fundamentals\n",
    "\n",
    "### What is Online Learning?\n",
    "\n",
    "**Online learning** (incremental learning) processes one observation at a time, updating models without storing the full dataset. This is fundamentally different from batch learning:\n",
    "\n",
    "**Batch Learning:**\n",
    "```python\n",
    "model.fit(X_train)  # Train on entire dataset\n",
    "predictions = model.predict(X_test)\n",
    "```\n",
    "\n",
    "**Online Learning:**\n",
    "```python\n",
    "for x, y in stream:\n",
    "    y_pred = model.predict_one(x)  # Predict first\n",
    "    model.learn_one(x, y)           # Then update\n",
    "```\n",
    "\n",
    "### \ud83d\udcdd Key Online Learning Concepts\n",
    "\n",
    "**1. Learn-Then-Predict vs Predict-Then-Learn:**\n",
    "- **Learn-then-predict**: Update model, then predict (lower error, but uses future data)\n",
    "- **Predict-then-learn**: Predict, then update (realistic, mimics production)\n",
    "\n",
    "**2. Forgetting Mechanisms:**\n",
    "- **Sliding window**: Only recent $w$ observations (hard cutoff)\n",
    "- **Exponential decay**: Older observations weighted by $\\lambda^t$ where $0 < \\lambda < 1$\n",
    "- **Adaptive window**: Window size adjusts based on drift detection\n",
    "\n",
    "**3. Performance Metrics:**\n",
    "- **Progressive validation**: Each observation used once for prediction, then training\n",
    "- **Prequential evaluation**: Running average of metrics (e.g., RMSE, MAE)\n",
    "- **Fading factors**: Recent errors weighted more than old errors\n",
    "\n",
    "### \ud83c\udfed Post-Silicon Application: Online Yield Forecasting\n",
    "\n",
    "**Scenario:** ATE tester streams pass/fail results every 2 seconds (30 devices/minute)\n",
    "\n",
    "**Challenge:** Yield patterns change hourly due to:\n",
    "- Wafer position effects (center vs edge)\n",
    "- Equipment warmup/cooldown\n",
    "- Environmental conditions (temperature, humidity)\n",
    "- Process drift (chemical depletion, chamber aging)\n",
    "\n",
    "**Solution:** Online logistic regression with exponential forgetting\n",
    "- Each test result updates model incrementally\n",
    "- Recent observations weighted more (forgetting factor $\\lambda = 0.98$)\n",
    "- Detect yield excursions within 60 seconds\n",
    "\n",
    "**Math:** Online gradient descent update for logistic regression:\n",
    "\n",
    "$$w_{t+1} = w_t + \\eta \\cdot (y_t - \\sigma(w_t^T x_t)) \\cdot x_t$$\n",
    "\n",
    "where:\n",
    "- $w_t$: Model weights at time $t$\n",
    "- $\\eta$: Learning rate (e.g., 0.01)\n",
    "- $y_t$: Actual label (0 = fail, 1 = pass)\n",
    "- $\\sigma(z) = \\frac{1}{1 + e^{-z}}$: Sigmoid function\n",
    "- $x_t$: Feature vector at time $t$\n",
    "\n",
    "**With exponential forgetting:**\n",
    "\n",
    "$$w_{t+1} = \\lambda w_t + \\eta \\cdot (y_t - \\sigma(w_t^T x_t)) \\cdot x_t$$\n",
    "\n",
    "where $\\lambda = 0.98$ (98% retention, 2% decay per observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Online Learning Implementation: ATE Wafer Test Yield Forecasting\n",
    "# ============================================================================\n",
    "\n",
    "class OnlineLogisticRegression:\n",
    "    \"\"\"\n",
    "    Online logistic regression with exponential forgetting.\n",
    "    \n",
    "    Updates weights incrementally for each new observation.\n",
    "    Suitable for streaming binary classification (pass/fail).\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, learning_rate=0.01, forgetting_factor=0.98):\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0.0\n",
    "        self.learning_rate = learning_rate\n",
    "        self.forgetting_factor = forgetting_factor\n",
    "        self.n_samples_seen = 0\n",
    "        \n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Sigmoid activation: \u03c3(z) = 1 / (1 + e^(-z))\"\"\"\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))  # Clip for numerical stability\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"Predict probability of positive class (pass)\"\"\"\n",
    "        z = np.dot(self.weights, x) + self.bias\n",
    "        return self._sigmoid(z)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict class label (0 or 1)\"\"\"\n",
    "        return 1 if self.predict_proba(x) >= 0.5 else 0\n",
    "    \n",
    "    def update(self, x, y):\n",
    "        \"\"\"\n",
    "        Incremental weight update with exponential forgetting.\n",
    "        \n",
    "        Update rule: w_{t+1} = \u03bb\u00b7w_t + \u03b7\u00b7(y - \u0177)\u00b7x\n",
    "        where \u03bb = forgetting factor, \u03b7 = learning rate\n",
    "        \"\"\"\n",
    "        # Predict current probability\n",
    "        y_pred = self.predict_proba(x)\n",
    "        \n",
    "        # Compute error\n",
    "        error = y - y_pred\n",
    "        \n",
    "        # Update weights with exponential forgetting\n",
    "        self.weights = self.forgetting_factor * self.weights + self.learning_rate * error * x\n",
    "        self.bias = self.forgetting_factor * self.bias + self.learning_rate * error\n",
    "        \n",
    "        self.n_samples_seen += 1\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "# Generate synthetic streaming wafer test data\n",
    "def generate_wafer_test_stream(n_samples=1000, yield_baseline=0.92, drift_point=500):\n",
    "    \"\"\"\n",
    "    Simulates streaming ATE test results with concept drift.\n",
    "    \n",
    "    Drift: Yield drops from 92% to 78% at t=500 (equipment degradation)\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    stream_data = []\n",
    "    for t in range(n_samples):\n",
    "        # Features: wafer position (x, y), test temperature, voltage\n",
    "        die_x = np.random.uniform(-1, 1)  # Normalized die X coordinate\n",
    "        die_y = np.random.uniform(-1, 1)  # Normalized die Y coordinate\n",
    "        temp = np.random.normal(25, 2)    # Temperature (\u00b0C)\n",
    "        voltage = np.random.normal(1.0, 0.05)  # Supply voltage (V)\n",
    "        \n",
    "        # Concept drift: Yield degrades after drift_point\n",
    "        if t < drift_point:\n",
    "            base_yield = yield_baseline\n",
    "        else:\n",
    "            # Gradual yield degradation\n",
    "            degradation = (t - drift_point) / (n_samples - drift_point) * 0.14\n",
    "            base_yield = yield_baseline - degradation\n",
    "        \n",
    "        # Yield influenced by position (edge effect) and environmental factors\n",
    "        edge_distance = np.sqrt(die_x**2 + die_y**2)  # Distance from wafer center\n",
    "        yield_prob = base_yield - 0.15 * edge_distance  # Edge dies have lower yield\n",
    "        yield_prob += 0.02 * (temp - 25) / 2  # Temperature sensitivity\n",
    "        yield_prob += 0.03 * (voltage - 1.0) / 0.05  # Voltage sensitivity\n",
    "        yield_prob = np.clip(yield_prob, 0, 1)\n",
    "        \n",
    "        # Generate pass/fail result\n",
    "        result = 1 if np.random.random() < yield_prob else 0\n",
    "        \n",
    "        stream_data.append({\n",
    "            'timestamp': t,\n",
    "            'die_x': die_x,\n",
    "            'die_y': die_y,\n",
    "            'temp': temp,\n",
    "            'voltage': voltage,\n",
    "            'result': result,\n",
    "            'true_yield': yield_prob\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(stream_data)\n",
    "\n",
    "# Generate streaming data\n",
    "print(\"Generating synthetic wafer test stream...\")\n",
    "stream_df = generate_wafer_test_stream(n_samples=1000)\n",
    "print(f\"\u2705 Generated {len(stream_df)} test results\")\n",
    "print(f\"\\nFirst 5 test results:\")\n",
    "print(stream_df.head())\n",
    "\n",
    "# Initialize online model\n",
    "n_features = 4  # die_x, die_y, temp, voltage\n",
    "online_model = OnlineLogisticRegression(\n",
    "    n_features=n_features,\n",
    "    learning_rate=0.01,\n",
    "    forgetting_factor=0.98\n",
    ")\n",
    "\n",
    "# Simulate streaming: predict-then-learn\n",
    "predictions = []\n",
    "actuals = []\n",
    "timestamps = []\n",
    "\n",
    "print(\"\\n\ud83d\udd04 Processing stream (predict-then-learn)...\")\n",
    "for idx, row in stream_df.iterrows():\n",
    "    # Feature vector\n",
    "    x = np.array([row['die_x'], row['die_y'], row['temp'], row['voltage']])\n",
    "    y = row['result']\n",
    "    \n",
    "    # Step 1: Predict (before learning)\n",
    "    y_pred = online_model.predict_proba(x)\n",
    "    \n",
    "    # Step 2: Learn (update model)\n",
    "    online_model.update(x, y)\n",
    "    \n",
    "    # Store for evaluation\n",
    "    predictions.append(y_pred)\n",
    "    actuals.append(y)\n",
    "    timestamps.append(row['timestamp'])\n",
    "\n",
    "# Convert to arrays\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "print(f\"\u2705 Processed {len(predictions)} streaming predictions\")\n",
    "print(f\"   Model saw {online_model.n_samples_seen} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4457d85e",
   "metadata": {},
   "source": [
    "### \ud83d\udcca Visualize Online Learning Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute progressive validation metrics\n",
    "window_size = 50  # Rolling window for metrics\n",
    "rolling_accuracy = []\n",
    "rolling_mae = []\n",
    "\n",
    "for i in range(window_size, len(predictions)):\n",
    "    window_preds = predictions[i-window_size:i]\n",
    "    window_actuals = actuals[i-window_size:i]\n",
    "    \n",
    "    # Accuracy (binary classification)\n",
    "    binary_preds = (window_preds >= 0.5).astype(int)\n",
    "    accuracy = np.mean(binary_preds == window_actuals)\n",
    "    rolling_accuracy.append(accuracy)\n",
    "    \n",
    "    # MAE (probability calibration)\n",
    "    mae = np.mean(np.abs(window_preds - window_actuals))\n",
    "    rolling_mae.append(mae)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Subplot 1: Predicted vs Actual Yield Probability\n",
    "axes[0].plot(timestamps, predictions, label='Predicted Yield Probability', alpha=0.7, linewidth=1)\n",
    "axes[0].plot(timestamps, actuals, label='Actual Result (Pass=1, Fail=0)', alpha=0.5, linewidth=0.8)\n",
    "axes[0].axvline(x=500, color='red', linestyle='--', label='Concept Drift Point', linewidth=2)\n",
    "axes[0].set_xlabel('Test Number (Time)', fontsize=11)\n",
    "axes[0].set_ylabel('Probability / Result', fontsize=11)\n",
    "axes[0].set_title('Online Learning: Predicted Yield Probability vs Actual Results', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(loc='upper right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Rolling Accuracy\n",
    "axes[1].plot(timestamps[window_size:], rolling_accuracy, color='green', linewidth=2)\n",
    "axes[1].axvline(x=500, color='red', linestyle='--', label='Concept Drift Point', linewidth=2)\n",
    "axes[1].axhline(y=0.8, color='orange', linestyle=':', label='80% Target', linewidth=1.5)\n",
    "axes[1].set_xlabel('Test Number (Time)', fontsize=11)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=11)\n",
    "axes[1].set_title(f'Rolling Accuracy (Window = {window_size} tests)', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(loc='lower left')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0.6, 1.0])\n",
    "\n",
    "# Subplot 3: Rolling MAE (Calibration)\n",
    "axes[2].plot(timestamps[window_size:], rolling_mae, color='purple', linewidth=2)\n",
    "axes[2].axvline(x=500, color='red', linestyle='--', label='Concept Drift Point', linewidth=2)\n",
    "axes[2].set_xlabel('Test Number (Time)', fontsize=11)\n",
    "axes[2].set_ylabel('MAE', fontsize=11)\n",
    "axes[2].set_title(f'Rolling MAE - Probability Calibration (Window = {window_size} tests)', fontsize=13, fontweight='bold')\n",
    "axes[2].legend(loc='upper left')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\ud83d\udcca ONLINE LEARNING PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "binary_preds = (predictions >= 0.5).astype(int)\n",
    "overall_accuracy = np.mean(binary_preds == actuals)\n",
    "overall_mae = np.mean(np.abs(predictions - actuals))\n",
    "print(f\"  \u2022 Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)\")\n",
    "print(f\"  \u2022 MAE: {overall_mae:.4f}\")\n",
    "\n",
    "print(f\"\\nBefore Drift (t < 500):\")\n",
    "pre_drift_acc = np.mean(binary_preds[:500] == actuals[:500])\n",
    "pre_drift_mae = np.mean(np.abs(predictions[:500] - actuals[:500]))\n",
    "print(f\"  \u2022 Accuracy: {pre_drift_acc:.4f} ({pre_drift_acc*100:.2f}%)\")\n",
    "print(f\"  \u2022 MAE: {pre_drift_mae:.4f}\")\n",
    "\n",
    "print(f\"\\nAfter Drift (t >= 500):\")\n",
    "post_drift_acc = np.mean(binary_preds[500:] == actuals[500:])\n",
    "post_drift_mae = np.mean(np.abs(predictions[500:] - actuals[500:]))\n",
    "print(f\"  \u2022 Accuracy: {post_drift_acc:.4f} ({post_drift_acc*100:.2f}%)\")\n",
    "print(f\"  \u2022 MAE: {post_drift_mae:.4f}\")\n",
    "\n",
    "print(f\"\\nModel Adaptation:\")\n",
    "recovery_window = 100  # Tests needed to adapt after drift\n",
    "if len(predictions) > 500 + recovery_window:\n",
    "    recovery_acc = np.mean(binary_preds[500:500+recovery_window] == actuals[500:500+recovery_window])\n",
    "    adapted_acc = np.mean(binary_preds[500+recovery_window:] == actuals[500+recovery_window:])\n",
    "    print(f\"  \u2022 Accuracy during adaptation (t=500-600): {recovery_acc:.4f}\")\n",
    "    print(f\"  \u2022 Accuracy after adaptation (t>600): {adapted_acc:.4f}\")\n",
    "    print(f\"  \u2022 Recovery rate: {(adapted_acc - recovery_acc) / recovery_acc * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n\ud83d\udca1 Key Insight:\")\n",
    "print(f\"   Online learning adapts to concept drift automatically through\")\n",
    "print(f\"   exponential forgetting (\u03bb={online_model.forgetting_factor}).\")\n",
    "print(f\"   Recent observations have higher influence on model weights.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51149c7e",
   "metadata": {},
   "source": [
    "## \ud83d\udd0d Part 2: Concept Drift Detection\n",
    "\n",
    "### What is Concept Drift?\n",
    "\n",
    "**Concept drift** occurs when the statistical properties of the target variable change over time. In streaming forecasting, this means the relationship between features and outcomes evolves.\n",
    "\n",
    "**Types of Drift:**\n",
    "\n",
    "1. **Sudden Drift** (abrupt change)\n",
    "   - Example: Equipment failure causes immediate yield drop\n",
    "   - Pattern: Step function\n",
    "   \n",
    "2. **Gradual Drift** (incremental change)\n",
    "   - Example: Process chemical depletion over weeks\n",
    "   - Pattern: Linear or exponential decay\n",
    "   \n",
    "3. **Incremental Drift** (slow, continuous change)\n",
    "   - Example: Equipment aging, environmental seasonality\n",
    "   - Pattern: Slow trend\n",
    "   \n",
    "4. **Recurring Drift** (periodic patterns)\n",
    "   - Example: Daily temperature cycles, weekly production schedules\n",
    "   - Pattern: Cyclical\n",
    "\n",
    "### \ud83d\udcca Drift Detection Algorithms\n",
    "\n",
    "**1. ADWIN (Adaptive Windowing)**\n",
    "- Maintains variable-length window\n",
    "- Detects changes in data distribution\n",
    "- Automatically resizes window when drift detected\n",
    "- **Advantage**: No assumptions about drift type\n",
    "- **Disadvantage**: Higher computational cost\n",
    "\n",
    "**2. DDM (Drift Detection Method)**\n",
    "- Monitors prediction error rate\n",
    "- Uses statistical process control (warning/drift thresholds)\n",
    "- Triggers alarm when error increases significantly\n",
    "- **Advantage**: Simple, interpretable\n",
    "- **Disadvantage**: Only detects sudden drift\n",
    "\n",
    "**3. EDDM (Early Drift Detection Method)**\n",
    "- Monitors distance between errors (not error rate)\n",
    "- More sensitive to gradual drift\n",
    "- Better for imbalanced datasets\n",
    "- **Advantage**: Early warning\n",
    "- **Disadvantage**: More false alarms\n",
    "\n",
    "**4. Page-Hinkley Test**\n",
    "- Cumulative sum (CUSUM) based\n",
    "- Detects change in mean of streaming values\n",
    "- Threshold-based alarm\n",
    "- **Advantage**: Fast, low memory\n",
    "- **Disadvantage**: Requires tuning threshold\n",
    "\n",
    "### \ud83c\udfed Post-Silicon Application: Equipment Degradation Detection\n",
    "\n",
    "**Scenario:** ATE tester shows gradual performance degradation\n",
    "\n",
    "**Symptoms:**\n",
    "- Increasing test time (10ms/test \u2192 15ms/test over 1 week)\n",
    "- Rising temperature (25\u00b0C \u2192 28\u00b0C)\n",
    "- More frequent calibration failures\n",
    "\n",
    "**Solution:** ADWIN drift detector on test time stream\n",
    "- Automatically detects when test time distribution changes\n",
    "- Triggers preventive maintenance before failures occur\n",
    "- Reduces unplanned downtime 40%\n",
    "\n",
    "**Math:** ADWIN hypothesis test\n",
    "\n",
    "For two sub-windows $W_0$ and $W_1$ with means $\\mu_0$ and $\\mu_1$:\n",
    "\n",
    "$$|\\mu_0 - \\mu_1| > \\epsilon_{cut}$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\\epsilon_{cut} = \\sqrt{\\frac{1}{2m} \\cdot \\ln\\frac{4n}{\\delta}}$$\n",
    "\n",
    "- $m$: Harmonic mean of sub-window sizes\n",
    "- $n$: Total window size\n",
    "- $\\delta$: Confidence level (e.g., 0.05)\n",
    "\n",
    "If condition holds \u2192 **drift detected**, window is cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ec521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Concept Drift Detection Implementation\n",
    "# ============================================================================\n",
    "\n",
    "class PageHinkleyDriftDetector:\n",
    "    \"\"\"\n",
    "    Page-Hinkley test for detecting changes in stream mean.\n",
    "    \n",
    "    CUSUM-based drift detection: accumulates deviations from mean,\n",
    "    triggers alarm when cumulative sum exceeds threshold.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=50, alpha=0.9999):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - threshold: Alarm threshold (higher = less sensitive)\n",
    "        - alpha: Forgetting factor for running mean (0 < alpha < 1)\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.alpha = alpha\n",
    "        self.running_mean = 0.0\n",
    "        self.cumsum = 0.0\n",
    "        self.min_cumsum = 0.0\n",
    "        self.n_samples = 0\n",
    "        self.drift_detected = False\n",
    "        \n",
    "    def update(self, value):\n",
    "        \"\"\"Update detector with new value, return True if drift detected\"\"\"\n",
    "        # Update running mean with exponential smoothing\n",
    "        if self.n_samples == 0:\n",
    "            self.running_mean = value\n",
    "        else:\n",
    "            self.running_mean = self.alpha * self.running_mean + (1 - self.alpha) * value\n",
    "        \n",
    "        # Update cumulative sum (deviation from mean)\n",
    "        self.cumsum += value - self.running_mean - 0.005  # Small delta to avoid false positives\n",
    "        \n",
    "        # Track minimum cumsum (for drift detection)\n",
    "        self.min_cumsum = min(self.min_cumsum, self.cumsum)\n",
    "        \n",
    "        # Detect drift: cumsum significantly above minimum\n",
    "        drift_magnitude = self.cumsum - self.min_cumsum\n",
    "        self.drift_detected = drift_magnitude > self.threshold\n",
    "        \n",
    "        self.n_samples += 1\n",
    "        \n",
    "        return self.drift_detected\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset detector after drift handled\"\"\"\n",
    "        self.cumsum = 0.0\n",
    "        self.min_cumsum = 0.0\n",
    "        self.drift_detected = False\n",
    "\n",
    "class SlidingWindowForecaster:\n",
    "    \"\"\"\n",
    "    Sliding window forecasting with automatic drift detection.\n",
    "    \n",
    "    Maintains fixed-size window of recent observations.\n",
    "    Retrains model when drift detected.\n",
    "    \"\"\"\n",
    "    def __init__(self, window_size=100, drift_threshold=50):\n",
    "        self.window_size = window_size\n",
    "        self.window = deque(maxlen=window_size)\n",
    "        self.drift_detector = PageHinkleyDriftDetector(threshold=drift_threshold)\n",
    "        self.model = None  # Will be simple moving average\n",
    "        self.drift_points = []\n",
    "        self.predictions = []\n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"Predict next value using moving average of window\"\"\"\n",
    "        if len(self.window) < 5:\n",
    "            return np.mean(list(self.window)) if len(self.window) > 0 else 0.0\n",
    "        \n",
    "        # Simple exponential weighted moving average\n",
    "        weights = np.exp(np.linspace(-1, 0, len(self.window)))\n",
    "        weights /= weights.sum()\n",
    "        return np.dot(weights, list(self.window))\n",
    "    \n",
    "    def update(self, value, timestamp):\n",
    "        \"\"\"Add new observation to window and check for drift\"\"\"\n",
    "        # Add to window (automatically removes oldest if full)\n",
    "        self.window.append(value)\n",
    "        \n",
    "        # Check for drift\n",
    "        if len(self.window) >= 10:  # Need minimum samples\n",
    "            drift_detected = self.drift_detector.update(value)\n",
    "            \n",
    "            if drift_detected:\n",
    "                self.drift_points.append(timestamp)\n",
    "                print(f\"\u26a0\ufe0f  DRIFT DETECTED at t={timestamp}\")\n",
    "                print(f\"   Cumsum: {self.drift_detector.cumsum:.2f}, Threshold: {self.drift_detector.threshold}\")\n",
    "                \n",
    "                # Reset drift detector and partially clear window\n",
    "                self.drift_detector.reset()\n",
    "                # Keep only recent 30% of window for faster adaptation\n",
    "                keep_size = int(self.window_size * 0.3)\n",
    "                recent_values = list(self.window)[-keep_size:]\n",
    "                self.window.clear()\n",
    "                self.window.extend(recent_values)\n",
    "                \n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "# Generate equipment degradation stream\n",
    "def generate_equipment_degradation_stream(n_samples=800):\n",
    "    \"\"\"\n",
    "    Simulates ATE equipment test time with gradual degradation.\n",
    "    \n",
    "    Phase 1 (t < 300): Normal operation, test_time ~ 10ms\n",
    "    Phase 2 (300 <= t < 600): Gradual degradation, 10ms \u2192 15ms\n",
    "    Phase 3 (t >= 600): Critical degradation, test_time ~ 16ms\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    stream = []\n",
    "    \n",
    "    for t in range(n_samples):\n",
    "        if t < 300:\n",
    "            # Normal operation\n",
    "            base_time = 10.0\n",
    "            noise = np.random.normal(0, 0.5)\n",
    "        elif t < 600:\n",
    "            # Gradual degradation\n",
    "            degradation = (t - 300) / 300 * 5.0  # +5ms over 300 samples\n",
    "            base_time = 10.0 + degradation\n",
    "            noise = np.random.normal(0, 0.7)  # Increased variance\n",
    "        else:\n",
    "            # Critical state\n",
    "            base_time = 16.0\n",
    "            noise = np.random.normal(0, 1.0)  # High variance\n",
    "        \n",
    "        test_time = base_time + noise\n",
    "        stream.append({'timestamp': t, 'test_time_ms': test_time})\n",
    "    \n",
    "    return pd.DataFrame(stream)\n",
    "\n",
    "# Generate streaming data\n",
    "print(\"Generating equipment degradation stream...\")\n",
    "equip_stream = generate_equipment_degradation_stream(n_samples=800)\n",
    "print(f\"\u2705 Generated {len(equip_stream)} test time observations\")\n",
    "\n",
    "# Initialize sliding window forecaster\n",
    "forecaster = SlidingWindowForecaster(window_size=100, drift_threshold=35)\n",
    "\n",
    "# Process stream with drift detection\n",
    "predictions = []\n",
    "actuals = []\n",
    "timestamps = []\n",
    "drift_timestamps = []\n",
    "\n",
    "print(\"\\n\ud83d\udd04 Processing equipment stream with drift detection...\\n\")\n",
    "for idx, row in equip_stream.iterrows():\n",
    "    timestamp = row['timestamp']\n",
    "    test_time = row['test_time_ms']\n",
    "    \n",
    "    # Predict next value\n",
    "    prediction = forecaster.predict()\n",
    "    \n",
    "    # Update window and detect drift\n",
    "    drift_detected = forecaster.update(test_time, timestamp)\n",
    "    if drift_detected:\n",
    "        drift_timestamps.append(timestamp)\n",
    "    \n",
    "    # Store\n",
    "    predictions.append(prediction)\n",
    "    actuals.append(test_time)\n",
    "    timestamps.append(timestamp)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "print(f\"\\n\u2705 Processed {len(predictions)} observations\")\n",
    "print(f\"   Drift detected at: {forecaster.drift_points}\")\n",
    "print(f\"   Number of drift events: {len(forecaster.drift_points)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e7fff",
   "metadata": {},
   "source": [
    "### \ud83d\udcca Visualize Drift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Drift Detection Performance\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 9))\n",
    "\n",
    "# Subplot 1: Actual vs Predicted Test Time\n",
    "axes[0].plot(timestamps, actuals, label='Actual Test Time', alpha=0.7, linewidth=1.5, color='blue')\n",
    "axes[0].plot(timestamps, predictions, label='Predicted Test Time (Sliding Window)', alpha=0.8, linewidth=1.2, color='orange')\n",
    "\n",
    "# Mark drift detection points\n",
    "for drift_t in forecaster.drift_points:\n",
    "    axes[0].axvline(x=drift_t, color='red', linestyle='--', alpha=0.7, linewidth=2)\n",
    "\n",
    "# Mark true drift regions\n",
    "axes[0].axvspan(300, 600, alpha=0.15, color='yellow', label='Gradual Degradation Phase')\n",
    "axes[0].axvspan(600, 800, alpha=0.15, color='red', label='Critical Phase')\n",
    "\n",
    "axes[0].set_xlabel('Time (Test Number)', fontsize=11)\n",
    "axes[0].set_ylabel('Test Time (ms)', fontsize=11)\n",
    "axes[0].set_title('Equipment Degradation: Drift Detection with Sliding Window', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(loc='upper left', fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Forecast Error Over Time\n",
    "forecast_error = np.abs(actuals - predictions)\n",
    "rolling_error = pd.Series(forecast_error).rolling(window=50, min_periods=1).mean()\n",
    "\n",
    "axes[1].plot(timestamps, forecast_error, label='Absolute Error', alpha=0.4, linewidth=0.8, color='gray')\n",
    "axes[1].plot(timestamps, rolling_error, label='Rolling MAE (window=50)', linewidth=2, color='purple')\n",
    "\n",
    "# Mark drift points\n",
    "for drift_t in forecaster.drift_points:\n",
    "    axes[1].axvline(x=drift_t, color='red', linestyle='--', alpha=0.7, linewidth=2, label='Drift Detected' if drift_t == forecaster.drift_points[0] else '')\n",
    "\n",
    "axes[1].axhline(y=1.0, color='green', linestyle=':', label='Target MAE < 1.0ms', linewidth=1.5)\n",
    "axes[1].set_xlabel('Time (Test Number)', fontsize=11)\n",
    "axes[1].set_ylabel('Forecast Error (ms)', fontsize=11)\n",
    "axes[1].set_title('Forecast Error Evolution (Auto-adaptation via Drift Detection)', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(loc='upper left', fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Performance summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\ud83d\udd0d DRIFT DETECTION PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nDrift Detection:\")\n",
    "print(f\"  \u2022 Drift points detected: {forecaster.drift_points}\")\n",
    "print(f\"  \u2022 Total drift events: {len(forecaster.drift_points)}\")\n",
    "print(f\"  \u2022 True drift regions: [300-600] (gradual), [600+] (critical)\")\n",
    "\n",
    "print(f\"\\nForecast Accuracy:\")\n",
    "overall_mae = np.mean(forecast_error)\n",
    "print(f\"  \u2022 Overall MAE: {overall_mae:.4f} ms\")\n",
    "\n",
    "# Phase-wise MAE\n",
    "phase1_mae = np.mean(forecast_error[:300])\n",
    "phase2_mae = np.mean(forecast_error[300:600])\n",
    "phase3_mae = np.mean(forecast_error[600:])\n",
    "print(f\"  \u2022 Phase 1 MAE (t<300, normal): {phase1_mae:.4f} ms\")\n",
    "print(f\"  \u2022 Phase 2 MAE (300\u2264t<600, degrading): {phase2_mae:.4f} ms\")\n",
    "print(f\"  \u2022 Phase 3 MAE (t\u2265600, critical): {phase3_mae:.4f} ms\")\n",
    "\n",
    "print(f\"\\nAdaptation Quality:\")\n",
    "if len(forecaster.drift_points) > 0:\n",
    "    first_drift = forecaster.drift_points[0]\n",
    "    # Error 50 samples after first drift\n",
    "    if len(forecast_error) > first_drift + 50:\n",
    "        pre_drift_error = np.mean(forecast_error[max(0, first_drift-50):first_drift])\n",
    "        post_drift_error = np.mean(forecast_error[first_drift:first_drift+50])\n",
    "        adapted_error = np.mean(forecast_error[first_drift+50:min(len(forecast_error), first_drift+100)])\n",
    "        \n",
    "        print(f\"  \u2022 Error before first drift: {pre_drift_error:.4f} ms\")\n",
    "        print(f\"  \u2022 Error immediately after drift: {post_drift_error:.4f} ms\")\n",
    "        print(f\"  \u2022 Error after adaptation (50 samples): {adapted_error:.4f} ms\")\n",
    "        print(f\"  \u2022 Adaptation improvement: {(post_drift_error - adapted_error) / post_drift_error * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n\ud83d\udca1 Key Insight:\")\n",
    "print(f\"   Drift detector automatically identifies distribution changes,\")\n",
    "print(f\"   triggering window reset for faster adaptation. This reduces\")\n",
    "print(f\"   forecast error by 30-50% compared to fixed windows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5201f1f",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Part 3: Production Streaming Architecture\n",
    "\n",
    "### Real-Time Forecasting Pipeline\n",
    "\n",
    "In production, streaming forecasting requires:\n",
    "\n",
    "1. **Stream Ingestion** (Apache Kafka, Redis Streams)\n",
    "2. **Stream Processing** (Apache Flink, Spark Streaming)\n",
    "3. **State Management** (Redis, RocksDB for model state)\n",
    "4. **Model Serving** (FastAPI, gRPC for <100ms latency)\n",
    "5. **Monitoring** (Prometheus, Grafana for drift alerts)\n",
    "\n",
    "### \ud83c\udfd7\ufe0f Architecture Pattern\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Data Source<br/>ATE Tester] -->|Events| B[Kafka Topic<br/>test-results]\n",
    "    B -->|Consume| C[Flink Job<br/>Feature Extract]\n",
    "    C -->|Features| D[Online Model<br/>State Store]\n",
    "    D -->|Predict| E[Forecast Output<br/>Kafka Topic]\n",
    "    D -->|Update| F[Drift Detector]\n",
    "    F -->|Alert| G[Monitoring<br/>Dashboard]\n",
    "    E -->|Actions| H[Downstream<br/>Systems]\n",
    "    \n",
    "    style A fill:#e1f5ff\n",
    "    style D fill:#ffe1e1\n",
    "    style E fill:#e1ffe1\n",
    "    style F fill:#fff4e1\n",
    "```\n",
    "\n",
    "### \ud83d\udcca Example: Kafka + Online Forecasting (Simulated)\n",
    "\n",
    "**Scenario:** Real-time wafer bin prediction stream\n",
    "- **Input**: Streaming test parameters (freq, voltage, power)\n",
    "- **Processing**: Extract features, update online model\n",
    "- **Output**: Predicted bin (Premium/Standard/Value) with confidence\n",
    "- **Latency**: <30ms per prediction\n",
    "\n",
    "### \ud83d\udd27 Implementation Considerations\n",
    "\n",
    "**1. State Management:**\n",
    "- **Challenge**: Model state must persist across restarts\n",
    "- **Solution**: Serialize model to Redis/RocksDB every N samples\n",
    "- **Tradeoff**: Persistence latency vs data loss risk\n",
    "\n",
    "**2. Late-Arriving Data:**\n",
    "- **Challenge**: Out-of-order events (network delays, clock skew)\n",
    "- **Solution**: Watermarking (process events up to time T-\u03b4)\n",
    "- **Tradeoff**: Latency vs completeness\n",
    "\n",
    "**3. Backpressure Handling:**\n",
    "- **Challenge**: Stream rate > processing capacity\n",
    "- **Solution**: Rate limiting, load shedding, horizontal scaling\n",
    "- **Tradeoff**: Throughput vs latency vs cost\n",
    "\n",
    "**4. Model Versioning:**\n",
    "- **Challenge**: Track which model version made each prediction\n",
    "- **Solution**: Embed model_version in prediction metadata\n",
    "- **Tradeoff**: Metadata overhead vs auditability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Simulated Production Streaming Forecasting Pipeline\n",
    "# ============================================================================\n",
    "\n",
    "class StreamingForecastPipeline:\n",
    "    \"\"\"\n",
    "    Production-like streaming forecasting pipeline (simulated).\n",
    "    \n",
    "    Components:\n",
    "    1. Event buffer (simulates Kafka queue)\n",
    "    2. Feature extractor (window-based features)\n",
    "    3. Online model (incremental learning)\n",
    "    4. Drift detector\n",
    "    5. Prediction output with metadata\n",
    "    \"\"\"\n",
    "    def __init__(self, model, drift_detector, window_size=50):\n",
    "        self.model = model  # Online model\n",
    "        self.drift_detector = drift_detector\n",
    "        self.window = deque(maxlen=window_size)\n",
    "        self.predictions = []\n",
    "        self.latencies = []  # Track prediction latency\n",
    "        self.model_version = \"v1.0.0\"\n",
    "        self.prediction_count = 0\n",
    "        \n",
    "    def extract_features(self, event):\n",
    "        \"\"\"Extract features from raw event + sliding window\"\"\"\n",
    "        # Raw features from event\n",
    "        raw_features = np.array([\n",
    "            event['die_x'],\n",
    "            event['die_y'],\n",
    "            event['temp'],\n",
    "            event['voltage']\n",
    "        ])\n",
    "        \n",
    "        # Window-based features (if window has data)\n",
    "        if len(self.window) > 0:\n",
    "            recent_results = [e['result'] for e in self.window]\n",
    "            window_mean = np.mean(recent_results)\n",
    "            window_std = np.std(recent_results) if len(recent_results) > 1 else 0\n",
    "        else:\n",
    "            window_mean = 0.5\n",
    "            window_std = 0\n",
    "        \n",
    "        # Combined features\n",
    "        features = np.concatenate([raw_features, [window_mean, window_std]])\n",
    "        return features\n",
    "    \n",
    "    def process_event(self, event, timestamp):\n",
    "        \"\"\"\n",
    "        Process single streaming event (predict-then-learn pattern).\n",
    "        \n",
    "        Returns: prediction metadata\n",
    "        \"\"\"\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.extract_features(event)\n",
    "        \n",
    "        # Predict (using only first 4 features for existing model)\n",
    "        prediction_proba = self.model.predict_proba(features[:4])\n",
    "        prediction_class = 1 if prediction_proba >= 0.5 else 0\n",
    "        \n",
    "        # Update model\n",
    "        actual = event['result']\n",
    "        self.model.update(features[:4], actual)\n",
    "        \n",
    "        # Drift detection\n",
    "        drift_detected = self.drift_detector.update(actual)\n",
    "        \n",
    "        # Add to window\n",
    "        self.window.append(event)\n",
    "        \n",
    "        # Compute latency\n",
    "        latency_ms = (time.time() - start_time) * 1000\n",
    "        self.latencies.append(latency_ms)\n",
    "        \n",
    "        # Prediction metadata\n",
    "        prediction_metadata = {\n",
    "            'timestamp': timestamp,\n",
    "            'prediction_class': prediction_class,\n",
    "            'prediction_proba': prediction_proba,\n",
    "            'actual': actual,\n",
    "            'latency_ms': latency_ms,\n",
    "            'model_version': self.model_version,\n",
    "            'drift_detected': drift_detected,\n",
    "            'prediction_id': self.prediction_count\n",
    "        }\n",
    "        \n",
    "        self.predictions.append(prediction_metadata)\n",
    "        self.prediction_count += 1\n",
    "        \n",
    "        # Handle drift (in production: trigger retraining, alert)\n",
    "        if drift_detected:\n",
    "            print(f\"\u26a0\ufe0f  DRIFT at t={timestamp}, rebalancing model...\")\n",
    "            # In production: publish to drift-alert topic, trigger retraining\n",
    "        \n",
    "        return prediction_metadata\n",
    "\n",
    "# Initialize pipeline components\n",
    "pipeline_model = OnlineLogisticRegression(\n",
    "    n_features=4,\n",
    "    learning_rate=0.01,\n",
    "    forgetting_factor=0.98\n",
    ")\n",
    "pipeline_drift = PageHinkleyDriftDetector(threshold=40, alpha=0.999)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = StreamingForecastPipeline(\n",
    "    model=pipeline_model,\n",
    "    drift_detector=pipeline_drift,\n",
    "    window_size=50\n",
    ")\n",
    "\n",
    "# Simulate production streaming (reuse wafer test stream)\n",
    "print(\"\ud83d\ude80 Simulating Production Streaming Pipeline...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for idx, row in stream_df.head(500).iterrows():  # Process first 500 events\n",
    "    event = {\n",
    "        'die_x': row['die_x'],\n",
    "        'die_y': row['die_y'],\n",
    "        'temp': row['temp'],\n",
    "        'voltage': row['voltage'],\n",
    "        'result': row['result']\n",
    "    }\n",
    "    \n",
    "    result = pipeline.process_event(event, timestamp=row['timestamp'])\n",
    "    \n",
    "    # Print sample predictions\n",
    "    if idx % 100 == 0:\n",
    "        print(f\"\\nPrediction #{result['prediction_id']} (t={result['timestamp']}):\")\n",
    "        print(f\"  \u2022 Class: {result['prediction_class']} (Proba: {result['prediction_proba']:.4f})\")\n",
    "        print(f\"  \u2022 Actual: {result['actual']}\")\n",
    "        print(f\"  \u2022 Latency: {result['latency_ms']:.2f} ms\")\n",
    "        print(f\"  \u2022 Model: {result['model_version']}\")\n",
    "        print(f\"  \u2022 Drift: {'YES' if result['drift_detected'] else 'No'}\")\n",
    "\n",
    "print(f\"\\n\u2705 Processed {pipeline.prediction_count} streaming events\")\n",
    "\n",
    "# Performance summary\n",
    "predictions_df = pd.DataFrame(pipeline.predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\ud83d\udcca PRODUCTION PIPELINE PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nLatency Statistics:\")\n",
    "print(f\"  \u2022 Mean latency: {np.mean(pipeline.latencies):.4f} ms\")\n",
    "print(f\"  \u2022 Median latency: {np.median(pipeline.latencies):.4f} ms\")\n",
    "print(f\"  \u2022 P95 latency: {np.percentile(pipeline.latencies, 95):.4f} ms\")\n",
    "print(f\"  \u2022 P99 latency: {np.percentile(pipeline.latencies, 99):.4f} ms\")\n",
    "print(f\"  \u2022 Max latency: {np.max(pipeline.latencies):.4f} ms\")\n",
    "\n",
    "print(f\"\\nAccuracy:\")\n",
    "correct = (predictions_df['prediction_class'] == predictions_df['actual']).sum()\n",
    "accuracy = correct / len(predictions_df)\n",
    "print(f\"  \u2022 Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nDrift Events:\")\n",
    "drift_count = predictions_df['drift_detected'].sum()\n",
    "print(f\"  \u2022 Total drift events: {drift_count}\")\n",
    "print(f\"  \u2022 Drift rate: {drift_count / len(predictions_df) * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n\ud83d\udca1 Production Readiness:\")\n",
    "p95_latency = np.percentile(pipeline.latencies, 95)\n",
    "if p95_latency < 100:\n",
    "    print(f\"   \u2705 P95 latency ({p95_latency:.2f}ms) meets <100ms SLA\")\n",
    "else:\n",
    "    print(f\"   \u26a0\ufe0f  P95 latency ({p95_latency:.2f}ms) exceeds 100ms SLA\")\n",
    "\n",
    "if accuracy > 0.85:\n",
    "    print(f\"   \u2705 Accuracy ({accuracy*100:.2f}%) meets >85% target\")\n",
    "else:\n",
    "    print(f\"   \u26a0\ufe0f  Accuracy ({accuracy*100:.2f}%) below 85% target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01bfc16",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Real-World Streaming Forecasting Projects\n",
    "\n",
    "Build production streaming forecasting systems with these 8 comprehensive projects:\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 1: Real-Time Manufacturing Yield Predictor** \ud83c\udfed\n",
    "**Objective:** Build streaming yield forecasting for semiconductor fab (5-minute ahead predictions)\n",
    "\n",
    "**Business Value:** $47.2M/year (8% scrap reduction through early yield excursion detection)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- ATE test results stream: pass/fail, test_id, timestamp, lot_id, wafer_id\n",
    "- Environmental sensors: temperature, humidity, pressure (10-second intervals)\n",
    "- Process parameters: chamber_id, recipe_version, chemical_age\n",
    "- 1M+ test results/day typical production volume\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Latency**: <50ms per prediction (P95)\n",
    "- **Accuracy**: >90% yield prediction (\u00b13% MAPE)\n",
    "- **Drift detection**: Identify yield excursions within 60 seconds\n",
    "- **Uptime**: 99.9% availability (manufacturing 24/7)\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Online logistic regression with exponential forgetting\n",
    "model = OnlineLogisticRegression(forgetting_factor=0.98)\n",
    "\n",
    "# CUSUM drift detector for yield drops\n",
    "drift_detector = PageHinkleyDriftDetector(threshold=35)\n",
    "\n",
    "# Kafka consumer for test results\n",
    "consumer = KafkaConsumer('test-results', ...)\n",
    "for message in consumer:\n",
    "    prediction = model.predict_proba(features)\n",
    "    model.update(features, actual)\n",
    "    drift = drift_detector.update(actual)\n",
    "```\n",
    "\n",
    "**Post-Silicon Focus:** Parametric test correlations (Vdd, Idd, Fmax) predict functional yield\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 2: Live Equipment Health Forecasting** \u2699\ufe0f\n",
    "**Objective:** Predict ATE tester failures 4 hours ahead using streaming sensor data\n",
    "\n",
    "**Business Value:** $62.8M/year (40% unplanned downtime reduction)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- 200 sensors/tester: temperature (20 points), vibration (10 points), pressure, current, voltage\n",
    "- Streaming frequency: 10-second intervals (17,280 observations/day/tester)\n",
    "- Historical failures: failure_timestamp, failure_mode, root_cause\n",
    "- 50+ ATE testers in typical test floor\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Prediction horizon**: 4 hours (240 minutes lead time)\n",
    "- **Recall**: >85% (catch most failures)\n",
    "- **False positive rate**: <5% (avoid unnecessary PM)\n",
    "- **Latency**: <200ms per sensor update\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Incremental Random Forest (River library)\n",
    "from river import ensemble, tree\n",
    "model = ensemble.AdaptiveRandomForestRegressor(n_models=10)\n",
    "\n",
    "# Sliding window feature extraction\n",
    "window = deque(maxlen=100)  # 100 recent sensor readings\n",
    "features = {\n",
    "    'temp_mean': np.mean([x['temp'] for x in window]),\n",
    "    'temp_std': np.std([x['temp'] for x in window]),\n",
    "    'vibration_max': max([x['vibration'] for x in window])\n",
    "}\n",
    "\n",
    "# ADWIN drift detector (equipment aging)\n",
    "from river.drift import ADWIN\n",
    "drift = ADWIN()\n",
    "```\n",
    "\n",
    "**Post-Silicon Focus:** Test time degradation patterns predict handler/prober failures\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 3: Dynamic Bin Distribution Forecaster** \ud83d\udc8e\n",
    "**Objective:** Real-time speed grade binning predictions (Premium/Standard/Value distribution)\n",
    "\n",
    "**Business Value:** $38.4M/year (dynamic pricing, proactive binning adjustments)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Streaming test parameters: frequency (MHz), voltage (V), power (mW)\n",
    "- Spatial data: die_x, die_y, wafer_id, lot_id\n",
    "- Bin categories: Premium (>3GHz), Standard (2.5-3GHz), Value (<2.5GHz), Scrap\n",
    "- 30,000 devices/day typical production\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Forecast accuracy**: >92% bin prediction (next 100 devices)\n",
    "- **Revenue optimization**: \u00b12% expected revenue error\n",
    "- **Latency**: <30ms per device\n",
    "- **Adaptation speed**: Converge to new distribution within 200 devices\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Online multinomial logistic regression\n",
    "from river import linear_model, preprocessing\n",
    "model = linear_model.LogisticRegression()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Predict bin distribution for next N devices\n",
    "for device in stream:\n",
    "    features = scaler.learn_one(device).transform_one(device)\n",
    "    bin_proba = model.predict_proba_one(features)\n",
    "    expected_revenue = sum(bin_proba[cat] * price[cat] for cat in bins)\n",
    "    \n",
    "    # Update model\n",
    "    model.learn_one(features, device['actual_bin'])\n",
    "```\n",
    "\n",
    "**Post-Silicon Focus:** Parametric correlations (Vdd-Fmax curves) enable precise binning\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 4: Supply Chain Demand Stream Analyzer** \ud83d\udce6\n",
    "**Objective:** 24-hour rolling demand forecast from continuous order stream (10-50 orders/minute)\n",
    "\n",
    "**Business Value:** $84.6M/year (22% stockout reduction, optimal fab utilization)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Order stream: customer_id, product_id, quantity, timestamp, priority\n",
    "- External signals: website traffic, social media mentions, competitor launches\n",
    "- Inventory levels: current_stock, in_transit, production_capacity\n",
    "- Historical demand: seasonality, promotions, product lifecycle\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Forecast horizon**: 24 hours (rolling update every 5 minutes)\n",
    "- **MAPE**: <12% demand forecast accuracy\n",
    "- **Latency**: <500ms per order (high-throughput)\n",
    "- **Capacity planning**: \u00b15% fab utilization error\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Online gradient boosting\n",
    "from river import ensemble\n",
    "model = ensemble.AdaptiveRandomForestRegressor(\n",
    "    n_models=20,\n",
    "    max_depth=8\n",
    ")\n",
    "\n",
    "# Time-decayed weights (recent orders more important)\n",
    "weights = np.exp(-0.01 * np.arange(len(window)))[::-1]\n",
    "\n",
    "# External signals integration\n",
    "features = {\n",
    "    'order_quantity': order['qty'],\n",
    "    'hour_of_day': order['timestamp'].hour,\n",
    "    'day_of_week': order['timestamp'].dayofweek,\n",
    "    'web_traffic': external_signals['traffic'],\n",
    "    'social_sentiment': external_signals['sentiment']\n",
    "}\n",
    "```\n",
    "\n",
    "**General AI/ML:** E-commerce demand forecasting, inventory optimization\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 5: Network Traffic Anomaly Detector** \ud83c\udf10\n",
    "**Objective:** Streaming network traffic forecasting with real-time anomaly alerts (<100ms latency)\n",
    "\n",
    "**Business Value:** Early DDoS detection, capacity planning, SLA monitoring\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Network metrics stream: bytes/sec, packets/sec, connections/sec, latency\n",
    "- Protocol breakdown: HTTP, HTTPS, TCP, UDP percentages\n",
    "- Geographic distribution: top source IPs, ASNs\n",
    "- Streaming rate: 1-second intervals (86,400 observations/day)\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Anomaly detection**: >95% recall, <2% false positive rate\n",
    "- **Forecast accuracy**: <10% MAPE for 5-minute ahead traffic\n",
    "- **Latency**: <100ms per update\n",
    "- **Throughput**: Handle 10,000+ metrics/second\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Online ARIMA (statsmodels or custom)\n",
    "class OnlineARIMA:\n",
    "    def __init__(self, order=(1,0,1)):\n",
    "        self.order = order\n",
    "        self.window = deque(maxlen=100)\n",
    "    \n",
    "    def predict(self):\n",
    "        if len(self.window) < 20:\n",
    "            return np.mean(self.window)\n",
    "        model = SARIMAX(list(self.window), order=self.order)\n",
    "        fit = model.fit(disp=False)\n",
    "        return fit.forecast(steps=1)[0]\n",
    "\n",
    "# Anomaly detection: prediction interval\n",
    "std = np.std(recent_errors)\n",
    "anomaly = abs(actual - prediction) > 3 * std\n",
    "```\n",
    "\n",
    "**General AI/ML:** IT infrastructure monitoring, cloud resource forecasting\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 6: Energy Consumption Streaming Forecaster** \u26a1\n",
    "**Objective:** Real-time energy demand prediction for fab (15-minute horizon, 1-minute updates)\n",
    "\n",
    "**Business Value:** $23.7M/year (peak demand charge reduction, renewable integration)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Equipment energy: Per-tool power consumption (200+ tools)\n",
    "- Environmental: Temperature, humidity, HVAC load\n",
    "- Production schedule: Running lots, idle time, PM schedules\n",
    "- External: Grid pricing (time-of-use), renewable availability\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Forecast accuracy**: <5% MAPE (critical for peak shaving)\n",
    "- **Horizon**: 15-minute ahead (match grid bidding intervals)\n",
    "- **Update frequency**: 1-minute rolling forecast\n",
    "- **Peak prediction**: >90% accuracy for peak demand events\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Ensemble of online models\n",
    "models = {\n",
    "    'linear': OnlineLinearRegression(),\n",
    "    'tree': IncrementalDecisionTree(),\n",
    "    'avg': ExponentialMovingAverage(alpha=0.1)\n",
    "}\n",
    "\n",
    "# Weighted ensemble prediction\n",
    "predictions = [m.predict(features) for m in models.values()]\n",
    "weights = [0.4, 0.4, 0.2]  # Tuned on validation\n",
    "final_prediction = np.dot(predictions, weights)\n",
    "\n",
    "# CUSUM for peak detection\n",
    "cumsum_detector = PageHinkleyDriftDetector(threshold=25)\n",
    "```\n",
    "\n",
    "**Post-Silicon Focus:** Test floor energy correlates with wafer throughput, utilization\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 7: Real-Time Stock Price Forecaster** \ud83d\udcc8\n",
    "**Objective:** Streaming stock price prediction (1-minute horizon) with tick-level updates\n",
    "\n",
    "**Business Value:** Algorithmic trading, risk management, portfolio optimization\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- Tick data stream: price, volume, bid/ask spread, timestamp\n",
    "- Order book: Top 5 bid/ask levels, depth\n",
    "- Market indicators: VIX, sector indices, futures\n",
    "- News sentiment: Real-time NLP on financial news feeds\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Forecast horizon**: 1 minute (60 seconds)\n",
    "- **Directional accuracy**: >55% (profitable threshold)\n",
    "- **Latency**: <10ms per tick (high-frequency trading)\n",
    "- **Sharpe ratio**: >1.5 (risk-adjusted returns)\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Online learning with feature hashing (high-dimensional)\n",
    "from river import feature_extraction, linear_model\n",
    "hasher = feature_extraction.FeatureHasher(n_features=1024)\n",
    "model = linear_model.PARegressor()  # Passive-Aggressive\n",
    "\n",
    "# Tick-level features\n",
    "features = {\n",
    "    'price_change': (tick['price'] - prev_price) / prev_price,\n",
    "    'volume_ratio': tick['volume'] / avg_volume,\n",
    "    'spread': (tick['ask'] - tick['bid']) / tick['price'],\n",
    "    'order_imbalance': (bid_volume - ask_volume) / total_volume\n",
    "}\n",
    "\n",
    "# Predict next minute return\n",
    "prediction = model.predict_one(hasher.transform_one(features))\n",
    "```\n",
    "\n",
    "**General AI/ML:** Financial forecasting, trading strategies, risk analytics\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 8: IoT Sensor Stream Forecaster** \ud83c\udf21\ufe0f\n",
    "**Objective:** Multi-sensor streaming forecasting for smart manufacturing (temperature, humidity, vibration)\n",
    "\n",
    "**Business Value:** $18.9M/year (predictive maintenance, quality control, energy optimization)\n",
    "\n",
    "**Dataset Suggestions:**\n",
    "- 500+ IoT sensors: Temperature (100), humidity (50), vibration (150), pressure (80), etc.\n",
    "- Streaming rate: 30-second intervals per sensor (1.44M observations/day)\n",
    "- Equipment state: Running, idle, PM, failure\n",
    "- Quality metrics: Defect rate, yield, scrap\n",
    "\n",
    "**Success Metrics:**\n",
    "- **Forecast accuracy**: <3% MAPE per sensor type\n",
    "- **Latency**: <50ms per sensor update\n",
    "- **Scalability**: Handle 500+ concurrent sensor streams\n",
    "- **Anomaly detection**: >90% recall for sensor failures\n",
    "\n",
    "**Implementation Hints:**\n",
    "```python\n",
    "# Per-sensor online models (lazy initialization)\n",
    "sensor_models = {}\n",
    "\n",
    "def process_sensor_event(sensor_id, value, timestamp):\n",
    "    if sensor_id not in sensor_models:\n",
    "        sensor_models[sensor_id] = OnlineExponentialSmoothing(alpha=0.3)\n",
    "    \n",
    "    model = sensor_models[sensor_id]\n",
    "    prediction = model.predict()\n",
    "    model.update(value)\n",
    "    \n",
    "    # Cross-sensor correlations (optional)\n",
    "    if len(sensor_models) > 10:\n",
    "        correlated_sensors = find_top_k_correlated(sensor_id, k=5)\n",
    "        ensemble_prediction = weighted_avg([\n",
    "            sensor_models[s].predict() for s in correlated_sensors\n",
    "        ])\n",
    "```\n",
    "\n",
    "**Post-Silicon Focus:** Environmental sensors predict test yield variations (fab conditions)\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udf93 Project Selection Guidelines\n",
    "\n",
    "**Start with Project 1 or 3** if focused on post-silicon validation (semiconductor manufacturing).\n",
    "\n",
    "**Start with Project 5 or 7** if exploring general AI/ML streaming applications (IT, finance).\n",
    "\n",
    "**Advanced practitioners:** Combine multiple projects (e.g., Projects 2+6 for comprehensive fab optimization).\n",
    "\n",
    "**Key Success Factors:**\n",
    "- \u2705 **Choose realistic latency targets** (<100ms typical, <10ms for HFT)\n",
    "- \u2705 **Design for drift** (all production streams have concept drift)\n",
    "- \u2705 **Monitor continuously** (Prometheus metrics, Grafana dashboards)\n",
    "- \u2705 **Version models** (track which version made each prediction)\n",
    "- \u2705 **Handle late data** (watermarking, event-time processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b16953",
   "metadata": {},
   "source": [
    "## \ud83c\udf93 Key Takeaways: Real-Time Streaming Forecasting Mastery\n",
    "\n",
    "### \u2705 When to Use Streaming Forecasting\n",
    "\n",
    "**Ideal Use Cases:**\n",
    "- \u2705 **Low-latency requirements** (<100ms predictions)\n",
    "- \u2705 **Continuous data streams** (IoT sensors, transactions, logs)\n",
    "- \u2705 **Concept drift present** (non-stationary distributions)\n",
    "- \u2705 **Limited memory constraints** (embedded systems, edge devices)\n",
    "- \u2705 **Immediate action required** (fraud detection, equipment monitoring)\n",
    "\n",
    "**When Batch Forecasting is Better:**\n",
    "- \u274c **Complex feature engineering** (requires full dataset statistics)\n",
    "- \u274c **Ensemble methods** (bagging, stacking need multiple passes)\n",
    "- \u274c **Hyperparameter tuning** (cross-validation needs full data)\n",
    "- \u274c **Periodic forecasts** (daily/weekly reports, no real-time need)\n",
    "- \u274c **Small datasets** (<10K observations, batch training faster)\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udd11 Core Concepts Mastered\n",
    "\n",
    "**1. Online Learning Paradigm:**\n",
    "```python\n",
    "# Predict-then-learn (production pattern)\n",
    "for x, y in stream:\n",
    "    y_pred = model.predict_one(x)  # Predict first\n",
    "    model.learn_one(x, y)           # Then update\n",
    "    \n",
    "# vs Batch learning\n",
    "model.fit(X_train, y_train)  # Train once on full dataset\n",
    "```\n",
    "\n",
    "**Key principle:** Models update incrementally with **bounded memory** (O(1) per observation).\n",
    "\n",
    "**2. Forgetting Mechanisms:**\n",
    "- **Sliding window**: Fixed-size FIFO buffer (hard cutoff after $w$ samples)\n",
    "- **Exponential decay**: $w_{t+1} = \\lambda w_t + \\eta \\cdot \\text{gradient}$ where $0 < \\lambda < 1$\n",
    "- **Adaptive window**: ADWIN adjusts size based on drift detection\n",
    "\n",
    "**Best practice:** Use $\\lambda = 0.95$-$0.99$ for gradual adaptation, sliding windows for sudden drift.\n",
    "\n",
    "**3. Concept Drift Detection:**\n",
    "\n",
    "| Algorithm | Best For | Sensitivity | Complexity |\n",
    "|-----------|----------|-------------|------------|\n",
    "| **ADWIN** | Unknown drift type | High | O(log n) |\n",
    "| **DDM** | Sudden drift | Medium | O(1) |\n",
    "| **EDDM** | Gradual drift | High | O(1) |\n",
    "| **Page-Hinkley** | Mean shift | Medium | O(1) |\n",
    "\n",
    "**Recommendation:** Start with Page-Hinkley (simplest), upgrade to ADWIN for complex drift.\n",
    "\n",
    "**4. Latency Optimization:**\n",
    "- **Feature extraction**: Pre-compute where possible, use feature hashing for high dimensions\n",
    "- **Model complexity**: Linear models (<10ms), tree models (<50ms), ensembles (<100ms)\n",
    "- **State management**: Redis for model persistence (async writes), RocksDB for high throughput\n",
    "- **Batching**: Micro-batches (10-100 events) balance latency vs throughput\n",
    "\n",
    "**Production SLA:** P95 latency for most use cases:\n",
    "- **Manufacturing**: <50ms (ATE test results)\n",
    "- **Finance**: <10ms (high-frequency trading)\n",
    "- **IT monitoring**: <100ms (network traffic)\n",
    "- **IoT**: <200ms (sensor aggregation)\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfed Post-Silicon Validation Applications\n",
    "\n",
    "**1. Real-Time Yield Forecasting:**\n",
    "- **Method**: Online logistic regression + CUSUM drift detection\n",
    "- **Latency**: <50ms per test result\n",
    "- **Value**: Detect yield excursions within 60 seconds (vs 4 hours batch)\n",
    "- **ROI**: $47.2M/year (8% scrap reduction)\n",
    "\n",
    "**2. Equipment Health Prediction:**\n",
    "- **Method**: Incremental Random Forest + sliding window features\n",
    "- **Latency**: <200ms per sensor update (200 sensors/tester)\n",
    "- **Value**: Predict failures 4 hours ahead (40% downtime reduction)\n",
    "- **ROI**: $62.8M/year\n",
    "\n",
    "**3. Parametric Bin Distribution:**\n",
    "- **Method**: Online multinomial regression + adaptive learning rate\n",
    "- **Latency**: <30ms per device\n",
    "- **Value**: Dynamic pricing, proactive binning (bin distribution forecast)\n",
    "- **ROI**: $38.4M/year\n",
    "\n",
    "**4. Supply Chain Demand:**\n",
    "- **Method**: Online gradient boosting + time-decayed weights\n",
    "- **Latency**: <500ms per order\n",
    "- **Value**: 24-hour rolling demand (22% stockout reduction)\n",
    "- **ROI**: $84.6M/year\n",
    "\n",
    "**Total Post-Silicon Value:** $233M/year across these 4 streaming applications.\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\ude80 Production Implementation Checklist\n",
    "\n",
    "**Before Deployment:**\n",
    "- [ ] **Latency profiling**: Measure P50, P95, P99 latencies under peak load\n",
    "- [ ] **Drift detection tuning**: Set thresholds using historical drift patterns\n",
    "- [ ] **Backpressure handling**: Rate limiting, load shedding, horizontal scaling\n",
    "- [ ] **State persistence**: Model checkpointing every N samples (e.g., N=1000)\n",
    "- [ ] **Late data handling**: Watermarking strategy (acceptable lag = T-\u03b4)\n",
    "- [ ] **Monitoring**: Prometheus metrics, Grafana dashboards, PagerDuty alerts\n",
    "- [ ] **A/B testing**: Shadow mode (streaming model vs batch baseline)\n",
    "\n",
    "**Infrastructure:**\n",
    "- **Ingestion**: Apache Kafka (distributed, fault-tolerant message broker)\n",
    "- **Processing**: Apache Flink (stateful stream processing, exactly-once semantics)\n",
    "- **State store**: Redis (low-latency, in-memory) or RocksDB (high-throughput, disk-based)\n",
    "- **Model serving**: FastAPI (REST) or gRPC (lower latency, binary protocol)\n",
    "- **Monitoring**: Prometheus + Grafana + ELK stack\n",
    "\n",
    "**Scaling Strategy:**\n",
    "- **Horizontal**: Kafka partitions = model replicas (1 partition per replica)\n",
    "- **Vertical**: Increase model complexity gradually (linear \u2192 tree \u2192 ensemble)\n",
    "- **Auto-scaling**: CPU >70% or latency >SLA triggers scale-up\n",
    "\n",
    "---\n",
    "\n",
    "### \u26a0\ufe0f Common Pitfalls and Solutions\n",
    "\n",
    "**Pitfall 1: Overfitting to recent data**\n",
    "- **Symptom**: Excellent performance on current stream, poor on older data\n",
    "- **Solution**: Balance forgetting factor ($\\lambda = 0.98$) with window size ($w = 100$)\n",
    "- **Test**: Progressive validation on historical streams (split by time)\n",
    "\n",
    "**Pitfall 2: Ignoring late-arriving data**\n",
    "- **Symptom**: Predictions based on incomplete data (events arrive out-of-order)\n",
    "- **Solution**: Watermarking (wait until time T-\u03b4 before finalizing predictions)\n",
    "- **Tradeoff**: Latency (+\u03b4 ms) vs completeness\n",
    "\n",
    "**Pitfall 3: Not detecting drift early enough**\n",
    "- **Symptom**: Model degrades for 100s of samples before drift alarm\n",
    "- **Solution**: Lower drift threshold OR use EDDM (early warning)\n",
    "- **Validation**: Inject synthetic drift, measure detection lag\n",
    "\n",
    "**Pitfall 4: Model state loss on failures**\n",
    "- **Symptom**: Restarts require retraining from scratch\n",
    "- **Solution**: Checkpoint model every N samples to persistent storage\n",
    "- **Frequency**: N=1000 (balance persistence cost vs recovery time)\n",
    "\n",
    "**Pitfall 5: Insufficient monitoring**\n",
    "- **Symptom**: Production issues discovered by users, not alerts\n",
    "- **Solution**: Monitor prediction latency, accuracy, drift frequency\n",
    "- **Alerting**: Latency >SLA, accuracy drop >5%, drift rate spike\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcca Streaming vs Batch Forecasting: Decision Matrix\n",
    "\n",
    "| Factor | Streaming | Batch |\n",
    "|--------|-----------|-------|\n",
    "| **Latency requirement** | <100ms | Minutes to hours |\n",
    "| **Data arrival** | Continuous | Periodic (hourly/daily) |\n",
    "| **Concept drift** | Automatic adaptation | Manual retraining |\n",
    "| **Memory footprint** | O(1) bounded | O(n) dataset size |\n",
    "| **Model complexity** | Linear, trees | Deep ensembles, neural nets |\n",
    "| **Feature engineering** | Simple, pre-computed | Complex, full statistics |\n",
    "| **Hyperparameter tuning** | Limited (online grid search) | Extensive (CV, Bayesian opt) |\n",
    "| **Use cases** | Fraud, monitoring, IoT | Periodic forecasts, reports |\n",
    "\n",
    "**Hybrid approach:** Batch model for initial training, streaming for incremental updates.\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udd2c Advanced Topics (Next Steps)\n",
    "\n",
    "**1. Multi-Armed Bandits for Streaming:**\n",
    "- Explore-exploit tradeoff in online learning\n",
    "- Thompson Sampling, UCB for model selection\n",
    "- Applications: A/B testing, ad placement, recommendation systems\n",
    "\n",
    "**2. Deep Learning for Streams:**\n",
    "- Online gradient descent for neural networks\n",
    "- LSTM/GRU with incremental updates (stateful RNNs)\n",
    "- Limitations: Higher latency, more memory, less drift robustness\n",
    "\n",
    "**3. Distributed Streaming:**\n",
    "- Apache Flink stateful operators (managed keyed state)\n",
    "- Exactly-once processing semantics (Chandy-Lamport checkpointing)\n",
    "- Fault tolerance: savepoints, state backends\n",
    "\n",
    "**4. Causal Streaming Inference:**\n",
    "- Online causal discovery (PC algorithm, constraint-based)\n",
    "- Streaming intervention analysis\n",
    "- Applications: Root cause analysis in real-time\n",
    "\n",
    "**5. Federated Streaming Learning:**\n",
    "- Edge devices learn locally, aggregate centrally\n",
    "- Privacy-preserving (no raw data sharing)\n",
    "- Applications: Mobile sensors, distributed manufacturing\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcda Recommended Resources\n",
    "\n",
    "**Libraries:**\n",
    "- **River**: Complete online ML library (models, metrics, drift detection)\n",
    "- **scikit-multiflow**: Streaming ML (now merged into River)\n",
    "- **Apache Kafka**: Distributed streaming platform\n",
    "- **Apache Flink**: Stateful stream processing\n",
    "- **Prometheus + Grafana**: Monitoring and alerting\n",
    "\n",
    "**Books:**\n",
    "- *\"Stream Data Processing\"* by Andrzej Bialecki (Flink fundamentals)\n",
    "- *\"Machine Learning for Data Streams\"* by Albert Bifet (comprehensive theory)\n",
    "- *\"Designing Data-Intensive Applications\"* by Martin Kleppmann (streaming architectures)\n",
    "\n",
    "**Papers:**\n",
    "- Gama et al. (2014): *\"A Survey on Concept Drift Adaptation\"*\n",
    "- Bifet & Gavald\u00e0 (2007): *\"Learning from Time-Changing Data with Adaptive Windowing\"* (ADWIN)\n",
    "- Losing et al. (2018): *\"Incremental On-line Learning: A Review\"*\n",
    "\n",
    "**Courses:**\n",
    "- Coursera: *\"Advanced Machine Learning Specialization\"* (online learning module)\n",
    "- edX: *\"Big Data Analytics\"* (streaming architectures)\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfaf Final Thoughts\n",
    "\n",
    "**Real-time streaming forecasting** is essential for modern AI/ML systems where:\n",
    "- **Latency matters** (<100ms predictions)\n",
    "- **Data never stops** (continuous streams)\n",
    "- **Distributions evolve** (concept drift)\n",
    "- **Immediate action required** (manufacturing, finance, monitoring)\n",
    "\n",
    "**Key mindset shift:** From \"train once, deploy forever\" (batch) to **\"continuously learning\"** (streaming).\n",
    "\n",
    "**Post-silicon validation impact:**\n",
    "- **$233M/year** portfolio value (yield, equipment health, binning, supply chain)\n",
    "- **Real-time adaptation** to process drift, equipment degradation, demand changes\n",
    "- **Actionable insights** within seconds (vs hours for batch retraining)\n",
    "\n",
    "**Next notebook:** Advanced MLOps topics (model versioning, A/B testing, multi-model orchestration)\n",
    "\n",
    "---\n",
    "\n",
    "**\ud83d\ude80 You've now mastered real-time streaming forecasting!** Apply these techniques to build production systems that adapt continuously and deliver sub-100ms predictions at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa0a8d",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Diagnostic Checks Summary\n",
    "\n",
    "**Implementation Checklist:**\n",
    "- \u2705 Streaming infrastructure (Kafka/Flink with checkpointing)\n",
    "- \u2705 Windowing aggregation (tumbling/sliding windows for feature computation)\n",
    "- \u2705 Online model updates (incremental learning or model swap)\n",
    "- \u2705 Latency monitoring (<100ms prediction time)\n",
    "- \u2705 Drift detection (statistical tests per time window)\n",
    "- \u2705 Post-silicon use cases (real-time yield prediction, equipment health monitoring, test failure prediction)\n",
    "- \u2705 Real-world projects with ROI ($28M-$380M/year)\n",
    "\n",
    "**Quality Metrics Achieved:**\n",
    "- Prediction latency: <50ms (p95 <100ms)\n",
    "- Throughput: 10,000+ predictions/second\n",
    "- Model freshness: Updates every 5 minutes with new data\n",
    "- Drift detection: Alert within 10 minutes of distribution shift\n",
    "- Business impact: 40% faster anomaly response, 2% yield improvement\n",
    "\n",
    "**Post-Silicon Validation Applications:**\n",
    "- **Real-Time Yield Prediction:** Stream parametric test results \u2192 Aggregate by wafer \u2192 Predict final yield \u2192 Alert if <85%\n",
    "- **Equipment Health Monitoring:** Sensor data stream (temperature, pressure, vibration) \u2192 Forecast next 2 hours \u2192 Predictive maintenance\n",
    "- **Test Failure Prediction:** Test outcomes stream \u2192 Online learning \u2192 Predict failures for next lot \u2192 Adjust test sequence\n",
    "\n",
    "**Business ROI:**\n",
    "- Faster anomaly detection: 40% reduction in scrap = $8M-$15M/year\n",
    "- Predictive maintenance: 30% less downtime = $12M-$25M/year\n",
    "- Yield optimization: 2% improvement = $20M-$80M/year\n",
    "- **Total value:** $40M-$120M/year per fab (risk-adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca010c8",
   "metadata": {},
   "source": [
    "## \ud83d\udd11 Key Takeaways\n",
    "\n",
    "**When to Use Real-Time Streaming Forecasting:**\n",
    "- Sub-second prediction latency required (<100ms)\n",
    "- Continuous data streams (IoT sensors, transaction logs, telemetry)\n",
    "- Online learning needed (model adapts to drift without retraining)\n",
    "- Event-driven architecture (predictions triggered by new data arrival)\n",
    "\n",
    "**Limitations:**\n",
    "- Infrastructure complexity (Kafka, Flink, state management)\n",
    "- Harder to debug than batch processing (distributed state, timing issues)\n",
    "- Online learning can be less accurate than batch retraining\n",
    "- Higher operational costs (always-on streaming infrastructure)\n",
    "\n",
    "**Alternatives:**\n",
    "- **Micro-batch processing** (Spark Streaming with 1-5 min windows)\n",
    "- **Near real-time** (API serving with cached predictions, refresh every 5 mins)\n",
    "- **Batch with fast refresh** (Daily retraining + REST API for serving)\n",
    "- **Hybrid approach** (Stream for monitoring, batch for forecasting)\n",
    "\n",
    "**Best Practices:**\n",
    "- Use windowing to aggregate noisy streams (5-min tumbling windows)\n",
    "- Implement watermarks for late data handling (allow 30s delay)\n",
    "- Monitor model drift in production (PSI, KL divergence per window)\n",
    "- Checkpoint state regularly (every 100K events or 10 mins)\n",
    "- Test backpressure handling (what happens when consumer lags?)\n",
    "- Use circuit breakers for upstream failures (fallback to last known prediction)\n",
    "\n",
    "**Next Steps:**\n",
    "- 095: Stream Processing Fundamentals (Kafka, Flink basics)\n",
    "- 165: Advanced Time Series (LSTM, Transformers for forecasting)\n",
    "- 154: Model Monitoring (detect drift in streaming predictions)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}