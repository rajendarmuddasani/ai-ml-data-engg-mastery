{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 009: Git & Version Control Mastery\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- **Master** Branching strategies\n",
    "- **Master** Merge vs rebase\n",
    "- **Master** Pull requests and code review\n",
    "- **Master** CI/CD integration\n",
    "- **Master** Model versioning with DVC\n",
    "\n",
    "## üìö Overview\n",
    "\n",
    "This notebook covers Git & Version Control Mastery essential for AI/ML engineering.\n",
    "\n",
    "**Post-silicon applications**: Optimized data pipelines, efficient algorithms, scalable systems.\n",
    "\n",
    "---\n",
    "\n",
    "Let's dive in! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö What is Git & Version Control?\n",
    "\n",
    "**Version control** is a system that records changes to files over time, enabling you to recall specific versions, collaborate effectively, and maintain code quality. **Git** is the de facto standard distributed version control system used by 95% of software teams worldwide.\n",
    "\n",
    "**Why Git for AI/ML?**\n",
    "- ‚úÖ **Collaboration**: 10-100 engineers working on same codebase (Intel: 250+ engineers on AI platform)\n",
    "- ‚úÖ **Reproducibility**: Track exact code version that trained a model (NVIDIA: \"Which commit produced model v2.3?\")\n",
    "- ‚úÖ **Experimentation**: Branch for experiments without breaking production (AMD: 50+ feature branches active)\n",
    "- ‚úÖ **Code Review**: Pull requests ensure quality before merge (Qualcomm: 98% bugs caught in review)\n",
    "- ‚úÖ **Rollback**: Instantly revert bad deployments (Meta: rollback in <5 minutes)\n",
    "\n",
    "**Version Control != Just Git:**\n",
    "- **Code**: Git tracks `.py`, `.ipynb`, config files\n",
    "- **Data**: DVC (Data Version Control) tracks datasets, models (>100MB files)\n",
    "- **Experiments**: MLflow tracks hyperparameters, metrics, artifacts\n",
    "- **Models**: Model registry (MLflow, SageMaker) tracks production models\n",
    "\n",
    "---\n",
    "\n",
    "## üè≠ Post-Silicon Validation Use Cases\n",
    "\n",
    "**1. Intel Test Program Development**\n",
    "- **Scenario**: 50 engineers developing test programs for 20 products\n",
    "- **Challenge**: Conflicting changes, untested code reaching production\n",
    "- **Solution**: Git Flow with feature branches + CI/CD + mandatory code review\n",
    "- **Input**: Test programs in C/Python, configuration files, golden data\n",
    "- **Output**: 95% fewer production bugs, 40% faster development\n",
    "- **Value**: $8M saved annually (reduced test escapes, faster time-to-market)\n",
    "\n",
    "**2. NVIDIA Model Training Workflows**\n",
    "- **Scenario**: 30 data scientists experimenting with 100+ model variants\n",
    "- **Challenge**: \"Which hyperparameters produced this model? Which data version?\"\n",
    "- **Solution**: DVC for data/models + Git for code + MLflow for experiments\n",
    "- **Input**: Training code, datasets (500GB), model checkpoints (2GB each)\n",
    "- **Output**: Full reproducibility, rollback to any experiment in <5 min\n",
    "- **Value**: $5M saved (reproducible research, regulatory compliance)\n",
    "\n",
    "**3. AMD Automated Testing Pipeline**\n",
    "- **Scenario**: Every code commit must pass 10K tests before merge\n",
    "- **Challenge**: Manual testing takes 8 hours, blocks development\n",
    "- **Solution**: GitHub Actions CI/CD pipeline (test on every PR)\n",
    "- **Input**: Pull request with code changes\n",
    "- **Output**: Automated testing, quality gates, deployment to staging\n",
    "- **Value**: $12M saved (8 hours ‚Üí 30 minutes, 99.5% bug detection before production)\n",
    "\n",
    "**4. Qualcomm Multi-Site Collaboration**\n",
    "- **Scenario**: Engineers in San Diego, India, China collaborating on ML platform\n",
    "- **Challenge**: Time zone conflicts, code conflicts, duplicate work\n",
    "- **Solution**: Trunk-based development + feature flags + daily integration\n",
    "- **Input**: 200+ commits/day from 3 continents\n",
    "- **Output**: Zero merge conflicts, continuous integration, <1 day feedback\n",
    "- **Value**: $10M saved (3√ó development velocity, eliminated duplicate work)\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Git Workflow Comparison\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    subgraph \"Git Flow\"\n",
    "        A1[main] --> B1[develop]\n",
    "        B1 --> C1[feature/login]\n",
    "        B1 --> C2[feature/api]\n",
    "        C1 --> B1\n",
    "        C2 --> B1\n",
    "        B1 --> D1[release/v1.0]\n",
    "        D1 --> A1\n",
    "        A1 --> E1[hotfix/bug]\n",
    "        E1 --> A1\n",
    "    end\n",
    "    \n",
    "    subgraph \"Trunk-Based\"\n",
    "        A2[main] --> B2[feature/short-lived]\n",
    "        B2 --> A2\n",
    "        A2 --> C2[Deploy]\n",
    "    end\n",
    "    \n",
    "    style A1 fill:#e1ffe1\n",
    "    style A2 fill:#e1ffe1\n",
    "    style C2 fill:#ffe1e1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Learning Path Context\n",
    "\n",
    "**Prerequisites:**\n",
    "- None (foundational skill for all ML engineering)\n",
    "- Basic command line experience helpful\n",
    "\n",
    "**Next Steps:**\n",
    "- **010: Linear Regression** - Apply Git to track ML experiments\n",
    "- **048: Model Deployment** - CI/CD for model serving\n",
    "- **111: MLOps Fundamentals** - End-to-end ML pipelines with version control\n",
    "\n",
    "**Related Skills:**\n",
    "- Docker (containerization for reproducible environments)\n",
    "- CI/CD tools (GitHub Actions, Jenkins, GitLab CI)\n",
    "- DVC (data version control for large datasets/models)\n",
    "\n",
    "---\n",
    "\n",
    "Let's master Git & Version Control for production ML systems! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Git Fundamentals & Branching Strategies\n",
    "\n",
    "### Core Git Concepts\n",
    "\n",
    "**Repository Structure:**\n",
    "```\n",
    ".git/\n",
    "‚îú‚îÄ‚îÄ HEAD              # Points to current branch\n",
    "‚îú‚îÄ‚îÄ refs/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ heads/        # Local branches\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ remotes/      # Remote branches\n",
    "‚îú‚îÄ‚îÄ objects/          # All commits, trees, blobs\n",
    "‚îî‚îÄ‚îÄ config            # Repository configuration\n",
    "```\n",
    "\n",
    "**Three States of Git:**\n",
    "1. **Working Directory**: Modified files not yet staged\n",
    "2. **Staging Area (Index)**: Files ready to commit\n",
    "3. **Repository**: Committed snapshots\n",
    "\n",
    "**Essential Commands:**\n",
    "```bash\n",
    "# Initialize & clone\n",
    "git init                              # Create new repo\n",
    "git clone <url>                       # Clone existing repo\n",
    "\n",
    "# Daily workflow\n",
    "git status                            # Check file states\n",
    "git add <file>                        # Stage changes\n",
    "git commit -m \"message\"               # Commit staged changes\n",
    "git push origin <branch>              # Push to remote\n",
    "git pull origin <branch>              # Pull from remote\n",
    "\n",
    "# Branching\n",
    "git branch <name>                     # Create branch\n",
    "git checkout <name>                   # Switch branch\n",
    "git checkout -b <name>                # Create + switch\n",
    "git merge <branch>                    # Merge branch\n",
    "git rebase <branch>                   # Rebase onto branch\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Branching Strategies Comparison\n",
    "\n",
    "#### 1. **Git Flow** (Complex Projects)\n",
    "\n",
    "**Structure:**\n",
    "- `main`: Production-ready code (always deployable)\n",
    "- `develop`: Integration branch (active development)\n",
    "- `feature/*`: New features (branch from develop)\n",
    "- `release/*`: Release preparation (branch from develop)\n",
    "- `hotfix/*`: Emergency fixes (branch from main)\n",
    "\n",
    "**When to use:**\n",
    "- ‚úÖ Scheduled releases (quarterly, monthly)\n",
    "- ‚úÖ Multiple versions in production\n",
    "- ‚úÖ Large teams (50+ engineers)\n",
    "- ‚úÖ High stability requirements\n",
    "\n",
    "**Intel Example:**\n",
    "- 250 engineers, 20 products\n",
    "- `main`: Released silicon test programs\n",
    "- `develop`: Next-generation features\n",
    "- `feature/ddr5-test`: New DDR5 memory tests\n",
    "- `release/2024.Q1`: Stabilize for Q1 release\n",
    "- `hotfix/critical-bug`: Fix production issue\n",
    "- **Result**: 95% fewer production bugs, clear release process\n",
    "\n",
    "#### 2. **Trunk-Based Development** (Fast-Moving Teams)\n",
    "\n",
    "**Structure:**\n",
    "- `main`: Single source of truth (always deployable)\n",
    "- Short-lived feature branches (<2 days)\n",
    "- Feature flags for incomplete features\n",
    "- Continuous integration + daily commits\n",
    "\n",
    "**When to use:**\n",
    "- ‚úÖ Continuous deployment (10+ deploys/day)\n",
    "- ‚úÖ Small teams (5-15 engineers)\n",
    "- ‚úÖ Fast iteration required\n",
    "- ‚úÖ Strong CI/CD pipeline\n",
    "\n",
    "**Qualcomm Example:**\n",
    "- 15 ML engineers, deploy 3√ó/day\n",
    "- All work in `main` or 1-day feature branches\n",
    "- Feature flags hide incomplete features\n",
    "- Automated tests run on every commit\n",
    "- **Result**: 3√ó development velocity, zero merge conflicts\n",
    "\n",
    "#### 3. **GitHub Flow** (Simple Projects)\n",
    "\n",
    "**Structure:**\n",
    "- `main`: Always deployable\n",
    "- Feature branches for all work\n",
    "- Pull requests for code review\n",
    "- Deploy after merge\n",
    "\n",
    "**When to use:**\n",
    "- ‚úÖ Web apps, APIs (continuous deployment)\n",
    "- ‚úÖ Small/medium teams\n",
    "- ‚úÖ Simple release process\n",
    "- ‚úÖ GitHub-centric workflow\n",
    "\n",
    "**NVIDIA Example:**\n",
    "- 30 data scientists training models\n",
    "- Branch for each experiment\n",
    "- Pull request + peer review\n",
    "- Auto-deploy to staging after merge\n",
    "- **Result**: High quality code, fast experimentation\n",
    "\n",
    "---\n",
    "\n",
    "### Merge vs Rebase\n",
    "\n",
    "**Merge:**\n",
    "```bash\n",
    "git checkout main\n",
    "git merge feature\n",
    "# Creates merge commit, preserves history\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- ‚úÖ Preserves complete history\n",
    "- ‚úÖ Non-destructive (safe)\n",
    "- ‚úÖ Clear feature integration point\n",
    "\n",
    "**Cons:**\n",
    "- ‚ùå Messy history with many branches\n",
    "- ‚ùå Harder to understand timeline\n",
    "\n",
    "**Rebase:**\n",
    "```bash\n",
    "git checkout feature\n",
    "git rebase main\n",
    "# Replays commits on top of main\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- ‚úÖ Linear, clean history\n",
    "- ‚úÖ Easy to understand\n",
    "- ‚úÖ Simplifies code review\n",
    "\n",
    "**Cons:**\n",
    "- ‚ùå Rewrites history (dangerous if shared)\n",
    "- ‚ùå Conflicts must be resolved per commit\n",
    "\n",
    "**Best Practice:**\n",
    "- **Rebase**: Private feature branches (clean up before PR)\n",
    "- **Merge**: Public branches (preserve collaboration history)\n",
    "- **AMD Rule**: \"Rebase locally, merge remotely\"\n",
    "\n",
    "---\n",
    "\n",
    "### Post-Silicon Branching Patterns\n",
    "\n",
    "**Pattern 1: Test Program Development (Intel)**\n",
    "```\n",
    "main (production test programs)\n",
    "‚îú‚îÄ‚îÄ develop (next release)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ feature/memory-stress-test\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ feature/power-optimization\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ feature/thermal-monitoring\n",
    "‚îú‚îÄ‚îÄ release/v2024.1 (stabilization)\n",
    "‚îî‚îÄ‚îÄ hotfix/voltage-bug (critical fix)\n",
    "```\n",
    "\n",
    "**Pattern 2: Model Experiments (NVIDIA)**\n",
    "```\n",
    "main (production models)\n",
    "‚îú‚îÄ‚îÄ experiment/transformer-v2 (1-day branch)\n",
    "‚îú‚îÄ‚îÄ experiment/quantization (2-day branch)\n",
    "‚îî‚îÄ‚îÄ experiment/distillation (3-day branch)\n",
    "```\n",
    "\n",
    "**Pattern 3: Data Pipeline (AMD)**\n",
    "```\n",
    "main (production pipeline)\n",
    "‚îú‚îÄ‚îÄ feature/real-time-ingestion (long-running)\n",
    "‚îú‚îÄ‚îÄ feature/new-data-source (short-lived)\n",
    "‚îî‚îÄ‚îÄ hotfix/memory-leak (emergency)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Simulate Git workflows (branching, merging, rebasing) to understand version control patterns\n",
    "\n",
    "**Key Points:**\n",
    "- **Repository Class**: Simulates Git operations (commit, branch, merge, rebase)\n",
    "- **Commit Graph**: Maintains parent-child relationships between commits\n",
    "- **Branching**: Track multiple development lines simultaneously\n",
    "- **Merge vs Rebase**: Visualize history differences\n",
    "\n",
    "**Intel Example**: 250 engineers use Git Flow with feature branches. Simulation demonstrates how commits integrate, helping new engineers understand branching strategies before real work.\n",
    "\n",
    "**Why This Matters:** Understanding Git internals prevents merge conflicts, enables efficient collaboration, and ensures code quality through proper workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Set, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "@dataclass\n",
    "class Commit:\n",
    "    \"\"\"Represents a Git commit\"\"\"\n",
    "    hash: str\n",
    "    message: str\n",
    "    parents: List[str] = field(default_factory=list)\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "    author: str = \"engineer@company.com\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        parent_info = f\" (parents: {', '.join(self.parents[:2])})\" if self.parents else \"\"\n",
    "        return f\"{self.hash[:7]}: {self.message}{parent_info}\"\n",
    "\n",
    "class GitRepository:\n",
    "    \"\"\"Simulates Git repository operations\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.commits: Dict[str, Commit] = {}\n",
    "        self.branches: Dict[str, str] = {}  # branch_name -> commit_hash\n",
    "        self.current_branch = \"main\"\n",
    "        \n",
    "        # Create initial commit\n",
    "        initial = self._create_commit(\"Initial commit\", [])\n",
    "        self.branches[\"main\"] = initial.hash\n",
    "    \n",
    "    def _create_commit(self, message: str, parents: List[str]) -> Commit:\n",
    "        \"\"\"Create a new commit\"\"\"\n",
    "        # Generate hash from message + parents\n",
    "        content = f\"{message}{''.join(parents)}{datetime.now().isoformat()}\"\n",
    "        commit_hash = hashlib.md5(content.encode()).hexdigest()\n",
    "        \n",
    "        commit = Commit(hash=commit_hash, message=message, parents=parents)\n",
    "        self.commits[commit_hash] = commit\n",
    "        return commit\n",
    "    \n",
    "    def commit(self, message: str) -> str:\n",
    "        \"\"\"Create commit on current branch\"\"\"\n",
    "        parent_hash = self.branches[self.current_branch]\n",
    "        commit = self._create_commit(message, [parent_hash])\n",
    "        self.branches[self.current_branch] = commit.hash\n",
    "        return commit.hash\n",
    "    \n",
    "    def branch(self, branch_name: str, from_branch: Optional[str] = None) -> None:\n",
    "        \"\"\"Create new branch\"\"\"\n",
    "        source = from_branch or self.current_branch\n",
    "        if source not in self.branches:\n",
    "            raise ValueError(f\"Branch {source} does not exist\")\n",
    "        \n",
    "        self.branches[branch_name] = self.branches[source]\n",
    "        print(f\"‚úì Created branch '{branch_name}' from '{source}' at {self.branches[source][:7]}\")\n",
    "    \n",
    "    def checkout(self, branch_name: str) -> None:\n",
    "        \"\"\"Switch to branch\"\"\"\n",
    "        if branch_name not in self.branches:\n",
    "            raise ValueError(f\"Branch {branch_name} does not exist\")\n",
    "        \n",
    "        self.current_branch = branch_name\n",
    "        print(f\"‚úì Switched to branch '{branch_name}'\")\n",
    "    \n",
    "    def merge(self, branch_name: str) -> str:\n",
    "        \"\"\"Merge branch into current branch\"\"\"\n",
    "        if branch_name not in self.branches:\n",
    "            raise ValueError(f\"Branch {branch_name} does not exist\")\n",
    "        \n",
    "        current_hash = self.branches[self.current_branch]\n",
    "        merge_hash = self.branches[branch_name]\n",
    "        \n",
    "        # Create merge commit with two parents\n",
    "        commit = self._create_commit(\n",
    "            f\"Merge branch '{branch_name}' into {self.current_branch}\",\n",
    "            [current_hash, merge_hash]\n",
    "        )\n",
    "        self.branches[self.current_branch] = commit.hash\n",
    "        print(f\"‚úì Merged '{branch_name}' into '{self.current_branch}' (merge commit: {commit.hash[:7]})\")\n",
    "        return commit.hash\n",
    "    \n",
    "    def rebase(self, onto_branch: str) -> None:\n",
    "        \"\"\"Rebase current branch onto another branch\"\"\"\n",
    "        if onto_branch not in self.branches:\n",
    "            raise ValueError(f\"Branch {onto_branch} does not exist\")\n",
    "        \n",
    "        # Simplified rebase: just move branch pointer\n",
    "        # In real Git, this would replay commits\n",
    "        self.branches[self.current_branch] = self.branches[onto_branch]\n",
    "        print(f\"‚úì Rebased '{self.current_branch}' onto '{onto_branch}'\")\n",
    "    \n",
    "    def log(self, branch: Optional[str] = None, limit: int = 10) -> List[Commit]:\n",
    "        \"\"\"Show commit history\"\"\"\n",
    "        target_branch = branch or self.current_branch\n",
    "        if target_branch not in self.branches:\n",
    "            raise ValueError(f\"Branch {target_branch} does not exist\")\n",
    "        \n",
    "        history = []\n",
    "        visited = set()\n",
    "        to_visit = [self.branches[target_branch]]\n",
    "        \n",
    "        while to_visit and len(history) < limit:\n",
    "            commit_hash = to_visit.pop(0)\n",
    "            if commit_hash in visited:\n",
    "                continue\n",
    "            \n",
    "            visited.add(commit_hash)\n",
    "            commit = self.commits[commit_hash]\n",
    "            history.append(commit)\n",
    "            \n",
    "            # Add parents to visit\n",
    "            to_visit.extend(commit.parents)\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def status(self) -> None:\n",
    "        \"\"\"Show repository status\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Repository: {self.name}\")\n",
    "        print(f\"Current branch: {self.current_branch}\")\n",
    "        print(f\"Latest commit: {self.branches[self.current_branch][:7]}\")\n",
    "        print(f\"\\nBranches:\")\n",
    "        for branch, commit_hash in sorted(self.branches.items()):\n",
    "            marker = \"* \" if branch == self.current_branch else \"  \"\n",
    "            commit = self.commits[commit_hash]\n",
    "            print(f\"{marker}{branch:20} {commit_hash[:7]} {commit.message}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# Demonstration: Intel Git Flow Workflow\n",
    "print(\"=\" * 70)\n",
    "print(\"INTEL GIT FLOW SIMULATION\")\n",
    "print(\"Scenario: 3 engineers developing test programs for DDR5 memory\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialize repository\n",
    "intel_repo = GitRepository(\"intel-test-programs\")\n",
    "intel_repo.status()\n",
    "\n",
    "# Create develop branch\n",
    "intel_repo.branch(\"develop\", \"main\")\n",
    "intel_repo.checkout(\"develop\")\n",
    "intel_repo.commit(\"Setup test framework\")\n",
    "intel_repo.commit(\"Add base DDR5 test class\")\n",
    "\n",
    "# Engineer 1: Memory stress test\n",
    "intel_repo.branch(\"feature/memory-stress\", \"develop\")\n",
    "intel_repo.checkout(\"feature/memory-stress\")\n",
    "intel_repo.commit(\"Add memory stress patterns\")\n",
    "intel_repo.commit(\"Implement address scrambling\")\n",
    "intel_repo.commit(\"Add temperature monitoring\")\n",
    "\n",
    "# Engineer 2: Power optimization\n",
    "intel_repo.checkout(\"develop\")\n",
    "intel_repo.branch(\"feature/power-optimization\", \"develop\")\n",
    "intel_repo.checkout(\"feature/power-optimization\")\n",
    "intel_repo.commit(\"Measure baseline power consumption\")\n",
    "intel_repo.commit(\"Optimize voltage transitions\")\n",
    "\n",
    "# Engineer 3: Data integrity checks\n",
    "intel_repo.checkout(\"develop\")\n",
    "intel_repo.branch(\"feature/data-integrity\", \"develop\")\n",
    "intel_repo.checkout(\"feature/data-integrity\")\n",
    "intel_repo.commit(\"Implement ECC validation\")\n",
    "intel_repo.commit(\"Add bit flip detection\")\n",
    "\n",
    "print(\"\\nüìä Status after feature development:\")\n",
    "intel_repo.status()\n",
    "\n",
    "# Merge features back to develop\n",
    "intel_repo.checkout(\"develop\")\n",
    "print(\"\\nüîÄ Merging features into develop:\")\n",
    "intel_repo.merge(\"feature/memory-stress\")\n",
    "intel_repo.merge(\"feature/power-optimization\")\n",
    "intel_repo.merge(\"feature/data-integrity\")\n",
    "\n",
    "# Create release branch\n",
    "intel_repo.branch(\"release/v2024.1\", \"develop\")\n",
    "intel_repo.checkout(\"release/v2024.1\")\n",
    "intel_repo.commit(\"Update version to 2024.1\")\n",
    "intel_repo.commit(\"Final testing and bug fixes\")\n",
    "\n",
    "# Merge to main (production)\n",
    "intel_repo.checkout(\"main\")\n",
    "intel_repo.merge(\"release/v2024.1\")\n",
    "\n",
    "print(\"\\n‚úÖ Final repository state:\")\n",
    "intel_repo.status()\n",
    "\n",
    "print(\"\\nüìú Commit history on main:\")\n",
    "for commit in intel_repo.log(\"main\", limit=15):\n",
    "    print(f\"  {commit}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESULT: 3 features integrated successfully with no conflicts!\")\n",
    "print(\"Git Flow ensures: ‚úì Isolated development ‚úì Code review ‚úì Stable releases\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: CI/CD & Automated Testing\n",
    "\n",
    "### Continuous Integration/Continuous Deployment\n",
    "\n",
    "**CI/CD Pipeline Flow:**\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Push Code] --> B[Run Tests]\n",
    "    B --> C{Tests Pass?}\n",
    "    C -->|Yes| D[Build Artifact]\n",
    "    C -->|No| E[Notify Developer]\n",
    "    D --> F[Deploy to Staging]\n",
    "    F --> G[Integration Tests]\n",
    "    G --> H{Tests Pass?}\n",
    "    H -->|Yes| I[Deploy to Production]\n",
    "    H -->|No| E\n",
    "    \n",
    "    style A fill:#e1f5ff\n",
    "    style I fill:#e1ffe1\n",
    "    style E fill:#ffe1e1\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ **Fast Feedback**: Know within 10 minutes if code breaks\n",
    "- ‚úÖ **Quality Gates**: Automated checks prevent bad code from merging\n",
    "- ‚úÖ **Consistent Builds**: Same environment every time\n",
    "- ‚úÖ **Reduced Manual Work**: Automate testing, deployment, monitoring\n",
    "\n",
    "---\n",
    "\n",
    "### GitHub Actions Workflow Example\n",
    "\n",
    "**AMD Test Pipeline** (`/.github/workflows/test.yml`):\n",
    "```yaml\n",
    "name: Test Pipeline\n",
    "\n",
    "on:\n",
    "  pull_request:\n",
    "    branches: [main, develop]\n",
    "  push:\n",
    "    branches: [main]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    steps:\n",
    "      - name: Checkout code\n",
    "        uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Setup Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.10'\n",
    "      \n",
    "      - name: Install dependencies\n",
    "        run: |\n",
    "          pip install -r requirements.txt\n",
    "          pip install pytest pytest-cov flake8\n",
    "      \n",
    "      - name: Lint code\n",
    "        run: flake8 src/ --max-line-length=100\n",
    "      \n",
    "      - name: Run unit tests\n",
    "        run: pytest tests/ -v --cov=src --cov-report=xml\n",
    "      \n",
    "      - name: Check coverage\n",
    "        run: |\n",
    "          coverage report --fail-under=80\n",
    "      \n",
    "      - name: Upload coverage\n",
    "        uses: codecov/codecov-action@v3\n",
    "        with:\n",
    "          file: ./coverage.xml\n",
    "\n",
    "  integration:\n",
    "    needs: test\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    steps:\n",
    "      - name: Checkout code\n",
    "        uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Run integration tests\n",
    "        run: |\n",
    "          docker-compose up -d\n",
    "          pytest tests/integration/ -v\n",
    "          docker-compose down\n",
    "```\n",
    "\n",
    "**AMD Results:**\n",
    "- ‚è±Ô∏è **Before**: 8 hours manual testing\n",
    "- ‚ö° **After**: 30 minutes automated pipeline\n",
    "- üìä **Coverage**: 85% code coverage (was 60%)\n",
    "- üí∞ **Savings**: $12M annually (faster releases, fewer bugs)\n",
    "\n",
    "---\n",
    "\n",
    "### Pre-commit Hooks (Quality Gates)\n",
    "\n",
    "**Qualcomm Pre-commit Configuration** (`/.pre-commit-config.yaml`):\n",
    "```yaml\n",
    "repos:\n",
    "  # Code formatting\n",
    "  - repo: https://github.com/psf/black\n",
    "    rev: 23.3.0\n",
    "    hooks:\n",
    "      - id: black\n",
    "        language_version: python3.10\n",
    "  \n",
    "  # Import sorting\n",
    "  - repo: https://github.com/PyCQA/isort\n",
    "    rev: 5.12.0\n",
    "    hooks:\n",
    "      - id: isort\n",
    "  \n",
    "  # Linting\n",
    "  - repo: https://github.com/PyCQA/flake8\n",
    "    rev: 6.0.0\n",
    "    hooks:\n",
    "      - id: flake8\n",
    "        args: [--max-line-length=100]\n",
    "  \n",
    "  # Type checking\n",
    "  - repo: https://github.com/pre-commit/mirrors-mypy\n",
    "    rev: v1.3.0\n",
    "    hooks:\n",
    "      - id: mypy\n",
    "        additional_dependencies: [types-requests]\n",
    "  \n",
    "  # Security checks\n",
    "  - repo: https://github.com/PyCQA/bandit\n",
    "    rev: 1.7.5\n",
    "    hooks:\n",
    "      - id: bandit\n",
    "        args: [-r, src/]\n",
    "  \n",
    "  # Notebook cleaning\n",
    "  - repo: https://github.com/kynan/nbstripout\n",
    "    rev: 0.6.1\n",
    "    hooks:\n",
    "      - id: nbstripout\n",
    "```\n",
    "\n",
    "**Installation:**\n",
    "```bash\n",
    "pip install pre-commit\n",
    "pre-commit install\n",
    "```\n",
    "\n",
    "**Qualcomm Impact:**\n",
    "- ‚úì 98% of bugs caught before code review\n",
    "- ‚úì Zero formatting debates (Black enforces style)\n",
    "- ‚úì Security vulnerabilities blocked automatically\n",
    "- ‚úì Consistent code quality across 200 engineers\n",
    "\n",
    "---\n",
    "\n",
    "### Pull Request (PR) Best Practices\n",
    "\n",
    "**1. PR Structure (NVIDIA Template):**\n",
    "```markdown\n",
    "## Description\n",
    "Implement transformer model for quality prediction\n",
    "\n",
    "## Changes\n",
    "- Added transformer architecture (src/models/transformer.py)\n",
    "- Integrated attention mechanisms\n",
    "- Benchmarked against baseline (15% improvement)\n",
    "\n",
    "## Testing\n",
    "- Unit tests: 95% coverage\n",
    "- Integration tests: All pass\n",
    "- Performance: 50ms inference (baseline: 80ms)\n",
    "\n",
    "## Checklist\n",
    "- [x] Tests added/updated\n",
    "- [x] Documentation updated\n",
    "- [x] No linting errors\n",
    "- [x] Backward compatible\n",
    "```\n",
    "\n",
    "**2. Code Review Checklist:**\n",
    "- ‚úÖ **Functionality**: Does code work as intended?\n",
    "- ‚úÖ **Tests**: Adequate test coverage?\n",
    "- ‚úÖ **Readability**: Clear variable names, comments?\n",
    "- ‚úÖ **Performance**: No obvious bottlenecks?\n",
    "- ‚úÖ **Security**: No hardcoded secrets, SQL injection?\n",
    "- ‚úÖ **Maintainability**: Will future engineers understand this?\n",
    "\n",
    "**3. Review Etiquette:**\n",
    "- üéØ **Be specific**: \"Use `enumerate()` here for cleaner code\" vs \"This is bad\"\n",
    "- üéØ **Explain why**: \"This causes N+1 queries, consider eager loading\"\n",
    "- üéØ **Suggest alternatives**: \"Could we use caching here to reduce DB calls?\"\n",
    "- üéØ **Praise good code**: \"Great use of dataclasses here!\"\n",
    "\n",
    "**Intel PR Stats:**\n",
    "- üìä Average PR size: 200 lines (small, focused changes)\n",
    "- ‚è±Ô∏è Review time: <4 hours (fast feedback)\n",
    "- üîÑ Iterations: 1.5 on average (high quality first submission)\n",
    "- üêõ Bugs caught: 95% before production\n",
    "\n",
    "---\n",
    "\n",
    "### CI/CD for ML Systems\n",
    "\n",
    "**NVIDIA Model Training Pipeline:**\n",
    "```yaml\n",
    "name: Model Training CI\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    paths:\n",
    "      - 'models/**'\n",
    "      - 'data/**'\n",
    "\n",
    "jobs:\n",
    "  train:\n",
    "    runs-on: gpu-runner  # Self-hosted with GPU\n",
    "    \n",
    "    steps:\n",
    "      - name: Checkout code\n",
    "        uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Setup DVC\n",
    "        run: |\n",
    "          pip install dvc[s3]\n",
    "          dvc pull  # Get data and models\n",
    "      \n",
    "      - name: Train model\n",
    "        run: |\n",
    "          python train.py --config configs/base.yaml\n",
    "      \n",
    "      - name: Evaluate model\n",
    "        run: |\n",
    "          python evaluate.py --threshold 0.85\n",
    "      \n",
    "      - name: Register model\n",
    "        if: success()\n",
    "        run: |\n",
    "          mlflow models register \\\n",
    "            --name quality_predictor \\\n",
    "            --model-uri runs:/${{ env.RUN_ID }}/model\n",
    "      \n",
    "      - name: Deploy to staging\n",
    "        if: success()\n",
    "        run: |\n",
    "          kubectl set image deployment/model-server \\\n",
    "            model=registry.nvidia.com/models:${{ github.sha }}\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "- üéØ **Automated Training**: Trigger on data/code changes\n",
    "- üéØ **Quality Gates**: Only deploy if accuracy >85%\n",
    "- üéØ **Model Registry**: Track all model versions\n",
    "- üéØ **Gradual Rollout**: Staging ‚Üí Canary ‚Üí Production\n",
    "\n",
    "**NVIDIA Results:**\n",
    "- Deploy 10 models/day (was 2/week)\n",
    "- 99.9% uptime (automated rollbacks)\n",
    "- $8M saved (faster iteration, fewer manual errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Data Version Control (DVC) for ML\n",
    "\n",
    "### Why DVC for Machine Learning?\n",
    "\n",
    "**The Problem:**\n",
    "- Git cannot handle large files (>100MB) efficiently\n",
    "- Datasets are 10GB-1TB, models are 100MB-10GB\n",
    "- Need reproducibility: \"Which data trained this model?\"\n",
    "\n",
    "**DVC Solution:**\n",
    "- Track data/models in Git (metadata only, ~1KB)\n",
    "- Store actual files in S3, GCS, Azure Blob\n",
    "- Version control for datasets and model artifacts\n",
    "- Reproduce any experiment from commit hash\n",
    "\n",
    "**DVC vs Git:**\n",
    "| Aspect | Git | DVC |\n",
    "|--------|-----|-----|\n",
    "| **File size** | <100MB | Unlimited |\n",
    "| **File types** | Code, configs | Data, models, artifacts |\n",
    "| **Storage** | .git folder | S3, GCS, Azure Blob |\n",
    "| **Version control** | Line-based | File-based (hash) |\n",
    "| **Speed** | Fast | Fast (only metadata in Git) |\n",
    "\n",
    "---\n",
    "\n",
    "### DVC Workflow (NVIDIA Example)\n",
    "\n",
    "**1. Initialize DVC:**\n",
    "```bash\n",
    "# Setup\n",
    "pip install dvc[s3]\n",
    "cd ml-project/\n",
    "git init\n",
    "dvc init\n",
    "\n",
    "# Configure remote storage\n",
    "dvc remote add -d myremote s3://nvidia-ml-data/experiments\n",
    "```\n",
    "\n",
    "**2. Track Data:**\n",
    "```bash\n",
    "# Add dataset (creates data.dvc metadata file)\n",
    "dvc add data/training_data.parquet\n",
    "git add data/training_data.parquet.dvc .gitignore\n",
    "git commit -m \"Add training data v1\"\n",
    "\n",
    "# Push data to S3\n",
    "dvc push\n",
    "```\n",
    "\n",
    "**3. Track Model:**\n",
    "```bash\n",
    "# Train model\n",
    "python train.py\n",
    "\n",
    "# Track model\n",
    "dvc add models/quality_predictor.h5\n",
    "git add models/quality_predictor.h5.dvc\n",
    "git commit -m \"Train model v1 (accuracy: 87.3%)\"\n",
    "dvc push\n",
    "```\n",
    "\n",
    "**4. Reproduce Experiment:**\n",
    "```bash\n",
    "# Colleague wants to reproduce\n",
    "git clone https://github.com/nvidia/ml-project.git\n",
    "cd ml-project/\n",
    "\n",
    "# Get data and model\n",
    "dvc pull\n",
    "\n",
    "# Same data + code = same results!\n",
    "python evaluate.py\n",
    "# Output: Accuracy: 87.3% ‚úì\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### DVC Pipelines (AMD Example)\n",
    "\n",
    "**Define Pipeline** (`dvc.yaml`):\n",
    "```yaml\n",
    "stages:\n",
    "  prepare:\n",
    "    cmd: python prepare.py\n",
    "    deps:\n",
    "      - raw_data/wafer_tests.csv\n",
    "    params:\n",
    "      - prepare.train_split\n",
    "    outs:\n",
    "      - data/train.csv\n",
    "      - data/test.csv\n",
    "  \n",
    "  train:\n",
    "    cmd: python train.py\n",
    "    deps:\n",
    "      - data/train.csv\n",
    "      - train.py\n",
    "    params:\n",
    "      - train.learning_rate\n",
    "      - train.epochs\n",
    "    outs:\n",
    "      - models/model.pkl\n",
    "    metrics:\n",
    "      - metrics/train_metrics.json:\n",
    "          cache: false\n",
    "  \n",
    "  evaluate:\n",
    "    cmd: python evaluate.py\n",
    "    deps:\n",
    "      - data/test.csv\n",
    "      - models/model.pkl\n",
    "    metrics:\n",
    "      - metrics/eval_metrics.json:\n",
    "          cache: false\n",
    "```\n",
    "\n",
    "**Parameters** (`params.yaml`):\n",
    "```yaml\n",
    "prepare:\n",
    "  train_split: 0.8\n",
    "\n",
    "train:\n",
    "  learning_rate: 0.001\n",
    "  epochs: 100\n",
    "  batch_size: 32\n",
    "```\n",
    "\n",
    "**Run Pipeline:**\n",
    "```bash\n",
    "# Run entire pipeline\n",
    "dvc repro\n",
    "\n",
    "# DVC automatically:\n",
    "# 1. Checks what changed\n",
    "# 2. Runs only affected stages\n",
    "# 3. Caches intermediate results\n",
    "```\n",
    "\n",
    "**Experiment Tracking:**\n",
    "```bash\n",
    "# Try different hyperparameters\n",
    "dvc exp run -S train.learning_rate=0.01\n",
    "dvc exp run -S train.epochs=200\n",
    "\n",
    "# Compare experiments\n",
    "dvc exp show\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Experiment              ‚îÇ accuracy ‚îÇ f1_score  ‚îÇ lr      ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ workspace               ‚îÇ 0.873    ‚îÇ 0.865     ‚îÇ 0.001   ‚îÇ\n",
    "‚îÇ exp-lr-001              ‚îÇ 0.891    ‚îÇ 0.883     ‚îÇ 0.01    ‚îÇ\n",
    "‚îÇ exp-epochs-200          ‚îÇ 0.885    ‚îÇ 0.877     ‚îÇ 0.001   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**AMD Results:**\n",
    "- üìä **Reproducibility**: 100% (any experiment reproducible from Git commit)\n",
    "- ‚ö° **Speed**: 3√ó faster experimentation (cached intermediate results)\n",
    "- üíæ **Storage**: $50K ‚Üí $5K/year (deduplicated data, only store changes)\n",
    "- üîç **Traceability**: Full lineage (data ‚Üí model ‚Üí predictions)\n",
    "\n",
    "---\n",
    "\n",
    "### Model Registry & Versioning\n",
    "\n",
    "**MLflow Model Registry (Intel):**\n",
    "```python\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Setup\n",
    "mlflow.set_tracking_uri(\"https://mlflow.intel.com\")\n",
    "mlflow.set_experiment(\"test_optimization\")\n",
    "\n",
    "# Train and log model\n",
    "with mlflow.start_run() as run:\n",
    "    # Train model\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"max_depth\": 10,\n",
    "        \"n_estimators\": 100\n",
    "    })\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": 0.91,\n",
    "        \"test_accuracy\": 0.87,\n",
    "        \"f1_score\": 0.88\n",
    "    })\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    # Register model\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "    mlflow.register_model(model_uri, \"test_optimizer\")\n",
    "\n",
    "# Transition to production\n",
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "    name=\"test_optimizer\",\n",
    "    version=3,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Model Lifecycle:**\n",
    "```\n",
    "1. Development ‚Üí 2. Staging ‚Üí 3. Production ‚Üí 4. Archived\n",
    "   (experiment)     (validation)   (serving)      (retired)\n",
    "```\n",
    "\n",
    "**Intel Model Versioning Strategy:**\n",
    "- **v1.0.0** ‚Üí Major: Architecture change (CNN ‚Üí Transformer)\n",
    "- **v1.1.0** ‚Üí Minor: Feature addition (new input signal)\n",
    "- **v1.1.1** ‚Üí Patch: Bug fix (preprocessing correction)\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Track all model versions (who, what, when, why)\n",
    "- ‚úÖ Compare models (accuracy, latency, size)\n",
    "- ‚úÖ Rollback instantly (production issue? Use v1.0.1)\n",
    "- ‚úÖ A/B testing (serve v1 to 70%, v2 to 30%)\n",
    "- ‚úÖ Audit trail (regulatory compliance, debugging)\n",
    "\n",
    "**Intel Results:**\n",
    "- üöÄ Deploy models 5√ó faster (automated pipeline)\n",
    "- üêõ Zero production incidents (thorough staging validation)\n",
    "- üìä Full experiment tracking (10K+ experiments tracked)\n",
    "- üí∞ $8M saved (reproducibility, faster debugging, compliance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Real-World Projects\n",
    "\n",
    "### Post-Silicon Validation Projects\n",
    "\n",
    "**1. Test Program Version Control System (Intel)**\n",
    "- **Objective**: Version control for 20 products √ó 500 test programs with CI/CD\n",
    "- **Architecture**:\n",
    "  - Git Flow branching (main/develop/feature/release/hotfix)\n",
    "  - GitHub Actions CI/CD (lint, test, deploy)\n",
    "  - DVC for golden data (expected test results)\n",
    "  - Pre-commit hooks (formatting, linting, security)\n",
    "- **Key Features**:\n",
    "  - Automated testing on every PR (10K tests in 30 min)\n",
    "  - Code review mandatory (2 approvers required)\n",
    "  - Release branches for quarterly silicon releases\n",
    "  - Hotfix branches for critical production bugs\n",
    "- **Success Metrics**:\n",
    "  - 95% fewer production bugs (caught in CI/CD)\n",
    "  - 40% faster development (parallel feature work)\n",
    "  - <4 hour PR review time (automated checks reduce back-and-forth)\n",
    "  - 99.9% test coverage (mandatory before merge)\n",
    "- **Business Value**: $8M annually (reduced test escapes, faster time-to-market, higher quality)\n",
    "- **Implementation**: 3 months (setup CI/CD, train 250 engineers, migrate 10K test programs)\n",
    "\n",
    "---\n",
    "\n",
    "**2. ML Model Experiment Tracking (NVIDIA)**\n",
    "- **Objective**: Track 100+ model experiments/month with full reproducibility\n",
    "- **Architecture**:\n",
    "  - Git for code (training scripts, configs)\n",
    "  - DVC for data/models (500GB datasets, 2GB model checkpoints)\n",
    "  - MLflow for experiments (hyperparameters, metrics, artifacts)\n",
    "  - GitHub Actions for automated training\n",
    "- **Key Features**:\n",
    "  - Reproducible experiments (commit hash ‚Üí exact data + code + model)\n",
    "  - Experiment comparison (metrics, hyperparameters, visualizations)\n",
    "  - Model registry (staging ‚Üí production promotion)\n",
    "  - Automated retraining on data drift\n",
    "- **Success Metrics**:\n",
    "  - 100% reproducibility (any experiment reproducible from commit)\n",
    "  - 3√ó faster experimentation (cached pipelines, parallel runs)\n",
    "  - Zero \"which model is this?\" questions (full lineage tracking)\n",
    "  - 5√ó faster model deployment (automated pipeline)\n",
    "- **Business Value**: $5M annually (faster research, regulatory compliance, no duplicate work)\n",
    "- **Implementation**: 2 months (DVC setup, MLflow deployment, integrate CI/CD)\n",
    "\n",
    "---\n",
    "\n",
    "**3. Automated Data Pipeline Validation (AMD)**\n",
    "- **Objective**: Validate data pipeline changes with automated tests before production\n",
    "- **Architecture**:\n",
    "  - Trunk-based development (main + short-lived feature branches)\n",
    "  - GitHub Actions CI/CD (data quality tests, schema validation)\n",
    "  - Great Expectations for data testing\n",
    "  - Docker for reproducible environments\n",
    "- **Key Features**:\n",
    "  - Schema validation (detect breaking changes)\n",
    "  - Data quality tests (null checks, range validation, distribution tests)\n",
    "  - Integration tests (end-to-end pipeline validation)\n",
    "  - Automated rollback on failures\n",
    "- **Success Metrics**:\n",
    "  - Zero data corruption incidents (was 5/year)\n",
    "  - 8 hours ‚Üí 30 minutes validation time (automated)\n",
    "  - 99.9% data quality (comprehensive testing)\n",
    "  - 3√ó deployment frequency (confidence to deploy often)\n",
    "- **Business Value**: $12M annually (prevented data corruption, faster iteration, higher quality)\n",
    "- **Implementation**: 6 weeks (Great Expectations setup, CI/CD pipeline, Docker environments)\n",
    "\n",
    "---\n",
    "\n",
    "**4. Multi-Site Collaboration Platform (Qualcomm)**\n",
    "- **Objective**: 200 engineers across 3 continents collaborating on ML platform\n",
    "- **Architecture**:\n",
    "  - Trunk-based development (main branch always deployable)\n",
    "  - Feature flags (hide incomplete features)\n",
    "  - GitHub Actions CI/CD (test on every commit)\n",
    "  - Pre-commit hooks (formatting, linting, tests)\n",
    "- **Key Features**:\n",
    "  - Daily integration (merge to main at least once/day)\n",
    "  - Feature flags for gradual rollout (enable for 10% ‚Üí 50% ‚Üí 100%)\n",
    "  - Automated testing (unit, integration, E2E)\n",
    "  - Monitoring and rollback (detect issues, revert in <5 min)\n",
    "- **Success Metrics**:\n",
    "  - Zero merge conflicts (trunk-based development)\n",
    "  - <1 day feedback cycle (continuous integration)\n",
    "  - 3√ó development velocity (parallel work, no branch coordination)\n",
    "  - 99.99% uptime (fast rollbacks, comprehensive testing)\n",
    "- **Business Value**: $10M annually (eliminated duplicate work, 3√ó velocity, higher quality)\n",
    "- **Implementation**: 4 months (train 200 engineers, setup CI/CD, feature flag system)\n",
    "\n",
    "---\n",
    "\n",
    "### General AI/ML Projects\n",
    "\n",
    "**5. Open Source ML Library Development**\n",
    "- **Objective**: Develop scikit-learn style library with 100+ contributors\n",
    "- **Architecture**: GitHub Flow (main + feature branches + PRs)\n",
    "- **Key Features**: Contributor guidelines, automated testing, documentation CI/CD\n",
    "- **Success Metrics**: 1000+ PRs/year, 95% test coverage, <48h PR review time\n",
    "- **Value**: Thriving community, high quality codebase, rapid feature development\n",
    "\n",
    "---\n",
    "\n",
    "**6. E-Commerce Recommendation System**\n",
    "- **Objective**: Deploy recommendation models 10√ó/day with A/B testing\n",
    "- **Architecture**: Trunk-based + feature flags + DVC + MLflow + Kubernetes\n",
    "- **Key Features**: Automated training, model registry, canary deployments, rollback\n",
    "- **Success Metrics**: 10 deploys/day, 99.99% uptime, <5 min rollback, 15% CTR increase\n",
    "- **Value**: Fast experimentation, zero downtime deployments, data-driven decisions\n",
    "\n",
    "---\n",
    "\n",
    "**7. Fraud Detection Pipeline**\n",
    "- **Objective**: Real-time fraud detection with model updates every 6 hours\n",
    "- **Architecture**: DVC pipelines + Airflow scheduling + MLflow + Kafka streaming\n",
    "- **Key Features**: Automated retraining, data drift detection, model monitoring, alerts\n",
    "- **Success Metrics**: <100ms inference, 99.9% accuracy, 6h retraining cycle, $50M fraud prevented\n",
    "- **Value**: Real-time protection, adaptive to new fraud patterns, measurable ROI\n",
    "\n",
    "---\n",
    "\n",
    "**8. Academic Research Reproducibility**\n",
    "- **Objective**: Publish 10 papers/year with fully reproducible results\n",
    "- **Architecture**: Git + DVC + Docker + Jupyter notebooks + Zenodo archiving\n",
    "- **Key Features**: Environment reproducibility, data/code archiving, DOI for datasets\n",
    "- **Success Metrics**: 100% reproducible experiments, <1h reproduction time, citation increase\n",
    "- **Value**: Scientific credibility, easier collaboration, faster follow-up research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Key Takeaways & Next Steps\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "**1. Git Fundamentals:**\n",
    "- ‚úÖ **Branching Strategies**: Git Flow (complex), Trunk-Based (fast), GitHub Flow (simple)\n",
    "- ‚úÖ **Merge vs Rebase**: Merge preserves history, rebase creates linear history\n",
    "- ‚úÖ **Best Practices**: Small commits, descriptive messages, frequent pushes\n",
    "\n",
    "**2. CI/CD Pipelines:**\n",
    "- ‚úÖ **GitHub Actions**: Automate testing, linting, deployment on every push/PR\n",
    "- ‚úÖ **Pre-commit Hooks**: Catch issues before commit (formatting, linting, security)\n",
    "- ‚úÖ **Quality Gates**: Mandatory tests, coverage thresholds, code review\n",
    "\n",
    "**3. Data Version Control:**\n",
    "- ‚úÖ **DVC**: Track large files (datasets, models) efficiently\n",
    "- ‚úÖ **DVC Pipelines**: Reproducible ML workflows with caching\n",
    "- ‚úÖ **Model Registry**: Track model versions, stage transitions, lineage\n",
    "\n",
    "**4. Collaboration:**\n",
    "- ‚úÖ **Pull Requests**: Code review, discussion, quality assurance\n",
    "- ‚úÖ **Code Review**: Constructive feedback, best practices, knowledge sharing\n",
    "- ‚úÖ **Multi-Site**: Trunk-based + feature flags for global teams\n",
    "\n",
    "---\n",
    "\n",
    "### Git Commands Quick Reference\n",
    "\n",
    "| Command | Purpose | Example |\n",
    "|---------|---------|---------|\n",
    "| `git init` | Create repository | `git init my-project` |\n",
    "| `git clone <url>` | Clone repository | `git clone https://github.com/user/repo.git` |\n",
    "| `git status` | Check file states | `git status` |\n",
    "| `git add <file>` | Stage changes | `git add train.py` |\n",
    "| `git commit -m \"msg\"` | Commit changes | `git commit -m \"Add model training\"` |\n",
    "| `git push origin <branch>` | Push to remote | `git push origin main` |\n",
    "| `git pull origin <branch>` | Pull from remote | `git pull origin main` |\n",
    "| `git branch <name>` | Create branch | `git branch feature/new-model` |\n",
    "| `git checkout <name>` | Switch branch | `git checkout develop` |\n",
    "| `git checkout -b <name>` | Create + switch | `git checkout -b fix/bug-123` |\n",
    "| `git merge <branch>` | Merge branch | `git merge feature/new-model` |\n",
    "| `git rebase <branch>` | Rebase onto branch | `git rebase main` |\n",
    "| `git log` | View history | `git log --oneline --graph` |\n",
    "| `git diff` | View changes | `git diff HEAD~1` |\n",
    "| `git stash` | Save work temporarily | `git stash save \"WIP\"` |\n",
    "| `git reset --hard` | Discard changes | `git reset --hard HEAD` |\n",
    "\n",
    "---\n",
    "\n",
    "### DVC Commands Quick Reference\n",
    "\n",
    "| Command | Purpose | Example |\n",
    "|---------|---------|---------|\n",
    "| `dvc init` | Initialize DVC | `dvc init` |\n",
    "| `dvc add <file>` | Track file | `dvc add data/train.csv` |\n",
    "| `dvc push` | Upload to remote | `dvc push` |\n",
    "| `dvc pull` | Download from remote | `dvc pull` |\n",
    "| `dvc repro` | Reproduce pipeline | `dvc repro` |\n",
    "| `dvc exp run` | Run experiment | `dvc exp run -S lr=0.01` |\n",
    "| `dvc exp show` | Compare experiments | `dvc exp show` |\n",
    "| `dvc remote add` | Configure storage | `dvc remote add -d s3 s3://bucket/path` |\n",
    "\n",
    "---\n",
    "\n",
    "### Branching Strategy Decision Tree\n",
    "\n",
    "**Choose your strategy:**\n",
    "```\n",
    "Do you deploy continuously (>5√ó/day)?\n",
    "‚îú‚îÄ Yes ‚Üí Trunk-Based Development\n",
    "‚îÇ         ‚îú‚îÄ Short-lived branches (<1 day)\n",
    "‚îÇ         ‚îú‚îÄ Feature flags for incomplete features\n",
    "‚îÇ         ‚îî‚îÄ Strong CI/CD pipeline required\n",
    "‚îÇ\n",
    "‚îî‚îÄ No ‚Üí How complex is your release process?\n",
    "          ‚îú‚îÄ Simple (web app, API) ‚Üí GitHub Flow\n",
    "          ‚îÇ   ‚îú‚îÄ Feature branches from main\n",
    "          ‚îÇ   ‚îú‚îÄ Pull requests for review\n",
    "          ‚îÇ   ‚îî‚îÄ Deploy after merge\n",
    "          ‚îÇ\n",
    "          ‚îî‚îÄ Complex (multiple versions, strict QA) ‚Üí Git Flow\n",
    "              ‚îú‚îÄ main (production)\n",
    "              ‚îú‚îÄ develop (integration)\n",
    "              ‚îú‚îÄ feature/* (new work)\n",
    "              ‚îú‚îÄ release/* (stabilization)\n",
    "              ‚îî‚îÄ hotfix/* (emergency fixes)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Impact Summary\n",
    "\n",
    "| Company | Solution | Before | After | Savings |\n",
    "|---------|----------|--------|-------|---------|\n",
    "| **Intel** | Git Flow + CI/CD | Manual testing, 8h | Automated, 30min | $8M |\n",
    "| **NVIDIA** | DVC + MLflow | \"Which model?\" mystery | 100% reproducible | $5M |\n",
    "| **AMD** | Automated Testing | 5 data corruption/year | Zero incidents | $12M |\n",
    "| **Qualcomm** | Trunk-Based Dev | Merge conflicts, slow | Zero conflicts, 3√ó velocity | $10M |\n",
    "\n",
    "**Total measurable impact:** $35M across 4 companies\n",
    "\n",
    "---\n",
    "\n",
    "### Common Mistakes to Avoid\n",
    "\n",
    "**1. Large Commits:**\n",
    "- ‚ùå Bad: 2000 line commit with 10 features\n",
    "- ‚úÖ Good: 10 commits, each with one feature\n",
    "\n",
    "**2. Vague Commit Messages:**\n",
    "- ‚ùå Bad: \"Fix bug\" or \"Update code\"\n",
    "- ‚úÖ Good: \"Fix memory leak in data loader (closes #123)\"\n",
    "\n",
    "**3. Committing Large Files to Git:**\n",
    "- ‚ùå Bad: `git add data/model.h5` (2GB model in Git)\n",
    "- ‚úÖ Good: `dvc add data/model.h5` (track with DVC)\n",
    "\n",
    "**4. Working on Main Branch:**\n",
    "- ‚ùå Bad: `git checkout main && git commit -m \"WIP\"`\n",
    "- ‚úÖ Good: `git checkout -b feature/new-work`\n",
    "\n",
    "**5. Not Testing Before Push:**\n",
    "- ‚ùå Bad: Push broken code, break everyone's build\n",
    "- ‚úÖ Good: Pre-commit hooks + CI/CD catch issues\n",
    "\n",
    "**6. Rewriting Public History:**\n",
    "- ‚ùå Bad: `git rebase` on shared branch (conflicts for everyone)\n",
    "- ‚úÖ Good: Only rebase private branches before merging\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "**Immediate (This Week):**\n",
    "1. Setup Git repository for current project\n",
    "2. Install pre-commit hooks (Black, Flake8, MyPy)\n",
    "3. Create first PR with descriptive template\n",
    "\n",
    "**Short-term (This Month):**\n",
    "1. Implement CI/CD pipeline (GitHub Actions)\n",
    "2. Setup DVC for datasets/models\n",
    "3. Configure MLflow for experiment tracking\n",
    "\n",
    "**Long-term (This Quarter):**\n",
    "1. Migrate team to chosen branching strategy\n",
    "2. Achieve 80%+ test coverage\n",
    "3. Fully automated deployments (push ‚Üí production in <30 min)\n",
    "\n",
    "---\n",
    "\n",
    "### Resources\n",
    "\n",
    "**Books:**\n",
    "1. *Pro Git* by Scott Chacon - Comprehensive Git guide (free online)\n",
    "2. *Git for Teams* by Emma Jane Hogbin Westby - Collaboration workflows\n",
    "3. *Continuous Delivery* by Jez Humble - CI/CD best practices\n",
    "\n",
    "**Online:**\n",
    "- [Git Documentation](https://git-scm.com/doc) - Official docs\n",
    "- [DVC Documentation](https://dvc.org/doc) - Data version control\n",
    "- [GitHub Actions](https://docs.github.com/en/actions) - CI/CD workflows\n",
    "- [MLflow](https://mlflow.org/docs/latest/index.html) - Experiment tracking\n",
    "- [Learn Git Branching](https://learngitbranching.js.org/) - Interactive tutorial\n",
    "\n",
    "**Practice:**\n",
    "- Setup Git repo for personal project\n",
    "- Create PR workflow with code review\n",
    "- Implement CI/CD pipeline for ML project\n",
    "- Track experiments with DVC + MLflow\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations!** You now master Git, CI/CD, and data version control for production ML systems. You can collaborate with 100+ engineers, track 1000+ experiments, and deploy models 10√ó/day with confidence.\n",
    "\n",
    "**Measurable skills gained:**\n",
    "- Version control for code, data, models\n",
    "- CI/CD pipelines reducing testing from 8h ‚Üí 30min\n",
    "- 100% reproducible ML experiments\n",
    "- Collaborate across multiple sites with zero conflicts\n",
    "- Save $5-12M through automation and quality improvements\n",
    "\n",
    "**Ready to apply ML algorithms?** Proceed to **Notebook 010: Linear Regression** to start building ML models with proper version control! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import FancyBboxPatch, FancyArrowPatch\n",
    "import numpy as np\n",
    "\n",
    "# Simulate Git branch history\n",
    "class GitCommit:\n",
    "    def __init__(self, hash_id, message, branch, parent=None):\n",
    "        self.hash_id = hash_id\n",
    "        self.message = message\n",
    "        self.branch = branch\n",
    "        self.parent = parent\n",
    "\n",
    "# Create commit history\n",
    "commits = [\n",
    "    GitCommit(\"a1b2c3d\", \"Initial commit\", \"main\"),\n",
    "    GitCommit(\"e4f5g6h\", \"Add data pipeline\", \"main\", \"a1b2c3d\"),\n",
    "    GitCommit(\"i7j8k9l\", \"Feature: ML model\", \"feature/ml-model\", \"e4f5g6h\"),\n",
    "    GitCommit(\"m1n2o3p\", \"Refactor preprocessing\", \"feature/ml-model\", \"i7j8k9l\"),\n",
    "    GitCommit(\"q4r5s6t\", \"Fix: Memory leak\", \"main\", \"e4f5g6h\"),\n",
    "    GitCommit(\"u7v8w9x\", \"Add tests\", \"feature/ml-model\", \"m1n2o3p\"),\n",
    "    GitCommit(\"y1z2a3b\", \"Merge feature/ml-model\", \"main\", \"u7v8w9x\"),\n",
    "]\n",
    "\n",
    "# Create comprehensive Git workflow visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 14))\n",
    "\n",
    "# Plot 1: Branch visualization (commit graph)\n",
    "ax1.set_xlim(0, 10)\n",
    "ax1.set_ylim(-1, 3)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Git Branch History Visualization', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Main branch commits\n",
    "main_commits = [(1, 1), (2, 1), (5, 1), (7, 1)]\n",
    "feature_commits = [(3, 2), (4, 2), (6, 2)]\n",
    "\n",
    "# Draw commits\n",
    "for i, (x, y) in enumerate(main_commits):\n",
    "    circle = plt.Circle((x, y), 0.15, color='#3498db', ec='black', linewidth=2, zorder=3)\n",
    "    ax1.add_patch(circle)\n",
    "    if i < len(commits):\n",
    "        ax1.text(x, y-0.5, commits[i].hash_id[:7], ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "for i, (x, y) in enumerate(feature_commits):\n",
    "    circle = plt.Circle((x, y), 0.15, color='#2ecc71', ec='black', linewidth=2, zorder=3)\n",
    "    ax1.add_patch(circle)\n",
    "\n",
    "# Draw branch lines\n",
    "ax1.plot([c[0] for c in main_commits[:3]], [c[1] for c in main_commits[:3]], \n",
    "         'o-', color='#3498db', linewidth=3, markersize=0, label='main branch')\n",
    "ax1.plot([2, 3, 4, 6], [1, 2, 2, 2], 'o-', color='#2ecc71', linewidth=3, \n",
    "         markersize=0, label='feature/ml-model')\n",
    "ax1.plot([6, 7], [2, 1], 'o-', color='#9b59b6', linewidth=3, linestyle='--', \n",
    "         markersize=0, label='merge')\n",
    "ax1.plot([5, 7], [1, 1], 'o-', color='#3498db', linewidth=3, markersize=0)\n",
    "\n",
    "# Add labels\n",
    "ax1.text(1, 0.3, 'Initial\\ncommit', ha='center', fontsize=8)\n",
    "ax1.text(2, 0.3, 'Add\\npipeline', ha='center', fontsize=8)\n",
    "ax1.text(3, 2.6, 'Feature:\\nML model', ha='center', fontsize=8)\n",
    "ax1.text(5, 0.3, 'Fix:\\nMemory', ha='center', fontsize=8)\n",
    "ax1.text(7, 0.3, 'Merge', ha='center', fontsize=8)\n",
    "\n",
    "ax1.legend(loc='upper right', fontsize=11)\n",
    "ax1.text(0.5, 1, 'main', fontsize=12, fontweight='bold', color='#3498db')\n",
    "ax1.text(2.5, 2.5, 'feature', fontsize=12, fontweight='bold', color='#2ecc71')\n",
    "\n",
    "# Plot 2: Merge vs Rebase comparison\n",
    "strategies = ['Merge\\n(Fast-Forward)', 'Merge\\n(3-Way)', 'Rebase', 'Squash & Merge']\n",
    "commits_kept = [3, 5, 3, 1]\n",
    "history_clarity = [8, 6, 9, 10]\n",
    "conflict_difficulty = [3, 7, 8, 5]\n",
    "\n",
    "x_pos = np.arange(len(strategies))\n",
    "width = 0.25\n",
    "\n",
    "ax2.bar(x_pos - width, commits_kept, width, label='Commits Kept', color='#3498db', alpha=0.8)\n",
    "ax2.bar(x_pos, history_clarity, width, label='History Clarity (1-10)', color='#2ecc71', alpha=0.8)\n",
    "ax2.bar(x_pos + width, conflict_difficulty, width, label='Conflict Difficulty (1-10)', \n",
    "        color='#e74c3c', alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Merge Strategy', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Merge Strategies Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(strategies, fontsize=10)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Annotate recommendations\n",
    "ax2.text(0, 8.5, '‚úÖ Simple\\nfeatures', ha='center', fontsize=8, color='green', fontweight='bold')\n",
    "ax2.text(2, 10, '‚úÖ Clean\\nhistory', ha='center', fontsize=8, color='green', fontweight='bold')\n",
    "ax2.text(3, 10.5, '‚úÖ PR\\nmerges', ha='center', fontsize=8, color='green', fontweight='bold')\n",
    "\n",
    "# Plot 3: Git workflow adoption\n",
    "workflows = ['Centralized', 'Feature Branch', 'Gitflow', 'Forking', 'Trunk-Based']\n",
    "team_sizes = {\n",
    "    '1-5 developers': [9, 8, 3, 2, 7],\n",
    "    '6-20 developers': [3, 9, 8, 5, 6],\n",
    "    '20+ developers': [1, 5, 7, 9, 8]\n",
    "}\n",
    "\n",
    "x = np.arange(len(workflows))\n",
    "width = 0.25\n",
    "\n",
    "for i, (team_size, scores) in enumerate(team_sizes.items()):\n",
    "    offset = (i - 1) * width\n",
    "    ax3.bar(x + offset, scores, width, label=team_size, alpha=0.8)\n",
    "\n",
    "ax3.set_xlabel('Git Workflow', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Suitability Score (1-10)', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Git Workflow Suitability by Team Size', fontsize=14, fontweight='bold')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(workflows, rotation=15, ha='right', fontsize=10)\n",
    "ax3.legend(fontsize=10, title='Team Size')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Conflict resolution timeline\n",
    "hours = np.arange(0, 24, 2)\n",
    "conflicts_detected = np.array([2, 1, 0, 0, 1, 3, 5, 8, 6, 4, 2, 1])\n",
    "conflicts_resolved = np.array([0, 1, 0, 0, 0, 2, 3, 5, 7, 5, 3, 2])\n",
    "\n",
    "ax4.plot(hours, conflicts_detected, 'o-', linewidth=2.5, markersize=8, \n",
    "         label='Conflicts Detected', color='#e74c3c')\n",
    "ax4.plot(hours, conflicts_resolved, 's-', linewidth=2.5, markersize=8, \n",
    "         label='Conflicts Resolved', color='#2ecc71')\n",
    "ax4.fill_between(hours, 0, conflicts_detected, alpha=0.2, color='#e74c3c')\n",
    "ax4.fill_between(hours, 0, conflicts_resolved, alpha=0.2, color='#2ecc71')\n",
    "\n",
    "ax4.set_xlabel('Hour of Day', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Number of Merge Conflicts', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Merge Conflict Pattern (Typical Development Day)', fontsize=14, fontweight='bold')\n",
    "ax4.legend(fontsize=11)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_xticks(hours)\n",
    "ax4.set_xticklabels([f'{h:02d}:00' for h in hours], rotation=45, ha='right', fontsize=9)\n",
    "\n",
    "# Annotate peak conflict time\n",
    "peak_hour_idx = np.argmax(conflicts_detected)\n",
    "peak_hour = hours[peak_hour_idx]\n",
    "ax4.annotate(f'Peak conflicts:\\n{conflicts_detected[peak_hour_idx]} at {peak_hour:02d}:00',\n",
    "             xy=(peak_hour, conflicts_detected[peak_hour_idx]),\n",
    "             xytext=(peak_hour + 2, conflicts_detected[peak_hour_idx] + 2),\n",
    "             fontsize=10, arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('git_workflows_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print workflow recommendations\n",
    "print(\"üìä Git Workflow Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n‚úÖ Merge Strategy Decision Tree:\")\n",
    "print(\"   Small feature (1-2 commits) ‚Üí Fast-forward merge\")\n",
    "print(\"   Feature branch (3-10 commits) ‚Üí Squash & merge (clean main history)\")\n",
    "print(\"   Long-lived feature (>10 commits) ‚Üí 3-way merge (preserve feature history)\")\n",
    "print(\"   Clean history critical ‚Üí Rebase before merge\")\n",
    "\n",
    "print(\"\\nüîÄ Workflow Recommendations by Team:\")\n",
    "print(\"   1-5 developers ‚Üí Feature Branch workflow (simple, effective)\")\n",
    "print(\"   6-20 developers ‚Üí Gitflow (structured releases)\")\n",
    "print(\"   20+ developers ‚Üí Forking workflow (security, code review)\")\n",
    "print(\"   High velocity ‚Üí Trunk-Based Development (CI/CD optimized)\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Conflict Prevention Strategies:\")\n",
    "print(f\"   Peak conflict time: {hours[peak_hour_idx]:02d}:00 (after lunch, before EOD)\")\n",
    "print(f\"   Average resolution time: {np.mean(conflicts_resolved):.1f} conflicts/2hr\")\n",
    "print(\"   Best practice: Pull main every 2-3 hours, merge small PRs daily\")\n",
    "\n",
    "print(\"\\nüè≠ Post-Silicon Validation Git Workflow:\")\n",
    "print(\"   main branch ‚Üí Production test scripts (always stable)\")\n",
    "print(\"   develop branch ‚Üí Integration testing\")\n",
    "print(\"   feature/* ‚Üí New test algorithms, analysis tools\")\n",
    "print(\"   hotfix/* ‚Üí Urgent test flow fixes\")\n",
    "print(\"   Release tags: v1.0-wafer-test, v1.1-final-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitConflictResolver:\n",
    "    \"\"\"Simulate Git merge conflicts and resolution strategies\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_version = None\n",
    "        self.head_version = None\n",
    "        self.incoming_version = None\n",
    "        self.resolution_strategies = [\"accept_ours\", \"accept_theirs\", \"manual_merge\"]\n",
    "    \n",
    "    def detect_conflict(self, base: str, head: str, incoming: str) -> bool:\n",
    "        \"\"\"Check if three-way merge results in conflict\"\"\"\n",
    "        self.base_version = base\n",
    "        self.head_version = head\n",
    "        self.incoming_version = incoming\n",
    "        \n",
    "        # Conflict if both changed differently from base\n",
    "        head_changed = (head != base)\n",
    "        incoming_changed = (incoming != base)\n",
    "        both_different = (head != incoming)\n",
    "        \n",
    "        return head_changed and incoming_changed and both_different\n",
    "    \n",
    "    def resolve_conflict(self, strategy: str) -> str:\n",
    "        \"\"\"Resolve conflict using specified strategy\"\"\"\n",
    "        if strategy == \"accept_ours\":\n",
    "            return self.head_version\n",
    "        elif strategy == \"accept_theirs\":\n",
    "            return self.incoming_version\n",
    "        elif strategy == \"manual_merge\":\n",
    "            # Simulate intelligent merge (take best of both)\n",
    "            return f\"{self.head_version} + {self.incoming_version}\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "# Simulate real-world merge conflicts\n",
    "resolver = GitConflictResolver()\n",
    "\n",
    "# Scenario 1: Test parameter conflict\n",
    "print(\"üîß Git Conflict Resolution Simulation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Scenario 1: Test Parameter Configuration Conflict\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "base_config = \"voltage_limit = 1.2V, current_limit = 500mA\"\n",
    "head_config = \"voltage_limit = 1.3V, current_limit = 500mA\"  # Engineer A raised voltage\n",
    "incoming_config = \"voltage_limit = 1.2V, current_limit = 600mA\"  # Engineer B raised current\n",
    "\n",
    "conflict_exists = resolver.detect_conflict(base_config, head_config, incoming_config)\n",
    "\n",
    "print(f\"Base version:     {base_config}\")\n",
    "print(f\"HEAD (yours):     {head_config}\")\n",
    "print(f\"Incoming (merge): {incoming_config}\")\n",
    "print(f\"\\n‚ö†Ô∏è Conflict detected: {conflict_exists}\")\n",
    "\n",
    "if conflict_exists:\n",
    "    print(\"\\nResolution Options:\")\n",
    "    for i, strategy in enumerate(resolver.resolution_strategies, 1):\n",
    "        result = resolver.resolve_conflict(strategy)\n",
    "        print(f\"   {i}. {strategy}: {result}\")\n",
    "    \n",
    "    # Best resolution: manual merge taking both changes\n",
    "    best_resolution = \"voltage_limit = 1.3V, current_limit = 600mA\"\n",
    "    print(f\"\\n‚úÖ Best resolution (manual): {best_resolution}\")\n",
    "    print(\"   Rationale: Both changes are independent, can be merged\")\n",
    "\n",
    "# Scenario 2: Code logic conflict\n",
    "print(\"\\n\\nüìä Scenario 2: Algorithm Logic Conflict\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "base_code = \"if yield_pct < 90: flag_wafer()\"\n",
    "head_code = \"if yield_pct < 85: flag_wafer()\"  # More lenient threshold\n",
    "incoming_code = \"if yield_pct < 95: flag_wafer()\"  # Stricter threshold\n",
    "\n",
    "conflict_exists_2 = resolver.detect_conflict(base_code, head_code, incoming_code)\n",
    "\n",
    "print(f\"Base version:     {base_code}\")\n",
    "print(f\"HEAD (yours):     {head_code}\")\n",
    "print(f\"Incoming (merge): {incoming_code}\")\n",
    "print(f\"\\n‚ö†Ô∏è Conflict detected: {conflict_exists_2}\")\n",
    "\n",
    "if conflict_exists_2:\n",
    "    print(\"\\nResolution Strategy:\")\n",
    "    print(\"   ‚ùå Accept ours: Too lenient (85% threshold)\")\n",
    "    print(\"   ‚ùå Accept theirs: Too strict (95% threshold)\")\n",
    "    print(\"   ‚úÖ Manual merge: Use configurable threshold with default 90%\")\n",
    "    print(\"   Final code: if yield_pct < config.yield_threshold: flag_wafer()\")\n",
    "\n",
    "# Conflict statistics\n",
    "print(\"\\n\\nüìà Conflict Resolution Statistics\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "conflict_types = [\"Parameter values\", \"Function logic\", \"File structure\", \"Comments/docs\"]\n",
    "frequency_pct = [40, 30, 20, 10]\n",
    "avg_resolution_time = [5, 15, 30, 2]  # minutes\n",
    "\n",
    "for i, (ctype, freq, time) in enumerate(zip(conflict_types, frequency_pct, avg_resolution_time)):\n",
    "    print(f\"   {ctype:20s}: {freq:3d}% of conflicts, avg {time:2d} min to resolve\")\n",
    "\n",
    "print(\"\\nüí° Conflict Prevention Best Practices:\")\n",
    "print(\"   1. Pull from main frequently (every 2-3 hours)\")\n",
    "print(\"   2. Keep feature branches short-lived (<3 days)\")\n",
    "print(\"   3. Communicate with team about overlapping work\")\n",
    "print(\"   4. Use clear commit messages for context\")\n",
    "print(\"   5. Run tests after every conflict resolution\")\n",
    "\n",
    "print(\"\\nüè≠ Post-Silicon Validation Git Conflicts:\")\n",
    "print(\"   Common conflicts:\")\n",
    "print(\"   ‚Ä¢ Test parameter thresholds (voltage, current, timing)\")\n",
    "print(\"   ‚Ä¢ Wafer map visualization settings\")\n",
    "print(\"   ‚Ä¢ Data pipeline transformation logic\")\n",
    "print(\"   ‚Ä¢ SQL query optimization changes\")\n",
    "print(\"   \")\n",
    "print(\"   Resolution approach:\")\n",
    "print(\"   ‚Ä¢ Parameter conflicts ‚Üí Use config files, avoid hardcoding\")\n",
    "print(\"   ‚Ä¢ Logic conflicts ‚Üí A/B test both versions, choose best performer\")\n",
    "print(\"   ‚Ä¢ Always validate against golden reference data after merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "from typing import List, Tuple\n",
    "\n",
    "class GitHooksSimulator:\n",
    "    \"\"\"Simulate Git hooks for automated quality checks\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.hooks_enabled = {\n",
    "            \"pre-commit\": True,\n",
    "            \"pre-push\": True,\n",
    "            \"commit-msg\": True,\n",
    "            \"post-merge\": True\n",
    "        }\n",
    "        self.checks_passed = []\n",
    "        self.checks_failed = []\n",
    "    \n",
    "    def pre_commit_hook(self, files: List[str]) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"Run checks before allowing commit\"\"\"\n",
    "        checks = []\n",
    "        all_passed = True\n",
    "        \n",
    "        # Check 1: Code formatting (Black for Python)\n",
    "        python_files = [f for f in files if f.endswith('.py')]\n",
    "        if python_files:\n",
    "            checks.append((\"Code formatting\", len(python_files), True))\n",
    "        \n",
    "        # Check 2: Linting (flake8)\n",
    "        lint_issues = len(python_files) * 0.1  # Simulate 10% have issues\n",
    "        if lint_issues > 0:\n",
    "            checks.append((\"Linting\", int(lint_issues), False))\n",
    "            all_passed = False\n",
    "        else:\n",
    "            checks.append((\"Linting\", 0, True))\n",
    "        \n",
    "        # Check 3: Unit tests (quick tests only)\n",
    "        tests_passed = len(files) < 10  # Fail if too many files changed\n",
    "        checks.append((\"Quick unit tests\", len(files), tests_passed))\n",
    "        if not tests_passed:\n",
    "            all_passed = False\n",
    "        \n",
    "        # Check 4: File size check (no large binaries)\n",
    "        large_files = [f for f in files if 'test_data' in f]\n",
    "        checks.append((\"File size check\", len(large_files), len(large_files) == 0))\n",
    "        if large_files:\n",
    "            all_passed = False\n",
    "        \n",
    "        return all_passed, checks\n",
    "    \n",
    "    def commit_msg_hook(self, message: str) -> Tuple[bool, str]:\n",
    "        \"\"\"Validate commit message format (conventional commits)\"\"\"\n",
    "        # Pattern: type(scope): description\n",
    "        # Example: feat(api): add user authentication\n",
    "        pattern = r'^(feat|fix|docs|style|refactor|test|chore)(\\(.+\\))?: .{10,}'\n",
    "        \n",
    "        if re.match(pattern, message):\n",
    "            return True, \"‚úÖ Commit message follows conventional format\"\n",
    "        else:\n",
    "            return False, \"‚ùå Invalid format. Use: type(scope): description (min 10 chars)\"\n",
    "    \n",
    "    def pre_push_hook(self, branch: str) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"Run comprehensive checks before pushing\"\"\"\n",
    "        checks = []\n",
    "        all_passed = True\n",
    "        \n",
    "        # Check 1: Full test suite\n",
    "        checks.append((\"Full test suite\", 150, True))  # 150 tests\n",
    "        \n",
    "        # Check 2: Code coverage\n",
    "        coverage_pct = 85  # Require 80% coverage\n",
    "        checks.append((\"Code coverage\", coverage_pct, coverage_pct >= 80))\n",
    "        \n",
    "        # Check 3: Branch protection (no direct push to main)\n",
    "        if branch == \"main\":\n",
    "            checks.append((\"Branch protection\", 0, False))\n",
    "            all_passed = False\n",
    "        else:\n",
    "            checks.append((\"Branch protection\", 0, True))\n",
    "        \n",
    "        # Check 4: Merge conflicts check\n",
    "        checks.append((\"Merge conflicts\", 0, True))\n",
    "        \n",
    "        return all_passed, checks\n",
    "    \n",
    "    def post_merge_hook(self) -> List[str]:\n",
    "        \"\"\"Actions to run after successful merge\"\"\"\n",
    "        actions = [\n",
    "            \"Update dependencies (pip install -r requirements.txt)\",\n",
    "            \"Run database migrations\",\n",
    "            \"Clear cache\",\n",
    "            \"Notify team on Slack #deployments channel\",\n",
    "            \"Trigger CI/CD pipeline\"\n",
    "        ]\n",
    "        return actions\n",
    "\n",
    "# Simulate Git hooks workflow\n",
    "hooks = GitHooksSimulator()\n",
    "\n",
    "print(\"ü™ù Git Hooks Automation Simulation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Scenario 1: Pre-commit hook\n",
    "print(\"\\nüìù Scenario 1: Pre-commit Hook\")\n",
    "print(\"-\" * 80)\n",
    "files_to_commit = [\n",
    "    \"src/data_pipeline.py\",\n",
    "    \"src/analysis.py\",\n",
    "    \"tests/test_pipeline.py\",\n",
    "    \"data/test_data.csv\",  # Should trigger warning\n",
    "]\n",
    "\n",
    "passed, checks = hooks.pre_commit_hook(files_to_commit)\n",
    "print(f\"Files to commit: {len(files_to_commit)}\")\n",
    "for check_name, count, check_passed in checks:\n",
    "    status = \"‚úÖ PASS\" if check_passed else \"‚ùå FAIL\"\n",
    "    print(f\"   {status} {check_name}: {count} items\")\n",
    "\n",
    "if not passed:\n",
    "    print(\"\\n‚ö†Ô∏è Commit blocked! Fix issues before committing:\")\n",
    "    print(\"   - Remove large data files (use Git LFS or .gitignore)\")\n",
    "    print(\"   - Fix linting issues: flake8 src/\")\n",
    "    print(\"   - Reduce changed files in single commit\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All pre-commit checks passed! Proceeding with commit.\")\n",
    "\n",
    "# Scenario 2: Commit message validation\n",
    "print(\"\\n\\nüìù Scenario 2: Commit Message Validation\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "commit_messages = [\n",
    "    \"feat(test): add voltage ramp test algorithm\",\n",
    "    \"fix wafer map bug\",  # Invalid (no scope, too short)\n",
    "    \"docs(readme): update installation instructions\",\n",
    "    \"WIP checkpoint\",  # Invalid (not conventional format)\n",
    "]\n",
    "\n",
    "for msg in commit_messages:\n",
    "    passed, feedback = hooks.commit_msg_hook(msg)\n",
    "    status = \"‚úÖ\" if passed else \"‚ùå\"\n",
    "    print(f\"{status} '{msg}'\")\n",
    "    if not passed:\n",
    "        print(f\"   {feedback}\")\n",
    "\n",
    "# Scenario 3: Pre-push hook\n",
    "print(\"\\n\\nüì§ Scenario 3: Pre-push Hook\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "branches = [\"feature/new-algorithm\", \"main\", \"develop\"]\n",
    "for branch in branches:\n",
    "    print(f\"\\nAttempting to push to '{branch}':\")\n",
    "    passed, checks = hooks.pre_push_hook(branch)\n",
    "    for check_name, value, check_passed in checks:\n",
    "        status = \"‚úÖ PASS\" if check_passed else \"‚ùå FAIL\"\n",
    "        if value > 0:\n",
    "            print(f\"   {status} {check_name}: {value}\")\n",
    "        else:\n",
    "            print(f\"   {status} {check_name}\")\n",
    "    \n",
    "    if not passed:\n",
    "        print(f\"   ‚ö†Ô∏è Push to '{branch}' blocked!\")\n",
    "        if branch == \"main\":\n",
    "            print(\"   ‚Üí Use pull request instead of direct push to main\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Push to '{branch}' allowed\")\n",
    "\n",
    "# Scenario 4: Post-merge hook\n",
    "print(\"\\n\\nüîÑ Scenario 4: Post-Merge Hook\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Feature branch 'feature/new-algorithm' merged to 'develop'\")\n",
    "print(\"\\nAutomated post-merge actions:\")\n",
    "actions = hooks.post_merge_hook()\n",
    "for i, action in enumerate(actions, 1):\n",
    "    print(f\"   {i}. {action}\")\n",
    "\n",
    "# Hook configuration summary\n",
    "print(\"\\n\\n‚öôÔ∏è Git Hooks Configuration Summary\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Enabled hooks:\")\n",
    "for hook_name, enabled in hooks.hooks_enabled.items():\n",
    "    status = \"‚úÖ Enabled\" if enabled else \"‚ùå Disabled\"\n",
    "    print(f\"   {status:12s} {hook_name}\")\n",
    "\n",
    "print(\"\\nüè≠ Post-Silicon Validation Git Hooks:\")\n",
    "print(\"   Pre-commit:\")\n",
    "print(\"   ‚Ä¢ Validate STDF file paths in test scripts\")\n",
    "print(\"   ‚Ä¢ Check test parameter ranges (voltage, current, frequency)\")\n",
    "print(\"   ‚Ä¢ Run quick syntax check on test definitions\")\n",
    "print(\"   \")\n",
    "print(\"   Pre-push:\")\n",
    "print(\"   ‚Ä¢ Run regression test suite (5-10 min)\")\n",
    "print(\"   ‚Ä¢ Validate against golden reference STDF files\")\n",
    "print(\"   ‚Ä¢ Check for test coverage on new code paths\")\n",
    "print(\"   \")\n",
    "print(\"   Post-merge:\")\n",
    "print(\"   ‚Ä¢ Update test equipment configurations\")\n",
    "print(\"   ‚Ä¢ Regenerate wafer map templates\")\n",
    "print(\"   ‚Ä¢ Notify fab operations team of test script changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Key Takeaways\n",
    "\n",
    "### Git Workflow Decision Matrix\n",
    "\n",
    "| Team Size | Project Type | Recommended Workflow | Branch Strategy |\n",
    "|-----------|--------------|---------------------|-----------------|\n",
    "| 1-3 | Personal/prototype | **Feature Branch** | main + feature/* |\n",
    "| 4-10 | Startup/product | **Gitflow** | main + develop + feature/* + release/* |\n",
    "| 10-50 | Enterprise | **Gitflow** or **Forking** | + hotfix/* branches |\n",
    "| 50+ | Open source | **Forking** | Fork-based contributions |\n",
    "| Any | High velocity | **Trunk-Based** | main only + feature flags |\n",
    "\n",
    "### Commit Best Practices ‚úÖ\n",
    "\n",
    "**Conventional Commits Format:**\n",
    "```\n",
    "<type>(<scope>): <description>\n",
    "\n",
    "[optional body]\n",
    "\n",
    "[optional footer]\n",
    "```\n",
    "\n",
    "**Types:**\n",
    "- `feat`: New feature\n",
    "- `fix`: Bug fix\n",
    "- `docs`: Documentation only\n",
    "- `style`: Formatting, no logic change\n",
    "- `refactor`: Code restructure, no behavior change\n",
    "- `test`: Add/modify tests\n",
    "- `chore`: Maintenance (dependencies, build)\n",
    "\n",
    "**Examples:**\n",
    "```\n",
    "feat(parser): add support for STDF v4 format\n",
    "fix(wafer-map): correct die coordinate calculation\n",
    "docs(readme): update installation instructions for Python 3.11\n",
    "test(yield): add edge case tests for 0% and 100% yield\n",
    "```\n",
    "\n",
    "### Merge Strategy Selection\n",
    "\n",
    "**When to use each strategy:**\n",
    "\n",
    "| Strategy | Use When | Avoid When |\n",
    "|----------|----------|------------|\n",
    "| **Fast-Forward** | Clean history, no conflicts | Want to preserve feature branch context |\n",
    "| **3-Way Merge** | Preserve full history | History becomes too complex |\n",
    "| **Rebase** | Clean linear history critical | Working on shared branch (force push risky) |\n",
    "| **Squash** | Many small commits, want clean main | Need detailed commit history |\n",
    "\n",
    "### Branch Protection Rules üîí\n",
    "\n",
    "**For `main` branch:**\n",
    "- ‚úÖ Require pull request reviews (min 2 approvals)\n",
    "- ‚úÖ Require status checks to pass (CI/CD pipeline)\n",
    "- ‚úÖ Require branches to be up to date before merging\n",
    "- ‚úÖ Restrict force pushes\n",
    "- ‚úÖ Restrict deletions\n",
    "\n",
    "**For `develop` branch:**\n",
    "- ‚úÖ Require pull request reviews (min 1 approval)\n",
    "- ‚úÖ Require status checks to pass\n",
    "- ‚ùå Allow force push (for rebasing)\n",
    "\n",
    "### Git Performance Tips ‚ö°\n",
    "\n",
    "**For Large Repositories:**\n",
    "```bash\n",
    "# Partial clone (faster, less disk space)\n",
    "git clone --filter=blob:none <repo-url>\n",
    "\n",
    "# Shallow clone (only recent history)\n",
    "git clone --depth=1 <repo-url>\n",
    "\n",
    "# Sparse checkout (only specific folders)\n",
    "git sparse-checkout set src/ tests/\n",
    "```\n",
    "\n",
    "**For Large Files:**\n",
    "- Use Git LFS (Large File Storage) for binaries, models, datasets\n",
    "- Add to `.gitattributes`: `*.stdf filter=lfs diff=lfs merge=lfs -text`\n",
    "- Configure LFS: `git lfs install`\n",
    "\n",
    "### Post-Silicon Validation Git Setup\n",
    "\n",
    "**Repository Structure:**\n",
    "```\n",
    "/semiconductor-test-automation\n",
    "‚îú‚îÄ‚îÄ .github/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ workflows/          # CI/CD pipelines\n",
    "‚îú‚îÄ‚îÄ test-scripts/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ wafer-test/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ final-test/\n",
    "‚îú‚îÄ‚îÄ analysis/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ yield-prediction/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ wafer-maps/\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ .gitignore          # Ignore large STDF files\n",
    "‚îî‚îÄ‚îÄ models/\n",
    "    ‚îî‚îÄ‚îÄ .gitlfs             # Track ML models with LFS\n",
    "```\n",
    "\n",
    "**Branching Strategy:**\n",
    "- `main`: Production test scripts (validated on real equipment)\n",
    "- `staging`: Pre-production testing\n",
    "- `feature/parametric-test-v2`: New test development\n",
    "- `hotfix/current-limit-fix`: Urgent production fixes\n",
    "- Tags: `v1.0-wafer-test`, `v1.1-final-test`\n",
    "\n",
    "**Pre-commit Checks:**\n",
    "- Validate test parameter ranges (voltage, current, frequency)\n",
    "- Check STDF file path references\n",
    "- Run syntax validation on test scripts\n",
    "- Ensure no hardcoded IP addresses or credentials\n",
    "\n",
    "### Common Pitfalls ‚ö†Ô∏è\n",
    "\n",
    "1. **‚ùå Committing Secrets**\n",
    "   - Problem: API keys, passwords in code\n",
    "   - Solution: Use environment variables, `.env` files in `.gitignore`\n",
    "\n",
    "2. **‚ùå Large Binary Files**\n",
    "   - Problem: Slows down clone, bloats repository\n",
    "   - Solution: Git LFS for models/data, build artifacts in `.gitignore`\n",
    "\n",
    "3. **‚ùå Merge vs Rebase Confusion**\n",
    "   - Problem: Messy history or lost commits\n",
    "   - Solution: Rebase feature branches, merge to main\n",
    "\n",
    "4. **‚ùå Detached HEAD State**\n",
    "   - Problem: Commits not on any branch\n",
    "   - Solution: Create branch before committing: `git checkout -b recovery`\n",
    "\n",
    "5. **‚ùå Force Push on Shared Branch**\n",
    "   - Problem: Overwrites others' work\n",
    "   - Solution: Never force push to `main`/`develop`, only on personal branches\n",
    "\n",
    "### Next Steps üöÄ\n",
    "\n",
    "**Master Git:**\n",
    "1. Practice: Clone open-source project, make contribution\n",
    "2. Setup: Configure Git hooks for your projects\n",
    "3. Learn: Advanced rebasing (`git rebase -i`), cherry-picking\n",
    "4. Tools: Try GitKraken, SourceTree for visualization\n",
    "\n",
    "**Continue Learning:**\n",
    "- **Next:** `048_Model_Deployment.ipynb` - Deploy code with Git-based CI/CD\n",
    "- **Advanced:** Container-based deployments with Git workflows\n",
    "- **Read:** \"Pro Git\" book (free online), Git documentation\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** üéâ You now understand Git version control from basics to advanced workflows. You can collaborate effectively on any software project, manage complex branching strategies, and automate quality checks with Git hooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Real-World Git Projects\n",
    "\n",
    "### Project 1: ML Model Version Control System ü§ñ\n",
    "**Objective:** Version control for ML models with experiments, hyperparameters, and datasets\n",
    "\n",
    "**Git Strategy:**\n",
    "- `main` branch: Production models only (deployed to test equipment)\n",
    "- `develop` branch: Validated models (passed accuracy threshold)\n",
    "- `experiment/*` branches: Short-lived (1-3 days), one per hypothesis\n",
    "- Tags: `model-v1.2-wafer-yield-predictor-acc-94.5pct`\n",
    "\n",
    "**Hooks:**\n",
    "- Pre-commit: Validate model file size <100MB, check hyperparameters JSON format\n",
    "- Pre-push: Run model evaluation on holdout dataset\n",
    "- Post-merge: Trigger MLflow logging, update model registry\n",
    "\n",
    "### Project 2: Data Pipeline with Multiple Contributors üîÑ\n",
    "**Objective:** Team of 5 engineers building ETL pipeline for semiconductor test data\n",
    "\n",
    "**Workflow: Gitflow**\n",
    "- `main`: Production pipeline (processes real fab data)\n",
    "- `develop`: Integration branch\n",
    "- `feature/stdf-parser`, `feature/wafer-map`, `feature/yield-analysis`\n",
    "- Release branches: `release/v2.0` (2-week sprint cycles)\n",
    "\n",
    "**Conflict Prevention:**\n",
    "- Module ownership: Engineer A owns parser, Engineer B owns visualization\n",
    "- Daily syncs: Pull from develop every morning\n",
    "- Small PRs: Max 300 lines changed per PR\n",
    "\n",
    "### Project 3: Open Source Test Automation Framework üåê\n",
    "**Objective:** Contribute to open-source semiconductor test framework with 50+ contributors\n",
    "\n",
    "**Workflow: Forking**\n",
    "- Fork main repository to personal GitHub\n",
    "- Clone fork locally, add upstream remote\n",
    "- Create feature branch, commit changes\n",
    "- Push to fork, create pull request to upstream\n",
    "- Maintainers review, request changes, merge\n",
    "\n",
    "**Best Practices:**\n",
    "- Rebase on upstream/main frequently (avoid merge conflicts)\n",
    "- Squash commits before PR (clean history)\n",
    "- Conventional commits: `feat(parser):`, `fix(map):`\n",
    "- Sign commits with GPG key (verified contributor)\n",
    "\n",
    "### Project 4: High-Velocity Continuous Deployment üöÄ\n",
    "**Objective:** Deploy test script updates 10+ times per day to production equipment\n",
    "\n",
    "**Workflow: Trunk-Based Development**\n",
    "- Single `main` branch\n",
    "- Short-lived feature branches (<4 hours)\n",
    "- Feature flags for incomplete features\n",
    "- Automated testing and deployment\n",
    "\n",
    "**Requirements:**\n",
    "- Comprehensive test suite (5-10 min)\n",
    "- Canary deployments (test on 1 equipment, then all)\n",
    "- Instant rollback capability\n",
    "- Real-time monitoring and alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™ù Git Hooks & Automation\n",
    "\n",
    "**Purpose:** Automate code quality checks before commits and pushes\n",
    "\n",
    "**Key Points:**\n",
    "- **Pre-commit hooks**: Run linters, formatters, tests before allowing commit\n",
    "- **Pre-push hooks**: Run full test suite, check branch protection\n",
    "- **Commit-msg hooks**: Enforce commit message format (conventional commits)\n",
    "- **Post-merge hooks**: Automated dependency updates, notifications\n",
    "\n",
    "**Post-Silicon Use Case:** Pre-commit hook validates STDF file paths exist, runs quick regression tests, checks test script syntax before committing to production branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Conflict Resolution Simulator\n",
    "\n",
    "**Purpose:** Interactive conflict resolution with automated detection and merge strategies\n",
    "\n",
    "**Key Points:**\n",
    "- **3-Way Merge**: Compares base commit, your changes, remote changes\n",
    "- **Conflict Markers**: `<<<<<<< HEAD`, `=======`, `>>>>>>> branch`\n",
    "- **Resolution Strategies**: Accept yours, accept theirs, manual merge\n",
    "- **Post-Resolution**: Always test code after conflict resolution\n",
    "\n",
    "**Post-Silicon Use Case:** Merge conflicts when multiple engineers modify same test script - automated conflict detection in parametric test definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÄ Part 4: Advanced Git Workflows\n",
    "\n",
    "### Branch Visualization & Merge Strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
