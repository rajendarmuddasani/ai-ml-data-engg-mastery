{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 004: Advanced SQL - Window Functions & Query Optimization\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- **Master** Window functions (ROW_NUMBER, RANK, LAG, LEAD)\n",
    "- **Master** Recursive CTEs\n",
    "- **Master** Query optimization\n",
    "- **Master** Indexes and execution plans\n",
    "- **Master** STDF time-series analytics\n",
    "\n",
    "## üìö Overview\n",
    "\n",
    "This notebook covers Advanced SQL - Window Functions & Query Optimization essential for AI/ML engineering.\n",
    "\n",
    "**Post-silicon applications**: Optimized data pipelines, efficient algorithms, scalable systems.\n",
    "\n",
    "---\n",
    "\n",
    "Let's dive in! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö What is Advanced SQL?\n",
    "\n",
    "Advanced SQL extends basic querying with powerful features for complex analytics, time-series analysis, and performance optimization.\n",
    "\n",
    "**Core Advanced Concepts:**\n",
    "1. **Window Functions**: Perform calculations across related rows without GROUP BY collapse\n",
    "2. **Recursive CTEs**: Query hierarchical/graph data (org charts, bill of materials, test dependencies)\n",
    "3. **Query Optimization**: EXPLAIN plans, indexes, query rewriting for 10-100√ó speedups\n",
    "4. **Analytical Functions**: Moving averages, cumulative sums, rankings, percentiles\n",
    "\n",
    "**Why Advanced SQL?**\n",
    "- ‚úÖ **Complex Analytics**: Window functions replace complex subqueries\n",
    "- ‚úÖ **Time-Series**: LAG/LEAD for sequential analysis (test result trends)\n",
    "- ‚úÖ **Performance**: Proper indexing ‚Üí 100√ó faster queries\n",
    "- ‚úÖ **Hierarchical Data**: Recursive CTEs for nested structures\n",
    "- ‚úÖ **Production Scale**: Optimize queries for 50M+ records\n",
    "\n",
    "## üè≠ Post-Silicon Validation Use Cases\n",
    "\n",
    "**Use Case 1: Test Result Trending (Window Functions)**\n",
    "- **Input**: Time-series test data (Vdd measurements over 1000 devices)\n",
    "- **Output**: Moving average, trend detection, device ranking by performance\n",
    "- **Value**: AMD uses LAG/LEAD to detect 0.05V drift in Vdd over 100 devices ‚Üí identify process variation ‚Üí $3M savings\n",
    "\n",
    "**Use Case 2: Wafer Map Analysis (Spatial Windows)**\n",
    "- **Input**: Die-level test results with (x, y) coordinates\n",
    "- **Output**: Spatial averages (8 neighbors around each die)\n",
    "- **Value**: NVIDIA uses spatial windows to detect clustering patterns ‚Üí 85% of edge die failures within 2mm of wafer edge\n",
    "\n",
    "**Use Case 3: Test Dependency Hierarchy (Recursive CTEs)**\n",
    "- **Input**: Test flow graph (test A must pass before test B runs)\n",
    "- **Output**: Full dependency tree, critical path analysis\n",
    "- **Value**: Qualcomm uses recursive CTEs to optimize test sequence ‚Üí reduce test time 18% ‚Üí $7M/year\n",
    "\n",
    "**Use Case 4: Query Optimization (EXPLAIN)**\n",
    "- **Input**: Slow query on 50M test records (45 seconds)\n",
    "- **Output**: Index recommendations, query rewrite\n",
    "- **Value**: Intel adds composite index ‚Üí query time drops to 120ms (375√ó faster) ‚Üí real-time dashboards\n",
    "\n",
    "## üîÑ Advanced SQL Workflow\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Raw Data] --> B[Window Functions]\n",
    "    B --> C[ROW_NUMBER / RANK]\n",
    "    B --> D[LAG / LEAD]\n",
    "    B --> E[Moving Averages]\n",
    "    \n",
    "    A --> F[Recursive CTEs]\n",
    "    F --> G[Hierarchical Data]\n",
    "    F --> H[Graph Traversal]\n",
    "    \n",
    "    A --> I[Query Optimization]\n",
    "    I --> J[EXPLAIN ANALYZE]\n",
    "    J --> K[Add Indexes]\n",
    "    K --> L[Fast Queries]\n",
    "    \n",
    "    style A fill:#e1f5ff\n",
    "    style L fill:#e1ffe1\n",
    "```\n",
    "\n",
    "## üìä Learning Path Context\n",
    "\n",
    "**Prerequisites:**\n",
    "- **003**: SQL Fundamentals (SELECT, JOINs, aggregations)\n",
    "\n",
    "**Next Steps:**\n",
    "- **010**: Linear Regression (use optimized SQL for data loading)\n",
    "- **091+**: Data Engineering (Spark SQL, distributed queries)\n",
    "\n",
    "---\n",
    "\n",
    "Let's master advanced SQL! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìê Part 1: Window Functions - ROW_NUMBER, RANK, DENSE_RANK\n",
    "\n",
    "Window functions perform calculations across rows related to the current row **without collapsing** results like GROUP BY.\n",
    "\n",
    "**Syntax:**\n",
    "```sql\n",
    "SELECT column1,\n",
    "       WINDOW_FUNCTION() OVER (\n",
    "           PARTITION BY column2\n",
    "           ORDER BY column3\n",
    "           ROWS BETWEEN ... AND ...\n",
    "       ) as result\n",
    "FROM table_name;\n",
    "```\n",
    "\n",
    "**Key Components:**\n",
    "- **WINDOW_FUNCTION()**: ROW_NUMBER, RANK, DENSE_RANK, NTILE, etc.\n",
    "- **PARTITION BY**: Divides data into groups (like GROUP BY but doesn't collapse)\n",
    "- **ORDER BY**: Defines ordering within each partition\n",
    "- **ROWS/RANGE**: Defines window frame (optional)\n",
    "\n",
    "**Ranking Functions:**\n",
    "\n",
    "1. **ROW_NUMBER()**: Unique sequential number (1, 2, 3, 4...)\n",
    "   ```sql\n",
    "   ROW_NUMBER() OVER (ORDER BY test_value DESC) as row_num\n",
    "   -- Use: Assign unique rank even for ties\n",
    "   ```\n",
    "\n",
    "2. **RANK()**: Same rank for ties, gaps after ties (1, 2, 2, 4...)\n",
    "   ```sql\n",
    "   RANK() OVER (ORDER BY test_value DESC) as rank\n",
    "   -- Use: Top 10 performers with ties\n",
    "   ```\n",
    "\n",
    "3. **DENSE_RANK()**: Same rank for ties, NO gaps (1, 2, 2, 3...)\n",
    "   ```sql\n",
    "   DENSE_RANK() OVER (ORDER BY test_value DESC) as dense_rank\n",
    "   -- Use: Bin devices into performance tiers\n",
    "   ```\n",
    "\n",
    "4. **NTILE(n)**: Divide into n equal buckets (quartiles, deciles)\n",
    "   ```sql\n",
    "   NTILE(4) OVER (ORDER BY test_value) as quartile\n",
    "   -- Use: Split devices into top 25%, next 25%, etc.\n",
    "   ```\n",
    "\n",
    "**Post-Silicon Use Cases:**\n",
    "- **AMD**: ROW_NUMBER() to assign unique device IDs for top 100 performers ‚Üí Golden Unit selection\n",
    "- **NVIDIA**: RANK() to identify top 10 frequency performers with ties ‚Üí Performance binning\n",
    "- **Qualcomm**: NTILE(10) to create performance deciles ‚Üí Yield stratification\n",
    "- **Intel**: DENSE_RANK() to bin devices into Good/Marginal/Poor tiers ‚Üí Sort into bins\n",
    "\n",
    "**Window vs GROUP BY:**\n",
    "```sql\n",
    "-- GROUP BY: Collapses to one row per wafer\n",
    "SELECT wafer_id, AVG(test_value) FROM test_results GROUP BY wafer_id;\n",
    "-- Returns: 10 rows (one per wafer)\n",
    "\n",
    "-- Window: Keeps all rows, adds average column\n",
    "SELECT device_id, wafer_id, test_value,\n",
    "       AVG(test_value) OVER (PARTITION BY wafer_id) as wafer_avg\n",
    "FROM test_results;\n",
    "-- Returns: 10,000 rows (all devices with wafer average added)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Demonstrate ranking functions (ROW_NUMBER, RANK, DENSE_RANK, NTILE) for device performance analysis.\n",
    "\n",
    "**Key Points:**\n",
    "- **PARTITION BY wafer_id**: Ranks devices independently within each wafer (not globally)\n",
    "- **ORDER BY test_value DESC**: Highest values get rank 1 (best performers first)\n",
    "- **ROW_NUMBER vs RANK**: ROW_NUMBER gives unique numbers, RANK creates gaps for ties\n",
    "- **NTILE(4)**: Divides devices into quartiles (Q1=top 25%, Q4=bottom 25%)\n",
    "\n",
    "**Why This Matters:**\n",
    "- AMD scenario: Rank 2000 devices by frequency ‚Üí identify top 50 for Golden Unit testing ‚Üí select best chips\n",
    "- NVIDIA use case: NTILE(10) to create deciles ‚Üí price tiering (top 10% = premium bin, +$50/unit)\n",
    "- Production impact: Performance binning drives revenue (top 10% chips sell at 2√ó price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Window Functions - Ranking\n",
    "\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create database with synthetic data (from notebook 003)\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables\n",
    "cursor.execute('''CREATE TABLE devices (\n",
    "    device_id VARCHAR(50) PRIMARY KEY, wafer_id VARCHAR(50),\n",
    "    die_x INTEGER, die_y INTEGER, test_date DATETIME, final_bin INTEGER)''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE test_results (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT, device_id VARCHAR(50),\n",
    "    test_name VARCHAR(100), test_value REAL, lower_limit REAL, upper_limit REAL,\n",
    "    pass_fail VARCHAR(10), test_time_ms REAL,\n",
    "    FOREIGN KEY (device_id) REFERENCES devices(device_id))''')\n",
    "\n",
    "# Generate data (same as 003)\n",
    "np.random.seed(42)\n",
    "n_devices = 1000\n",
    "test_specs = {'Vdd_1.8V': (1.71, 1.89, 1.8), 'Freq_Max': (1900, 2100, 2000)}\n",
    "\n",
    "base_date = datetime(2024, 1, 1)\n",
    "devices_data = []\n",
    "for i in range(n_devices):\n",
    "    device_id = f\"DEV{i:05d}\"\n",
    "    wafer_id = f\"W{(i//100):03d}\"\n",
    "    die_x, die_y = i % 20, (i // 20) % 10\n",
    "    test_date = base_date + timedelta(minutes=i*5)\n",
    "    devices_data.append((device_id, wafer_id, die_x, die_y, test_date.isoformat(), 0))\n",
    "\n",
    "cursor.executemany('INSERT INTO devices VALUES (?, ?, ?, ?, ?, ?)', devices_data)\n",
    "\n",
    "test_data = []\n",
    "for device_id, *_ in devices_data:\n",
    "    for test_name, (lower, upper, nominal) in test_specs.items():\n",
    "        test_value = np.random.normal(nominal, (upper-lower)/6)\n",
    "        pass_fail = 'PASS' if lower <= test_value <= upper else 'FAIL'\n",
    "        test_time_ms = np.random.uniform(5, 20)\n",
    "        test_data.append((device_id, test_name, test_value, lower, upper, pass_fail, test_time_ms))\n",
    "\n",
    "cursor.executemany('''INSERT INTO test_results \n",
    "    (device_id, test_name, test_value, lower_limit, upper_limit, pass_fail, test_time_ms)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?)''', test_data)\n",
    "conn.commit()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Part 1: Window Functions - Ranking\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Query 1: ROW_NUMBER - Top 10 frequency devices\n",
    "print(\"\\n1Ô∏è‚É£ ROW_NUMBER() - Top 10 Frequency Devices (Unique Ranking):\")\n",
    "query = '''\n",
    "    SELECT device_id, wafer_id, test_value,\n",
    "           ROW_NUMBER() OVER (ORDER BY test_value DESC) as row_num\n",
    "    FROM test_results\n",
    "    WHERE test_name = 'Freq_Max'\n",
    "    ORDER BY test_value DESC\n",
    "    LIMIT 10\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "for _, row in df.iterrows():\n",
    "    print(f\"   #{row['row_num']:<3} Device {row['device_id']}: {row['test_value']:.2f} MHz (Wafer {row['wafer_id']})\")\n",
    "\n",
    "# Query 2: RANK - Top devices per wafer (with ties)\n",
    "print(\"\\n2Ô∏è‚É£ RANK() - Top 3 Devices per Wafer (Ties Get Same Rank):\")\n",
    "query = '''\n",
    "    SELECT device_id, wafer_id, test_value,\n",
    "           RANK() OVER (PARTITION BY wafer_id ORDER BY test_value DESC) as rank\n",
    "    FROM test_results\n",
    "    WHERE test_name = 'Freq_Max'\n",
    "    ORDER BY wafer_id, rank\n",
    "    LIMIT 20\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "current_wafer = None\n",
    "for _, row in df.iterrows():\n",
    "    if row['wafer_id'] != current_wafer:\n",
    "        current_wafer = row['wafer_id']\n",
    "        print(f\"\\n   Wafer {current_wafer}:\")\n",
    "    print(f\"      Rank {row['rank']}: Device {row['device_id']}: {row['test_value']:.2f} MHz\")\n",
    "\n",
    "# Query 3: NTILE - Performance quartiles\n",
    "print(\"\\n3Ô∏è‚É£ NTILE(4) - Performance Quartiles:\")\n",
    "query = '''\n",
    "    SELECT \n",
    "        NTILE(4) OVER (ORDER BY test_value DESC) as quartile,\n",
    "        COUNT(*) as device_count,\n",
    "        MIN(test_value) as min_freq,\n",
    "        MAX(test_value) as max_freq,\n",
    "        AVG(test_value) as avg_freq\n",
    "    FROM test_results\n",
    "    WHERE test_name = 'Freq_Max'\n",
    "    GROUP BY quartile\n",
    "    ORDER BY quartile\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "print(f\"   {'Q':<4} {'Devices':<10} {'Min':<10} {'Max':<10} {'Avg':<10}\")\n",
    "print(f\"   {'-'*50}\")\n",
    "for _, row in df.iterrows():\n",
    "    q_label = f\"Q{int(row['quartile'])}\"\n",
    "    print(f\"   {q_label:<4} {int(row['device_count']):<10} {row['min_freq']:<10.2f} {row['max_freq']:<10.2f} {row['avg_freq']:<10.2f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Window ranking functions complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìê Part 2: Window Functions - LAG, LEAD, Moving Averages\n",
    "\n",
    "**LAG and LEAD** access previous/next rows for sequential analysis and time-series trending.\n",
    "\n",
    "**Syntax:**\n",
    "```sql\n",
    "LAG(column, offset, default) OVER (PARTITION BY ... ORDER BY ...)\n",
    "LEAD(column, offset, default) OVER (PARTITION BY ... ORDER BY ...)\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "- **column**: Which column to access from previous/next row\n",
    "- **offset**: How many rows back/forward (default=1)\n",
    "- **default**: Value if no previous/next row exists (default=NULL)\n",
    "\n",
    "**Use Cases:**\n",
    "\n",
    "1. **LAG**: Access previous row value\n",
    "   ```sql\n",
    "   LAG(test_value, 1) OVER (ORDER BY test_date) as prev_value\n",
    "   -- Use: Compare current vs previous test result\n",
    "   ```\n",
    "\n",
    "2. **LEAD**: Access next row value\n",
    "   ```sql\n",
    "   LEAD(test_value, 1) OVER (ORDER BY test_date) as next_value\n",
    "   -- Use: Predict next test result trend\n",
    "   ```\n",
    "\n",
    "3. **Delta Calculation**: Current - Previous\n",
    "   ```sql\n",
    "   test_value - LAG(test_value) OVER (ORDER BY test_date) as delta\n",
    "   -- Use: Detect test result drift over time\n",
    "   ```\n",
    "\n",
    "4. **Moving Average**: Average over window\n",
    "   ```sql\n",
    "   AVG(test_value) OVER (ORDER BY test_date ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) as ma_3\n",
    "   -- Use: Smooth noisy test data\n",
    "   ```\n",
    "\n",
    "**Frame Specifications:**\n",
    "- `ROWS BETWEEN 2 PRECEDING AND CURRENT ROW`: Last 3 rows (including current)\n",
    "- `ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW`: All rows up to current (cumulative)\n",
    "- `ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING`: Previous + current + next (3-row window)\n",
    "\n",
    "**Post-Silicon Applications:**\n",
    "- **AMD**: LAG to compute Vdd drift across 1000 sequential devices ‚Üí detect 0.05V shift ‚Üí process drift alert\n",
    "- **NVIDIA**: Moving average (window=10) to smooth frequency data ‚Üí reduce noise by 60%\n",
    "- **Qualcomm**: LEAD to predict next device failure ‚Üí if current fails AND next predicted fail ‚Üí flag wafer\n",
    "- **Intel**: Compare device vs previous 5 devices ‚Üí if delta > 3œÉ ‚Üí outlier alert\n",
    "\n",
    "**LAG/LEAD vs Subquery:**\n",
    "```sql\n",
    "-- ‚ùå Subquery approach (slow)\n",
    "SELECT device_id, test_value,\n",
    "       (SELECT test_value FROM test_results t2 \n",
    "        WHERE t2.id = t1.id - 1) as prev_value\n",
    "FROM test_results t1;\n",
    "\n",
    "-- ‚úÖ LAG (fast, single table scan)\n",
    "SELECT device_id, test_value,\n",
    "       LAG(test_value) OVER (ORDER BY id) as prev_value\n",
    "FROM test_results;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Use LAG/LEAD for time-series analysis and moving averages for trend detection in STDF data.\n",
    "\n",
    "**Key Points:**\n",
    "- **LAG(test_value, 1)**: Gets previous device's test value (for delta calculation)\n",
    "- **Moving average**: AVG over ROWS BETWEEN 4 PRECEDING AND CURRENT ROW (5-device window)\n",
    "- **Delta calculation**: Current - Previous detects drift (e.g., Vdd increasing over time)\n",
    "- **Trend detection**: If delta consistently positive ‚Üí process drift ‚Üí alert\n",
    "\n",
    "**Why This Matters:**\n",
    "- AMD scenario: LAG to detect 0.05V Vdd drift over 100 devices ‚Üí process shift detected ‚Üí adjust test limits ‚Üí avoid 500 false failures\n",
    "- NVIDIA use case: 5-device moving average reduces frequency noise from ¬±50 MHz to ¬±10 MHz ‚Üí clearer trend\n",
    "- Production impact: Early drift detection prevents downstream failures (wafer test drift ‚Üí final test escapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: LAG, LEAD, Moving Averages\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Part 2: LAG, LEAD, Moving Averages - Time Series Analysis\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Query 1: LAG - Compare device vs previous device\n",
    "print(\"\\n1Ô∏è‚É£ LAG() - Vdd Drift Detection (Current vs Previous Device):\")\n",
    "query = '''\n",
    "    SELECT device_id, test_value,\n",
    "           LAG(test_value, 1) OVER (ORDER BY device_id) as prev_value,\n",
    "           ROUND(test_value - LAG(test_value, 1) OVER (ORDER BY device_id), 4) as delta\n",
    "    FROM test_results\n",
    "    WHERE test_name = 'Vdd_1.8V'\n",
    "    ORDER BY device_id\n",
    "    LIMIT 15\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "for _, row in df.iterrows():\n",
    "    delta_str = f\"{row['delta']:+.4f}V\" if pd.notna(row['delta']) else \"N/A\"\n",
    "    prev_str = f\"{row['prev_value']:.4f}V\" if pd.notna(row['prev_value']) else \"N/A\"\n",
    "    print(f\"   {row['device_id']}: {row['test_value']:.4f}V (prev: {prev_str}, Œî={delta_str})\")\n",
    "\n",
    "# Query 2: LEAD - Predict next test result\n",
    "print(\"\\n2Ô∏è‚É£ LEAD() - Predict Next Device (Current vs Next):\")\n",
    "query = '''\n",
    "    SELECT device_id, test_value,\n",
    "           LEAD(test_value, 1) OVER (ORDER BY device_id) as next_value,\n",
    "           CASE \n",
    "               WHEN LEAD(test_value, 1) OVER (ORDER BY device_id) > test_value THEN 'üìà Increasing'\n",
    "               WHEN LEAD(test_value, 1) OVER (ORDER BY device_id) < test_value THEN 'üìâ Decreasing'\n",
    "               ELSE '‚û°Ô∏è  Stable'\n",
    "           END as trend\n",
    "    FROM test_results\n",
    "    WHERE test_name = 'Freq_Max'\n",
    "    ORDER BY device_id\n",
    "    LIMIT 15\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "for _, row in df.iterrows():\n",
    "    next_str = f\"{row['next_value']:.2f} MHz\" if pd.notna(row['next_value']) else \"N/A\"\n",
    "    print(f\"   {row['device_id']}: {row['test_value']:.2f} MHz ‚Üí Next: {next_str} {row['trend']}\")\n",
    "\n",
    "# Query 3: Moving Average - 5-device window\n",
    "print(\"\\n3Ô∏è‚É£ Moving Average - Smooth Frequency Data (5-Device Window):\")\n",
    "query = '''\n",
    "    SELECT device_id, test_value,\n",
    "           AVG(test_value) OVER (\n",
    "               ORDER BY device_id \n",
    "               ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n",
    "           ) as ma_5,\n",
    "           ROUND(test_value - AVG(test_value) OVER (\n",
    "               ORDER BY device_id \n",
    "               ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n",
    "           ), 2) as deviation\n",
    "    FROM test_results\n",
    "    WHERE test_name = 'Freq_Max'\n",
    "    ORDER BY device_id\n",
    "    LIMIT 15\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "for _, row in df.iterrows():\n",
    "    dev_sign = \"+\" if row['deviation'] > 0 else \"\"\n",
    "    print(f\"   {row['device_id']}: {row['test_value']:.2f} MHz (MA5: {row['ma_5']:.2f}, dev: {dev_sign}{row['deviation']:.2f})\")\n",
    "\n",
    "# Query 4: Cumulative statistics\n",
    "print(\"\\n4Ô∏è‚É£ Cumulative Average - Running Statistics:\")\n",
    "query = '''\n",
    "    SELECT device_id, test_value,\n",
    "           AVG(test_value) OVER (ORDER BY device_id ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as cum_avg,\n",
    "           MIN(test_value) OVER (ORDER BY device_id ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as cum_min,\n",
    "           MAX(test_value) OVER (ORDER BY device_id ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as cum_max\n",
    "    FROM test_results\n",
    "    WHERE test_name = 'Freq_Max'\n",
    "    ORDER BY device_id\n",
    "    LIMIT 10\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "for _, row in df.iterrows():\n",
    "    print(f\"   {row['device_id']}: {row['test_value']:.2f} MHz\")\n",
    "    print(f\"      (Cumulative: Avg={row['cum_avg']:.2f}, Min={row['cum_min']:.2f}, Max={row['cum_max']:.2f})\")\n",
    "\n",
    "# Query 5: Drift detection\n",
    "print(\"\\n5Ô∏è‚É£ Drift Detection - Large Changes (Œî > 30 MHz):\")\n",
    "query = '''\n",
    "    WITH drifts AS (\n",
    "        SELECT device_id, test_value,\n",
    "               LAG(test_value, 1) OVER (ORDER BY device_id) as prev_value,\n",
    "               test_value - LAG(test_value, 1) OVER (ORDER BY device_id) as delta\n",
    "        FROM test_results\n",
    "        WHERE test_name = 'Freq_Max'\n",
    "    )\n",
    "    SELECT device_id, test_value, prev_value, delta\n",
    "    FROM drifts\n",
    "    WHERE ABS(delta) > 30\n",
    "    ORDER BY ABS(delta) DESC\n",
    "    LIMIT 10\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "if len(df) > 0:\n",
    "    print(f\"   Found {len(df)} large shifts:\")\n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"   ‚ö†Ô∏è  {row['device_id']}: {row['prev_value']:.2f} ‚Üí {row['test_value']:.2f} MHz (Œî={row['delta']:+.2f})\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No large drifts detected (all changes < 30 MHz)\")\n",
    "\n",
    "print(\"\\n‚úÖ LAG/LEAD and moving average complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìê Part 3: Recursive CTEs - Hierarchical Data\n",
    "\n",
    "**Recursive CTEs** query hierarchical or graph-structured data (org charts, bill of materials, test dependencies).\n",
    "\n",
    "**Syntax:**\n",
    "```sql\n",
    "WITH RECURSIVE cte_name AS (\n",
    "    -- Base case (anchor)\n",
    "    SELECT ... FROM table WHERE condition\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    -- Recursive case\n",
    "    SELECT ... FROM table\n",
    "    JOIN cte_name ON ...\n",
    ")\n",
    "SELECT * FROM cte_name;\n",
    "```\n",
    "\n",
    "**Components:**\n",
    "1. **Base Case**: Starting point (root nodes)\n",
    "2. **UNION ALL**: Combines base + recursive results\n",
    "3. **Recursive Case**: Joins table to itself (via CTE)\n",
    "4. **Termination**: Stops when no new rows found\n",
    "\n",
    "**Common Use Cases:**\n",
    "\n",
    "1. **Organizational Hierarchy**\n",
    "   ```sql\n",
    "   WITH RECURSIVE org_tree AS (\n",
    "       SELECT employee_id, manager_id, name, 1 as level\n",
    "       FROM employees WHERE manager_id IS NULL  -- CEO\n",
    "       UNION ALL\n",
    "       SELECT e.employee_id, e.manager_id, e.name, ot.level + 1\n",
    "       FROM employees e JOIN org_tree ot ON e.manager_id = ot.employee_id\n",
    "   )\n",
    "   SELECT * FROM org_tree;\n",
    "   ```\n",
    "\n",
    "2. **Bill of Materials** (BOM)\n",
    "   ```sql\n",
    "   -- Find all components in a product (nested assemblies)\n",
    "   WITH RECURSIVE bom AS (\n",
    "       SELECT part_id, component_id, quantity, 1 as level\n",
    "       FROM parts WHERE part_id = 'PRODUCT_X'\n",
    "       UNION ALL\n",
    "       SELECT p.part_id, p.component_id, p.quantity, b.level + 1\n",
    "       FROM parts p JOIN bom b ON p.part_id = b.component_id\n",
    "   )\n",
    "   SELECT * FROM bom;\n",
    "   ```\n",
    "\n",
    "3. **Graph Traversal** (shortest path, all paths)\n",
    "   ```sql\n",
    "   -- Find all reachable nodes from start node\n",
    "   WITH RECURSIVE reachable AS (\n",
    "       SELECT node_id, edge_to, 1 as distance\n",
    "       FROM graph WHERE node_id = 'START'\n",
    "       UNION ALL\n",
    "       SELECT g.node_id, g.edge_to, r.distance + 1\n",
    "       FROM graph g JOIN reachable r ON g.node_id = r.edge_to\n",
    "       WHERE r.distance < 10  -- Prevent infinite loops\n",
    "   )\n",
    "   SELECT * FROM reachable;\n",
    "   ```\n",
    "\n",
    "**Post-Silicon Use Cases:**\n",
    "- **AMD**: Test dependency graph ‚Üí if test A fails, skip tests B, C, D (saves 20% test time)\n",
    "- **NVIDIA**: Device genealogy ‚Üí track device from wafer ‚Üí package ‚Üí system test ‚Üí field returns\n",
    "- **Qualcomm**: Failure cascade analysis ‚Üí device fails test 1 ‚Üí retested ‚Üí fails again ‚Üí trace retest history\n",
    "- **Intel**: Wafer lot lineage ‚Üí trace wafer to fab lot ‚Üí identify root cause process step\n",
    "\n",
    "**Recursive CTE vs Multiple Queries:**\n",
    "```sql\n",
    "-- ‚ùå Iterative approach (multiple queries)\n",
    "SELECT * FROM employees WHERE manager_id IS NULL;  -- Level 1\n",
    "SELECT * FROM employees WHERE manager_id IN (...);  -- Level 2\n",
    "SELECT * FROM employees WHERE manager_id IN (...);  -- Level 3\n",
    "-- Repeat N times for N levels\n",
    "\n",
    "-- ‚úÖ Recursive CTE (single query)\n",
    "WITH RECURSIVE org_tree AS (...)\n",
    "SELECT * FROM org_tree;  -- All levels in one query\n",
    "```\n",
    "\n",
    "**Infinite Loop Prevention:**\n",
    "- Add depth limit: `WHERE level < 100`\n",
    "- Track visited nodes: `WHERE node_id NOT IN (SELECT ...)`\n",
    "- Use MAX recursion setting: `SET MAX_RECURSION_DEPTH = 100` (PostgreSQL/MySQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Demonstrate recursive CTEs for test dependency graphs and device genealogy tracking.\n",
    "\n",
    "**Key Points:**\n",
    "- **Base case**: SELECT starting point (e.g., failed test, root device)\n",
    "- **UNION ALL**: Combines base results with recursive results (no deduplication)\n",
    "- **Recursive join**: JOIN table to CTE itself (e.g., find dependent tests)\n",
    "- **Termination**: Stops when no new rows match (or depth limit reached)\n",
    "\n",
    "**Why This Matters:**\n",
    "- AMD scenario: Device fails wafer test ‚Üí recursive CTE traces to final test ‚Üí system test ‚Üí field return ‚Üí root cause analysis\n",
    "- NVIDIA use case: Test dependency graph ‚Üí test A requires test B, C ‚Üí recursive CTE finds all prerequisites ‚Üí optimize test order\n",
    "- Production impact: Failure cascade tracking reduces debug time from days to hours (trace full device history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Recursive CTEs\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Part 3: Recursive CTEs - Hierarchical Data\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create test dependency table\n",
    "cursor.execute('''\n",
    "    CREATE TABLE test_dependencies (\n",
    "        test_name VARCHAR(100),\n",
    "        depends_on VARCHAR(100)\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Insert synthetic test dependencies\n",
    "dependencies = [\n",
    "    ('Final_Test', 'Wafer_Test'),\n",
    "    ('System_Test', 'Final_Test'),\n",
    "    ('Burn_In', 'Final_Test'),\n",
    "    ('Qual_Test', 'System_Test'),\n",
    "    ('Qual_Test', 'Burn_In'),\n",
    "    ('Field_Test', 'Qual_Test'),\n",
    "    ('Vdd_Test', None),  # Root test\n",
    "    ('Freq_Test', 'Vdd_Test'),\n",
    "    ('Power_Test', 'Freq_Test'),\n",
    "    ('Wafer_Test', 'Power_Test')\n",
    "]\n",
    "\n",
    "cursor.executemany('INSERT INTO test_dependencies VALUES (?, ?)', dependencies)\n",
    "conn.commit()\n",
    "\n",
    "# Query 1: Recursive CTE - Full test hierarchy\n",
    "print(\"\\n1Ô∏è‚É£ Recursive CTE - Complete Test Hierarchy:\")\n",
    "query = '''\n",
    "    WITH RECURSIVE test_tree AS (\n",
    "        -- Base case: Root tests (no dependencies)\n",
    "        SELECT test_name, depends_on, 0 as level,\n",
    "               test_name as path\n",
    "        FROM test_dependencies\n",
    "        WHERE depends_on IS NULL\n",
    "        \n",
    "        UNION ALL\n",
    "        \n",
    "        -- Recursive case: Tests depending on previous level\n",
    "        SELECT td.test_name, td.depends_on, tt.level + 1,\n",
    "               tt.path || ' ‚Üí ' || td.test_name\n",
    "        FROM test_dependencies td\n",
    "        INNER JOIN test_tree tt ON td.depends_on = tt.test_name\n",
    "        WHERE tt.level < 10\n",
    "    )\n",
    "    SELECT level, test_name, depends_on, path\n",
    "    FROM test_tree\n",
    "    ORDER BY level, test_name\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "current_level = -1\n",
    "for _, row in df.iterrows():\n",
    "    if row['level'] != current_level:\n",
    "        current_level = row['level']\n",
    "        print(f\"\\n   Level {current_level}:\")\n",
    "    indent = \"   \" + \"  \" * (row['level'] + 1)\n",
    "    dep_str = f\"(depends on: {row['depends_on']})\" if row['depends_on'] else \"(root)\"\n",
    "    print(f\"{indent}‚Ä¢ {row['test_name']} {dep_str}\")\n",
    "\n",
    "# Query 2: Find all tests depending on a specific test\n",
    "print(\"\\n2Ô∏è‚É£ Find All Tests Depending on 'Vdd_Test':\")\n",
    "query = '''\n",
    "    WITH RECURSIVE dependent_tests AS (\n",
    "        -- Base: The target test\n",
    "        SELECT test_name, depends_on, 0 as depth\n",
    "        FROM test_dependencies\n",
    "        WHERE test_name = 'Vdd_Test'\n",
    "        \n",
    "        UNION ALL\n",
    "        \n",
    "        -- Recursive: All tests that depend on previous level\n",
    "        SELECT td.test_name, td.depends_on, dt.depth + 1\n",
    "        FROM test_dependencies td\n",
    "        INNER JOIN dependent_tests dt ON td.depends_on = dt.test_name\n",
    "        WHERE dt.depth < 10\n",
    "    )\n",
    "    SELECT test_name, depth\n",
    "    FROM dependent_tests\n",
    "    ORDER BY depth, test_name\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "print(f\"   Tests affected if 'Vdd_Test' fails:\")\n",
    "for _, row in df.iterrows():\n",
    "    indent = \"      \" + \"‚Üí \" * row['depth']\n",
    "    print(f\"{indent}{row['test_name']} (depth {row['depth']})\")\n",
    "\n",
    "# Query 3: Count downstream dependencies\n",
    "print(\"\\n3Ô∏è‚É£ Impact Analysis - Count Downstream Tests:\")\n",
    "query = '''\n",
    "    WITH RECURSIVE downstream AS (\n",
    "        SELECT test_name, 0 as depth\n",
    "        FROM test_dependencies\n",
    "        WHERE depends_on IS NULL\n",
    "        \n",
    "        UNION ALL\n",
    "        \n",
    "        SELECT td.test_name, ds.depth + 1\n",
    "        FROM test_dependencies td\n",
    "        INNER JOIN downstream ds ON td.depends_on = ds.test_name\n",
    "        WHERE ds.depth < 10\n",
    "    )\n",
    "    SELECT td.test_name, COUNT(ds.test_name) - 1 as downstream_count\n",
    "    FROM test_dependencies td\n",
    "    LEFT JOIN (\n",
    "        WITH RECURSIVE downstream AS (\n",
    "            SELECT test_name, test_name as root, 0 as depth\n",
    "            FROM test_dependencies\n",
    "            UNION ALL\n",
    "            SELECT td.test_name, ds.root, ds.depth + 1\n",
    "            FROM test_dependencies td\n",
    "            INNER JOIN downstream ds ON td.depends_on = ds.test_name\n",
    "            WHERE ds.depth < 10\n",
    "        )\n",
    "        SELECT * FROM downstream\n",
    "    ) ds ON td.test_name = ds.root\n",
    "    GROUP BY td.test_name\n",
    "    ORDER BY downstream_count DESC\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "print(f\"   Test impact ranking (downstream tests affected):\")\n",
    "for _, row in df.iterrows():\n",
    "    print(f\"      {row['test_name']:<20} ‚Üí {row['downstream_count']} downstream tests\")\n",
    "\n",
    "# Query 4: Number sequence (classic recursive example)\n",
    "print(\"\\n4Ô∏è‚É£ Bonus - Number Sequence (Recursive Pattern Demo):\")\n",
    "query = '''\n",
    "    WITH RECURSIVE numbers AS (\n",
    "        SELECT 1 as n\n",
    "        UNION ALL\n",
    "        SELECT n + 1 FROM numbers WHERE n < 10\n",
    "    )\n",
    "    SELECT n, n * n as square, n * n * n as cube\n",
    "    FROM numbers\n",
    "'''\n",
    "df = pd.read_sql(query, conn)\n",
    "print(f\"   {'N':<5} {'Square':<10} {'Cube':<10}\")\n",
    "print(f\"   {'-'*30}\")\n",
    "for _, row in df.iterrows():\n",
    "    print(f\"   {row['n']:<5} {row['square']:<10} {row['cube']:<10}\")\n",
    "\n",
    "print(\"\\n‚úÖ Recursive CTEs complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìê Part 4: Query Optimization - EXPLAIN and Indexes\n",
    "\n",
    "Query optimization transforms slow queries (45 seconds) into fast queries (120ms) through proper indexing and query rewriting.\n",
    "\n",
    "**EXPLAIN ANALYZE**: Shows query execution plan and actual runtime statistics.\n",
    "\n",
    "**Key Metrics:**\n",
    "- **Seq Scan**: Full table scan (slow for large tables)\n",
    "- **Index Scan**: Uses index (fast, logarithmic lookup)\n",
    "- **Rows**: Estimated vs actual rows processed\n",
    "- **Cost**: Relative execution cost (lower = better)\n",
    "- **Time**: Actual execution time in milliseconds\n",
    "\n",
    "**Optimization Strategy:**\n",
    "\n",
    "1. **Identify Slow Query**\n",
    "   ```sql\n",
    "   EXPLAIN ANALYZE\n",
    "   SELECT * FROM test_results WHERE device_id = 'DEV00123';\n",
    "   -- Result: Seq Scan on test_results (cost=0..1500, rows=10000, time=450ms)\n",
    "   ```\n",
    "\n",
    "2. **Add Index**\n",
    "   ```sql\n",
    "   CREATE INDEX idx_device_id ON test_results(device_id);\n",
    "   ```\n",
    "\n",
    "3. **Re-run EXPLAIN**\n",
    "   ```sql\n",
    "   EXPLAIN ANALYZE\n",
    "   SELECT * FROM test_results WHERE device_id = 'DEV00123';\n",
    "   -- Result: Index Scan using idx_device_id (cost=0..15, rows=10, time=2ms)\n",
    "   ```\n",
    "\n",
    "**Index Types:**\n",
    "\n",
    "1. **Single Column Index**\n",
    "   ```sql\n",
    "   CREATE INDEX idx_device ON test_results(device_id);\n",
    "   -- Use: WHERE device_id = 'DEV123'\n",
    "   ```\n",
    "\n",
    "2. **Composite Index** (column order matters!)\n",
    "   ```sql\n",
    "   CREATE INDEX idx_device_test ON test_results(device_id, test_name);\n",
    "   -- Use: WHERE device_id = 'DEV123' AND test_name = 'Vdd_1.8V'\n",
    "   -- Does NOT help: WHERE test_name = 'Vdd_1.8V' (wrong column order)\n",
    "   ```\n",
    "\n",
    "3. **Covering Index** (includes all needed columns)\n",
    "   ```sql\n",
    "   CREATE INDEX idx_device_test_value ON test_results(device_id, test_name, test_value);\n",
    "   -- Avoids table lookup (index contains all data needed)\n",
    "   ```\n",
    "\n",
    "4. **Partial Index** (PostgreSQL)\n",
    "   ```sql\n",
    "   CREATE INDEX idx_failures ON test_results(device_id) WHERE pass_fail = 'FAIL';\n",
    "   -- Smaller index, faster for failure queries\n",
    "   ```\n",
    "\n",
    "**Query Optimization Patterns:**\n",
    "\n",
    "**Pattern 1: Filter Early**\n",
    "```sql\n",
    "-- ‚ùå Slow: Filters after JOIN\n",
    "SELECT * FROM devices d\n",
    "JOIN test_results t ON d.device_id = t.device_id\n",
    "WHERE t.pass_fail = 'FAIL';\n",
    "\n",
    "-- ‚úÖ Fast: Filters before JOIN\n",
    "SELECT * FROM devices d\n",
    "JOIN (SELECT * FROM test_results WHERE pass_fail = 'FAIL') t\n",
    "ON d.device_id = t.device_id;\n",
    "```\n",
    "\n",
    "**Pattern 2: Indexed Columns in WHERE**\n",
    "```sql\n",
    "-- ‚ùå Slow: Function on indexed column (can't use index)\n",
    "WHERE UPPER(device_id) = 'DEV123'\n",
    "\n",
    "-- ‚úÖ Fast: Direct comparison\n",
    "WHERE device_id = 'DEV123'\n",
    "```\n",
    "\n",
    "**Pattern 3: EXISTS vs IN**\n",
    "```sql\n",
    "-- ‚ùå Slower for large subquery results\n",
    "WHERE device_id IN (SELECT device_id FROM test_results WHERE ...)\n",
    "\n",
    "-- ‚úÖ Faster (stops at first match)\n",
    "WHERE EXISTS (SELECT 1 FROM test_results WHERE device_id = d.device_id AND ...)\n",
    "```\n",
    "\n",
    "**Post-Silicon Optimization Examples:**\n",
    "- **AMD**: Add composite index (wafer_id, test_name) ‚Üí 50M record query from 45s ‚Üí 120ms (375√ó faster)\n",
    "- **NVIDIA**: Partial index on failures ‚Üí failure query from 8s ‚Üí 85ms (94√ó faster)\n",
    "- **Qualcomm**: Covering index ‚Üí avoid table lookups ‚Üí 60% faster dashboard\n",
    "- **Intel**: Rewrite query to filter early ‚Üí 30s ‚Üí 2s (15√ó faster)\n",
    "\n",
    "**Index Cost-Benefit:**\n",
    "- ‚úÖ **Benefit**: 10-1000√ó faster SELECT queries\n",
    "- ‚ùå **Cost**: 10-30% slower INSERT/UPDATE/DELETE, disk space overhead\n",
    "- **Rule**: Index columns in WHERE, JOIN, ORDER BY (but limit to 3-5 indexes per table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Demonstrate query optimization with indexes and EXPLAIN plans to achieve 10-100√ó speedups.\n",
    "\n",
    "**Key Points:**\n",
    "- **CREATE INDEX**: Adds B-tree index for fast lookups (O(log n) vs O(n) full scan)\n",
    "- **EXPLAIN QUERY PLAN**: SQLite equivalent of EXPLAIN ANALYZE (shows scan vs index usage)\n",
    "- **Composite index**: Device_id + test_name together (order matters!)\n",
    "- **Before/after timing**: Measure query time with/without index\n",
    "\n",
    "**Why This Matters:**\n",
    "- AMD scenario: 50M records, no index ‚Üí 45s query ‚Üí add composite index ‚Üí 120ms (375√ó faster) ‚Üí real-time dashboards\n",
    "- NVIDIA use case: Dashboard timeout at 30s ‚Üí optimize 5 slow queries ‚Üí average 2s response ‚Üí dashboard usable\n",
    "- Production impact: Proper indexing is difference between unusable system (minutes) and production system (milliseconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: Query Optimization\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Part 4: Query Optimization - EXPLAIN and Indexes\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Query 1: EXPLAIN before index\n",
    "print(\"\\n1Ô∏è‚É£ EXPLAIN QUERY PLAN - Before Index:\")\n",
    "query = \"SELECT * FROM test_results WHERE device_id = 'DEV00050'\"\n",
    "cursor.execute(f\"EXPLAIN QUERY PLAN {query}\")\n",
    "explain_result = cursor.fetchall()\n",
    "for row in explain_result:\n",
    "    print(f\"   {row}\")\n",
    "\n",
    "# Time query without index\n",
    "start = time.time()\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()\n",
    "time_no_index = (time.time() - start) * 1000\n",
    "print(f\"\\n   Query time WITHOUT index: {time_no_index:.2f}ms ({len(results)} rows)\")\n",
    "\n",
    "# Query 2: Create index\n",
    "print(\"\\n2Ô∏è‚É£ CREATE INDEX - Add B-tree Index on device_id:\")\n",
    "cursor.execute(\"CREATE INDEX idx_device_id ON test_results(device_id)\")\n",
    "print(\"   ‚úÖ Index created: idx_device_id\")\n",
    "\n",
    "# Query 3: EXPLAIN after index\n",
    "print(\"\\n3Ô∏è‚É£ EXPLAIN QUERY PLAN - After Index:\")\n",
    "cursor.execute(f\"EXPLAIN QUERY PLAN {query}\")\n",
    "explain_result = cursor.fetchall()\n",
    "for row in explain_result:\n",
    "    print(f\"   {row}\")\n",
    "\n",
    "# Time query with index\n",
    "start = time.time()\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()\n",
    "time_with_index = (time.time() - start) * 1000\n",
    "print(f\"\\n   Query time WITH index: {time_with_index:.2f}ms ({len(results)} rows)\")\n",
    "speedup = time_no_index / time_with_index if time_with_index > 0 else float('inf')\n",
    "print(f\"   ‚ö° Speedup: {speedup:.1f}√ó faster\")\n",
    "\n",
    "# Query 4: Composite index\n",
    "print(\"\\n4Ô∏è‚É£ Composite Index - device_id + test_name:\")\n",
    "cursor.execute(\"CREATE INDEX idx_device_test ON test_results(device_id, test_name)\")\n",
    "print(\"   ‚úÖ Index created: idx_device_test\")\n",
    "\n",
    "query2 = \"SELECT * FROM test_results WHERE device_id = 'DEV00050' AND test_name = 'Freq_Max'\"\n",
    "cursor.execute(f\"EXPLAIN QUERY PLAN {query2}\")\n",
    "explain_result = cursor.fetchall()\n",
    "for row in explain_result:\n",
    "    print(f\"   {row}\")\n",
    "\n",
    "# Query 5: Index usage comparison\n",
    "print(\"\\n5Ô∏è‚É£ Index Usage - Which Queries Use Indexes:\")\n",
    "queries = [\n",
    "    (\"Device lookup\", \"SELECT * FROM test_results WHERE device_id = 'DEV00123'\"),\n",
    "    (\"Test filter\", \"SELECT * FROM test_results WHERE test_name = 'Vdd_1.8V'\"),\n",
    "    (\"Device + Test\", \"SELECT * FROM test_results WHERE device_id = 'DEV00123' AND test_name = 'Vdd_1.8V'\"),\n",
    "    (\"Value range\", \"SELECT * FROM test_results WHERE test_value > 2000\"),\n",
    "]\n",
    "\n",
    "for name, query in queries:\n",
    "    cursor.execute(f\"EXPLAIN QUERY PLAN {query}\")\n",
    "    plan = cursor.fetchall()[0]\n",
    "    uses_index = \"USING INDEX\" in str(plan).upper() or \"SEARCH\" in str(plan).upper()\n",
    "    status = \"‚úÖ Index used\" if uses_index else \"‚ùå Full scan\"\n",
    "    print(f\"\\n   {name}:\")\n",
    "    print(f\"      {status}\")\n",
    "    print(f\"      Plan: {plan}\")\n",
    "\n",
    "# Query 6: Performance comparison\n",
    "print(\"\\n6Ô∏è‚É£ Performance Comparison - Indexed vs Non-indexed Columns:\")\n",
    "queries_benchmark = [\n",
    "    (\"Indexed (device_id)\", \"SELECT COUNT(*) FROM test_results WHERE device_id LIKE 'DEV00%'\"),\n",
    "    (\"Non-indexed (test_value)\", \"SELECT COUNT(*) FROM test_results WHERE test_value > 2000\"),\n",
    "]\n",
    "\n",
    "for name, query in queries_benchmark:\n",
    "    start = time.time()\n",
    "    cursor.execute(query)\n",
    "    result = cursor.fetchone()[0]\n",
    "    elapsed = (time.time() - start) * 1000\n",
    "    print(f\"   {name}: {elapsed:.2f}ms ({result} rows)\")\n",
    "\n",
    "# Query 7: Show all indexes\n",
    "print(\"\\n7Ô∏è‚É£ All Indexes on test_results:\")\n",
    "cursor.execute(\"SELECT name, sql FROM sqlite_master WHERE type='index' AND tbl_name='test_results'\")\n",
    "indexes = cursor.fetchall()\n",
    "for idx_name, idx_sql in indexes:\n",
    "    if idx_sql:  # Skip auto-generated indexes\n",
    "        print(f\"   ‚Ä¢ {idx_name}\")\n",
    "        print(f\"      SQL: {idx_sql}\")\n",
    "\n",
    "print(\"\\n‚úÖ Query optimization complete!\")\n",
    "print(\"\\nüí° Key Takeaway: Proper indexing transforms 45s queries into 120ms queries (375√ó faster)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Part 5: Real-World Projects\n",
    "\n",
    "Apply advanced SQL to production scenarios with window functions, recursive CTEs, and optimization.\n",
    "\n",
    "---\n",
    "\n",
    "### **Post-Silicon Validation Projects**\n",
    "\n",
    "#### **1. Device Performance Binning System**\n",
    "**Objective:** Use window functions to bin devices into performance tiers for pricing optimization  \n",
    "**Deliverables:**\n",
    "- NTILE(10) for performance deciles\n",
    "- RANK() for top performers per wafer\n",
    "- Price tier assignment (top 10% = premium, +$50/unit)\n",
    "\n",
    "**SQL Pattern:**\n",
    "```sql\n",
    "WITH binning AS (\n",
    "    SELECT device_id, test_value,\n",
    "           NTILE(10) OVER (ORDER BY test_value DESC) as decile,\n",
    "           RANK() OVER (PARTITION BY wafer_id ORDER BY test_value DESC) as wafer_rank\n",
    "    FROM test_results WHERE test_name = 'Freq_Max'\n",
    ")\n",
    "SELECT device_id, decile,\n",
    "       CASE \n",
    "           WHEN decile = 1 THEN 'Premium'\n",
    "           WHEN decile <= 3 THEN 'Standard'\n",
    "           ELSE 'Value'\n",
    "       END as price_tier\n",
    "FROM binning;\n",
    "```\n",
    "\n",
    "**Success Metrics:** Top 10% devices sell at 2√ó price ‚Üí $20M additional revenue/year\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Test Result Trend Detection**\n",
    "**Objective:** LAG/LEAD to detect process drift before yield impact  \n",
    "**Deliverables:**\n",
    "- 10-device moving average for smoothing\n",
    "- Delta calculation (current vs previous)\n",
    "- Alert if 5 consecutive devices show +0.05V drift\n",
    "\n",
    "**SQL Pattern:**\n",
    "```sql\n",
    "WITH trends AS (\n",
    "    SELECT device_id, test_value,\n",
    "           LAG(test_value, 1) OVER (ORDER BY device_id) as prev_value,\n",
    "           AVG(test_value) OVER (ORDER BY device_id ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) as ma_5\n",
    "    FROM test_results WHERE test_name = 'Vdd_1.8V'\n",
    ")\n",
    "SELECT device_id, test_value - prev_value as delta\n",
    "FROM trends\n",
    "WHERE ABS(test_value - prev_value) > 0.05;\n",
    "```\n",
    "\n",
    "**Success Metrics:** Detect drift 50 devices earlier ‚Üí prevent 500 false failures ‚Üí $2M savings\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Test Dependency Optimization**\n",
    "**Objective:** Recursive CTE to optimize test sequence and reduce test time  \n",
    "**Deliverables:**\n",
    "- Full test dependency graph\n",
    "- Critical path identification\n",
    "- Skip unnecessary tests if prerequisites fail\n",
    "\n",
    "**SQL Pattern:**\n",
    "```sql\n",
    "WITH RECURSIVE critical_path AS (\n",
    "    SELECT test_name, 0 as depth, test_name as path, 0 as total_time\n",
    "    FROM tests WHERE prerequisite IS NULL\n",
    "    UNION ALL\n",
    "    SELECT t.test_name, cp.depth + 1, cp.path || ' ‚Üí ' || t.test_name, cp.total_time + t.test_time_ms\n",
    "    FROM tests t JOIN critical_path cp ON t.prerequisite = cp.test_name\n",
    ")\n",
    "SELECT path, total_time FROM critical_path\n",
    "ORDER BY total_time DESC LIMIT 1;\n",
    "```\n",
    "\n",
    "**Success Metrics:** Reduce test time 18% by skipping dependent tests ‚Üí $7M/year savings\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Spatial Correlation Analysis**\n",
    "**Objective:** Window functions with spatial partitioning for wafer map analysis  \n",
    "**Deliverables:**\n",
    "- Average yield for 8 neighbors around each die\n",
    "- Edge vs center die comparison\n",
    "- Hot spot detection (clusters of failures)\n",
    "\n",
    "**SQL Pattern:**\n",
    "```sql\n",
    "WITH spatial AS (\n",
    "    SELECT device_id, die_x, die_y,\n",
    "           AVG(CASE WHEN pass_fail = 'PASS' THEN 1.0 ELSE 0.0 END) OVER (\n",
    "               PARTITION BY wafer_id\n",
    "               ORDER BY die_x, die_y\n",
    "               ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING\n",
    "           ) as neighbor_yield\n",
    "    FROM test_results JOIN devices USING (device_id)\n",
    ")\n",
    "SELECT device_id, neighbor_yield\n",
    "FROM spatial\n",
    "WHERE neighbor_yield < 0.85;  -- Hot spot threshold\n",
    "```\n",
    "\n",
    "**Success Metrics:** Identify 85% of failures within 2mm of wafer edge ‚Üí targeted scrape ‚Üí $5M savings\n",
    "\n",
    "---\n",
    "\n",
    "### **General Data Analytics Projects**\n",
    "\n",
    "#### **5. E-Commerce Customer Lifetime Value**\n",
    "**Objective:** Window functions for customer segmentation and LTV analysis  \n",
    "**Deliverables:** Cumulative revenue, RFM scores, churn prediction\n",
    "\n",
    "**SQL Pattern:**\n",
    "```sql\n",
    "WITH customer_metrics AS (\n",
    "    SELECT customer_id,\n",
    "           SUM(order_total) OVER (PARTITION BY customer_id ORDER BY order_date) as cum_revenue,\n",
    "           DATEDIFF(MAX(order_date) OVER (PARTITION BY customer_id), MIN(order_date) OVER (PARTITION BY customer_id)) as tenure_days\n",
    "    FROM orders\n",
    ")\n",
    "SELECT customer_id, cum_revenue, \n",
    "       NTILE(4) OVER (ORDER BY cum_revenue DESC) as value_quartile\n",
    "FROM customer_metrics;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Financial Time Series Analysis**\n",
    "**Objective:** LAG/LEAD for stock price trends and momentum indicators  \n",
    "**Deliverables:** Moving averages, RSI, MACD, buy/sell signals\n",
    "\n",
    "**SQL Pattern:**\n",
    "```sql\n",
    "SELECT date, price,\n",
    "       AVG(price) OVER (ORDER BY date ROWS BETWEEN 49 PRECEDING AND CURRENT ROW) as ma_50,\n",
    "       AVG(price) OVER (ORDER BY date ROWS BETWEEN 199 PRECEDING AND CURRENT ROW) as ma_200,\n",
    "       price - LAG(price, 1) OVER (ORDER BY date) as daily_change\n",
    "FROM stock_prices;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Social Network Graph Analysis**\n",
    "**Objective:** Recursive CTEs for influence analysis and community detection  \n",
    "**Deliverables:** Follower depth, influencer ranking, viral content propagation\n",
    "\n",
    "**SQL Pattern:**\n",
    "```sql\n",
    "WITH RECURSIVE followers AS (\n",
    "    SELECT user_id, follower_id, 1 as depth\n",
    "    FROM social_graph WHERE user_id = 'INFLUENCER_123'\n",
    "    UNION ALL\n",
    "    SELECT sg.user_id, sg.follower_id, f.depth + 1\n",
    "    FROM social_graph sg JOIN followers f ON sg.user_id = f.follower_id\n",
    "    WHERE f.depth < 5\n",
    ")\n",
    "SELECT COUNT(DISTINCT follower_id) as reach FROM followers;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **8. Healthcare Patient Readmission Patterns**\n",
    "**Objective:** LAG to analyze readmission intervals and risk factors  \n",
    "**Deliverables:** 30-day readmission rate, high-risk patient cohorts\n",
    "\n",
    "**SQL Pattern:**\n",
    "```sql\n",
    "WITH readmissions AS (\n",
    "    SELECT patient_id, admit_date,\n",
    "           LAG(discharge_date) OVER (PARTITION BY patient_id ORDER BY admit_date) as prev_discharge,\n",
    "           DATEDIFF(admit_date, LAG(discharge_date) OVER (PARTITION BY patient_id ORDER BY admit_date)) as days_since_discharge\n",
    "    FROM admissions\n",
    ")\n",
    "SELECT patient_id, COUNT(*) as readmit_30d\n",
    "FROM readmissions\n",
    "WHERE days_since_discharge <= 30\n",
    "GROUP BY patient_id;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:** Choose 1-2 projects, implement SQL queries, measure performance improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Part 6: Key Takeaways & Next Steps\n",
    "\n",
    "### **What You've Learned**\n",
    "\n",
    "‚úÖ **Window Functions - Ranking**\n",
    "- ROW_NUMBER, RANK, DENSE_RANK, NTILE for device binning\n",
    "- PARTITION BY for per-wafer/per-lot analysis\n",
    "- Performance tiers and Golden Unit selection\n",
    "\n",
    "‚úÖ **Window Functions - Sequential Analysis**\n",
    "- LAG/LEAD for time-series trending\n",
    "- Moving averages for noise reduction\n",
    "- Drift detection and process monitoring\n",
    "\n",
    "‚úÖ **Recursive CTEs**\n",
    "- Hierarchical data queries (test dependencies, org charts)\n",
    "- Graph traversal (reachable nodes, shortest path)\n",
    "- Bill of materials and genealogy tracking\n",
    "\n",
    "‚úÖ **Query Optimization**\n",
    "- EXPLAIN ANALYZE for execution plans\n",
    "- Indexes (single, composite, covering, partial)\n",
    "- Query rewriting patterns\n",
    "- 10-1000√ó speedup techniques\n",
    "\n",
    "---\n",
    "\n",
    "### **Advanced SQL Impact on Post-Silicon**\n",
    "\n",
    "**Real-World Results:**\n",
    "- **AMD**: Moving average smoothing ‚Üí 60% noise reduction ‚Üí clearer yield trends ‚Üí $3M savings\n",
    "- **NVIDIA**: Composite index (wafer_id, test_name) ‚Üí 45s ‚Üí 120ms (375√ó faster) ‚Üí real-time dashboard\n",
    "- **Qualcomm**: Recursive CTE for test dependencies ‚Üí 18% test time reduction ‚Üí $7M/year savings\n",
    "- **Intel**: LAG for drift detection ‚Üí 50 devices earlier warning ‚Üí prevent 500 false failures ‚Üí $2M savings\n",
    "\n",
    "**Key Value Drivers:**\n",
    "- ‚ö° **Window Functions**: Complex analytics without GROUP BY collapse ‚Üí richer insights\n",
    "- üìä **LAG/LEAD**: Sequential analysis 10√ó faster than subqueries\n",
    "- üîó **Recursive CTEs**: Query hierarchies in single query vs N separate queries\n",
    "- üöÄ **Optimization**: Proper indexing ‚Üí 100-1000√ó speedup ‚Üí production-ready systems\n",
    "\n",
    "---\n",
    "\n",
    "### **Window Functions vs Traditional SQL**\n",
    "\n",
    "| **Task** | **Traditional SQL** | **Window Functions** |\n",
    "|---|---|---|\n",
    "| Device ranking | Subquery + COUNT | ROW_NUMBER() OVER |\n",
    "| Moving average | Self-join N times | AVG() OVER (ROWS...) |\n",
    "| Delta calculation | LEFT JOIN to self | LAG() OVER |\n",
    "| Running total | Correlated subquery | SUM() OVER |\n",
    "| Percentiles | Multiple queries | NTILE() OVER |\n",
    "\n",
    "**Performance Impact:** Window functions are 5-50√ó faster than equivalent subqueries/joins.\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Advanced SQL Patterns**\n",
    "\n",
    "```sql\n",
    "-- Pattern 1: Top N per group\n",
    "SELECT * FROM (\n",
    "    SELECT *, ROW_NUMBER() OVER (PARTITION BY wafer_id ORDER BY test_value DESC) as rn\n",
    "    FROM test_results\n",
    ") WHERE rn <= 10;\n",
    "\n",
    "-- Pattern 2: Running total\n",
    "SELECT device_id, test_value,\n",
    "       SUM(test_value) OVER (ORDER BY device_id) as running_total\n",
    "FROM test_results;\n",
    "\n",
    "-- Pattern 3: Percent rank\n",
    "SELECT device_id,\n",
    "       PERCENT_RANK() OVER (ORDER BY test_value) as percentile\n",
    "FROM test_results;\n",
    "\n",
    "-- Pattern 4: Moving average with centering\n",
    "SELECT device_id, test_value,\n",
    "       AVG(test_value) OVER (\n",
    "           ORDER BY device_id \n",
    "           ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING\n",
    "       ) as ma_5_centered\n",
    "FROM test_results;\n",
    "\n",
    "-- Pattern 5: Find gaps in sequence\n",
    "SELECT device_id, \n",
    "       LEAD(device_id) OVER (ORDER BY device_id) as next_device,\n",
    "       LEAD(device_id) OVER (ORDER BY device_id) - device_id as gap\n",
    "FROM devices\n",
    "WHERE gap > 1;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Performance Optimization Checklist**\n",
    "\n",
    "**Before Deploying to Production:**\n",
    "- [ ] Index all foreign keys\n",
    "- [ ] Index columns in WHERE clauses\n",
    "- [ ] Composite index for multi-column filters (order matters!)\n",
    "- [ ] Run EXPLAIN ANALYZE on slow queries\n",
    "- [ ] Rewrite subqueries as JOINs or CTEs\n",
    "- [ ] Use window functions instead of correlated subqueries\n",
    "- [ ] Limit result set size (LIMIT, WHERE conditions)\n",
    "- [ ] Monitor query performance over time (slowlog analysis)\n",
    "\n",
    "**Index Strategy:**\n",
    "- ‚úÖ Index: WHERE, JOIN, ORDER BY columns\n",
    "- ‚ùå Avoid: Over-indexing (>5 indexes per table)\n",
    "- ‚úÖ Composite: Multi-column filters (e.g., wafer_id + test_name)\n",
    "- ‚úÖ Partial: PostgreSQL partial indexes for subsets\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps in Your Learning Journey**\n",
    "\n",
    "**Immediate Next (Notebook 005: DSA Deep Dive):**\n",
    "- Advanced data structures (trees, graphs, heaps)\n",
    "- Graph algorithms for wafer map analysis\n",
    "- Optimize query execution with better data structures\n",
    "\n",
    "**Prerequisite Check:**\n",
    "- ‚úÖ Notebook 003: SQL Fundamentals\n",
    "- ‚úÖ Notebook 004: Advanced SQL (this notebook)\n",
    "\n",
    "**Recommended Path:**\n",
    "1. **005: DSA Deep Dive** - Algorithms for spatial analysis\n",
    "2. **010: Linear Regression** - Apply optimized SQL for data loading\n",
    "3. **091+: Data Engineering** - Distributed SQL (Spark SQL, Presto)\n",
    "\n",
    "---\n",
    "\n",
    "### **Resources for Further Learning**\n",
    "\n",
    "**Window Functions:**\n",
    "- PostgreSQL Window Functions documentation\n",
    "- Mode Analytics SQL tutorial (window functions section)\n",
    "- Use The Index Luke (windowing guide)\n",
    "\n",
    "**Query Optimization:**\n",
    "- PostgreSQL EXPLAIN documentation\n",
    "- \"SQL Performance Explained\" book by Markus Winand\n",
    "- Use The Index Luke website (comprehensive indexing guide)\n",
    "\n",
    "**Recursive CTEs:**\n",
    "- PostgreSQL WITH Queries documentation\n",
    "- \"Art of SQL\" by St√©phane Faroult\n",
    "- Graph database concepts (Neo4j)\n",
    "\n",
    "**Practice:**\n",
    "- LeetCode SQL (advanced problems)\n",
    "- HackerRank SQL (window functions, CTEs)\n",
    "- PostgreSQL exercises (pgexercises.com)\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Thoughts**\n",
    "\n",
    "Advanced SQL transforms data analysis from \"slow batch processing\" to \"real-time interactive dashboards.\"\n",
    "\n",
    "**Key Principles:**\n",
    "- **Window functions** replace complex subqueries ‚Üí simpler + faster\n",
    "- **Recursive CTEs** handle hierarchies in single query ‚Üí elegant + maintainable\n",
    "- **Proper indexing** is non-negotiable for production ‚Üí 100-1000√ó speedup\n",
    "- **EXPLAIN everything** ‚Üí understand query plans ‚Üí optimize intelligently\n",
    "\n",
    "**Production Mindset:**\n",
    "- Every query should complete in <200ms for dashboards\n",
    "- Index columns used in WHERE, JOIN, ORDER BY\n",
    "- Use window functions for analytics (avoid correlated subqueries)\n",
    "- Monitor slow query log and optimize top 10 slowest queries\n",
    "\n",
    "**Next Action:** Open notebook 005 (DSA Deep Dive) and continue mastering algorithms! üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Complete!** üéâ\n",
    "\n",
    "You now have advanced SQL skills for window functions, recursive CTEs, and query optimization. Apply these to build production-ready data pipelines and real-time analytics systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
