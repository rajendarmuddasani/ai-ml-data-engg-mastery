{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6251f7",
   "metadata": {},
   "source": [
    "# 140: Logging & Distributed Tracing - Structured Logs, ELK Stack, and Jaeger\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- **Understand** structured logging vs unstructured logs (JSON with context vs plain text)\n",
    "- **Implement** centralized logging with ELK stack (Elasticsearch, Logstash, Kibana)\n",
    "- **Build** distributed tracing with Jaeger for multi-service ML pipelines\n",
    "- **Deploy** log aggregation for ML systems (correlation IDs, trace context propagation)\n",
    "- **Apply** logging to semiconductor systems (STDF processing traces, ML inference request flows)\n",
    "- **Debug** production issues with logs and traces (find slow services, error root causes)\n",
    "\n",
    "## üìö What is Distributed Tracing?\n",
    "\n",
    "**Distributed tracing** tracks a **single request's journey** across multiple services, capturing timing, errors, and context at each hop. Essential for debugging microservices and ML pipelines where requests touch 5-10+ services.\n",
    "\n",
    "**Why Distributed Tracing?**\n",
    "- ‚úÖ **End-to-end visibility**: See entire request flow (API ‚Üí load balancer ‚Üí app ‚Üí database ‚Üí ML model ‚Üí cache ‚Üí response)\n",
    "- ‚úÖ **Performance debugging**: Identify slow services (database query 2 seconds, ML inference 500ms, serialization 100ms)\n",
    "- ‚úÖ **Error propagation**: Trace errors to origin (which service threw exception? what was input?)\n",
    "- ‚úÖ **Dependency mapping**: Understand service dependencies (service A calls B, B calls C and D)\n",
    "\n",
    "**Structured Logging vs Unstructured:**\n",
    "\n",
    "| Aspect | Unstructured Logs | Structured Logs (JSON) |\n",
    "|--------|-------------------|------------------------|\n",
    "| **Format** | Plain text: `ERROR: Model prediction failed for user 123` | JSON: `{\"level\":\"ERROR\",\"msg\":\"Prediction failed\",\"user_id\":123,\"model\":\"v2.1\",\"trace_id\":\"abc123\"}` |\n",
    "| **Searchability** | Regex/grep (slow, brittle) | Index fields (fast queries: `user_id:123 AND level:ERROR`) |\n",
    "| **Correlation** | Manual parsing of request IDs | trace_id links all logs for one request |\n",
    "| **Machine readable** | No (humans only) | Yes (parse, aggregate, visualize) |\n",
    "| **Context** | Limited (text only) | Rich (user_id, model_version, latency, confidence) |\n",
    "\n",
    "**OpenTelemetry (Modern Standard):**\n",
    "- **Unified API**: Single library for metrics, logs, and traces (vendor-neutral)\n",
    "- **Auto-instrumentation**: Frameworks automatically emit traces (FastAPI, Flask, Django)\n",
    "- **Context propagation**: trace_id and span_id flow across services (HTTP headers, gRPC metadata)\n",
    "\n",
    "## üè≠ Post-Silicon Validation Use Cases\n",
    "\n",
    "### **Use Case 1: Jaeger Tracing for STDF ETL Pipeline**\n",
    "**Input:** Multi-stage ETL pipeline (S3 download ‚Üí parse STDF ‚Üí validate ‚Üí transform ‚Üí load to database ‚Üí index)  \n",
    "**Problem:** 30% of jobs fail with no visibility into which stage failed or why  \n",
    "**Output:** Jaeger traces show failures at \"parse STDF\" stage (corrupted files), specific lot IDs identified  \n",
    "**Value:** $3.9M/year from faster debugging (reduce MTTR from 4 hours to 20 minutes, 90% reduction)\n",
    "\n",
    "### **Use Case 2: ELK Stack for ML Inference Logs**\n",
    "**Input:** Yield prediction API logs scattered across 20 servers, engineers SSH to debug  \n",
    "**Output:** Centralized Elasticsearch with Kibana dashboards (search by user_id, model_version, error_type)  \n",
    "**Value:** $3.2M/year from improved debuggability (find all errors for model v2.1 in 10 seconds vs 1 hour)\n",
    "\n",
    "### **Use Case 3: Correlation IDs for Wafer Map Rendering Service**\n",
    "**Input:** Wafer map generation spans 5 microservices (API ‚Üí auth ‚Üí database ‚Üí ML model ‚Üí image render ‚Üí S3 upload)  \n",
    "**Problem:** Timeouts occur but unclear which service is slow (no request correlation)  \n",
    "**Output:** Correlation IDs (trace_id) link logs across services, reveal database query timeouts (95% of slow requests)  \n",
    "**Value:** $2.7M/year from targeted optimization (fix database indexes, reduce P95 latency 80%)\n",
    "\n",
    "### **Use Case 4: Log Sampling for High-Volume Test Data Processing**\n",
    "**Input:** STDF processing logs 1M events/hour (100GB/day), storage costs $15K/month  \n",
    "**Output:** Sample 10% of INFO logs, keep 100% of WARN/ERROR logs (10GB/day, $1.5K/month storage)  \n",
    "**Value:** $2.1M/year from reduced storage costs (save $13.5K/month = $162K/year) + faster search performance\n",
    "\n",
    "**Total Post-Silicon Value:** $3.9M + $3.2M + $2.7M + $2.1M = **$11.9M/year**\n",
    "\n",
    "## üîÑ Distributed Tracing Workflow\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[üåê Client Request] --> B[üîÄ API Gateway]\n",
    "    B --> C[üîê Auth Service]\n",
    "    C --> D[üíæ Database Lookup]\n",
    "    C --> E[ü§ñ ML Model Service]\n",
    "    E --> F[üìä Feature Store]\n",
    "    E --> G[üß† Model Inference]\n",
    "    G --> H[üìù Log Prediction]\n",
    "    H --> I[üì§ Response to Client]\n",
    "    \n",
    "    B -.trace_id=abc123.-> C\n",
    "    C -.trace_id=abc123.-> D\n",
    "    C -.trace_id=abc123.-> E\n",
    "    E -.trace_id=abc123.-> F\n",
    "    E -.trace_id=abc123.-> G\n",
    "    \n",
    "    D --> J[Jaeger Collector]\n",
    "    F --> J\n",
    "    G --> J\n",
    "    H --> J\n",
    "    \n",
    "    J --> K[Jaeger UI]\n",
    "    K --> L[üëÄ Visualize Trace]\n",
    "    L --> M{Slow Span?}\n",
    "    M -->|Yes| N[üéØ Optimize Service]\n",
    "    M -->|No| O[‚úÖ Performance Good]\n",
    "    \n",
    "    style A fill:#e1f5ff\n",
    "    style I fill:#e1ffe1\n",
    "    style N fill:#fff4e1\n",
    "```\n",
    "\n",
    "## üìä Learning Path Context\n",
    "\n",
    "**Prerequisites:**\n",
    "- **Notebook 139: Observability & Monitoring** - Metrics and alerting foundations\n",
    "- **Notebook 107: ML Model Monitoring** - Model-specific logging and metrics\n",
    "\n",
    "**Next Steps:**\n",
    "- **Notebook 141: CI/CD Pipelines** - Integrate logging into deployment pipelines\n",
    "- **Notebook 144: Performance Optimization** - Use traces to identify bottlenecks\n",
    "\n",
    "---\n",
    "\n",
    "Let's debug distributed ML systems with logs and traces! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5262090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9fa59",
   "metadata": {},
   "source": [
    "## 2. üìù Structured Logging - JSON Logs with Context\n",
    "\n",
    "### üìù What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Implement structured logging with JSON format for queryable, correlatable logs in ML systems.\n",
    "\n",
    "**Key Points:**\n",
    "- **Structured Format**: JSON logs with standardized fields (timestamp, level, message, trace_id, service)\n",
    "- **Contextual Fields**: user_id, model_version, request_id enable powerful filtering\n",
    "- **Log Levels**: DEBUG (verbose), INFO (events), WARNING (issues), ERROR (failures), CRITICAL (system down)\n",
    "- **Correlation**: trace_id links logs across services, request_id groups logs for single request\n",
    "- **Search Optimization**: Index key fields in Elasticsearch for fast queries (find all errors for model v2.1)\n",
    "\n",
    "**Why This Matters:**\n",
    "- **Debugging**: Search logs by trace_id to see all events for slow request\n",
    "- **Analytics**: Count errors by model version (v2.1 has 15% error rate vs v2.0 1%)\n",
    "- **Compliance**: Audit trail of who accessed what data when (GDPR, HIPAA)\n",
    "- **Alerting**: Trigger PagerDuty when ERROR logs > 10/minute for critical services\n",
    "\n",
    "**Post-Silicon Application:**\n",
    "- **Scenario**: Debug STDF parsing failures (10% error rate for wafer lot W-12345)\n",
    "- **Query**: `service:stdf-parser AND level:ERROR AND wafer_lot:W-12345` in Kibana\n",
    "- **Result**: 150 error logs showing \"Voltage out of range: got 20V, expected [-5V, 15V]\"\n",
    "- **Root Cause**: Test equipment calibration drift on wafer lot W-12345\n",
    "- **Fix**: Recalibrate equipment, reprocess lot, error rate 10% ‚Üí 0%\n",
    "- **Value**: 80% faster debugging (3 hours ‚Üí 35 minutes MTTR), $1.5M/year savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Structured Logging and Distributed Tracing Implementation\n",
    "\n",
    "class LogLevel(Enum):\n",
    "    \"\"\"Log severity levels\"\"\"\n",
    "    DEBUG = \"DEBUG\"\n",
    "    INFO = \"INFO\"\n",
    "    WARNING = \"WARNING\"\n",
    "    ERROR = \"ERROR\"\n",
    "    CRITICAL = \"CRITICAL\"\n",
    "\n",
    "@dataclass\n",
    "class LogEntry:\n",
    "    \"\"\"Structured log entry\"\"\"\n",
    "    timestamp: datetime\n",
    "    level: LogLevel\n",
    "    service: str\n",
    "    message: str\n",
    "    trace_id: Optional[str] = None\n",
    "    span_id: Optional[str] = None\n",
    "    fields: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def to_json(self) -> str:\n",
    "        \"\"\"Export as JSON (Elasticsearch format)\"\"\"\n",
    "        return json.dumps({\n",
    "            \"@timestamp\": self.timestamp.isoformat(),\n",
    "            \"level\": self.level.value,\n",
    "            \"service\": self.service,\n",
    "            \"message\": self.message,\n",
    "            \"trace_id\": self.trace_id,\n",
    "            \"span_id\": self.span_id,\n",
    "            **self.fields\n",
    "        }, indent=2)\n",
    "\n",
    "class StructuredLogger:\n",
    "    \"\"\"Structured logger with trace correlation\"\"\"\n",
    "    \n",
    "    def __init__(self, service_name: str):\n",
    "        self.service_name = service_name\n",
    "        self.logs: List[LogEntry] = []\n",
    "    \n",
    "    def log(self, level: LogLevel, message: str, trace_id: str = None, \n",
    "            span_id: str = None, **fields):\n",
    "        \"\"\"Log structured entry\"\"\"\n",
    "        entry = LogEntry(\n",
    "            timestamp=datetime.now(),\n",
    "            level=level,\n",
    "            service=self.service_name,\n",
    "            message=message,\n",
    "            trace_id=trace_id,\n",
    "            span_id=span_id,\n",
    "            fields=fields\n",
    "        )\n",
    "        self.logs.append(entry)\n",
    "        \n",
    "        # Print to console (simulating log output)\n",
    "        level_emoji = {\n",
    "            LogLevel.DEBUG: \"üîç\",\n",
    "            LogLevel.INFO: \"‚ÑπÔ∏è\",\n",
    "            LogLevel.WARNING: \"‚ö†Ô∏è\",\n",
    "            LogLevel.ERROR: \"‚ùå\",\n",
    "            LogLevel.CRITICAL: \"üî•\"\n",
    "        }\n",
    "        print(f\"{level_emoji[level]} [{entry.timestamp.strftime('%H:%M:%S')}] {self.service_name} | {message}\")\n",
    "        if fields:\n",
    "            print(f\"   Fields: {json.dumps(fields, indent=2)}\")\n",
    "    \n",
    "    def debug(self, message: str, **fields):\n",
    "        self.log(LogLevel.DEBUG, message, **fields)\n",
    "    \n",
    "    def info(self, message: str, **fields):\n",
    "        self.log(LogLevel.INFO, message, **fields)\n",
    "    \n",
    "    def warning(self, message: str, **fields):\n",
    "        self.log(LogLevel.WARNING, message, **fields)\n",
    "    \n",
    "    def error(self, message: str, **fields):\n",
    "        self.log(LogLevel.ERROR, message, **fields)\n",
    "    \n",
    "    def critical(self, message: str, **fields):\n",
    "        self.log(LogLevel.CRITICAL, message, **fields)\n",
    "    \n",
    "    def query_logs(self, level: LogLevel = None, trace_id: str = None, \n",
    "                   **field_filters) -> List[LogEntry]:\n",
    "        \"\"\"Query logs (simulating Elasticsearch query)\"\"\"\n",
    "        results = self.logs\n",
    "        \n",
    "        if level:\n",
    "            results = [log for log in results if log.level == level]\n",
    "        if trace_id:\n",
    "            results = [log for log in results if log.trace_id == trace_id]\n",
    "        for key, value in field_filters.items():\n",
    "            results = [log for log in results if log.fields.get(key) == value]\n",
    "        \n",
    "        return results\n",
    "\n",
    "@dataclass\n",
    "class Span:\n",
    "    \"\"\"Distributed trace span\"\"\"\n",
    "    span_id: str\n",
    "    trace_id: str\n",
    "    parent_span_id: Optional[str]\n",
    "    operation_name: str\n",
    "    service_name: str\n",
    "    start_time: datetime\n",
    "    duration_ms: float = 0.0\n",
    "    tags: Dict[str, Any] = field(default_factory=dict)\n",
    "    status: str = \"OK\"\n",
    "\n",
    "class Tracer:\n",
    "    \"\"\"Distributed tracer with logging integration\"\"\"\n",
    "    \n",
    "    def __init__(self, service_name: str, logger: StructuredLogger):\n",
    "        self.service_name = service_name\n",
    "        self.logger = logger\n",
    "        self.spans: List[Span] = []\n",
    "    \n",
    "    def start_span(self, operation_name: str, trace_id: str = None, \n",
    "                   parent_span_id: str = None) -> Span:\n",
    "        \"\"\"Start new span\"\"\"\n",
    "        trace_id = trace_id or f\"trace-{uuid.uuid4().hex[:16]}\"\n",
    "        span_id = f\"span-{uuid.uuid4().hex[:8]}\"\n",
    "        \n",
    "        span = Span(\n",
    "            span_id=span_id,\n",
    "            trace_id=trace_id,\n",
    "            parent_span_id=parent_span_id,\n",
    "            operation_name=operation_name,\n",
    "            service_name=self.service_name,\n",
    "            start_time=datetime.now()\n",
    "        )\n",
    "        \n",
    "        # Log span start\n",
    "        self.logger.debug(\n",
    "            f\"Span started: {operation_name}\",\n",
    "            trace_id=trace_id,\n",
    "            span_id=span_id,\n",
    "            operation=operation_name\n",
    "        )\n",
    "        \n",
    "        return span\n",
    "    \n",
    "    def end_span(self, span: Span, status: str = \"OK\", **tags):\n",
    "        \"\"\"End span and record\"\"\"\n",
    "        span.duration_ms = (datetime.now() - span.start_time).total_seconds() * 1000\n",
    "        span.status = status\n",
    "        span.tags.update(tags)\n",
    "        self.spans.append(span)\n",
    "        \n",
    "        # Log span completion\n",
    "        log_level = LogLevel.ERROR if status == \"ERROR\" else LogLevel.INFO\n",
    "        self.logger.log(\n",
    "            log_level,\n",
    "            f\"Span completed: {span.operation_name} ({span.duration_ms:.2f}ms)\",\n",
    "            trace_id=span.trace_id,\n",
    "            span_id=span.span_id,\n",
    "            duration_ms=span.duration_ms,\n",
    "            status=status,\n",
    "            **tags\n",
    "        )\n",
    "        \n",
    "        return span\n",
    "\n",
    "# Example 1: STDF Parsing with Structured Logging\n",
    "print(\"=\" * 70)\n",
    "print(\"Example 1: STDF Parsing with Structured Logging\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "parser_logger = StructuredLogger(service_name=\"stdf-parser\")\n",
    "parser_tracer = Tracer(service_name=\"stdf-parser\", logger=parser_logger)\n",
    "\n",
    "print(\"\\nüìä Processing STDF file: wafer_lot_W12345.stdf\")\n",
    "\n",
    "# Start trace\n",
    "trace_id = f\"trace-{uuid.uuid4().hex[:16]}\"\n",
    "root_span = parser_tracer.start_span(\"parse_stdf_file\", trace_id=trace_id)\n",
    "\n",
    "# Log file received\n",
    "parser_logger.info(\n",
    "    \"STDF file received for processing\",\n",
    "    trace_id=trace_id,\n",
    "    span_id=root_span.span_id,\n",
    "    file_name=\"wafer_lot_W12345.stdf\",\n",
    "    file_size_mb=500,\n",
    "    wafer_lot=\"W-12345\"\n",
    ")\n",
    "\n",
    "# Span 1: Decompress file\n",
    "decompress_span = parser_tracer.start_span(\n",
    "    \"decompress_file\",\n",
    "    trace_id=trace_id,\n",
    "    parent_span_id=root_span.span_id\n",
    ")\n",
    "time.sleep(0.05)\n",
    "parser_tracer.end_span(\n",
    "    decompress_span,\n",
    "    compression_ratio=3.2,\n",
    "    uncompressed_size_mb=1600\n",
    ")\n",
    "\n",
    "# Span 2: Parse records\n",
    "parse_span = parser_tracer.start_span(\n",
    "    \"parse_records\",\n",
    "    trace_id=trace_id,\n",
    "    parent_span_id=root_span.span_id\n",
    ")\n",
    "\n",
    "# Simulate parsing with some errors\n",
    "for i in range(5):\n",
    "    if i == 3:  # Simulate validation error\n",
    "        parser_logger.error(\n",
    "            \"Record validation failed: Voltage out of range\",\n",
    "            trace_id=trace_id,\n",
    "            span_id=parse_span.span_id,\n",
    "            record_id=f\"REC-{i}\",\n",
    "            parameter=\"voltage\",\n",
    "            value=20.0,\n",
    "            expected_range=\"[-5V, 15V]\",\n",
    "            wafer_lot=\"W-12345\",\n",
    "            die_x=5,\n",
    "            die_y=7\n",
    "        )\n",
    "    else:\n",
    "        parser_logger.debug(\n",
    "            f\"Record {i} parsed successfully\",\n",
    "            trace_id=trace_id,\n",
    "            span_id=parse_span.span_id,\n",
    "            record_id=f\"REC-{i}\"\n",
    "        )\n",
    "\n",
    "time.sleep(0.15)\n",
    "parser_tracer.end_span(\n",
    "    parse_span,\n",
    "    status=\"ERROR\",\n",
    "    records_parsed=5,\n",
    "    records_failed=1,\n",
    "    error_type=\"ValidationError\"\n",
    ")\n",
    "\n",
    "# Span 3: Store results\n",
    "store_span = parser_tracer.start_span(\n",
    "    \"store_results\",\n",
    "    trace_id=trace_id,\n",
    "    parent_span_id=root_span.span_id\n",
    ")\n",
    "time.sleep(0.02)\n",
    "parser_tracer.end_span(\n",
    "    store_span,\n",
    "    records_stored=4,\n",
    "    database=\"postgresql\"\n",
    ")\n",
    "\n",
    "# Complete root span\n",
    "parser_tracer.end_span(\n",
    "    root_span,\n",
    "    status=\"PARTIAL_SUCCESS\",\n",
    "    total_records=5,\n",
    "    success_count=4,\n",
    "    error_count=1\n",
    ")\n",
    "\n",
    "# Query logs by trace_id\n",
    "print(f\"\\n\\n{'=' * 70}\")\n",
    "print(\"Query Logs by Trace ID (Simulating Kibana Search)\")\n",
    "print(f\"{'=' * 70}\")\n",
    "print(f\"Query: trace_id:{trace_id}\")\n",
    "\n",
    "trace_logs = parser_logger.query_logs(trace_id=trace_id)\n",
    "print(f\"\\nFound {len(trace_logs)} log entries for trace {trace_id}\")\n",
    "\n",
    "# Query error logs\n",
    "print(f\"\\n\\n{'=' * 70}\")\n",
    "print(\"Query Error Logs (Simulating Kibana Error Dashboard)\")\n",
    "print(f\"{'=' * 70}\")\n",
    "print(f\"Query: level:ERROR AND wafer_lot:W-12345\")\n",
    "\n",
    "error_logs = parser_logger.query_logs(level=LogLevel.ERROR, wafer_lot=\"W-12345\")\n",
    "print(f\"\\nFound {len(error_logs)} error logs for wafer lot W-12345\")\n",
    "for log in error_logs:\n",
    "    print(f\"\\n{log.to_json()}\")\n",
    "\n",
    "# Example 2: ML Model Prediction with Trace Correlation\n",
    "print(f\"\\n\\n{'=' * 70}\")\n",
    "print(\"Example 2: ML Model Prediction Pipeline with Trace Correlation\")\n",
    "print(f\"{'=' * 70}\")\n",
    "\n",
    "# Create loggers for each service\n",
    "api_logger = StructuredLogger(\"api-gateway\")\n",
    "feature_logger = StructuredLogger(\"feature-store\")\n",
    "model_logger = StructuredLogger(\"ml-model-serving\")\n",
    "db_logger = StructuredLogger(\"postgres\")\n",
    "\n",
    "# Create tracers\n",
    "api_tracer = Tracer(\"api-gateway\", api_logger)\n",
    "feature_tracer = Tracer(\"feature-store\", feature_logger)\n",
    "model_tracer = Tracer(\"ml-model-serving\", model_logger)\n",
    "db_tracer = Tracer(\"postgres\", db_logger)\n",
    "\n",
    "print(\"\\nüìä Processing prediction request for device DEV-789\")\n",
    "\n",
    "# API Gateway\n",
    "trace_id_2 = f\"trace-{uuid.uuid4().hex[:16]}\"\n",
    "api_span = api_tracer.start_span(\"handle_prediction_request\", trace_id=trace_id_2)\n",
    "\n",
    "api_logger.info(\n",
    "    \"Prediction request received\",\n",
    "    trace_id=trace_id_2,\n",
    "    span_id=api_span.span_id,\n",
    "    user_id=\"user-456\",\n",
    "    device_id=\"DEV-789\",\n",
    "    http_method=\"POST\",\n",
    "    http_path=\"/api/v1/predict\"\n",
    ")\n",
    "\n",
    "# Feature Store Query\n",
    "feature_span = feature_tracer.start_span(\n",
    "    \"fetch_features\",\n",
    "    trace_id=trace_id_2,\n",
    "    parent_span_id=api_span.span_id\n",
    ")\n",
    "\n",
    "feature_logger.info(\n",
    "    \"Fetching device features\",\n",
    "    trace_id=trace_id_2,\n",
    "    span_id=feature_span.span_id,\n",
    "    device_id=\"DEV-789\",\n",
    "    feature_count=120\n",
    ")\n",
    "\n",
    "time.sleep(0.015)\n",
    "feature_tracer.end_span(\n",
    "    feature_span,\n",
    "    features_fetched=120,\n",
    "    cache_hit=False\n",
    ")\n",
    "\n",
    "# Model Inference\n",
    "model_span = model_tracer.start_span(\n",
    "    \"predict_yield\",\n",
    "    trace_id=trace_id_2,\n",
    "    parent_span_id=api_span.span_id\n",
    ")\n",
    "\n",
    "model_logger.info(\n",
    "    \"Running model inference\",\n",
    "    trace_id=trace_id_2,\n",
    "    span_id=model_span.span_id,\n",
    "    model_name=\"yield_predictor\",\n",
    "    model_version=\"v2.1\",\n",
    "    device_id=\"DEV-789\"\n",
    ")\n",
    "\n",
    "time.sleep(0.025)\n",
    "\n",
    "model_logger.info(\n",
    "    \"Model prediction complete\",\n",
    "    trace_id=trace_id_2,\n",
    "    span_id=model_span.span_id,\n",
    "    prediction=0.87,\n",
    "    confidence=0.92\n",
    ")\n",
    "\n",
    "model_tracer.end_span(\n",
    "    model_span,\n",
    "    prediction=0.87,\n",
    "    confidence=0.92,\n",
    "    model_version=\"v2.1\"\n",
    ")\n",
    "\n",
    "# Database Write\n",
    "db_span = db_tracer.start_span(\n",
    "    \"insert_prediction\",\n",
    "    trace_id=trace_id_2,\n",
    "    parent_span_id=api_span.span_id\n",
    ")\n",
    "\n",
    "db_logger.info(\n",
    "    \"Storing prediction result\",\n",
    "    trace_id=trace_id_2,\n",
    "    span_id=db_span.span_id,\n",
    "    device_id=\"DEV-789\",\n",
    "    prediction=0.87\n",
    ")\n",
    "\n",
    "time.sleep(0.012)\n",
    "db_tracer.end_span(db_span, rows_inserted=1)\n",
    "\n",
    "# Complete API request\n",
    "api_tracer.end_span(\n",
    "    api_span,\n",
    "    total_latency_ms=52.0,\n",
    "    status_code=200\n",
    ")\n",
    "\n",
    "api_logger.info(\n",
    "    \"Prediction request completed successfully\",\n",
    "    trace_id=trace_id_2,\n",
    "    span_id=api_span.span_id,\n",
    "    total_latency_ms=52.0,\n",
    "    status=\"success\"\n",
    ")\n",
    "\n",
    "# Demonstrate Log-to-Trace Correlation\n",
    "print(f\"\\n\\n{'=' * 70}\")\n",
    "print(\"Log-to-Trace Correlation (Jump from Logs to Jaeger)\")\n",
    "print(f\"{'=' * 70}\")\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£ User searches logs in Kibana:\")\n",
    "print(f\"   Query: level:INFO AND model_version:v2.1\")\n",
    "print(f\"\\n2Ô∏è‚É£ User clicks on log entry with trace_id: {trace_id_2}\")\n",
    "print(f\"\\n3Ô∏è‚É£ Kibana redirects to Jaeger UI with trace_id: {trace_id_2}\")\n",
    "print(f\"\\n4Ô∏è‚É£ Jaeger shows complete trace timeline:\")\n",
    "\n",
    "# Show trace timeline\n",
    "all_spans = (api_tracer.spans + feature_tracer.spans + \n",
    "             model_tracer.spans + db_tracer.spans)\n",
    "trace_spans = [s for s in all_spans if s.trace_id == trace_id_2]\n",
    "\n",
    "print(f\"\\n{'Service':<25} {'Operation':<30} {'Duration (ms)':<15}\")\n",
    "print(\"=\" * 70)\n",
    "for span in sorted(trace_spans, key=lambda s: s.start_time):\n",
    "    print(f\"{span.service_name:<25} {span.operation_name:<30} {span.duration_ms:<15.2f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Logging and tracing integration demonstrated!\")\n",
    "print(f\"   - Structured JSON logs with trace_id for correlation\")\n",
    "print(f\"   - Distributed tracing across 4 services\")\n",
    "print(f\"   - Bi-directional correlation (logs ‚Üî traces)\")\n",
    "print(f\"   - Queryable fields for debugging and analytics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3e0c38",
   "metadata": {},
   "source": [
    "## 3. üîç ELK Stack - Centralized Log Management\n",
    "\n",
    "**Purpose:** Build centralized logging infrastructure with Elasticsearch (storage), Logstash (processing), and Kibana (visualization).\n",
    "\n",
    "**Key Components:**\n",
    "- **Elasticsearch**: Distributed search engine with full-text indexing, real-time search, and aggregations\n",
    "- **Logstash**: Log pipeline for parsing (grok patterns), filtering (field extraction), and enrichment (geoip, user-agent)\n",
    "- **Kibana**: Visualization platform with dashboards, search, and alerting\n",
    "- **Index management**: Index templates, retention policies, rollover strategies\n",
    "\n",
    "**Why ELK Stack?**\n",
    "- **Centralization**: Collect logs from 100+ services into single searchable index\n",
    "- **Performance**: Query 100M logs in <1 second with proper indexing\n",
    "- **Flexibility**: Support structured (JSON) and unstructured (text) logs\n",
    "- **Visualization**: Build real-time dashboards for monitoring and debugging\n",
    "\n",
    "**Post-Silicon Application:**\n",
    "\n",
    "**Scenario:** STDF processing pipeline generates 50GB logs/day across 20 services. Debug test failures, track processing performance, and monitor data quality.\n",
    "\n",
    "**Implementation:**\n",
    "1. **Logstash pipeline**: Parse STDF logs, extract device_id/wafer_lot/test_name fields\n",
    "2. **Elasticsearch index**: `stdf-logs-YYYY.MM.DD` with 7-day retention\n",
    "3. **Kibana dashboard**: Test failure rates, processing latency P95, data quality metrics\n",
    "4. **Alerting**: Trigger when test failure rate >5% or processing latency >60s\n",
    "\n",
    "**Example Query:**\n",
    "```\n",
    "GET /stdf-logs-*/_search\n",
    "{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\"term\": {\"level\": \"ERROR\"}},\n",
    "        {\"term\": {\"service\": \"stdf-parser\"}},\n",
    "        {\"range\": {\"@timestamp\": {\"gte\": \"now-1h\"}}}\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"aggs\": {\n",
    "    \"top_errors\": {\n",
    "      \"terms\": {\"field\": \"error_type.keyword\", \"size\": 10}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Value:** 80% faster debugging ($1.5M/year) + proactive alerting prevents 50 test equipment failures/year ($500K savings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fcd2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELK Stack Simulation - Elasticsearch, Logstash, Kibana\n",
    "\n",
    "class ElasticsearchIndex:\n",
    "    \"\"\"Simulates Elasticsearch index\"\"\"\n",
    "    \n",
    "    def __init__(self, index_name: str):\n",
    "        self.index_name = index_name\n",
    "        self.documents: List[Dict[str, Any]] = []\n",
    "    \n",
    "    def index_document(self, doc_id: str, document: Dict[str, Any]):\n",
    "        \"\"\"Index document (simulating Elasticsearch indexing)\"\"\"\n",
    "        document['_id'] = doc_id\n",
    "        document['_index'] = self.index_name\n",
    "        self.documents.append(document)\n",
    "    \n",
    "    def search(self, query: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search documents (simulating Elasticsearch query)\"\"\"\n",
    "        results = self.documents\n",
    "        \n",
    "        # Simple query implementation\n",
    "        if 'query' in query:\n",
    "            bool_query = query['query'].get('bool', {})\n",
    "            \n",
    "            # Must clauses (AND)\n",
    "            for must_clause in bool_query.get('must', []):\n",
    "                if 'term' in must_clause:\n",
    "                    field, value = list(must_clause['term'].items())[0]\n",
    "                    results = [doc for doc in results if doc.get(field) == value]\n",
    "                elif 'range' in must_clause:\n",
    "                    field, range_cond = list(must_clause['range'].items())[0]\n",
    "                    # Simplified range check\n",
    "                    results = [doc for doc in results \n",
    "                              if 'gte' not in range_cond or doc.get(field, 0) >= range_cond['gte']]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def aggregate(self, query: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Run aggregations (simulating Elasticsearch aggregations)\"\"\"\n",
    "        results = self.search(query)\n",
    "        aggregations = {}\n",
    "        \n",
    "        if 'aggs' in query:\n",
    "            for agg_name, agg_spec in query['aggs'].items():\n",
    "                if 'terms' in agg_spec:\n",
    "                    field = agg_spec['terms']['field'].replace('.keyword', '')\n",
    "                    size = agg_spec['terms'].get('size', 10)\n",
    "                    \n",
    "                    # Count by field value\n",
    "                    counts = {}\n",
    "                    for doc in results:\n",
    "                        value = doc.get(field, 'unknown')\n",
    "                        counts[value] = counts.get(value, 0) + 1\n",
    "                    \n",
    "                    # Sort and limit\n",
    "                    sorted_buckets = sorted(counts.items(), key=lambda x: x[1], reverse=True)[:size]\n",
    "                    aggregations[agg_name] = {\n",
    "                        'buckets': [{'key': k, 'doc_count': v} for k, v in sorted_buckets]\n",
    "                    }\n",
    "        \n",
    "        return aggregations\n",
    "\n",
    "class LogstashPipeline:\n",
    "    \"\"\"Simulates Logstash processing pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, es_index: ElasticsearchIndex):\n",
    "        self.es_index = es_index\n",
    "    \n",
    "    def process_log(self, log_entry: LogEntry):\n",
    "        \"\"\"Process and enrich log entry\"\"\"\n",
    "        # Convert log to Elasticsearch document\n",
    "        doc = {\n",
    "            '@timestamp': log_entry.timestamp.isoformat(),\n",
    "            'level': log_entry.level.value,\n",
    "            'service': log_entry.service,\n",
    "            'message': log_entry.message,\n",
    "            'trace_id': log_entry.trace_id,\n",
    "            'span_id': log_entry.span_id,\n",
    "            **log_entry.fields\n",
    "        }\n",
    "        \n",
    "        # Enrich document\n",
    "        doc['@ingestion_time'] = datetime.now().isoformat()\n",
    "        doc['index_name'] = self.es_index.index_name\n",
    "        \n",
    "        # Index to Elasticsearch\n",
    "        doc_id = f\"{log_entry.service}-{uuid.uuid4().hex[:8]}\"\n",
    "        self.es_index.index_document(doc_id, doc)\n",
    "\n",
    "class KibanaQuery:\n",
    "    \"\"\"Simulates Kibana query interface\"\"\"\n",
    "    \n",
    "    def __init__(self, es_index: ElasticsearchIndex):\n",
    "        self.es_index = es_index\n",
    "    \n",
    "    def search(self, lucene_query: str, time_range: str = \"now-24h\") -> List[Dict[str, Any]]:\n",
    "        \"\"\"Simplified Lucene query parser\"\"\"\n",
    "        # Parse simple queries like \"level:ERROR AND service:stdf-parser\"\n",
    "        filters = []\n",
    "        \n",
    "        for part in lucene_query.split(' AND '):\n",
    "            part = part.strip()\n",
    "            if ':' in part:\n",
    "                field, value = part.split(':', 1)\n",
    "                filters.append({'term': {field: value}})\n",
    "        \n",
    "        es_query = {\n",
    "            'query': {\n",
    "                'bool': {\n",
    "                    'must': filters\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return self.es_index.search(es_query)\n",
    "    \n",
    "    def visualize_error_trends(self, service: str = None):\n",
    "        \"\"\"Create error trend visualization\"\"\"\n",
    "        query = {\n",
    "            'query': {\n",
    "                'bool': {\n",
    "                    'must': [{'term': {'level': 'ERROR'}}]\n",
    "                }\n",
    "            },\n",
    "            'aggs': {\n",
    "                'errors_by_service': {\n",
    "                    'terms': {'field': 'service', 'size': 10}\n",
    "                },\n",
    "                'errors_by_type': {\n",
    "                    'terms': {'field': 'error_type', 'size': 10}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if service:\n",
    "            query['query']['bool']['must'].append({'term': {'service': service}})\n",
    "        \n",
    "        return self.es_index.aggregate(query)\n",
    "\n",
    "# Example 3: ELK Stack in Action\n",
    "print(\"=\" * 70)\n",
    "print(\"Example 3: ELK Stack - Centralized Logging for STDF Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create ELK stack\n",
    "es_index = ElasticsearchIndex(index_name=\"stdf-logs-2025.01\")\n",
    "logstash = LogstashPipeline(es_index)\n",
    "kibana = KibanaQuery(es_index)\n",
    "\n",
    "# Create services\n",
    "services = {\n",
    "    'stdf-parser': StructuredLogger('stdf-parser'),\n",
    "    'ml-model': StructuredLogger('ml-model'),\n",
    "    'database': StructuredLogger('database'),\n",
    "    'api-gateway': StructuredLogger('api-gateway')\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Simulating 24 hours of STDF processing logs...\")\n",
    "\n",
    "# Generate sample logs\n",
    "trace_id_elk = f\"trace-{uuid.uuid4().hex[:16]}\"\n",
    "\n",
    "# Normal processing logs\n",
    "services['api-gateway'].info(\n",
    "    \"STDF file upload request\",\n",
    "    trace_id=trace_id_elk,\n",
    "    file_name=\"wafer_W12345.stdf\",\n",
    "    file_size_mb=500,\n",
    "    user_id=\"user-123\"\n",
    ")\n",
    "\n",
    "# Parser warnings\n",
    "for i in range(3):\n",
    "    services['stdf-parser'].warning(\n",
    "        \"Missing optional field in STDF record\",\n",
    "        trace_id=trace_id_elk,\n",
    "        record_id=f\"REC-{i}\",\n",
    "        wafer_lot=\"W-12345\",\n",
    "        missing_field=\"SITE_NUM\"\n",
    "    )\n",
    "\n",
    "# Parser errors\n",
    "for i in range(5):\n",
    "    services['stdf-parser'].error(\n",
    "        \"Voltage parameter out of range\",\n",
    "        trace_id=trace_id_elk,\n",
    "        record_id=f\"REC-{100+i}\",\n",
    "        wafer_lot=\"W-12345\",\n",
    "        error_type=\"ValidationError\",\n",
    "        parameter=\"voltage\",\n",
    "        value=20.0 + i,\n",
    "        expected_range=\"[-5V, 15V]\"\n",
    "    )\n",
    "\n",
    "# ML model errors\n",
    "services['ml-model'].error(\n",
    "    \"Model prediction failed due to missing features\",\n",
    "    trace_id=trace_id_elk,\n",
    "    error_type=\"FeatureError\",\n",
    "    model_version=\"v2.1\",\n",
    "    missing_features=[\"voltage_mean\", \"current_stddev\"]\n",
    ")\n",
    "\n",
    "# Database errors\n",
    "services['database'].error(\n",
    "    \"Connection timeout to PostgreSQL\",\n",
    "    trace_id=trace_id_elk,\n",
    "    error_type=\"ConnectionError\",\n",
    "    database_host=\"postgres-prod-1\",\n",
    "    timeout_ms=5000\n",
    ")\n",
    "\n",
    "# Send all logs to Logstash\n",
    "print(f\"\\nüì§ Sending {sum(len(logger.logs) for logger in services.values())} logs to Logstash pipeline...\")\n",
    "for service_logger in services.values():\n",
    "    for log in service_logger.logs:\n",
    "        logstash.process_log(log)\n",
    "\n",
    "print(f\"‚úÖ {len(es_index.documents)} documents indexed in Elasticsearch\")\n",
    "\n",
    "# Kibana Query 1: Search for errors\n",
    "print(f\"\\n\\n{'=' * 70}\")\n",
    "print(\"Kibana Query 1: All ERROR logs in last 24 hours\")\n",
    "print(f\"{'=' * 70}\")\n",
    "print(\"Query: level:ERROR\")\n",
    "\n",
    "error_results = kibana.search(\"level:ERROR\")\n",
    "print(f\"\\nFound {len(error_results)} error logs:\")\n",
    "for result in error_results[:3]:\n",
    "    print(f\"\\n  Service: {result['service']}\")\n",
    "    print(f\"  Message: {result['message']}\")\n",
    "    print(f\"  Trace ID: {result.get('trace_id', 'N/A')}\")\n",
    "    if 'error_type' in result:\n",
    "        print(f\"  Error Type: {result['error_type']}\")\n",
    "\n",
    "# Kibana Query 2: Service-specific errors\n",
    "print(f\"\\n\\n{'=' * 70}\")\n",
    "print(\"Kibana Query 2: STDF Parser errors\")\n",
    "print(f\"{'=' * 70}\")\n",
    "print(\"Query: level:ERROR AND service:stdf-parser\")\n",
    "\n",
    "parser_errors = kibana.search(\"level:ERROR AND service:stdf-parser\")\n",
    "print(f\"\\nFound {len(parser_errors)} parser errors\")\n",
    "\n",
    "# Kibana Visualization: Error trends\n",
    "print(f\"\\n\\n{'=' * 70}\")\n",
    "print(\"Kibana Visualization: Error Distribution\")\n",
    "print(f\"{'=' * 70}\")\n",
    "\n",
    "error_trends = kibana.visualize_error_trends()\n",
    "print(\"\\nüìä Errors by Service:\")\n",
    "for bucket in error_trends['errors_by_service']['buckets']:\n",
    "    print(f\"  {bucket['key']}: {bucket['doc_count']} errors\")\n",
    "\n",
    "print(\"\\nüìä Errors by Type:\")\n",
    "for bucket in error_trends['errors_by_type']['buckets']:\n",
    "    print(f\"  {bucket['key']}: {bucket['doc_count']} errors\")\n",
    "\n",
    "# Advanced: Trace-based log aggregation\n",
    "print(f\"\\n\\n{'=' * 70}\")\n",
    "print(\"Advanced Query: All logs for specific trace\")\n",
    "print(f\"{'=' * 70}\")\n",
    "print(f\"Query: trace_id:{trace_id_elk}\")\n",
    "\n",
    "trace_logs_elk = [doc for doc in es_index.documents if doc.get('trace_id') == trace_id_elk]\n",
    "print(f\"\\nFound {len(trace_logs_elk)} logs for trace {trace_id_elk}\")\n",
    "print(f\"\\nüìà Log Level Distribution:\")\n",
    "level_counts = {}\n",
    "for log in trace_logs_elk:\n",
    "    level = log['level']\n",
    "    level_counts[level] = level_counts.get(level, 0) + 1\n",
    "\n",
    "for level, count in sorted(level_counts.items()):\n",
    "    print(f\"  {level}: {count} logs\")\n",
    "\n",
    "print(f\"\\n‚úÖ ELK Stack demonstration complete!\")\n",
    "print(f\"   - Centralized logging from 4 services\")\n",
    "print(f\"   - Full-text search with Kibana queries\")\n",
    "print(f\"   - Aggregations for error analysis\")\n",
    "print(f\"   - Trace-based log correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df5df9",
   "metadata": {},
   "source": [
    "## 4. üî¨ Real-World Projects: Production Logging & Tracing\n",
    "\n",
    "### Project 1: **Centralized Logging Platform with Log Retention** üí∞ **$2.1M/year**\n",
    "**Objective:** Build multi-tenant logging platform with 90-day retention, supporting 500GB logs/day across 200 services.\n",
    "\n",
    "**Key Features:**\n",
    "- **ELK Stack**: Elasticsearch cluster (10 nodes, 20TB storage), Logstash (5 pipeline workers), Kibana (multi-tenant dashboards)\n",
    "- **Index lifecycle management**: Hot (7 days SSD), Warm (30 days HDD), Cold (90 days object storage), Delete\n",
    "- **Retention policies**: Production logs 90 days, staging logs 30 days, development logs 7 days\n",
    "- **Access control**: Role-based access (developers see own team logs, SRE see all logs)\n",
    "\n",
    "**Business Value:**\n",
    "- 90% faster debugging with centralized search ($1.5M/year from reduced MTTR: 4h ‚Üí 24min)\n",
    "- Compliance audit trail for SOC2/ISO27001 ($400K/year from automated compliance)\n",
    "- Proactive alerting prevents 30 severity-1 incidents/year ($200K/year from reduced downtime)\n",
    "\n",
    "---\n",
    "\n",
    "### Project 2: **Distributed Tracing with Jaeger for Microservices** üí∞ **$1.8M/year**\n",
    "**Objective:** Implement distributed tracing for 50-service architecture, tracking 10M requests/day with <0.1% overhead.\n",
    "\n",
    "**Key Features:**\n",
    "- **OpenTelemetry instrumentation**: Auto-instrumentation for Python/Java/Node.js services\n",
    "- **Jaeger backend**: Cassandra storage (30-day retention), Spark analytics for trace aggregation\n",
    "- **Sampling strategies**: Probabilistic (1% baseline), rate-limiting (100 traces/sec), error-based (100% errors)\n",
    "- **Performance monitoring**: P50/P95/P99 latency by service, critical path analysis, dependency graphs\n",
    "\n",
    "**Business Value:**\n",
    "- 80% reduction in latency investigation time ($950K/year from faster root cause analysis)\n",
    "- Identify and fix 15 performance bottlenecks/quarter ($600K/year from optimizations)\n",
    "- Capacity planning insights reduce infrastructure costs 20% ($250K/year savings)\n",
    "\n",
    "---\n",
    "\n",
    "### Project 3: **Log-Trace Correlation for Unified Debugging** üí∞ **$1.5M/year**\n",
    "**Objective:** Integrate logs and traces with trace_id correlation, enabling seamless debugging across both signals.\n",
    "\n",
    "**Key Features:**\n",
    "- **trace_id injection**: Automatic trace context propagation (W3C Trace Context standard)\n",
    "- **Kibana-Jaeger integration**: Click trace_id in Kibana ‚Üí open Jaeger UI, click span in Jaeger ‚Üí show logs\n",
    "- **Correlated alerts**: Alert on ERROR logs with trace_id, link to full trace in Jaeger\n",
    "- **Unified search**: Search logs by trace_id, show trace timeline with log events overlaid\n",
    "\n",
    "**Business Value:**\n",
    "- 85% faster incident resolution ($1.1M/year from reduced MTTR: 90min ‚Üí 13min)\n",
    "- 50% reduction in alert noise with context-aware alerts ($300K/year from reduced on-call burden)\n",
    "- Improved observability ROI: 3x debugging efficiency ($100K/year from team productivity)\n",
    "\n",
    "---\n",
    "\n",
    "### Project 4: **ML Model Observability with Structured Logging** üí∞ **$1.2M/year**\n",
    "**Objective:** Log all ML model predictions with structured format, enabling model performance analysis and debugging.\n",
    "\n",
    "**Key Features:**\n",
    "- **Prediction logging**: Every prediction logged with model_version, features, prediction, confidence, latency_ms\n",
    "- **Model drift detection**: Daily aggregation of prediction distribution, alert on >10% shift from baseline\n",
    "- **Feature importance tracking**: Log feature values, identify which features drive prediction changes\n",
    "- **A/B test analysis**: Compare model versions with structured queries (v2.1 vs v2.0 accuracy)\n",
    "\n",
    "**Business Value:**\n",
    "- Detect model drift 7 days faster ($750K/year from preventing accuracy degradation: 93% maintained vs 85%)\n",
    "- Debug model failures 90% faster ($350K/year from trace_id ‚Üí feature values)\n",
    "- A/B testing enables 5% accuracy improvement ($100K/year from better model selection)\n",
    "\n",
    "---\n",
    "\n",
    "### Project 5: **Compliance Audit Trail with Immutable Logs** üí∞ **$950K/year**\n",
    "**Objective:** Build tamper-proof audit trail for GDPR/HIPAA compliance, tracking all data access and modifications.\n",
    "\n",
    "**Key Features:**\n",
    "- **Immutable logging**: Append-only log storage with cryptographic signatures (SHA-256 hash chain)\n",
    "- **Compliance fields**: Log user_id, action, resource_id, timestamp, IP address, reason for every data access\n",
    "- **Audit reports**: Generate compliance reports (who accessed patient data, when, why) in <1 hour\n",
    "- **Retention policies**: Compliance logs retained 7 years (legal requirement), archived to S3 Glacier\n",
    "\n",
    "**Business Value:**\n",
    "- Automated compliance reduces audit preparation 95% ($600K/year from 3 weeks ‚Üí 1 day)\n",
    "- Tamper-proof logs prevent $300K/year in compliance fines (SOC2 violations avoided)\n",
    "- Data breach investigation 10x faster ($50K/year from faster incident response)\n",
    "\n",
    "---\n",
    "\n",
    "### Project 6: **Real-Time Anomaly Detection from Logs** üí∞ **$850K/year**\n",
    "**Objective:** Use log analytics to detect anomalies (error spikes, latency increases) and alert 10min before user impact.\n",
    "\n",
    "**Key Features:**\n",
    "- **Streaming analytics**: Kafka ‚Üí Flink streaming job ‚Üí Elasticsearch (log ingestion in <5 seconds)\n",
    "- **Anomaly detection**: Statistical baselines (P95 error rate, P99 latency), ML-based anomaly detection (Isolation Forest)\n",
    "- **Predictive alerting**: Alert when error rate trending toward SLA breach (predict 10min ahead)\n",
    "- **Auto-remediation**: Trigger auto-scaling when latency >200ms for 5min (Kubernetes HPA)\n",
    "\n",
    "**Business Value:**\n",
    "- Prevent 40 severity-1 incidents/year with predictive alerts ($650K/year from avoided downtime)\n",
    "- Reduce false positives 70% with ML anomaly detection ($150K/year from reduced alert fatigue)\n",
    "- Auto-remediation reduces manual intervention 80% ($50K/year from SRE time savings)\n",
    "\n",
    "---\n",
    "\n",
    "### Project 7: **Multi-Region Log Aggregation** üí∞ **$720K/year**\n",
    "**Objective:** Aggregate logs from 5 AWS regions into centralized platform, supporting global debugging and compliance.\n",
    "\n",
    "**Key Features:**\n",
    "- **Regional Logstash**: Logstash in each region (us-east-1, eu-west-1, ap-south-1), local buffering for network failures\n",
    "- **Cross-region replication**: Elasticsearch cross-cluster replication (CCR) with <30s lag\n",
    "- **Geo-routing**: Kibana auto-routes to closest Elasticsearch cluster (minimize query latency)\n",
    "- **Compliance**: EU logs stored in eu-west-1 (GDPR data residency requirement)\n",
    "\n",
    "**Business Value:**\n",
    "- Unified debugging across regions saves 2 hours/incident ($500K/year from faster multi-region issues)\n",
    "- GDPR compliance prevents $150K/year in fines (data residency violations avoided)\n",
    "- Disaster recovery: 99.99% log availability with multi-region redundancy ($70K/year from resilience)\n",
    "\n",
    "---\n",
    "\n",
    "### Project 8: **Log-Based Security Monitoring (SIEM)** üí∞ **$680K/year**\n",
    "**Objective:** Build Security Information and Event Management (SIEM) system with log-based threat detection.\n",
    "\n",
    "**Key Features:**\n",
    "- **Security log sources**: Application logs, AWS CloudTrail, Kubernetes audit logs, WAF logs\n",
    "- **Threat detection rules**: Brute force login attempts (>10 failed logins/min), privilege escalation, data exfiltration (>10GB transfer)\n",
    "- **MITRE ATT&CK mapping**: Categorize threats by tactics (Initial Access, Persistence, Lateral Movement)\n",
    "- **Automated response**: Block IP after 20 failed logins, revoke API keys on suspicious activity\n",
    "\n",
    "**Business Value:**\n",
    "- Detect security incidents 10x faster ($450K/year from reduced breach impact: 48h ‚Üí 4.8h detection)\n",
    "- Prevent 5 security incidents/year with automated blocking ($180K/year from avoided breaches)\n",
    "- Compliance: SOC2 requirement for centralized security monitoring ($50K/year from audit pass)\n",
    "\n",
    "---\n",
    "\n",
    "## üí∞ **Total Project Value: $10.72M/year**\n",
    "**Average ROI: 450% (infrastructure costs ~$2.4M/year, value $10.72M/year)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015ad3f",
   "metadata": {},
   "source": [
    "## 5. üéØ Comprehensive Takeaways: Logging & Tracing Mastery\n",
    "\n",
    "### **Core Concepts**\n",
    "\n",
    "**Structured Logging:**\n",
    "- ‚úÖ **JSON format** with standardized fields (`timestamp`, `level`, `message`, `trace_id`, `service`)\n",
    "- ‚úÖ **Contextual enrichment** (user_id, model_version, request_id) enables powerful filtering\n",
    "- ‚úÖ **Log levels** (DEBUG/INFO/WARNING/ERROR/CRITICAL) for severity-based routing\n",
    "- ‚úÖ **Correlation** via trace_id links logs across distributed services\n",
    "\n",
    "**ELK Stack:**\n",
    "- ‚úÖ **Elasticsearch** for log storage with full-text indexing (100M logs searchable in <1s)\n",
    "- ‚úÖ **Logstash** for log parsing (grok patterns), filtering (extract fields), enrichment (geoip)\n",
    "- ‚úÖ **Kibana** for visualization (dashboards, search, alerting, saved queries)\n",
    "- ‚úÖ **Index lifecycle** (hot/warm/cold tiers) optimizes storage costs (SSD ‚Üí HDD ‚Üí object storage)\n",
    "\n",
    "**Distributed Tracing:**\n",
    "- ‚úÖ **Spans** represent individual operations with duration, parent relationships, tags\n",
    "- ‚úÖ **Traces** are collections of spans forming complete request journey\n",
    "- ‚úÖ **Context propagation** (W3C Trace Context) passes trace_id across service boundaries\n",
    "- ‚úÖ **Sampling strategies** (probabilistic 1%, error-based 100%) balance cost and coverage\n",
    "\n",
    "**Log-Trace Correlation:**\n",
    "- ‚úÖ **Bi-directional linking** (logs ‚Üí traces via trace_id, traces ‚Üí logs via span_id)\n",
    "- ‚úÖ **Unified debugging** (click log in Kibana ‚Üí open Jaeger, click span ‚Üí show logs)\n",
    "- ‚úÖ **Complete context** (trace shows \"what took time\", logs show \"why it failed\")\n",
    "\n",
    "---\n",
    "\n",
    "### **Best Practices**\n",
    "\n",
    "**Structured Logging:**\n",
    "- ‚úÖ Use consistent field names across all services (`user_id`, not `userId` vs `user_identifier`)\n",
    "- ‚úÖ Include trace_id in every log for correlation (auto-inject from OpenTelemetry context)\n",
    "- ‚úÖ Log meaningful context, not just error messages (`device_id`, `model_version`, `feature_values`)\n",
    "- ‚úÖ Avoid logging sensitive data (PII, API keys, passwords) or redact with `***`\n",
    "- ‚úÖ Use appropriate log levels (INFO for business events, ERROR for failures requiring action)\n",
    "\n",
    "**ELK Stack:**\n",
    "- ‚úÖ Use index templates for consistent field mappings (define `@timestamp` as date, `trace_id` as keyword)\n",
    "- ‚úÖ Implement retention policies (hot 7 days, warm 30 days, cold 90 days) to control storage costs\n",
    "- ‚úÖ Optimize queries with field filters (`term` queries) before full-text search (`match` queries)\n",
    "- ‚úÖ Use aggregations for analytics (error counts, P95 latency, top failing services)\n",
    "- ‚úÖ Monitor Elasticsearch cluster health (heap usage <75%, disk usage <85%, search latency <100ms)\n",
    "\n",
    "**Distributed Tracing:**\n",
    "- ‚úÖ Use auto-instrumentation libraries (OpenTelemetry for Python/Java/Node.js) to reduce manual effort\n",
    "- ‚úÖ Sample intelligently: 1% baseline + 100% errors + 100% slow requests (>1s) balances cost and coverage\n",
    "- ‚úÖ Tag spans with meaningful metadata (`http.status_code`, `db.statement`, `model.version`)\n",
    "- ‚úÖ Minimize span count (5-20 spans per trace) to reduce overhead and storage costs\n",
    "- ‚úÖ Set trace retention based on value (production 30 days, staging 7 days, development 1 day)\n",
    "\n",
    "**Log-Trace Correlation:**\n",
    "- ‚úÖ Auto-inject trace_id from OpenTelemetry context into all logs (avoid manual passing)\n",
    "- ‚úÖ Include span_id in logs for precise correlation (which span generated which log)\n",
    "- ‚úÖ Link Kibana and Jaeger UIs for seamless navigation (URL templates with trace_id)\n",
    "- ‚úÖ Use trace_id in alerts (include Jaeger link in PagerDuty/Slack notifications)\n",
    "\n",
    "---\n",
    "\n",
    "### **Advanced Patterns**\n",
    "\n",
    "**Log Sampling:**\n",
    "- For high-volume services (>10K logs/sec), sample DEBUG logs (10%) and keep 100% of ERROR/WARNING logs\n",
    "- Use consistent hashing on trace_id for deterministic sampling (same trace always sampled/dropped)\n",
    "\n",
    "**Tail-Based Sampling:**\n",
    "- Buffer traces in memory for 10 seconds, then decide to keep/drop based on outcome (errors, slow latency)\n",
    "- Keeps 100% of interesting traces while dropping 99% of \"happy path\" traces\n",
    "\n",
    "**Trace-Based Testing:**\n",
    "- Record production traces, replay in test environment to validate behavior under real conditions\n",
    "- Compare trace structure (span count, durations, error rates) between releases (detect regressions)\n",
    "\n",
    "**Log-Driven Alerts:**\n",
    "- Alert on log patterns (ERROR rate >10/min, specific error type \"OutOfMemoryError\", missing expected logs)\n",
    "- Correlate alerts with traces (if alert fires, auto-fetch related traces for context)\n",
    "\n",
    "**Cost Optimization:**\n",
    "- Archive old logs to S3 Glacier (90 days+) for compliance at 1/100th storage cost ($0.004/GB vs $0.10/GB SSD)\n",
    "- Use tiered sampling (production 1%, staging 0.1%, development 0.01%) to reduce trace storage\n",
    "- Compress logs in Logstash (gzip reduces size 5-10x) before sending to Elasticsearch\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Pitfalls**\n",
    "\n",
    "**Logging Mistakes:**\n",
    "- ‚ùå Logging secrets (API keys, passwords) exposes vulnerabilities ‚Üí Use redaction `\"api_key\": \"***\"`\n",
    "- ‚ùå High-cardinality fields (user_id with 10M values) as indexed fields ‚Üí Elasticsearch OOM\n",
    "- ‚ùå Logging too much (DEBUG logs in production) wastes storage ‚Üí Use log levels and sampling\n",
    "- ‚ùå Unstructured logs (\"User 123 did thing\") hard to query ‚Üí Use JSON with structured fields\n",
    "\n",
    "**ELK Mistakes:**\n",
    "- ‚ùå No retention policies ‚Üí Elasticsearch disk fills up ‚Üí Cluster failure\n",
    "- ‚ùå Indexing all fields ‚Üí High memory usage ‚Üí Slow queries ‚Üí Use selective field mapping\n",
    "- ‚ùå No index rollover ‚Üí Single 10TB index ‚Üí Slow searches ‚Üí Use daily/weekly indices\n",
    "- ‚ùå Alerting on raw log counts without baseline ‚Üí High false positive rate ‚Üí Alert fatigue\n",
    "\n",
    "**Tracing Mistakes:**\n",
    "- ‚ùå Tracing everything (100% sampling) ‚Üí 100x cost vs 1% sampling ‚Üí Unsustainable at scale\n",
    "- ‚ùå Too many spans (>100 per trace) ‚Üí High overhead ‚Üí Use fewer, coarse-grained spans\n",
    "- ‚ùå Missing context propagation ‚Üí Broken traces ‚Üí Ensure trace_id passed in HTTP headers/message queues\n",
    "- ‚ùå No error tagging ‚Üí Can't filter traces by errors ‚Üí Tag spans with `error=true`\n",
    "\n",
    "**Correlation Mistakes:**\n",
    "- ‚ùå Different trace_id formats across services ‚Üí Can't correlate ‚Üí Standardize on W3C Trace Context\n",
    "- ‚ùå Logging trace_id but not span_id ‚Üí Can't pinpoint which span ‚Üí Include both in logs\n",
    "- ‚ùå No integration between Kibana and Jaeger ‚Üí Manual copy-paste ‚Üí Automate with URL templates\n",
    "\n",
    "---\n",
    "\n",
    "### **Production Checklist**\n",
    "\n",
    "**Before deploying logging & tracing to production:**\n",
    "- ‚úÖ All services emit JSON logs with `timestamp`, `level`, `service`, `message`, `trace_id`\n",
    "- ‚úÖ OpenTelemetry instrumentation auto-injects trace_id into logs (no manual passing)\n",
    "- ‚úÖ Elasticsearch cluster sized for 500GB logs/day (10 nodes, 20TB storage, 64GB RAM/node)\n",
    "- ‚úÖ Index lifecycle policies configured (hot/warm/cold tiers, 90-day retention, auto-delete)\n",
    "- ‚úÖ Logstash pipelines parse and enrich logs (grok patterns tested, field mappings validated)\n",
    "- ‚úÖ Jaeger backend configured with Cassandra storage (30-day retention, compression enabled)\n",
    "- ‚úÖ Sampling strategy defined (1% baseline, 100% errors, 100% slow >1s, tail-based sampling)\n",
    "- ‚úÖ Kibana dashboards created for each service (error rates, latency P95, log volume)\n",
    "- ‚úÖ Alerts configured for critical issues (ERROR rate >10/min, Elasticsearch heap >80%)\n",
    "- ‚úÖ Runbooks link to Kibana/Jaeger queries for common incidents (example trace_id for reference)\n",
    "- ‚úÖ Sensitive data redacted (PII, API keys, passwords replaced with `***`)\n",
    "- ‚úÖ Access control configured (developers see own team logs, SRE see all logs)\n",
    "\n",
    "---\n",
    "\n",
    "### **Troubleshooting Guide**\n",
    "\n",
    "**Problem: Logs not appearing in Kibana**\n",
    "- Check Logstash pipeline status (`curl localhost:9600/_node/stats/pipelines`)\n",
    "- Verify Elasticsearch indexing (`GET /_cat/indices?v`, check doc count increasing)\n",
    "- Check index pattern in Kibana (must match index name `stdf-logs-*`)\n",
    "- Verify @timestamp field format (must be ISO 8601 `2025-01-01T12:00:00Z`)\n",
    "\n",
    "**Problem: Traces missing spans**\n",
    "- Verify context propagation (trace_id in HTTP headers `traceparent: 00-...`)\n",
    "- Check sampling decision (span might be sampled out, check sampling rate)\n",
    "- Ensure parent_span_id set correctly (child spans must reference parent)\n",
    "- Check Jaeger backend connectivity (spans buffered locally if backend down)\n",
    "\n",
    "**Problem: Kibana queries slow (>5s)**\n",
    "- Reduce time range (last 7 days ‚Üí last 24 hours)\n",
    "- Add field filters before full-text search (`service:stdf-parser AND level:ERROR` before `message:timeout`)\n",
    "- Use keyword fields for exact match (`user_id.keyword` instead of `user_id`)\n",
    "- Check Elasticsearch cluster health (`GET /_cluster/health`, should be green)\n",
    "\n",
    "**Problem: High Elasticsearch disk usage**\n",
    "- Enable index lifecycle management (ILM) to archive old indices\n",
    "- Compress logs in Logstash (`gzip` codec reduces size 5-10x)\n",
    "- Reduce retention period (90 days ‚Üí 30 days for non-compliance logs)\n",
    "- Delete unused indices (`DELETE /stdf-logs-2024.*`)\n",
    "\n",
    "**Problem: High trace storage costs**\n",
    "- Reduce sampling rate (1% ‚Üí 0.1% for baseline traffic)\n",
    "- Shorten retention period (30 days ‚Üí 7 days for non-production)\n",
    "- Use tail-based sampling (keep errors/slow requests, drop happy path)\n",
    "- Enable compression in Jaeger storage backend (Cassandra compression saves 50%)\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "\n",
    "**Immediate (Week 1):**\n",
    "- Implement structured logging in 1 service (add trace_id, JSON format, log levels)\n",
    "- Set up local ELK stack (Docker Compose: Elasticsearch, Logstash, Kibana)\n",
    "- Add OpenTelemetry instrumentation to 1 service (auto-inject trace_id, create spans)\n",
    "- Create first Kibana dashboard (error rate, P95 latency, log volume)\n",
    "\n",
    "**Short-term (1-3 months):**\n",
    "- Roll out structured logging to all services (standardize field names, add correlation)\n",
    "- Deploy production ELK cluster (10 nodes, 20TB storage, high availability)\n",
    "- Implement distributed tracing for top 10 critical services (API gateway, ML models, databases)\n",
    "- Set up log-trace correlation (Kibana ‚Üí Jaeger links, trace_id in alerts)\n",
    "- Build runbooks with example Kibana/Jaeger queries for common incidents\n",
    "\n",
    "**Long-term (3-6 months):**\n",
    "- Advanced observability (metrics + logs + traces unified in Grafana)\n",
    "- Implement tail-based sampling (intelligent trace sampling based on outcome)\n",
    "- Build ML-based anomaly detection from logs (predict incidents 10min ahead)\n",
    "- Multi-region log aggregation with cross-cluster replication\n",
    "- Compliance audit trail with immutable logs (7-year retention, cryptographic signatures)\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Metrics to Track**\n",
    "\n",
    "**Logging Metrics:**\n",
    "- Log volume: 500GB/day (baseline), alert if >750GB/day (unexpected spike)\n",
    "- Log ingestion latency: <5 seconds (Logstash ‚Üí Elasticsearch)\n",
    "- Elasticsearch cluster health: Green (all shards allocated, no unassigned shards)\n",
    "- Query latency: P95 <100ms (Kibana search response time)\n",
    "- Index size: Monitor daily growth, alert if >10% increase without expected cause\n",
    "\n",
    "**Tracing Metrics:**\n",
    "- Trace sampling rate: 1% baseline (adjust based on cost/coverage tradeoff)\n",
    "- Trace completeness: >95% of sampled traces have all expected spans (no missing spans)\n",
    "- Trace storage size: 50GB/day (baseline for 10M requests/day at 1% sampling)\n",
    "- Query latency: P95 <200ms (Jaeger trace search response time)\n",
    "- Error trace rate: 100% of errors traced (no sampling for errors)\n",
    "\n",
    "**Business Metrics:**\n",
    "- MTTR reduction: Target 80% reduction (4 hours ‚Üí 48 minutes with logging/tracing)\n",
    "- Incident detection speed: Target 10min before user reports (proactive alerting from logs)\n",
    "- Compliance audit time: Target 95% reduction (3 weeks ‚Üí 1 day with structured logs)\n",
    "- Debugging efficiency: Target 3x improvement (trace shows bottleneck instantly vs manual investigation)\n",
    "\n",
    "---\n",
    "\n",
    "### üéì **Congratulations! You've Mastered Logging & Distributed Tracing!**\n",
    "\n",
    "You can now:\n",
    "- ‚úÖ **Build structured logging** systems with JSON format and trace correlation\n",
    "- ‚úÖ **Deploy ELK stack** for centralized log management (Elasticsearch, Logstash, Kibana)\n",
    "- ‚úÖ **Implement distributed tracing** with OpenTelemetry and Jaeger\n",
    "- ‚úÖ **Correlate logs and traces** for unified debugging (bi-directional navigation)\n",
    "- ‚úÖ **Optimize costs** with sampling strategies, retention policies, and tiered storage\n",
    "- ‚úÖ **Build production observability** platforms with 99.9% reliability and 80% faster debugging\n",
    "\n",
    "**Next Notebook:** 141_Infrastructure_as_Code - Terraform & CloudFormation for automated infrastructure provisioning üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e810e5",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways\n",
    "\n",
    "**When to Use**: Production microservices (>5 services), debugging distributed systems, performance monitoring, compliance/audit trails\n",
    "\n",
    "**Limitations**: High-cardinality logging costly (TB/day storage), trace sampling misses rare bugs, learning curve for query languages (PromQL, Jaeger)\n",
    "\n",
    "**Best Practices**: Structured JSON logging with trace IDs, sample traces 1-10%, centralize with ELK/Loki, correlate logs+traces+metrics for debugging\n",
    "\n",
    "**Post-Silicon Application**: ATE test flow distributed tracing (wafer test ‚Üí final test ‚Üí binning), debug 10x faster, save $2.5M/year\n",
    "\n",
    "## üîç Diagnostic & Mastery\n",
    "\n",
    "‚úÖ Structured logging (JSON) with correlation IDs  \n",
    "‚úÖ Distributed tracing (Jaeger/Zipkin) across services  \n",
    "‚úÖ Log aggregation (ELK stack, Loki)  \n",
    "‚úÖ Trace sampling strategies (1-10%)  \n",
    "‚úÖ Apply to semiconductor test pipelines  \n",
    "\n",
    "**Next**: 139_Observability_Monitoring, 154_Model_Monitoring_Observability\n",
    "\n",
    "## üìà Progress Update\n",
    "\n",
    "**Completed**: 41 notebooks (previous 39 + 140, 142)  \n",
    "**Progress**: ~85.1% (149/175 notebooks ‚â•15 cells)  \n",
    "**Next**: 7-cell and below notebooks ‚Üí 100% completion üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
