{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 143: Security Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import hashlib\n",
    "import hmac\n",
    "import secrets\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Optional, Set\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "\n",
    "print(\"\u2705 Security & Compliance environment ready!\")\n",
    "print(\"\ud83d\udce6 Modules: IAM, Encryption (AES-256, RSA), Audit Trails, Compliance Monitoring\")\n",
    "print(\"\ud83d\udd10 Ready to build secure ML systems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d003e2a",
   "metadata": {},
   "source": [
    "## 2. \ud83d\udd10 IAM (Identity & Access Management) - Least Privilege and RBAC\n",
    "\n",
    "### **Purpose:** Implement role-based access control with least privilege for ML systems\n",
    "\n",
    "**Key Concepts:**\n",
    "- **IAM (Identity and Access Management)**: Controls who (authentication) can do what (authorization) on which resources\n",
    "- **Least Privilege**: Grant minimum permissions needed (read-only analyst vs admin engineer)\n",
    "- **RBAC (Role-Based Access Control)**: Group permissions into roles (data-scientist, ml-engineer, auditor)\n",
    "- **MFA (Multi-Factor Authentication)**: Require 2+ factors (password + YubiKey) for sensitive operations\n",
    "- **Temporary Credentials**: Use time-limited credentials (15-minute session tokens) instead of permanent access keys\n",
    "\n",
    "**IAM Components:**\n",
    "- **Principals**: Users, services, applications that make requests (Alice, SageMaker service, Lambda function)\n",
    "- **Policies**: JSON documents defining permissions (allow s3:GetObject on bucket X)\n",
    "- **Roles**: Collections of policies assigned to principals (data-scientist role has S3 read, SageMaker full access)\n",
    "- **Resources**: AWS/Azure/GCP services being accessed (S3 buckets, SageMaker endpoints, BigQuery datasets)\n",
    "\n",
    "**Why IAM Matters:**\n",
    "- **Prevent insider threats**: 34% of breaches involve insiders (Verizon DBIR 2023), least privilege reduces blast radius\n",
    "- **Enable auditing**: Track who accessed what when (CloudTrail logs all API calls with user identity)\n",
    "- **Simplify compliance**: GDPR/HIPAA require access controls, IAM provides documentation for audits\n",
    "- **Reduce breach impact**: If credentials leaked, attacker limited to assigned role (read-only vs admin)\n",
    "\n",
    "**Post-Silicon Application:**\n",
    "- **ML Engineers**: SageMaker full access, S3 read-write on ml-data/* bucket, no access to production endpoints\n",
    "- **Data Scientists**: SageMaker notebook instances, S3 read-only on stdf-data/* bucket, no model deployment\n",
    "- **DevOps Engineers**: EKS/Lambda deployment, CloudWatch monitoring, no S3 data access\n",
    "- **Auditors**: CloudTrail read-only, S3 access logs read-only, no resource modification\n",
    "\n",
    "**IAM Best Practices:**\n",
    "- \u2705 **Use roles not access keys**: IAM roles provide temporary credentials (15 min - 12 hours), auto-rotate\n",
    "- \u2705 **Enable MFA**: Require MFA for console login, sensitive API calls (DeleteBucket, TerminateInstances)\n",
    "- \u2705 **Audit regularly**: Review IAM policies quarterly, remove unused roles, tighten overly permissive policies\n",
    "- \u2705 **Separate duties**: Dev team can't access production, data scientists can't modify infrastructure\n",
    "- \u2705 **Monitor with alerts**: Alert on suspicious activity (root account login, AccessDenied spike, new IAM user creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IAM Implementation: Role-Based Access Control with Least Privilege\n",
    "\n",
    "class Permission(Enum):\n",
    "    \"\"\"Granular permissions for resources\"\"\"\n",
    "    S3_READ = \"s3:GetObject\"\n",
    "    S3_WRITE = \"s3:PutObject\"\n",
    "    S3_DELETE = \"s3:DeleteObject\"\n",
    "    SAGEMAKER_READ = \"sagemaker:DescribeTrainingJob\"\n",
    "    SAGEMAKER_TRAIN = \"sagemaker:CreateTrainingJob\"\n",
    "    SAGEMAKER_DEPLOY = \"sagemaker:CreateEndpoint\"\n",
    "    CLOUDWATCH_READ = \"cloudwatch:GetMetricData\"\n",
    "    CLOUDTRAIL_READ = \"cloudtrail:LookupEvents\"\n",
    "\n",
    "@dataclass\n",
    "class Policy:\n",
    "    \"\"\"IAM policy with permissions and resources\"\"\"\n",
    "    name: str\n",
    "    permissions: List[Permission]\n",
    "    resources: List[str]  # ARNs: arn:aws:s3:::bucket-name/*\n",
    "    effect: str = \"Allow\"  # Allow or Deny\n",
    "    \n",
    "    def to_json(self) -> Dict:\n",
    "        \"\"\"Convert to AWS IAM policy JSON format\"\"\"\n",
    "        return {\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [{\n",
    "                \"Effect\": self.effect,\n",
    "                \"Action\": [p.value for p in self.permissions],\n",
    "                \"Resource\": self.resources\n",
    "            }]\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class Role:\n",
    "    \"\"\"IAM role aggregating multiple policies\"\"\"\n",
    "    name: str\n",
    "    policies: List[Policy]\n",
    "    requires_mfa: bool = False\n",
    "    max_session_duration: int = 3600  # 1 hour default\n",
    "    \n",
    "    def get_permissions(self) -> Set[Permission]:\n",
    "        \"\"\"Get all permissions from all policies\"\"\"\n",
    "        all_perms = set()\n",
    "        for policy in self.policies:\n",
    "            all_perms.update(policy.permissions)\n",
    "        return all_perms\n",
    "    \n",
    "    def can_perform(self, permission: Permission, resource: str) -> bool:\n",
    "        \"\"\"Check if role can perform permission on resource\"\"\"\n",
    "        for policy in self.policies:\n",
    "            if permission in policy.permissions:\n",
    "                # Check if resource matches (simple prefix matching)\n",
    "                for allowed_resource in policy.resources:\n",
    "                    if resource.startswith(allowed_resource.replace('/*', '')):\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "@dataclass\n",
    "class User:\n",
    "    \"\"\"IAM user with assigned roles\"\"\"\n",
    "    username: str\n",
    "    roles: List[Role]\n",
    "    mfa_enabled: bool = False\n",
    "    \n",
    "    def assume_role(self, role_name: str) -> Optional[Role]:\n",
    "        \"\"\"Assume a role (get temporary credentials)\"\"\"\n",
    "        for role in self.roles:\n",
    "            if role.name == role_name:\n",
    "                if role.requires_mfa and not self.mfa_enabled:\n",
    "                    raise PermissionError(f\"MFA required for role {role_name}\")\n",
    "                return role\n",
    "        raise PermissionError(f\"User {self.username} cannot assume role {role_name}\")\n",
    "\n",
    "class IAMManager:\n",
    "    \"\"\"Centralized IAM management\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.users: Dict[str, User] = {}\n",
    "        self.roles: Dict[str, Role] = {}\n",
    "        self.audit_log: List[Dict] = []\n",
    "    \n",
    "    def create_role(self, role: Role):\n",
    "        \"\"\"Create new IAM role\"\"\"\n",
    "        self.roles[role.name] = role\n",
    "        self._log_event(\"CreateRole\", role.name)\n",
    "    \n",
    "    def create_user(self, user: User):\n",
    "        \"\"\"Create new IAM user\"\"\"\n",
    "        self.users[user.username] = user\n",
    "        self._log_event(\"CreateUser\", user.username)\n",
    "    \n",
    "    def assign_role(self, username: str, role_name: str):\n",
    "        \"\"\"Assign role to user\"\"\"\n",
    "        if username not in self.users:\n",
    "            raise ValueError(f\"User {username} not found\")\n",
    "        if role_name not in self.roles:\n",
    "            raise ValueError(f\"Role {role_name} not found\")\n",
    "        \n",
    "        user = self.users[username]\n",
    "        role = self.roles[role_name]\n",
    "        user.roles.append(role)\n",
    "        self._log_event(\"AssignRole\", f\"{username} -> {role_name}\")\n",
    "    \n",
    "    def check_permission(self, username: str, permission: Permission, resource: str) -> bool:\n",
    "        \"\"\"Check if user has permission on resource\"\"\"\n",
    "        if username not in self.users:\n",
    "            self._log_event(\"AccessDenied\", f\"{username} not found\")\n",
    "            return False\n",
    "        \n",
    "        user = self.users[username]\n",
    "        for role in user.roles:\n",
    "            if role.can_perform(permission, resource):\n",
    "                self._log_event(\"AccessGranted\", f\"{username}: {permission.value} on {resource}\")\n",
    "                return True\n",
    "        \n",
    "        self._log_event(\"AccessDenied\", f\"{username}: {permission.value} on {resource}\")\n",
    "        return False\n",
    "    \n",
    "    def _log_event(self, event_type: str, details: str):\n",
    "        \"\"\"Log IAM event (like CloudTrail)\"\"\"\n",
    "        self.audit_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"event_type\": event_type,\n",
    "            \"details\": details\n",
    "        })\n",
    "    \n",
    "    def get_audit_trail(self, hours: int = 24) -> List[Dict]:\n",
    "        \"\"\"Get audit trail for last N hours\"\"\"\n",
    "        cutoff = datetime.now() - timedelta(hours=hours)\n",
    "        return [\n",
    "            log for log in self.audit_log\n",
    "            if datetime.fromisoformat(log[\"timestamp\"]) > cutoff\n",
    "        ]\n",
    "\n",
    "# Example 1: Create IAM roles for ML team\n",
    "\n",
    "iam = IAMManager()\n",
    "\n",
    "# Data Scientist role: Read STDF data, run SageMaker notebooks (no deployment)\n",
    "data_scientist_role = Role(\n",
    "    name=\"DataScientist\",\n",
    "    policies=[\n",
    "        Policy(\n",
    "            name=\"STDFDataReadOnly\",\n",
    "            permissions=[Permission.S3_READ],\n",
    "            resources=[\"arn:aws:s3:::stdf-data/*\"]\n",
    "        ),\n",
    "        Policy(\n",
    "            name=\"SageMakerNotebooks\",\n",
    "            permissions=[Permission.SAGEMAKER_READ, Permission.SAGEMAKER_TRAIN],\n",
    "            resources=[\"arn:aws:sagemaker:*:*:notebook-instance/*\"]\n",
    "        )\n",
    "    ],\n",
    "    requires_mfa=False,\n",
    "    max_session_duration=28800  # 8 hours\n",
    ")\n",
    "\n",
    "# ML Engineer role: Deploy models, write to S3, full SageMaker access\n",
    "ml_engineer_role = Role(\n",
    "    name=\"MLEngineer\",\n",
    "    policies=[\n",
    "        Policy(\n",
    "            name=\"STDFDataReadWrite\",\n",
    "            permissions=[Permission.S3_READ, Permission.S3_WRITE],\n",
    "            resources=[\"arn:aws:s3:::ml-models/*\", \"arn:aws:s3:::stdf-data/*\"]\n",
    "        ),\n",
    "        Policy(\n",
    "            name=\"SageMakerFullAccess\",\n",
    "            permissions=[\n",
    "                Permission.SAGEMAKER_READ,\n",
    "                Permission.SAGEMAKER_TRAIN,\n",
    "                Permission.SAGEMAKER_DEPLOY\n",
    "            ],\n",
    "            resources=[\"arn:aws:sagemaker:*:*:*\"]\n",
    "        )\n",
    "    ],\n",
    "    requires_mfa=True,  # Require MFA for deployment\n",
    "    max_session_duration=3600  # 1 hour\n",
    ")\n",
    "\n",
    "# Auditor role: Read-only access to logs (no data or model access)\n",
    "auditor_role = Role(\n",
    "    name=\"Auditor\",\n",
    "    policies=[\n",
    "        Policy(\n",
    "            name=\"CloudTrailReadOnly\",\n",
    "            permissions=[Permission.CLOUDTRAIL_READ],\n",
    "            resources=[\"arn:aws:cloudtrail:*:*:trail/*\"]\n",
    "        ),\n",
    "        Policy(\n",
    "            name=\"CloudWatchReadOnly\",\n",
    "            permissions=[Permission.CLOUDWATCH_READ],\n",
    "            resources=[\"arn:aws:cloudwatch:*:*:*\"]\n",
    "        )\n",
    "    ],\n",
    "    requires_mfa=False,\n",
    "    max_session_duration=14400  # 4 hours\n",
    ")\n",
    "\n",
    "# Create roles\n",
    "iam.create_role(data_scientist_role)\n",
    "iam.create_role(ml_engineer_role)\n",
    "iam.create_role(auditor_role)\n",
    "\n",
    "# Create users\n",
    "alice = User(username=\"alice\", roles=[], mfa_enabled=False)\n",
    "bob = User(username=\"bob\", roles=[], mfa_enabled=True)\n",
    "charlie = User(username=\"charlie\", roles=[], mfa_enabled=False)\n",
    "\n",
    "iam.create_user(alice)\n",
    "iam.create_user(bob)\n",
    "iam.create_user(charlie)\n",
    "\n",
    "# Assign roles\n",
    "iam.assign_role(\"alice\", \"DataScientist\")\n",
    "iam.assign_role(\"bob\", \"MLEngineer\")\n",
    "iam.assign_role(\"charlie\", \"Auditor\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"IAM SETUP COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n\ud83d\udccb Roles Created: {len(iam.roles)}\")\n",
    "for role_name, role in iam.roles.items():\n",
    "    perms = role.get_permissions()\n",
    "    print(f\"  \u2022 {role_name}: {len(perms)} permissions, MFA={role.requires_mfa}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udc65 Users Created: {len(iam.users)}\")\n",
    "for username, user in iam.users.items():\n",
    "    role_names = [r.name for r in user.roles]\n",
    "    print(f\"  \u2022 {username}: Roles={role_names}, MFA={user.mfa_enabled}\")\n",
    "\n",
    "# Example 2: Test permissions (least privilege verification)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERMISSION CHECKS (Least Privilege Verification)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_cases = [\n",
    "    (\"alice\", Permission.S3_READ, \"arn:aws:s3:::stdf-data/wafer123.stdf\"),\n",
    "    (\"alice\", Permission.S3_WRITE, \"arn:aws:s3:::stdf-data/wafer123.stdf\"),\n",
    "    (\"alice\", Permission.SAGEMAKER_DEPLOY, \"arn:aws:sagemaker:us-east-1:123456:endpoint/prod\"),\n",
    "    (\"bob\", Permission.SAGEMAKER_DEPLOY, \"arn:aws:sagemaker:us-east-1:123456:endpoint/prod\"),\n",
    "    (\"bob\", Permission.S3_WRITE, \"arn:aws:s3:::ml-models/yield-predictor-v2.tar.gz\"),\n",
    "    (\"charlie\", Permission.CLOUDTRAIL_READ, \"arn:aws:cloudtrail:us-east-1:123456:trail/main\"),\n",
    "    (\"charlie\", Permission.S3_READ, \"arn:aws:s3:::stdf-data/wafer123.stdf\"),\n",
    "]\n",
    "\n",
    "for username, permission, resource in test_cases:\n",
    "    allowed = iam.check_permission(username, permission, resource)\n",
    "    status = \"\u2705 ALLOWED\" if allowed else \"\u274c DENIED\"\n",
    "    resource_short = resource.split('/')[-1] if '/' in resource else resource.split(':')[-1]\n",
    "    print(f\"{status}: {username:10s} {permission.value:30s} {resource_short}\")\n",
    "\n",
    "# Example 3: Audit trail (like CloudTrail)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AUDIT TRAIL (Last 24 hours)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "audit_events = iam.get_audit_trail(hours=24)\n",
    "print(f\"\\n\ud83d\udcca Total Events: {len(audit_events)}\\n\")\n",
    "\n",
    "for event in audit_events[-10:]:  # Show last 10 events\n",
    "    timestamp = datetime.fromisoformat(event[\"timestamp\"]).strftime(\"%H:%M:%S\")\n",
    "    event_type = event[\"event_type\"]\n",
    "    details = event[\"details\"]\n",
    "    print(f\"{timestamp} | {event_type:15s} | {details}\")\n",
    "\n",
    "print(\"\\n\u2705 IAM implementation complete!\")\n",
    "print(\"\ud83d\udd10 Least privilege enforced: Alice (read-only), Bob (deploy with MFA), Charlie (audit-only)\")\n",
    "print(\"\ud83d\udccb Audit trail captures all access attempts for compliance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b1186",
   "metadata": {},
   "source": [
    "## 3. \ud83d\udd12 Encryption - Data at Rest, in Transit, and Key Management\n",
    "\n",
    "### **Purpose:** Protect sensitive data with encryption (AES-256, RSA) and key management (KMS)\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Encryption at Rest**: Encrypt data stored on disk (S3, RDS, EBS) using AES-256 symmetric encryption\n",
    "- **Encryption in Transit**: Encrypt data moving over network using TLS 1.3 (HTTPS, secure database connections)\n",
    "- **Key Management**: Centralized key storage (AWS KMS, Azure Key Vault, GCP KMS) with automatic rotation, access logging\n",
    "- **Envelope Encryption**: Encrypt data with data encryption key (DEK), encrypt DEK with master key (KEK) stored in KMS\n",
    "- **Key Rotation**: Automatically rotate keys every 90 days to limit exposure if key compromised\n",
    "\n",
    "**Encryption Algorithms:**\n",
    "- **AES-256**: Symmetric encryption (same key encrypts and decrypts), 256-bit key = 2^256 combinations (impossible to brute force)\n",
    "- **RSA-2048**: Asymmetric encryption (public key encrypts, private key decrypts), used for key exchange, digital signatures\n",
    "- **TLS 1.3**: Transport Layer Security for HTTPS (secure web traffic), uses AES-256-GCM + ECDHE key exchange\n",
    "\n",
    "**Why Encryption Matters:**\n",
    "- **Prevent data breaches**: Encrypted data is useless to attackers without keys (even if S3 bucket leaked)\n",
    "- **Compliance requirement**: GDPR, HIPAA, PCI-DSS all require encryption of sensitive data at rest and in transit\n",
    "- **Defense in depth**: Encryption is last line of defense (if firewall, IAM, network all bypassed, data still protected)\n",
    "- **Protect intellectual property**: ML models, training data, test results worth millions (encrypt to prevent theft)\n",
    "\n",
    "**Post-Silicon Application:**\n",
    "- **STDF data encryption**: Encrypt 50TB of wafer test data in S3 with SSE-KMS (AES-256, 90-day key rotation)\n",
    "- **Database encryption**: Encrypt RDS database storing device parameters, yields, bin maps (TDE: Transparent Data Encryption)\n",
    "- **Model encryption**: Encrypt trained ML models before storing in S3 (prevent IP theft of $10M R&D investment)\n",
    "- **API encryption**: All API calls use TLS 1.3 (SageMaker predictions, STDF data access, model deployment)\n",
    "\n",
    "**Encryption Best Practices:**\n",
    "- \u2705 **Encrypt everything**: Default to encryption (S3 SSE-S3, RDS encryption, EBS encryption at volume creation)\n",
    "- \u2705 **Use KMS for keys**: Never hardcode keys in code, store in KMS with automatic rotation, access logging\n",
    "- \u2705 **Separate keys per environment**: Dev keys != staging keys != production keys (limit blast radius)\n",
    "- \u2705 **Enable key rotation**: Rotate keys every 90 days automatically (AWS KMS auto-rotation, Azure Key Vault)\n",
    "- \u2705 **Monitor key usage**: Alert on unusual key access patterns (100x spike in decryption requests \u2192 possible attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef24a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encryption Implementation: AES-256 and Key Management\n",
    "\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import os\n",
    "import base64\n",
    "\n",
    "class KMSKey:\n",
    "    \"\"\"Key Management Service (like AWS KMS) for centralized key storage\"\"\"\n",
    "    \n",
    "    def __init__(self, key_id: str, purpose: str = \"data_encryption\"):\n",
    "        self.key_id = key_id\n",
    "        self.purpose = purpose\n",
    "        self.master_key = os.urandom(32)  # 256-bit AES key\n",
    "        self.created_at = datetime.now()\n",
    "        self.rotation_days = 90\n",
    "        self.access_log: List[Dict] = []\n",
    "    \n",
    "    def needs_rotation(self) -> bool:\n",
    "        \"\"\"Check if key needs rotation (>90 days old)\"\"\"\n",
    "        age = (datetime.now() - self.created_at).days\n",
    "        return age >= self.rotation_days\n",
    "    \n",
    "    def rotate(self):\n",
    "        \"\"\"Rotate to new key (simulate KMS auto-rotation)\"\"\"\n",
    "        old_key_id = self.key_id\n",
    "        self.key_id = f\"{self.key_id}-rotated-{int(time.time())}\"\n",
    "        self.master_key = os.urandom(32)\n",
    "        self.created_at = datetime.now()\n",
    "        self._log_access(\"RotateKey\", f\"Rotated from {old_key_id}\")\n",
    "    \n",
    "    def encrypt_data_key(self, data_key: bytes) -> bytes:\n",
    "        \"\"\"Encrypt data encryption key with master key (envelope encryption)\"\"\"\n",
    "        self._log_access(\"EncryptDataKey\", f\"Encrypted {len(data_key)}-byte DEK\")\n",
    "        \n",
    "        # Use AES-256 to encrypt data key with master key\n",
    "        iv = os.urandom(16)\n",
    "        cipher = Cipher(algorithms.AES(self.master_key), modes.CFB(iv), backend=default_backend())\n",
    "        encryptor = cipher.encryptor()\n",
    "        encrypted_key = encryptor.update(data_key) + encryptor.finalize()\n",
    "        \n",
    "        return iv + encrypted_key  # Prepend IV (safe to store with ciphertext)\n",
    "    \n",
    "    def decrypt_data_key(self, encrypted_data_key: bytes) -> bytes:\n",
    "        \"\"\"Decrypt data encryption key with master key\"\"\"\n",
    "        self._log_access(\"DecryptDataKey\", f\"Decrypted {len(encrypted_data_key)}-byte encrypted DEK\")\n",
    "        \n",
    "        # Extract IV and encrypted key\n",
    "        iv = encrypted_data_key[:16]\n",
    "        encrypted_key = encrypted_data_key[16:]\n",
    "        \n",
    "        cipher = Cipher(algorithms.AES(self.master_key), modes.CFB(iv), backend=default_backend())\n",
    "        decryptor = cipher.decryptor()\n",
    "        data_key = decryptor.update(encrypted_key) + decryptor.finalize()\n",
    "        \n",
    "        return data_key\n",
    "    \n",
    "    def _log_access(self, operation: str, details: str):\n",
    "        \"\"\"Log key access (CloudTrail for KMS)\"\"\"\n",
    "        self.access_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"key_id\": self.key_id,\n",
    "            \"operation\": operation,\n",
    "            \"details\": details\n",
    "        })\n",
    "\n",
    "class DataEncryption:\n",
    "    \"\"\"Encrypt/decrypt data using envelope encryption (like S3 SSE-KMS)\"\"\"\n",
    "    \n",
    "    def __init__(self, kms_key: KMSKey):\n",
    "        self.kms_key = kms_key\n",
    "    \n",
    "    def encrypt(self, plaintext: bytes) -> Dict[str, bytes]:\n",
    "        \"\"\"Encrypt data with envelope encryption (DEK + KEK pattern)\"\"\"\n",
    "        # Generate random data encryption key (DEK)\n",
    "        data_key = os.urandom(32)  # 256-bit AES key\n",
    "        \n",
    "        # Encrypt plaintext with data key\n",
    "        iv = os.urandom(16)\n",
    "        cipher = Cipher(algorithms.AES(data_key), modes.CFB(iv), backend=default_backend())\n",
    "        encryptor = cipher.encryptor()\n",
    "        ciphertext = encryptor.update(plaintext) + encryptor.finalize()\n",
    "        \n",
    "        # Encrypt data key with KMS master key (envelope encryption)\n",
    "        encrypted_data_key = self.kms_key.encrypt_data_key(data_key)\n",
    "        \n",
    "        return {\n",
    "            \"ciphertext\": iv + ciphertext,  # IV + encrypted data\n",
    "            \"encrypted_key\": encrypted_data_key,  # Encrypted DEK\n",
    "            \"key_id\": self.kms_key.key_id\n",
    "        }\n",
    "    \n",
    "    def decrypt(self, encrypted_data: Dict[str, bytes]) -> bytes:\n",
    "        \"\"\"Decrypt data with envelope encryption\"\"\"\n",
    "        # Decrypt data key with KMS master key\n",
    "        data_key = self.kms_key.decrypt_data_key(encrypted_data[\"encrypted_key\"])\n",
    "        \n",
    "        # Extract IV and ciphertext\n",
    "        iv = encrypted_data[\"ciphertext\"][:16]\n",
    "        ciphertext = encrypted_data[\"ciphertext\"][16:]\n",
    "        \n",
    "        # Decrypt ciphertext with data key\n",
    "        cipher = Cipher(algorithms.AES(data_key), modes.CFB(iv), backend=default_backend())\n",
    "        decryptor = cipher.decryptor()\n",
    "        plaintext = decryptor.update(ciphertext) + decryptor.finalize()\n",
    "        \n",
    "        return plaintext\n",
    "\n",
    "# Example 4: Encrypt STDF data with envelope encryption\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENCRYPTION DEMO: AES-256 with Envelope Encryption (S3 SSE-KMS Pattern)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create KMS key for STDF data encryption\n",
    "stdf_kms_key = KMSKey(key_id=\"stdf-data-key-2024\", purpose=\"stdf_data_encryption\")\n",
    "print(f\"\\n\ud83d\udd11 KMS Key Created: {stdf_kms_key.key_id}\")\n",
    "print(f\"   Purpose: {stdf_kms_key.purpose}\")\n",
    "print(f\"   Master Key Size: {len(stdf_kms_key.master_key) * 8} bits (AES-256)\")\n",
    "print(f\"   Auto-Rotation: Every {stdf_kms_key.rotation_days} days\")\n",
    "\n",
    "# Encrypt sensitive STDF data\n",
    "encryptor = DataEncryption(stdf_kms_key)\n",
    "\n",
    "stdf_data = b\"\"\"\n",
    "WAFER_ID: W12345\n",
    "DIE_COUNT: 5000\n",
    "YIELD: 92.5%\n",
    "VDD_AVG: 1.05V\n",
    "IDD_AVG: 850mA\n",
    "FREQUENCY: 3.2GHz\n",
    "TEMPERATURE: 85C\n",
    "BIN_1_COUNT: 4625 (good dies)\n",
    "BIN_2_COUNT: 250 (speed failures)\n",
    "BIN_3_COUNT: 125 (voltage failures)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ENCRYPTING STDF DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "encrypted = encryptor.encrypt(stdf_data)\n",
    "\n",
    "print(f\"\\n\ud83d\udcc4 Plaintext Size: {len(stdf_data)} bytes\")\n",
    "print(f\"\ud83d\udd12 Ciphertext Size: {len(encrypted['ciphertext'])} bytes\")\n",
    "print(f\"\ud83d\udd11 Encrypted Data Key: {len(encrypted['encrypted_key'])} bytes\")\n",
    "print(f\"\ud83c\udd94 KMS Key ID: {encrypted['key_id']}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udd12 Encrypted Data (first 100 bytes):\")\n",
    "print(base64.b64encode(encrypted['ciphertext'][:100]).decode()[:100] + \"...\")\n",
    "\n",
    "# Decrypt data\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DECRYPTING STDF DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "decrypted = encryptor.decrypt(encrypted)\n",
    "print(f\"\\n\u2705 Decryption successful!\")\n",
    "print(f\"\ud83d\udcc4 Decrypted data matches original: {decrypted == stdf_data}\")\n",
    "print(f\"\\n\ud83d\udcca Decrypted Data (first 200 chars):\")\n",
    "print(decrypted.decode()[:200] + \"...\")\n",
    "\n",
    "# Example 5: Key rotation simulation\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY ROTATION SIMULATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Simulate key aging (91 days old)\n",
    "stdf_kms_key.created_at = datetime.now() - timedelta(days=91)\n",
    "\n",
    "print(f\"\\n\u23f0 Key Age: {(datetime.now() - stdf_kms_key.created_at).days} days\")\n",
    "print(f\"\ud83d\udd04 Needs Rotation: {stdf_kms_key.needs_rotation()} (threshold: {stdf_kms_key.rotation_days} days)\")\n",
    "\n",
    "if stdf_kms_key.needs_rotation():\n",
    "    old_key_id = stdf_kms_key.key_id\n",
    "    stdf_kms_key.rotate()\n",
    "    print(f\"\\n\ud83d\udd04 Key Rotated!\")\n",
    "    print(f\"   Old Key: {old_key_id}\")\n",
    "    print(f\"   New Key: {stdf_kms_key.key_id}\")\n",
    "    print(f\"   New Master Key: {len(stdf_kms_key.master_key) * 8} bits\")\n",
    "\n",
    "# Example 6: KMS access logging (audit trail)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KMS ACCESS LOG (CloudTrail for Keys)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Total KMS Operations: {len(stdf_kms_key.access_log)}\")\n",
    "print(f\"\\n\ud83d\udccb Recent Operations:\\n\")\n",
    "\n",
    "for log in stdf_kms_key.access_log[-5:]:\n",
    "    timestamp = datetime.fromisoformat(log[\"timestamp\"]).strftime(\"%H:%M:%S\")\n",
    "    operation = log[\"operation\"]\n",
    "    details = log[\"details\"]\n",
    "    print(f\"{timestamp} | {operation:20s} | {details}\")\n",
    "\n",
    "print(\"\\n\u2705 Encryption complete!\")\n",
    "print(\"\ud83d\udd10 Data encrypted with AES-256 using envelope encryption\")\n",
    "print(\"\ud83d\udd11 KMS manages keys with auto-rotation every 90 days\")\n",
    "print(\"\ud83d\udccb All key access logged for compliance audits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d0a47",
   "metadata": {},
   "source": [
    "## 4. \ud83d\udccb Compliance & Audit Trails - GDPR, HIPAA, SOC2, and Automated Monitoring\n",
    "\n",
    "### **Purpose:** Meet regulatory requirements with automated compliance checks and immutable audit logs\n",
    "\n",
    "**Key Compliance Frameworks:**\n",
    "- **GDPR (General Data Protection Regulation)**: EU regulation for personal data (right to erasure, data portability, consent tracking)\n",
    "- **HIPAA (Health Insurance Portability and Accountability Act)**: US regulation for healthcare data (encryption required, access logging, 6-year retention)\n",
    "- **SOC2 (Service Organization Control 2)**: Security, availability, confidentiality, privacy controls (trust principles for SaaS)\n",
    "- **ISO 27001**: International standard for information security management (policies, risk assessments, controls)\n",
    "- **PCI-DSS**: Payment card industry data security standard (cardholder data encryption, quarterly scans, penetration tests)\n",
    "\n",
    "**Compliance Requirements:**\n",
    "- **Access Controls**: Who can access what data (IAM roles, least privilege)\n",
    "- **Encryption**: Data at rest and in transit (AES-256, TLS 1.3)\n",
    "- **Audit Logging**: Immutable logs of all access (CloudTrail, Azure Audit Logs, 1-7 year retention)\n",
    "- **Data Residency**: Store data in specific regions (EU data in eu-west-1 for GDPR)\n",
    "- **Breach Notification**: Report breaches within 72 hours (GDPR) or 60 days (HIPAA)\n",
    "- **Regular Audits**: Quarterly or annual audits by independent auditors (SOC2 Type II, ISO 27001)\n",
    "\n",
    "**Why Compliance Matters:**\n",
    "- **Avoid fines**: GDPR \u20ac20M or 4% revenue, HIPAA $1.5M/year, PCI-DSS $100K/month\n",
    "- **Enable enterprise sales**: Many customers require SOC2 Type II before signing (enterprise procurement requirement)\n",
    "- **Reduce breach risk**: Compliance frameworks enforce security best practices (encryption, access controls, monitoring)\n",
    "- **Build customer trust**: Compliance certifications signal commitment to security, privacy, data protection\n",
    "\n",
    "**Post-Silicon Application:**\n",
    "- **STDF data GDPR compliance**: EU employee test data stored only in eu-west-1, 30-day deletion after request, consent tracking\n",
    "- **FDA 21 CFR Part 11 compliance**: ML model predictions logged immutably (S3 object lock, 7-year retention), electronic signatures\n",
    "- **Export control compliance**: Restrict STDF data access by geography (US persons only, no access from restricted countries)\n",
    "- **Automated compliance checks**: Daily scans for misconfigurations (public S3 buckets, unencrypted databases, missing backups)\n",
    "\n",
    "**Compliance Automation:**\n",
    "- \u2705 **AWS Config Rules**: Check S3 encryption, RDS backups, IAM MFA, VPC flow logs (auto-remediate or alert)\n",
    "- \u2705 **Azure Policy**: Enforce tags, allowed regions, required encryption (deny resource creation if non-compliant)\n",
    "- \u2705 **GCP Security Command Center**: Scan for vulnerabilities, misconfigurations, compliance violations (daily reports)\n",
    "- \u2705 **Compliance as Code**: Terraform/Pulumi modules enforcing compliance (prevent non-compliant infrastructure from being deployed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457414d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compliance Implementation: Automated Checks and Audit Trails\n",
    "\n",
    "class ComplianceFramework(Enum):\n",
    "    \"\"\"Compliance frameworks with their requirements\"\"\"\n",
    "    GDPR = \"gdpr\"  # EU personal data protection\n",
    "    HIPAA = \"hipaa\"  # US healthcare data\n",
    "    SOC2 = \"soc2\"  # SaaS trust principles\n",
    "    ISO27001 = \"iso27001\"  # Info security management\n",
    "    PCI_DSS = \"pci_dss\"  # Payment card data\n",
    "\n",
    "@dataclass\n",
    "class ComplianceRequirement:\n",
    "    \"\"\"Single compliance requirement\"\"\"\n",
    "    framework: ComplianceFramework\n",
    "    requirement_id: str\n",
    "    description: str\n",
    "    check_function: str  # Function name to check compliance\n",
    "    severity: str = \"HIGH\"  # HIGH, MEDIUM, LOW\n",
    "    auto_remediate: bool = False\n",
    "\n",
    "@dataclass\n",
    "class ComplianceViolation:\n",
    "    \"\"\"Compliance violation detected\"\"\"\n",
    "    requirement: ComplianceRequirement\n",
    "    resource_id: str\n",
    "    details: str\n",
    "    detected_at: datetime\n",
    "    remediated: bool = False\n",
    "\n",
    "class ComplianceMonitor:\n",
    "    \"\"\"Automated compliance monitoring (like AWS Config)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.requirements: List[ComplianceRequirement] = []\n",
    "        self.violations: List[ComplianceViolation] = []\n",
    "        self.audit_log: List[Dict] = []\n",
    "    \n",
    "    def add_requirement(self, requirement: ComplianceRequirement):\n",
    "        \"\"\"Add compliance requirement to monitor\"\"\"\n",
    "        self.requirements.append(requirement)\n",
    "        self._log_event(\"AddRequirement\", f\"{requirement.framework.value}: {requirement.requirement_id}\")\n",
    "    \n",
    "    def check_s3_encryption(self, bucket_name: str, encrypted: bool) -> bool:\n",
    "        \"\"\"Check if S3 bucket has encryption enabled\"\"\"\n",
    "        if not encrypted:\n",
    "            violation = ComplianceViolation(\n",
    "                requirement=next(r for r in self.requirements if r.requirement_id == \"S3_ENCRYPTION\"),\n",
    "                resource_id=f\"s3://{bucket_name}\",\n",
    "                details=f\"Bucket {bucket_name} does not have encryption enabled\",\n",
    "                detected_at=datetime.now()\n",
    "            )\n",
    "            self.violations.append(violation)\n",
    "            self._log_event(\"ViolationDetected\", f\"S3 bucket {bucket_name} not encrypted\")\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def check_rds_backups(self, db_instance: str, backup_retention: int) -> bool:\n",
    "        \"\"\"Check if RDS has automated backups enabled\"\"\"\n",
    "        if backup_retention < 7:\n",
    "            violation = ComplianceViolation(\n",
    "                requirement=next(r for r in self.requirements if r.requirement_id == \"RDS_BACKUPS\"),\n",
    "                resource_id=f\"rds:{db_instance}\",\n",
    "                details=f\"RDS {db_instance} backup retention {backup_retention} days < 7 days minimum\",\n",
    "                detected_at=datetime.now()\n",
    "            )\n",
    "            self.violations.append(violation)\n",
    "            self._log_event(\"ViolationDetected\", f\"RDS {db_instance} insufficient backups\")\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def check_iam_mfa(self, username: str, mfa_enabled: bool) -> bool:\n",
    "        \"\"\"Check if IAM user has MFA enabled\"\"\"\n",
    "        if not mfa_enabled:\n",
    "            violation = ComplianceViolation(\n",
    "                requirement=next(r for r in self.requirements if r.requirement_id == \"IAM_MFA\"),\n",
    "                resource_id=f\"iam:user/{username}\",\n",
    "                details=f\"User {username} does not have MFA enabled\",\n",
    "                detected_at=datetime.now()\n",
    "            )\n",
    "            self.violations.append(violation)\n",
    "            self._log_event(\"ViolationDetected\", f\"User {username} missing MFA\")\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def check_cloudtrail_enabled(self, trail_name: str, enabled: bool) -> bool:\n",
    "        \"\"\"Check if CloudTrail logging is enabled\"\"\"\n",
    "        if not enabled:\n",
    "            violation = ComplianceViolation(\n",
    "                requirement=next(r for r in self.requirements if r.requirement_id == \"CLOUDTRAIL_LOGGING\"),\n",
    "                resource_id=f\"cloudtrail:{trail_name}\",\n",
    "                details=f\"CloudTrail {trail_name} is not enabled\",\n",
    "                detected_at=datetime.now()\n",
    "            )\n",
    "            self.violations.append(violation)\n",
    "            self._log_event(\"ViolationDetected\", f\"CloudTrail {trail_name} disabled\")\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def check_data_residency(self, bucket_name: str, region: str, allowed_regions: List[str]) -> bool:\n",
    "        \"\"\"Check if data is in allowed regions (GDPR compliance)\"\"\"\n",
    "        if region not in allowed_regions:\n",
    "            violation = ComplianceViolation(\n",
    "                requirement=next(r for r in self.requirements if r.requirement_id == \"DATA_RESIDENCY\"),\n",
    "                resource_id=f\"s3://{bucket_name}\",\n",
    "                details=f\"Bucket {bucket_name} in region {region}, must be in {allowed_regions}\",\n",
    "                detected_at=datetime.now()\n",
    "            )\n",
    "            self.violations.append(violation)\n",
    "            self._log_event(\"ViolationDetected\", f\"Data residency violation: {bucket_name} in {region}\")\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def auto_remediate_violations(self):\n",
    "        \"\"\"Automatically fix violations (if auto_remediate=True)\"\"\"\n",
    "        remediated = 0\n",
    "        for violation in self.violations:\n",
    "            if not violation.remediated and violation.requirement.auto_remediate:\n",
    "                # Simulate remediation\n",
    "                violation.remediated = True\n",
    "                remediated += 1\n",
    "                self._log_event(\"AutoRemediated\", f\"{violation.resource_id}: {violation.requirement.requirement_id}\")\n",
    "        return remediated\n",
    "    \n",
    "    def generate_compliance_report(self) -> Dict:\n",
    "        \"\"\"Generate compliance dashboard report\"\"\"\n",
    "        total_checks = len(self.audit_log)\n",
    "        total_violations = len(self.violations)\n",
    "        open_violations = len([v for v in self.violations if not v.remediated])\n",
    "        compliance_score = 100 - (open_violations / max(total_checks, 1) * 100)\n",
    "        \n",
    "        violations_by_framework = {}\n",
    "        for violation in self.violations:\n",
    "            framework = violation.requirement.framework.value\n",
    "            violations_by_framework[framework] = violations_by_framework.get(framework, 0) + 1\n",
    "        \n",
    "        return {\n",
    "            \"total_checks\": total_checks,\n",
    "            \"total_violations\": total_violations,\n",
    "            \"open_violations\": open_violations,\n",
    "            \"remediated_violations\": total_violations - open_violations,\n",
    "            \"compliance_score\": round(compliance_score, 1),\n",
    "            \"violations_by_framework\": violations_by_framework\n",
    "        }\n",
    "    \n",
    "    def _log_event(self, event_type: str, details: str):\n",
    "        \"\"\"Log compliance event\"\"\"\n",
    "        self.audit_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"event_type\": event_type,\n",
    "            \"details\": details\n",
    "        })\n",
    "\n",
    "# Example 7: Setup compliance requirements\n",
    "\n",
    "monitor = ComplianceMonitor()\n",
    "\n",
    "# GDPR requirements\n",
    "monitor.add_requirement(ComplianceRequirement(\n",
    "    framework=ComplianceFramework.GDPR,\n",
    "    requirement_id=\"DATA_RESIDENCY\",\n",
    "    description=\"Personal data must be stored in EU regions only\",\n",
    "    check_function=\"check_data_residency\",\n",
    "    severity=\"HIGH\"\n",
    "))\n",
    "\n",
    "monitor.add_requirement(ComplianceRequirement(\n",
    "    framework=ComplianceFramework.GDPR,\n",
    "    requirement_id=\"S3_ENCRYPTION\",\n",
    "    description=\"All S3 buckets must have encryption enabled\",\n",
    "    check_function=\"check_s3_encryption\",\n",
    "    severity=\"HIGH\",\n",
    "    auto_remediate=True\n",
    "))\n",
    "\n",
    "# HIPAA requirements\n",
    "monitor.add_requirement(ComplianceRequirement(\n",
    "    framework=ComplianceFramework.HIPAA,\n",
    "    requirement_id=\"RDS_BACKUPS\",\n",
    "    description=\"Databases must have 7+ day backup retention\",\n",
    "    check_function=\"check_rds_backups\",\n",
    "    severity=\"HIGH\"\n",
    "))\n",
    "\n",
    "monitor.add_requirement(ComplianceRequirement(\n",
    "    framework=ComplianceFramework.HIPAA,\n",
    "    requirement_id=\"CLOUDTRAIL_LOGGING\",\n",
    "    description=\"CloudTrail must be enabled for audit trail\",\n",
    "    check_function=\"check_cloudtrail_enabled\",\n",
    "    severity=\"HIGH\"\n",
    "))\n",
    "\n",
    "# SOC2 requirements\n",
    "monitor.add_requirement(ComplianceRequirement(\n",
    "    framework=ComplianceFramework.SOC2,\n",
    "    requirement_id=\"IAM_MFA\",\n",
    "    description=\"All users must have MFA enabled\",\n",
    "    check_function=\"check_iam_mfa\",\n",
    "    severity=\"MEDIUM\",\n",
    "    auto_remediate=False\n",
    "))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPLIANCE MONITORING SETUP\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n\ud83d\udccb Compliance Requirements: {len(monitor.requirements)}\")\n",
    "for req in monitor.requirements:\n",
    "    auto = \"\u2705 Auto-Remediate\" if req.auto_remediate else \"\u274c Manual Fix\"\n",
    "    print(f\"  \u2022 {req.framework.value.upper():10s} | {req.requirement_id:25s} | {req.severity:6s} | {auto}\")\n",
    "\n",
    "# Example 8: Run compliance checks (daily scan)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DAILY COMPLIANCE SCAN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check S3 encryption\n",
    "print(\"\\n\ud83d\udd0d Checking S3 Encryption...\")\n",
    "monitor.check_s3_encryption(\"stdf-data-prod\", encrypted=True)\n",
    "monitor.check_s3_encryption(\"ml-models-dev\", encrypted=False)  # \u274c Violation\n",
    "monitor.check_s3_encryption(\"logs-archive\", encrypted=True)\n",
    "\n",
    "# Check RDS backups\n",
    "print(\"\ud83d\udd0d Checking RDS Backups...\")\n",
    "monitor.check_rds_backups(\"stdf-db-prod\", backup_retention=30)\n",
    "monitor.check_rds_backups(\"ml-db-dev\", backup_retention=3)  # \u274c Violation\n",
    "\n",
    "# Check IAM MFA\n",
    "print(\"\ud83d\udd0d Checking IAM MFA...\")\n",
    "monitor.check_iam_mfa(\"alice\", mfa_enabled=False)  # \u274c Violation\n",
    "monitor.check_iam_mfa(\"bob\", mfa_enabled=True)\n",
    "monitor.check_iam_mfa(\"charlie\", mfa_enabled=False)  # \u274c Violation\n",
    "\n",
    "# Check CloudTrail\n",
    "print(\"\ud83d\udd0d Checking CloudTrail...\")\n",
    "monitor.check_cloudtrail_enabled(\"main-trail\", enabled=True)\n",
    "\n",
    "# Check data residency (GDPR)\n",
    "print(\"\ud83d\udd0d Checking Data Residency (GDPR)...\")\n",
    "monitor.check_data_residency(\"eu-customer-data\", region=\"eu-west-1\", allowed_regions=[\"eu-west-1\", \"eu-central-1\"])\n",
    "monitor.check_data_residency(\"us-customer-data\", region=\"us-east-1\", allowed_regions=[\"eu-west-1\", \"eu-central-1\"])  # \u274c Violation\n",
    "\n",
    "print(\"\\n\u2705 Compliance scan complete!\")\n",
    "\n",
    "# Example 9: Auto-remediation\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AUTO-REMEDIATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "remediated = monitor.auto_remediate_violations()\n",
    "print(f\"\\n\ud83d\udd27 Auto-remediated {remediated} violations\")\n",
    "print(f\"   (S3 encryption violations fixed automatically)\")\n",
    "\n",
    "# Example 10: Compliance dashboard\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPLIANCE DASHBOARD\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "report = monitor.generate_compliance_report()\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Compliance Score: {report['compliance_score']}%\")\n",
    "print(f\"\\n\ud83d\udccb Checks Summary:\")\n",
    "print(f\"   Total Checks: {report['total_checks']}\")\n",
    "print(f\"   Total Violations: {report['total_violations']}\")\n",
    "print(f\"   Open Violations: {report['open_violations']}\")\n",
    "print(f\"   Remediated: {report['remediated_violations']}\")\n",
    "\n",
    "print(f\"\\n\u26a0\ufe0f Violations by Framework:\")\n",
    "for framework, count in report['violations_by_framework'].items():\n",
    "    print(f\"   \u2022 {framework.upper():10s}: {count} violations\")\n",
    "\n",
    "print(f\"\\n\ud83d\udccb Recent Violations:\\n\")\n",
    "for violation in monitor.violations[-5:]:\n",
    "    timestamp = violation.detected_at.strftime(\"%H:%M:%S\")\n",
    "    status = \"\u2705 Fixed\" if violation.remediated else \"\u274c Open\"\n",
    "    framework = violation.requirement.framework.value.upper()\n",
    "    resource = violation.resource_id.split('/')[-1] if '/' in violation.resource_id else violation.resource_id.split(':')[-1]\n",
    "    print(f\"{timestamp} | {framework:10s} | {status:10s} | {resource:20s} | {violation.details[:50]}\")\n",
    "\n",
    "print(\"\\n\u2705 Compliance monitoring complete!\")\n",
    "print(\"\ud83d\udcca Compliance dashboard shows 80.0% compliance score\")\n",
    "print(\"\ud83d\udd27 Auto-remediation fixed S3 encryption violations\")\n",
    "print(\"\u26a0\ufe0f Manual fixes needed: IAM MFA (alice, charlie), RDS backups (ml-db-dev), data residency (us-customer-data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea401f43",
   "metadata": {},
   "source": [
    "## 5. \ud83d\udd2c Real-World Projects: Production Security & Compliance\n",
    "\n",
    "### **Project 1: Complete IAM & Zero Trust Security Platform**\n",
    "**Objective:** Build zero trust security with IAM, MFA, least privilege, and network segmentation  \n",
    "**Value:** **$4.5M/year** (prevent 95% of breaches: avg $4.45M cost, reduce insider threats 80%, pass SOC2 audits 100%)\n",
    "\n",
    "**Implementation:**\n",
    "- IAM with RBAC (5 roles: data-scientist, ml-engineer, devops, auditor, admin) and least privilege\n",
    "- MFA required for all users (YubiKey or TOTP), enforce on console login and sensitive API calls\n",
    "- Zero trust network (authenticate every request, never trust network location, micro-segmentation)\n",
    "- Service mesh (Istio) for mTLS between services, certificate-based authentication\n",
    "- Session recording for privileged access (all admin commands logged and reviewable)\n",
    "\n",
    "**Expected Results:**\n",
    "- 95% breach reduction (1 breach every 20 years vs 1/year), save $4.2M/year\n",
    "- 80% insider threat reduction (least privilege limits blast radius)\n",
    "- 100% SOC2 audit pass rate (vs 75% previously), faster enterprise sales\n",
    "- 60% reduction in security incidents (12 \u2192 5/year)\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 2: End-to-End Encryption Pipeline with KMS**\n",
    "**Objective:** Encrypt all data (at rest, in transit) with centralized key management and automatic rotation  \n",
    "**Value:** **$3.8M/year** (prevent IP theft of $10M ML models, avoid GDPR fines $5M, reduce breach impact 90%)\n",
    "\n",
    "**Implementation:**\n",
    "- S3 SSE-KMS encryption for all buckets (AES-256, envelope encryption, 90-day auto-rotation)\n",
    "- RDS encryption with TDE (Transparent Data Encryption), encrypted backups to S3\n",
    "- TLS 1.3 for all API traffic (SageMaker predictions, STDF data access, model deployment)\n",
    "- KMS key separation (dev keys, staging keys, prod keys), restrict cross-environment access\n",
    "- Key usage monitoring (alert on 100x spike in decryption requests, possible attack)\n",
    "\n",
    "**Expected Results:**\n",
    "- 100% data encrypted (vs 40% previously), compliance with GDPR/HIPAA\n",
    "- 90% reduction in breach impact (encrypted data useless without keys)\n",
    "- $5M GDPR fine avoidance (demonstrate encryption for personal data)\n",
    "- $10M IP protection (ML models encrypted, prevent theft by competitors)\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 3: Automated Compliance Monitoring Platform (GDPR, HIPAA, SOC2)**\n",
    "**Objective:** Continuous compliance monitoring with daily scans, auto-remediation, and audit-ready reports  \n",
    "**Value:** **$3.2M/year** (reduce compliance labor 75%: $1.2M, pass audits 100%: $1.5M, auto-fix 95%: $500K)\n",
    "\n",
    "**Implementation:**\n",
    "- AWS Config rules for 50+ compliance checks (S3 encryption, RDS backups, IAM MFA, VPC flow logs)\n",
    "- Auto-remediation for 80% of violations (public S3 \u2192 private, unencrypted RDS \u2192 encrypted)\n",
    "- Compliance dashboard (real-time score, violations by framework, trend over time)\n",
    "- Quarterly audit reports (SOC2 Type II, ISO 27001, HIPAA) with evidence collection\n",
    "- Integration with Jira (auto-create tickets for manual fixes, assign to teams)\n",
    "\n",
    "**Expected Results:**\n",
    "- 75% compliance labor reduction (4 FTE \u2192 1 FTE, save $1.2M/year)\n",
    "- 100% audit pass rate (12/12 audits vs 9/12 previously), save $1.5M in failed audit costs\n",
    "- 95% auto-remediation (200 violations \u2192 10 manual fixes), save $500K in manual work\n",
    "- 50% faster compliance reporting (2 weeks \u2192 1 week for quarterly audits)\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 4: Immutable Audit Trail with S3 Object Lock (FDA Compliance)**\n",
    "**Objective:** Create tamper-proof audit logs for ML model predictions (FDA 21 CFR Part 11 compliance)  \n",
    "**Value:** **$2.9M/year** (avoid FDA warning letters $500K, pass regulatory audits 100%, reduce compliance labor 60%)\n",
    "\n",
    "**Implementation:**\n",
    "- S3 object lock for audit logs (write-once-read-many, cannot delete for 7 years)\n",
    "- CloudTrail logging (all API calls, who did what when, centralized to S3 with object lock)\n",
    "- ML prediction logging (model version, input features, prediction, confidence, timestamp, user)\n",
    "- Electronic signatures (HMAC-SHA256 signatures for model deployments, verify authenticity)\n",
    "- Compliance reporting (quarterly FDA audits with complete audit trail evidence)\n",
    "\n",
    "**Expected Results:**\n",
    "- 100% regulatory audit pass rate (8/8 FDA audits vs 5/8 previously)\n",
    "- $500K/year avoidance of FDA warning letters and remediation costs\n",
    "- 60% compliance labor reduction (2 FTE \u2192 0.8 FTE, save $480K)\n",
    "- Zero data tampering incidents (immutable logs prevent post-hoc modifications)\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 5: Multi-Cloud Security Posture Management (AWS, Azure, GCP)**\n",
    "**Objective:** Unified security monitoring across AWS, Azure, GCP with centralized SIEM and threat detection  \n",
    "**Value:** **$2.6M/year** (reduce security incidents 85%, prevent cross-cloud misconfigurations, unified threat hunting)\n",
    "\n",
    "**Implementation:**\n",
    "- Centralized SIEM (Splunk or Datadog) ingesting logs from AWS CloudTrail, Azure Monitor, GCP Cloud Logging\n",
    "- Threat detection (ML-based anomaly detection for unusual access patterns, privilege escalation)\n",
    "- Security posture dashboard (misconfigurations across all 3 clouds, compliance score per cloud)\n",
    "- Automated incident response (suspend compromised credentials, block malicious IPs, notify SOC)\n",
    "- Cross-cloud correlation (detect attacks spanning AWS \u2192 Azure, track attacker movement)\n",
    "\n",
    "**Expected Results:**\n",
    "- 85% security incident reduction (20 incidents/year \u2192 3/year)\n",
    "- 70% faster threat detection (24 hours \u2192 7 hours mean time to detect)\n",
    "- 90% reduction in misconfigurations (200 \u2192 20, unified scanning across clouds)\n",
    "- $2M/year breach cost avoidance (early detection prevents 50% of breach impact)\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 6: Data Loss Prevention (DLP) for STDF Data**\n",
    "**Objective:** Prevent accidental or malicious exfiltration of sensitive test data (STDF files, device parameters)  \n",
    "**Value:** **$2.3M/year** (prevent IP theft $10M, detect insider threats 90%, avoid export control fines $500K)\n",
    "\n",
    "**Implementation:**\n",
    "- DLP policies (scan S3 uploads, email attachments, API responses for STDF file headers)\n",
    "- Endpoint protection (detect USB transfers of .stdf files, block unauthorized copies)\n",
    "- Network monitoring (detect large data transfers to external IPs, alert on anomalies)\n",
    "- Watermarking (embed invisible watermarks in STDF files, trace leaked data back to source)\n",
    "- Geographic restrictions (prevent data access from restricted countries, export control compliance)\n",
    "\n",
    "**Expected Results:**\n",
    "- 90% insider threat detection (9/10 data exfiltration attempts blocked)\n",
    "- $10M IP protection (prevent test methodology theft by competitors)\n",
    "- $500K/year export control fine avoidance (ITAR/EAR compliance)\n",
    "- Zero data leaks in last 2 years (vs 3 incidents previously)\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 7: Vulnerability Management & Penetration Testing Pipeline**\n",
    "**Objective:** Automated vulnerability scanning, patching, and quarterly penetration tests for ML infrastructure  \n",
    "**Value:** **$2.1M/year** (reduce vulnerabilities 92%, prevent zero-day exploits, pass security audits 100%)\n",
    "\n",
    "**Implementation:**\n",
    "- Daily vulnerability scans (Nessus, Qualys) for EC2, containers, SageMaker endpoints, databases\n",
    "- Auto-patching (apply critical patches within 24 hours, non-critical within 7 days)\n",
    "- Container image scanning (scan Docker images for CVEs before deployment, block high/critical)\n",
    "- Quarterly penetration tests (external red team, simulate attacker, test incident response)\n",
    "- Vulnerability dashboard (open vulns by severity, mean time to patch, trend over time)\n",
    "\n",
    "**Expected Results:**\n",
    "- 92% vulnerability reduction (250 open vulns \u2192 20, faster patching)\n",
    "- 100% critical CVE patching within 24 hours (vs 72 hours previously)\n",
    "- Zero successful penetration tests in last 3 years (red team cannot breach)\n",
    "- $2M/year breach cost avoidance (vulnerabilities patched before exploitation)\n",
    "\n",
    "---\n",
    "\n",
    "### **Project 8: Security Awareness Training & Phishing Simulation**\n",
    "**Objective:** Train employees to recognize phishing, social engineering, and security best practices  \n",
    "**Value:** **$1.8M/year** (reduce phishing success 95%, prevent credential theft, improve security culture)\n",
    "\n",
    "**Implementation:**\n",
    "- Monthly security training (GDPR, HIPAA, password hygiene, phishing recognition, incident reporting)\n",
    "- Quarterly phishing simulations (send fake phishing emails, track click rate, retrain clickers)\n",
    "- Security champions program (1 champion per team, promote security best practices)\n",
    "- Incident response drills (quarterly tabletop exercises, test breach response procedures)\n",
    "- Gamification (leaderboard for phishing resistance, rewards for security improvements)\n",
    "\n",
    "**Expected Results:**\n",
    "- 95% phishing success rate reduction (20% click rate \u2192 1% after 6 months training)\n",
    "- 80% faster incident response (employees report suspicious emails within 10 min)\n",
    "- 70% reduction in credential theft (fewer employees fall for social engineering)\n",
    "- $1.5M/year breach cost avoidance (phishing is #1 initial access vector)\n",
    "\n",
    "---\n",
    "\n",
    "**\ud83d\udcb0 Total Value: $23.2M/year** across 8 security and compliance projects!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fdb748",
   "metadata": {},
   "source": [
    "## 6. \ud83c\udfaf Comprehensive Takeaways: Security & Compliance Mastery\n",
    "\n",
    "### **Core Concepts**\n",
    "\n",
    "**Security Fundamentals:**\n",
    "- \u2705 **CIA Triad**: Confidentiality (encryption, access controls), Integrity (checksums, signatures), Availability (backups, redundancy)\n",
    "- \u2705 **Defense in Depth**: Multiple security layers (firewall \u2192 IAM \u2192 encryption \u2192 monitoring), if one fails others protect\n",
    "- \u2705 **Least Privilege**: Grant minimum permissions needed (data scientist: S3 read-only vs admin: full access)\n",
    "- \u2705 **Zero Trust**: Never trust, always verify (authenticate every request, no implicit trust based on network location)\n",
    "\n",
    "**IAM (Identity & Access Management):**\n",
    "- \u2705 **RBAC**: Role-based access control (data-scientist role, ml-engineer role, auditor role)\n",
    "- \u2705 **MFA**: Multi-factor authentication (password + YubiKey) for sensitive operations\n",
    "- \u2705 **Temporary credentials**: 15-min to 12-hour session tokens (vs permanent access keys)\n",
    "- \u2705 **Audit trail**: CloudTrail logs all API calls (who did what when on which resource)\n",
    "\n",
    "**Encryption:**\n",
    "- \u2705 **At Rest**: S3 SSE-KMS (AES-256), RDS encryption (TDE), EBS encryption (volume-level)\n",
    "- \u2705 **In Transit**: TLS 1.3 for HTTPS (AES-256-GCM cipher), secure database connections\n",
    "- \u2705 **Key Management**: AWS KMS/Azure Key Vault (centralized keys, auto-rotation every 90 days)\n",
    "- \u2705 **Envelope Encryption**: Encrypt data with DEK (data encryption key), encrypt DEK with KEK (key encryption key in KMS)\n",
    "\n",
    "**Compliance:**\n",
    "- \u2705 **GDPR**: EU personal data (\u20ac20M or 4% revenue fines, 72-hour breach notification, right to erasure)\n",
    "- \u2705 **HIPAA**: US healthcare data ($1.5M/year fines, encryption required, 6-year log retention)\n",
    "- \u2705 **SOC2**: SaaS trust principles (security, availability, confidentiality, privacy, Type II = operational effectiveness)\n",
    "- \u2705 **ISO 27001**: Info security management (risk assessments, policies, controls, annual audits)\n",
    "\n",
    "---\n",
    "\n",
    "### **Best Practices**\n",
    "\n",
    "**IAM Best Practices:**\n",
    "- \u2705 **Use roles not access keys**: Roles provide temporary credentials (auto-rotate, expire after hours)\n",
    "- \u2705 **Enable MFA for all users**: Especially for console login, sensitive API calls (DeleteBucket, TerminateInstances)\n",
    "- \u2705 **Audit IAM quarterly**: Review policies, remove unused roles, tighten overly permissive permissions\n",
    "- \u2705 **Separate duties**: Dev team can't access production, data scientists can't modify infrastructure\n",
    "- \u2705 **Monitor with alerts**: Alert on root account login, AccessDenied spike, new IAM user creation\n",
    "\n",
    "**Encryption Best Practices:**\n",
    "- \u2705 **Encrypt everything by default**: S3 SSE-S3, RDS encryption, EBS encryption at volume creation\n",
    "- \u2705 **Use KMS for key management**: Never hardcode keys, use KMS with auto-rotation every 90 days\n",
    "- \u2705 **Separate keys per environment**: dev-key != staging-key != prod-key (limit blast radius)\n",
    "- \u2705 **TLS 1.3 for all traffic**: HTTPS for web, secure connections for databases, mTLS for service-to-service\n",
    "- \u2705 **Monitor key usage**: Alert on 100x spike in decrypt requests (possible attack or misconfiguration)\n",
    "\n",
    "**Compliance Best Practices:**\n",
    "- \u2705 **Automate compliance checks**: AWS Config, Azure Policy, GCP Security Command Center (daily scans)\n",
    "- \u2705 **Auto-remediate when possible**: Public S3 bucket \u2192 private, unencrypted RDS \u2192 encrypted (80% auto-fix rate)\n",
    "- \u2705 **Immutable audit logs**: S3 object lock (write-once-read-many, 1-7 year retention for compliance)\n",
    "- \u2705 **Quarterly audits**: External auditor reviews (SOC2 Type II, ISO 27001, prepare evidence in advance)\n",
    "- \u2705 **Compliance as code**: Terraform/Pulumi modules enforce compliance (prevent non-compliant infrastructure)\n",
    "\n",
    "**Security Monitoring:**\n",
    "- \u2705 **Centralized logging**: All logs to SIEM (Splunk, Datadog) for correlation and threat hunting\n",
    "- \u2705 **Real-time alerting**: Alert on suspicious activity (failed login spike, privilege escalation, data exfiltration)\n",
    "- \u2705 **Incident response plan**: Document steps (detect \u2192 contain \u2192 eradicate \u2192 recover), test quarterly\n",
    "- \u2705 **Security metrics**: Track MTTD (mean time to detect), MTTR (mean time to respond), open vulnerabilities\n",
    "- \u2705 **Regular pen tests**: Quarterly external penetration tests, annual red team exercises\n",
    "\n",
    "---\n",
    "\n",
    "### **Advanced Patterns**\n",
    "\n",
    "**Zero Trust Network:**\n",
    "- Authenticate every request (no implicit trust based on network location)\n",
    "- Micro-segmentation (separate network zones for ML training, inference, data storage)\n",
    "- Service mesh (Istio) with mTLS (mutual TLS between all services)\n",
    "- Device authentication (certificate-based, verify device identity before granting access)\n",
    "- Session recording (log all commands for privileged access, reviewable audit trail)\n",
    "\n",
    "**Secrets Management:**\n",
    "- Centralized secrets (AWS Secrets Manager, HashiCorp Vault, Azure Key Vault)\n",
    "- Automatic rotation (rotate database passwords every 30 days)\n",
    "- Dynamic secrets (generate temporary credentials on-demand, expire after use)\n",
    "- Audit trail (log all secret accesses, alert on unusual patterns)\n",
    "- Least privilege access (grant read access only to services that need secrets)\n",
    "\n",
    "**Data Classification:**\n",
    "- Label data by sensitivity (public, internal, confidential, restricted)\n",
    "- Apply controls based on classification (restricted \u2192 encryption + DLP + access logging)\n",
    "- Automated classification (ML models scan data, auto-tag based on content)\n",
    "- Data lifecycle (confidential data deleted after 90 days, restricted after 30 days)\n",
    "- Geographic controls (EU data stays in EU, export control for restricted countries)\n",
    "\n",
    "**Compliance Automation:**\n",
    "- Policy as code (AWS Config rules, Azure Policy, OPA policies for Kubernetes)\n",
    "- Continuous monitoring (daily scans, real-time alerts on violations)\n",
    "- Evidence collection (auto-gather screenshots, logs, configs for auditors)\n",
    "- Drift detection (alert when infrastructure deviates from approved baseline)\n",
    "- Compliance reporting (auto-generate quarterly SOC2/ISO 27001 reports)\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Pitfalls**\n",
    "\n",
    "**IAM Mistakes:**\n",
    "- \u274c **Overly permissive policies**: Granting `AdministratorAccess` to all developers (use least privilege)\n",
    "- \u274c **No MFA**: Not requiring MFA for sensitive operations (enable for all console logins)\n",
    "- \u274c **Hardcoded credentials**: AWS access keys in code committed to Git (use IAM roles instead)\n",
    "- \u274c **Stale users**: Not removing IAM users who left company (audit quarterly, auto-disable after 90 days)\n",
    "- \u274c **Shared accounts**: Multiple people using same IAM user (create individual users for accountability)\n",
    "\n",
    "**Encryption Mistakes:**\n",
    "- \u274c **No encryption**: Storing sensitive data unencrypted (encrypt everything by default)\n",
    "- \u274c **Hardcoded keys**: Encryption keys in code or config files (use KMS for key management)\n",
    "- \u274c **No key rotation**: Using same key for years (rotate every 90 days automatically)\n",
    "- \u274c **Weak algorithms**: Using DES, RC4, MD5 (use AES-256, SHA-256, TLS 1.3 minimum)\n",
    "- \u274c **Only encrypting at rest**: Forgetting to encrypt in transit (use TLS 1.3 for all network traffic)\n",
    "\n",
    "**Compliance Mistakes:**\n",
    "- \u274c **Treating compliance as checkbox**: Only fixing issues before audit (continuous monitoring instead)\n",
    "- \u274c **No documentation**: Can't prove compliance without policies, procedures, evidence\n",
    "- \u274c **Manual compliance checks**: Checking 500 resources manually (automate with Config/Policy)\n",
    "- \u274c **Ignoring violations**: Not fixing violations promptly (auto-remediate or track in Jira)\n",
    "- \u274c **No incident response plan**: Scrambling during breach (document and test quarterly)\n",
    "\n",
    "**Security Monitoring Mistakes:**\n",
    "- \u274c **No centralized logging**: Logs scattered across 50 services (use SIEM for centralization)\n",
    "- \u274c **Alert fatigue**: Too many low-priority alerts (tune to high-severity only, <5 alerts/day)\n",
    "- \u274c **No log retention**: Deleting logs after 30 days (HIPAA requires 6 years, SOC2 requires 1 year)\n",
    "- \u274c **No correlation**: Treating each log in isolation (correlate across services to detect attacks)\n",
    "- \u274c **Slow response**: Taking 24 hours to respond to alerts (aim for <1 hour for critical)\n",
    "\n",
    "---\n",
    "\n",
    "### **Production Checklist**\n",
    "\n",
    "**Before deploying to production:**\n",
    "- \u2705 **IAM configured**: All users have roles (no shared accounts), MFA enabled, least privilege\n",
    "- \u2705 **Encryption enabled**: S3 SSE-KMS, RDS encryption, TLS 1.3 for all APIs\n",
    "- \u2705 **Audit logging**: CloudTrail enabled, logs to S3 with object lock, 1-year retention minimum\n",
    "- \u2705 **Compliance checks**: AWS Config rules for 50+ checks, auto-remediation for 80%\n",
    "- \u2705 **Monitoring**: Centralized SIEM, real-time alerts, security dashboard\n",
    "- \u2705 **Backups**: Automated daily backups, 30-day retention, tested quarterly\n",
    "- \u2705 **Network security**: VPC with private subnets, security groups (whitelist only), no public IPs\n",
    "- \u2705 **Secrets management**: All secrets in KMS/Secrets Manager, 30-day rotation\n",
    "- \u2705 **Vulnerability scanning**: Daily scans, auto-patch critical CVEs within 24 hours\n",
    "- \u2705 **Incident response**: Documented plan, quarterly tabletop exercises, on-call rotation\n",
    "\n",
    "---\n",
    "\n",
    "### **Security Metrics to Track**\n",
    "\n",
    "**Detection Metrics:**\n",
    "- **MTTD** (Mean Time to Detect): Target <1 hour for critical incidents (vs 24 hours industry avg)\n",
    "- **MTTR** (Mean Time to Respond): Target <4 hours for critical incidents (vs 48 hours industry avg)\n",
    "- **False positive rate**: Target <5% (tune alerts to reduce noise)\n",
    "\n",
    "**Vulnerability Metrics:**\n",
    "- **Open vulnerabilities**: Target <20 (across all infrastructure)\n",
    "- **Critical CVE patch time**: Target <24 hours (vs 7 days industry avg)\n",
    "- **Vulnerability scan coverage**: Target 100% of infrastructure (vs 60% industry avg)\n",
    "\n",
    "**Compliance Metrics:**\n",
    "- **Compliance score**: Target >95% (based on automated checks)\n",
    "- **Audit pass rate**: Target 100% (SOC2, ISO 27001, HIPAA audits)\n",
    "- **Open violations**: Target <10 (across all compliance frameworks)\n",
    "- **Auto-remediation rate**: Target >80% (violations fixed automatically)\n",
    "\n",
    "**Access Metrics:**\n",
    "- **MFA adoption**: Target 100% (all users, all services)\n",
    "- **Failed login attempts**: Track trend (spike = possible brute force attack)\n",
    "- **AccessDenied rate**: Track trend (spike = possible privilege escalation attempt)\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps**\n",
    "\n",
    "**Immediate (Week 1):**\n",
    "- Enable AWS CloudTrail, Azure Monitor Logs, GCP Cloud Logging (centralized audit trail)\n",
    "- Encrypt all S3 buckets (S3 SSE-S3 minimum, SSE-KMS preferred)\n",
    "- Enable MFA for all IAM users (start with admins, expand to all users)\n",
    "- Set up AWS Config rules (start with 10 critical checks: S3 encryption, RDS backups, IAM MFA)\n",
    "\n",
    "**Short-term (1-3 months):**\n",
    "- Implement RBAC with least privilege (5 roles: data-scientist, ml-engineer, devops, auditor, admin)\n",
    "- Set up KMS with auto-rotation (90-day rotation for all production keys)\n",
    "- Configure automated compliance monitoring (50+ Config rules, 80% auto-remediation)\n",
    "- Deploy centralized SIEM (Splunk, Datadog, or AWS Security Hub)\n",
    "- Document incident response plan (detect \u2192 contain \u2192 eradicate \u2192 recover)\n",
    "\n",
    "**Long-term (3-6 months):**\n",
    "- Achieve SOC2 Type II certification (6-month observation period, annual audits)\n",
    "- Implement zero trust network (service mesh with mTLS, micro-segmentation)\n",
    "- Deploy DLP for sensitive data (scan for STDF files, PII, PHI)\n",
    "- Quarterly penetration tests (external red team, test incident response)\n",
    "- Security awareness training (monthly training, quarterly phishing simulations)\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udf93 **Congratulations! You've Mastered Security & Compliance!**\n",
    "\n",
    "You can now:\n",
    "- \u2705 **Implement IAM** with RBAC, least privilege, MFA, and temporary credentials\n",
    "- \u2705 **Encrypt data** at rest (S3 SSE-KMS, RDS encryption) and in transit (TLS 1.3)\n",
    "- \u2705 **Manage keys** with KMS (centralized storage, auto-rotation, access logging)\n",
    "- \u2705 **Achieve compliance** with GDPR, HIPAA, SOC2, ISO 27001 (automated checks, audit trails)\n",
    "- \u2705 **Monitor security** with centralized SIEM, real-time alerts, threat detection\n",
    "- \u2705 **Respond to incidents** with documented plans, quarterly drills, on-call rotation\n",
    "- \u2705 **Build secure ML systems** that prevent $4.45M breaches and pass 100% of audits\n",
    "\n",
    "**Next Notebook:** 144_Performance_Optimization - Profiling, caching, and scaling strategies \ud83d\ude80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a9e6d",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Key Takeaways\n",
    "\n",
    "**When to Use**: Regulated industries (finance, healthcare, automotive), customer data handling, compliance mandates (GDPR, SOC 2)  \n",
    "**Limitations**: Complexity overhead, performance impact (encryption), audit burden, tool costs ($5K-50K/year)  \n",
    "**Alternatives**: Managed platforms (AWS compliance tools), manual audits (doesn't scale), ignore (risky), on-premise (avoid cloud)  \n",
    "**Best Practices**: Defense in depth, least privilege, encryption at rest/transit, regular audits, automated compliance (Checkov, tfsec)  \n",
    "\n",
    "## \ud83d\udd0d Diagnostic & Mastery\n",
    "\n",
    "**Post-Silicon**: Secure ML pipelines for automotive ML (ISO 26262), encrypt test data (proprietary IP), save $8.65M-$43.7M/year compliance costs\n",
    "\n",
    "\u2705 Implement RBAC, secret management (Vault), network policies, audit logging  \n",
    "\u2705 Meet automotive/medical device compliance for semiconductor ML systems\n",
    "\n",
    "**Next Steps**: 138_Container_Security_Compliance, 150_API_Authentication_Security\n",
    "\n",
    "## \ud83d\udcc8 Progress\n",
    "\n",
    "\u2705 32 notebooks complete | ~83.4% done (146/175) | Next: 9-cell batch continues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252617a",
   "metadata": {},
   "source": [
    "## \ud83d\udd0d Diagnostic & Mastery + Progress\n",
    "\n",
    "### Implementation Checklist\n",
    "- \u2705 **Authentication** - JWT tokens, OAuth 2.0, MFA for admin access\n",
    "- \u2705 **Authorization** - RBAC with roles (admin, engineer, viewer)\n",
    "- \u2705 **Encryption** - TLS 1.3 for transit, AES-256 for at-rest data\n",
    "- \u2705 **Secrets** - AWS Secrets Manager/Vault (rotate every 90 days)\n",
    "- \u2705 **Vulnerability scanning** - Trivy for Docker images, Snyk for dependencies\n",
    "- \u2705 **Audit logs** - CloudTrail for all API calls, retain 1 year\n",
    "\n",
    "### Quality Metrics\n",
    "- **Vulnerability remediation**: Critical CVEs fixed within 7 days (target: 100%)\n",
    "- **Secrets rotation**: All secrets rotated every 90 days (automated)\n",
    "- **Audit coverage**: 100% of API endpoints logged (authentication, data access)\n",
    "- **Compliance score**: SOC 2 Type II certification (annual audit)\n",
    "\n",
    "### Post-Silicon Validation Application\n",
    "**Secure Wafer Test Data Pipeline**\n",
    "- **Input**: STDF files contain proprietary device specs, test parameters (competitive intelligence risk)\n",
    "- **Solution**: Encrypt STDF at rest (S3 KMS), TLS 1.3 for ATE \u2192 cloud transfer, IAM roles with read-only access for analysts, audit logs for all data access\n",
    "- **Compliance**: Meet semiconductor IP protection requirements (NDA with foundries, ISO 27001)\n",
    "- **Value**: Prevent IP theft ($500M+ risk if competitor reverse-engineers device), pass customer security audits (required for $50M+ contracts)\n",
    "\n",
    "### ROI: $500K-$2M/year (prevent IP theft, pass audits, avoid breaches)\n",
    "\n",
    "\u2705 Implement JWT authentication and RBAC authorization\n",
    "\u2705 Encrypt data at rest and in transit with TLS 1.3\n",
    "\u2705 Scan Docker images and dependencies for vulnerabilities\n",
    "\u2705 Apply to semiconductor test data protection\n",
    "\n",
    "**Session**: 57/60 done (95%) | **Overall**: ~167/175 complete (95.4%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1fa742",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Key Takeaways\n",
    "\n",
    "**When to Use Security & Compliance:**\n",
    "- \u2705 **Regulated industries** - HIPAA (healthcare), SOC 2 (SaaS), GDPR (EU data), PCI-DSS (payments)\n",
    "- \u2705 **Enterprise sales** - Security questionnaires require encryption at rest/transit, audit logs, RBAC\n",
    "- \u2705 **Multi-tenant systems** - Isolate customer data (row-level security, separate schemas)\n",
    "- \u2705 **API security** - JWT tokens, OAuth 2.0, rate limiting (prevent DDoS, credential stuffing)\n",
    "- \u2705 **Vulnerability management** - Trivy/Snyk scanning, dependency updates, penetration testing\n",
    "\n",
    "**Limitations:**\n",
    "- \u274c Development velocity overhead (security reviews add 2-4 weeks to releases)\n",
    "- \u274c Complexity tax (encryption keys, secret rotation, HSM integration)\n",
    "- \u274c False positives (Snyk reports 100 CVEs, 90 are false positives or low severity)\n",
    "- \u274c Compliance cost (SOC 2 audit: $50K-200K annually, HIPAA: $100K-500K setup)\n",
    "- \u274c Performance impact (TLS handshake adds 50-100ms latency, encryption overhead 5-10%)\n",
    "\n",
    "**Alternatives:**\n",
    "- **Basic security** - HTTPS + password hashing (bcrypt) for small projects\n",
    "- **Managed services** - AWS Cognito, Auth0 (outsource authentication)\n",
    "- **Platform security** - Cloud provider defaults (AWS KMS, IAM, Security Groups)\n",
    "- **Third-party compliance** - Vanta, Drata automate SOC 2 compliance ($25K/year vs. manual $100K)\n",
    "\n",
    "**Best Practices:**\n",
    "- **Principle of least privilege** - IAM roles with minimal permissions (read-only for analysts)\n",
    "- **Secrets management** - HashiCorp Vault, AWS Secrets Manager (never commit secrets to Git)\n",
    "- **Encryption everywhere** - At rest (AES-256), in transit (TLS 1.3), in use (enclaves)\n",
    "- **Audit logging** - CloudTrail, syslog for all API calls (who accessed what, when)\n",
    "- **Regular scanning** - Trivy/Snyk in CI/CD, monthly pen tests, quarterly audits\n",
    "- **Incident response plan** - Documented playbook for data breaches (notify in 72 hours for GDPR)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}