{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03558f4",
   "metadata": {},
   "source": [
    "# 013: Logistic Regression for Classification\n",
    "\n",
    "Logistic regression predicts **probability** of class membership using the sigmoid function to map linear combinations to [0, 1].\n",
    "\n",
    "### \ud83d\udcca Classification Concept\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Features X] --> B[Linear Combination]\n",
    "    B --> C[Sigmoid Function]\n",
    "    C --> D[Probability 0 to 1]\n",
    "    D --> E{Threshold 0.5}\n",
    "    E -->|P >= 0.5| F[Class 1]\n",
    "    E -->|P < 0.5| G[Class 0]\n",
    "    style C fill:#FF9800,stroke:#333,stroke-width:2px,color:#fff\n",
    "    style F fill:#4CAF50,stroke:#333,stroke-width:2px,color:#fff\n",
    "    style G fill:#f44336,stroke:#333,stroke-width:2px,color:#fff\n",
    "```\n",
    "\n",
    "### The Sigmoid Function\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "$$P(y=1|\\mathbf{x}) = \\sigma(\\mathbf{w}^T \\mathbf{x} + b)$$\n",
    "\n",
    "Where:\n",
    "- $z = \\mathbf{w}^T \\mathbf{x} + b$ is the linear combination\n",
    "- $\\sigma(z)$ maps $(-\\infty, +\\infty) \\rightarrow (0, 1)$\n",
    "- $P(y=1|\\mathbf{x})$ is probability of positive class\n",
    "\n",
    "### Decision Boundary\n",
    "\n",
    "Classification decision at $\\sigma(z) = 0.5$:\n",
    "$$\\mathbf{w}^T \\mathbf{x} + b = 0$$\n",
    "\n",
    "This defines a **linear** decision boundary in feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e9e6f",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Logistic Regression Workflow\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Labeled Data] --> B[Explore Class Balance]\n",
    "    B --> C{Imbalanced?}\n",
    "    C -->|Yes| D[Handle Imbalance]\n",
    "    C -->|No| E[Train-Test Split]\n",
    "    D --> E\n",
    "    E --> F[Fit Logistic Model]\n",
    "    F --> G[Predict Probabilities]\n",
    "    G --> H[Evaluate: Accuracy, Precision, Recall, ROC]\n",
    "    H --> I{Good Performance?}\n",
    "    I -->|Yes| J[Deploy]\n",
    "    I -->|No| K[Feature Engineering or Try Non-linear]\n",
    "    K --> F\n",
    "    style F fill:#FF9800,stroke:#333,stroke-width:2px,color:#fff\n",
    "    style J fill:#4CAF50,stroke:#333,stroke-width:2px,color:#fff\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b8a614",
   "metadata": {},
   "source": [
    "### When to Use Logistic Regression?\n",
    "\n",
    "\u2705 **Use when:**\n",
    "- Binary or multi-class classification task\n",
    "- Need probability estimates (not just class labels)\n",
    "- Interpretability important (coefficients show feature impact)\n",
    "- Baseline model before complex classifiers\n",
    "- Linear decision boundary sufficient\n",
    "\n",
    "\u274c **Don't use when:**\n",
    "- Non-linear decision boundaries required\n",
    "- Classes highly overlapping\n",
    "- Need to capture complex interactions\n",
    "- Image/video classification (use CNNs)\n",
    "\n",
    "### \ud83c\udfed Real-World Applications\n",
    "\n",
    "**Post-Silicon Validation:**\n",
    "- Pass/fail prediction from parametric tests\n",
    "- Bin classification (speed grades, quality tiers)\n",
    "- Defect detection (faulty vs good devices)\n",
    "- Wafer acceptance decisions (ship vs scrap)\n",
    "\n",
    "**General AI/ML:**\n",
    "- Customer churn prediction\n",
    "- Fraud detection\n",
    "- Email spam classification\n",
    "- Medical diagnosis\n",
    "- Credit approval\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0704a",
   "metadata": {},
   "source": [
    "## 2. Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report,\n",
    "                             roc_curve, roc_auc_score, precision_recall_curve)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('\u2705 Libraries imported successfully')\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b39ca",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Import classification-specific libraries and metrics\n",
    "\n",
    "**Key Points:**\n",
    "- **LogisticRegression**: Scikit-learn's classifier with multiple solvers and regularization\n",
    "- **Classification metrics**: Accuracy, precision, recall, F1, ROC-AUC for thorough evaluation\n",
    "- **Confusion matrix**: Shows true/false positives/negatives for error analysis\n",
    "- **ROC/PR curves**: Visualize tradeoffs between metrics at different thresholds\n",
    "\n",
    "**Why This Matters:**\n",
    "- Classification requires different metrics than regression (not RMSE/R\u00b2)\n",
    "- Single metric insufficient - need precision AND recall\n",
    "- ROC curve essential for threshold tuning in production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6bd85",
   "metadata": {},
   "source": [
    "### 2.1 Generate Binary Classification Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391ba4f",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Create synthetic pass/fail classification data mimicking semiconductor testing\n",
    "\n",
    "**Key Points:**\n",
    "- **Two classes**: Pass (1) vs Fail (0) devices\n",
    "- **Linearly separable**: With some overlap to mimic real measurement noise\n",
    "- **STDF-like features**: Voltage, current, frequency, temperature\n",
    "- **Class balance**: 70-30 split (realistic for yield scenarios)\n",
    "\n",
    "**Why This Approach:**\n",
    "- Mimics real STDF pass/fail outcomes\n",
    "- Known ground truth for validation\n",
    "- Demonstrates binary classification mechanics clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8decd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_device_passfail_data(n_samples=500, noise=0.3):\n",
    "    \"\"\"\n",
    "    Generate semiconductor device pass/fail classification data\n",
    "    \"\"\"\n",
    "    # Features: voltage, current, frequency, temperature\n",
    "    voltage = np.random.uniform(0.9, 1.1, n_samples)\n",
    "    current = np.random.uniform(80, 120, n_samples)\n",
    "    frequency = np.random.uniform(2.0, 3.0, n_samples)\n",
    "    temperature = np.random.uniform(25, 85, n_samples)\n",
    "    \n",
    "    # Decision boundary (pass if conditions met)\n",
    "    score = (voltage - 1.0) * 100 + (current - 100) * 0.5 - (temperature - 55) * 0.3 + frequency * 10\n",
    "    score += np.random.randn(n_samples) * noise * 10\n",
    "    \n",
    "    # Pass (1) if score > 0, Fail (0) otherwise\n",
    "    pass_fail = (score > 0).astype(int)\n",
    "    \n",
    "    # Create feature matrix\n",
    "    X = np.column_stack([voltage, current, frequency, temperature])\n",
    "    y = pass_fail\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Generate dataset\n",
    "X, y = generate_device_passfail_data(n_samples=500, noise=0.3)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X, columns=['Voltage_V', 'Current_mA', 'Frequency_GHz', 'Temperature_C'])\n",
    "df['Pass_Fail'] = y\n",
    "df['Class_Label'] = df['Pass_Fail'].map({0: 'Fail', 1: 'Pass'})\n",
    "\n",
    "print('\u2705 Binary classification dataset generated')\n",
    "print(f'Total samples: {len(df)}')\n",
    "print(f'\\nClass distribution:')\n",
    "print(df['Class_Label'].value_counts())\n",
    "print(f'\\nClass balance: {df[\"Pass_Fail\"].mean()*100:.1f}% Pass, {(1-df[\"Pass_Fail\"].mean())*100:.1f}% Fail')\n",
    "print('\\nFirst 5 samples:')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580dc90",
   "metadata": {},
   "source": [
    "### 2.2 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae7e76",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Visualize feature distributions and class separability\n",
    "\n",
    "**Key Points:**\n",
    "- **Box plots**: Show feature distributions for each class (Pass vs Fail)\n",
    "- **Separation**: Clear difference indicates features are predictive\n",
    "- **Overlap**: Some overlap expected (real-world noise)\n",
    "- **Feature importance preview**: Features with more separation matter more\n",
    "\n",
    "**Why This Matters:**\n",
    "- Visual confirmation that classification is feasible\n",
    "- Identifies which features discriminate classes best\n",
    "- Helps set expectations for model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00579cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(['Voltage_V', 'Current_mA', 'Frequency_GHz', 'Temperature_C']):\n",
    "    df.boxplot(column=col, by='Class_Label', ax=axes[i])\n",
    "    axes[i].set_title(f'{col} by Class')\n",
    "    axes[i].set_xlabel('Class')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "plt.suptitle('Feature Distributions by Pass/Fail Class', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\ud83d\udcca Interpretation:')\n",
    "print('   \u2192 Pass devices: Higher voltage, current, frequency')\n",
    "print('   \u2192 Fail devices: Lower performance parameters, higher temperature')\n",
    "print('   \u2192 Overlap indicates classification challenge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c9b80",
   "metadata": {},
   "source": [
    "### 2.3 Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c06736",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Split data with stratification to preserve class balance\n",
    "\n",
    "**Key Points:**\n",
    "- **Stratify**: Ensures both train and test have same class proportions\n",
    "- **Critical for imbalanced data**: Prevents test set having all one class\n",
    "- **80-20 split**: Standard ratio\n",
    "- **StandardScaler**: Less critical than regularization, but good practice\n",
    "\n",
    "**Why This Matters:**\n",
    "- Without stratification, might get unlucky split (e.g., 90% Pass in train, 50% in test)\n",
    "- Ensures consistent evaluation across experiments\n",
    "- Fair comparison with other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df[['Voltage_V', 'Current_mA', 'Frequency_GHz', 'Temperature_C']].values\n",
    "y = df['Pass_Fail'].values\n",
    "\n",
    "# Split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'\u2705 Data split completed')\n",
    "print(f'Training samples: {len(X_train)} (Pass: {y_train.sum()}, Fail: {len(y_train)-y_train.sum()})')\n",
    "print(f'Test samples: {len(X_test)} (Pass: {y_test.sum()}, Fail: {len(y_test)-y_test.sum()})')\n",
    "print(f'\\nClass balance preserved:')\n",
    "print(f'  Train: {y_train.mean()*100:.1f}% Pass')\n",
    "print(f'  Test: {y_test.mean()*100:.1f}% Pass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b15ae5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Mathematical Foundation\n",
    "\n",
    "### 3.1 Sigmoid Function Properties\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "Properties:\n",
    "- $\\lim_{z \\to \\infty} \\sigma(z) = 1$\n",
    "- $\\lim_{z \\to -\\infty} \\sigma(z) = 0$\n",
    "- $\\sigma(0) = 0.5$\n",
    "- $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))$\n",
    "\n",
    "### 3.2 Log-Likelihood and Cross-Entropy Loss\n",
    "\n",
    "**For binary classification:**\n",
    "$$\\mathcal{L} = -\\frac{1}{n}\\sum_{i=1}^{n} \\left[ y_i \\log(\\hat{p}_i) + (1-y_i)\\log(1-\\hat{p}_i) \\right]$$\n",
    "\n",
    "Where $\\hat{p}_i = \\sigma(\\mathbf{w}^T \\mathbf{x}_i + b)$\n",
    "\n",
    "**Goal:** Minimize cross-entropy by finding optimal $\\mathbf{w}$, $b$\n",
    "\n",
    "### 3.3 Gradient Descent Update\n",
    "\n",
    "No closed-form solution \u2192 use iterative optimization:\n",
    "\n",
    "$$\\mathbf{w}_{t+1} = \\mathbf{w}_t - \\eta \\nabla_{\\mathbf{w}} \\mathcal{L}$$\n",
    "\n",
    "Gradient:\n",
    "$$\\nabla_{\\mathbf{w}} \\mathcal{L} = \\frac{1}{n} \\mathbf{X}^T (\\hat{\\mathbf{p}} - \\mathbf{y})$$\n",
    "\n",
    "### 3.4 Odds and Logit\n",
    "\n",
    "**Odds ratio:**\n",
    "$$\\text{Odds} = \\frac{P(y=1)}{P(y=0)} = \\frac{P(y=1)}{1 - P(y=1)}$$\n",
    "\n",
    "**Logit (log-odds):**\n",
    "$$\\text{logit}(p) = \\log\\left(\\frac{p}{1-p}\\right) = \\mathbf{w}^T \\mathbf{x} + b$$\n",
    "\n",
    "Logistic regression models **log-odds** as linear function of features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccdd9b2",
   "metadata": {},
   "source": [
    "## 4. Implementation from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5b405",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Build logistic regression from scratch using gradient descent\n",
    "\n",
    "**Key Points:**\n",
    "- **Sigmoid implementation**: Core transformation function\n",
    "- **Cross-entropy loss**: Proper loss for classification (not MSE)\n",
    "- **Gradient descent**: Iterative weight updates with learning rate\n",
    "- **Convergence tracking**: Monitor loss to verify training progress\n",
    "\n",
    "**Why This Matters:**\n",
    "- Demystifies logistic regression internals\n",
    "- Shows why gradient descent needed (no closed form)\n",
    "- Understanding helps debug convergence issues in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcdf169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionScratch:\n",
    "    \"\"\"\n",
    "    Logistic Regression from scratch using gradient descent\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iter = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.losses = []\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))  # Clip for numerical stability\n",
    "    \n",
    "    def compute_loss(self, y_true, y_pred_prob):\n",
    "        \"\"\"Binary cross-entropy loss\"\"\"\n",
    "        epsilon = 1e-15\n",
    "        y_pred_prob = np.clip(y_pred_prob, epsilon, 1 - epsilon)\n",
    "        return -np.mean(y_true * np.log(y_pred_prob) + (1 - y_true) * np.log(1 - y_pred_prob))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Gradient descent\n",
    "        for i in range(self.n_iter):\n",
    "            # Forward pass\n",
    "            linear_pred = X @ self.weights + self.bias\n",
    "            y_pred_prob = self.sigmoid(linear_pred)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = self.compute_loss(y, y_pred_prob)\n",
    "            self.losses.append(loss)\n",
    "            \n",
    "            # Compute gradients\n",
    "            dw = (1/n_samples) * X.T @ (y_pred_prob - y)\n",
    "            db = (1/n_samples) * np.sum(y_pred_prob - y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        linear_pred = X @ self.weights + self.bias\n",
    "        return self.sigmoid(linear_pred)\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))\n",
    "\n",
    "# Train from-scratch model\n",
    "model_scratch = LogisticRegressionScratch(learning_rate=0.1, n_iterations=1000)\n",
    "model_scratch.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_acc = model_scratch.score(X_train_scaled, y_train)\n",
    "test_acc = model_scratch.score(X_test_scaled, y_test)\n",
    "\n",
    "print('\u2705 From-Scratch Logistic Regression')\n",
    "print(f'Training Accuracy: {train_acc:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "print(f'Final Loss: {model_scratch.losses[-1]:.4f}')\n",
    "\n",
    "# Plot loss curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(model_scratch.losses, linewidth=2)\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Cross-Entropy Loss', fontsize=12)\n",
    "plt.title('Training Loss Convergence', fontsize=13, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544e3458",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Production Implementation with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8e2c0",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Train production-grade logistic regression with regularization\n",
    "\n",
    "**Key Points:**\n",
    "- **Penalty**: L2 (Ridge) by default prevents overfitting\n",
    "- **Solver**: 'lbfgs' efficient for small datasets, 'saga' for large/L1\n",
    "- **max_iter**: Increased to ensure convergence\n",
    "- **Probability calibration**: Well-calibrated probabilities for decision making\n",
    "\n",
    "**Why This Matters:**\n",
    "- Production model needs regularization for robustness\n",
    "- Different solvers optimize different scenarios\n",
    "- Probability estimates critical for threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train sklearn model with L2 regularization\n",
    "model_sklearn = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=1000, random_state=42)\n",
    "model_sklearn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = model_sklearn.predict(X_train_scaled)\n",
    "y_test_pred = model_sklearn.predict(X_test_scaled)\n",
    "y_test_pred_proba = model_sklearn.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Comprehensive metrics\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "\n",
    "print('\ud83c\udfaf Logistic Regression Performance (Scikit-learn)\\n')\n",
    "print('='*60)\n",
    "print(f'Training Accuracy:     {train_acc:.4f}')\n",
    "print(f'Test Accuracy:         {test_acc:.4f}')\n",
    "print(f'Test Precision:        {test_precision:.4f}')\n",
    "print(f'Test Recall:           {test_recall:.4f}')\n",
    "print(f'Test F1-Score:         {test_f1:.4f}')\n",
    "print(f'Test ROC-AUC:          {test_auc:.4f}')\n",
    "print('='*60)\n",
    "\n",
    "# Classification report\n",
    "print('\\n\ud83d\udcca Detailed Classification Report:\\n')\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Fail', 'Pass']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c7431",
   "metadata": {},
   "source": [
    "### 5.1 Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a20cce",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Visualize prediction errors with confusion matrix\n",
    "\n",
    "**Key Points:**\n",
    "- **True Positives (TP)**: Correctly predicted Pass\n",
    "- **True Negatives (TN)**: Correctly predicted Fail\n",
    "- **False Positives (FP)**: Predicted Pass, actually Fail (Type I error)\n",
    "- **False Negatives (FN)**: Predicted Fail, actually Pass (Type II error)\n",
    "\n",
    "**Why This Matters:**\n",
    "- Different errors have different costs (FP vs FN)\n",
    "- In semiconductor: FP = shipping bad devices (costly recalls)\n",
    "- FN = scrapping good devices (lost revenue)\n",
    "- Helps set optimal classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Fail', 'Pass'], yticklabels=['Fail', 'Pass'],\n",
    "            annot_kws={'size': 16}, ax=ax)\n",
    "ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "ax.set_ylabel('True Label', fontsize=12)\n",
    "ax.set_title('Confusion Matrix (Test Set)', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\ud83d\udd0d Confusion Matrix Breakdown:')\n",
    "print(f'   True Negatives (TN):  {cm[0, 0]} - Correctly predicted Fail')\n",
    "print(f'   False Positives (FP): {cm[0, 1]} - Predicted Pass, actually Fail \u26a0\ufe0f')\n",
    "print(f'   False Negatives (FN): {cm[1, 0]} - Predicted Fail, actually Pass')\n",
    "print(f'   True Positives (TP):  {cm[1, 1]} - Correctly predicted Pass')\n",
    "print(f'\\n   \u2192 Precision = TP/(TP+FP) = {cm[1,1]}/{cm[1,1]+cm[0,1]} = {test_precision:.3f}')\n",
    "print(f'   \u2192 Recall = TP/(TP+FN) = {cm[1,1]}/{cm[1,1]+cm[1,0]} = {test_recall:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ad10a3",
   "metadata": {},
   "source": [
    "### 5.2 ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c250eb66",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Evaluate classifier performance across all thresholds\n",
    "\n",
    "**Key Points:**\n",
    "- **ROC Curve**: Plots True Positive Rate vs False Positive Rate\n",
    "- **AUC**: Area Under Curve - single metric for overall performance (higher better)\n",
    "- **AUC = 1.0**: Perfect classifier\n",
    "- **AUC = 0.5**: Random guessing\n",
    "- **Threshold selection**: Choose point on curve based on cost tradeoffs\n",
    "\n",
    "**Why This Matters:**\n",
    "- Default 0.5 threshold may not be optimal\n",
    "- ROC shows full performance spectrum\n",
    "- AUC enables model comparison (one number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4dfa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {test_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier (AUC = 0.5)')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Recall)', fontsize=12)\n",
    "plt.title('ROC Curve - Logistic Regression', fontsize=13, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\ud83d\udcc8 ROC Curve Interpretation:')\n",
    "print(f'   \u2192 AUC = {test_auc:.4f} (closer to 1.0 = better)')\n",
    "if test_auc > 0.9:\n",
    "    print('   \u2192 Excellent classifier (AUC > 0.9)')\n",
    "elif test_auc > 0.8:\n",
    "    print('   \u2192 Good classifier (AUC > 0.8)')\n",
    "elif test_auc > 0.7:\n",
    "    print('   \u2192 Fair classifier (AUC > 0.7)')\n",
    "else:\n",
    "    print('   \u2192 Poor classifier (AUC < 0.7)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ac8fb",
   "metadata": {},
   "source": [
    "### 5.3 Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b3689",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Alternative view focusing on precision-recall tradeoff\n",
    "\n",
    "**Key Points:**\n",
    "- **Precision-Recall Curve**: Better for imbalanced datasets than ROC\n",
    "- **High precision**: Few false positives (strict predictions)\n",
    "- **High recall**: Few false negatives (catch all positives)\n",
    "- **Tradeoff**: Can't maximize both simultaneously\n",
    "\n",
    "**Why This Matters:**\n",
    "- In production, choose threshold based on business costs\n",
    "- Semiconductor: High precision (avoid shipping bad devices) may sacrifice recall\n",
    "- Different applications need different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Precision-Recall curve\n",
    "precision_vals, recall_vals, pr_thresholds = precision_recall_curve(y_test, y_test_pred_proba)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall_vals, precision_vals, linewidth=2, label='Precision-Recall Curve')\n",
    "plt.xlabel('Recall (True Positive Rate)', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve - Logistic Regression', fontsize=13, fontweight='bold')\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\u2696\ufe0f Precision-Recall Tradeoff:')\n",
    "print('   \u2192 Higher threshold \u2192 Higher precision, Lower recall')\n",
    "print('   \u2192 Lower threshold \u2192 Higher recall, Lower precision')\n",
    "print(f'   \u2192 Current (0.5 threshold): Precision={test_precision:.3f}, Recall={test_recall:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c314180",
   "metadata": {},
   "source": [
    "### 5.4 Feature Importance (Coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a32e83d",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Interpret which features drive classification decisions\n",
    "\n",
    "**Key Points:**\n",
    "- **Positive coefficients**: Feature increases probability of Pass\n",
    "- **Negative coefficients**: Feature decreases probability of Pass\n",
    "- **Magnitude**: Larger |coefficient| \u2192 stronger effect\n",
    "- **Odds ratio**: $e^{\\beta}$ shows multiplicative effect on odds\n",
    "\n",
    "**Why This Matters:**\n",
    "- Explains model to domain experts (\"high voltage \u2192 more likely to pass\")\n",
    "- Validates domain knowledge (coefficients match physics)\n",
    "- Identifies unexpected relationships (debugging data issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fa2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients\n",
    "feature_names = ['Voltage_V', 'Current_mA', 'Frequency_GHz', 'Temperature_C']\n",
    "coefficients = model_sklearn.coef_[0]\n",
    "intercept = model_sklearn.intercept_[0]\n",
    "\n",
    "# Create DataFrame\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Coefficient': np.abs(coefficients),\n",
    "    'Odds_Ratio': np.exp(coefficients)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print('\ud83d\udcca Feature Importance (Logistic Regression Coefficients)\\n')\n",
    "print(coef_df.to_string(index=False))\n",
    "print(f'\\nIntercept (bias): {intercept:.4f}')\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if c >= 0 else 'red' for c in coef_df['Coefficient']]\n",
    "plt.barh(coef_df['Feature'], coef_df['Coefficient'], color=colors, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Feature Importance (Logistic Regression Coefficients)', fontsize=13, fontweight='bold')\n",
    "plt.axvline(0, color='black', linewidth=0.8)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\n\ud83d\udd0d Interpretation:')\n",
    "print('   \u2192 Positive coefficients increase Pass probability')\n",
    "print('   \u2192 Negative coefficients increase Fail probability')\n",
    "print('   \u2192 Odds ratio > 1: Feature increases odds of Pass')\n",
    "print('   \u2192 Odds ratio < 1: Feature decreases odds of Pass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d334822",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Multi-Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43e8aa",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd What's Happening in This Code?\n",
    "\n",
    "**Purpose:** Extend binary logistic regression to multi-class problems\n",
    "\n",
    "**Key Points:**\n",
    "- **Three strategies**: One-vs-Rest (OvR), One-vs-One (OvO), Softmax (multinomial)\n",
    "- **OvR**: Train N binary classifiers (class vs all others)\n",
    "- **Softmax**: Direct multi-class probabilities (preferred)\n",
    "- **Bin classification**: Realistic semiconductor scenario (speed grades)\n",
    "\n",
    "**Why This Matters:**\n",
    "- Most real problems have >2 classes\n",
    "- Semiconductor: Bins (Premium, Standard, Value, Reject)\n",
    "- Softmax provides calibrated probabilities across all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 3-class dataset (device bins)\n",
    "def generate_multiclass_bins(n_samples=500):\n",
    "    X, _ = generate_device_passfail_data(n_samples, noise=0.3)\n",
    "    \n",
    "    # Create 3 bins based on performance score\n",
    "    score = X[:, 0] * 100 + X[:, 1] * 0.5 + X[:, 2] * 10 - X[:, 3] * 0.3\n",
    "    \n",
    "    # Bin assignment: Premium (2), Standard (1), Reject (0)\n",
    "    y_multi = np.zeros(n_samples, dtype=int)\n",
    "    y_multi[score > np.percentile(score, 66)] = 2  # Top 33% \u2192 Premium\n",
    "    y_multi[(score > np.percentile(score, 33)) & (score <= np.percentile(score, 66))] = 1  # Middle \u2192 Standard\n",
    "    # Bottom 33% stays 0 \u2192 Reject\n",
    "    \n",
    "    return X, y_multi\n",
    "\n",
    "X_multi, y_multi = generate_multiclass_bins(n_samples=500)\n",
    "\n",
    "# Split\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.2, random_state=42, stratify=y_multi\n",
    ")\n",
    "\n",
    "# Scale\n",
    "scaler_m = StandardScaler()\n",
    "X_train_m_scaled = scaler_m.fit_transform(X_train_m)\n",
    "X_test_m_scaled = scaler_m.transform(X_test_m)\n",
    "\n",
    "# Train multi-class logistic regression (softmax)\n",
    "model_multi = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "model_multi.fit(X_train_m_scaled, y_train_m)\n",
    "\n",
    "# Evaluate\n",
    "y_test_m_pred = model_multi.predict(X_test_m_scaled)\n",
    "test_acc_multi = accuracy_score(y_test_m, y_test_m_pred)\n",
    "\n",
    "print('\ud83c\udfaf Multi-Class Logistic Regression (3 Bins)\\n')\n",
    "print(f'Test Accuracy: {test_acc_multi:.4f}')\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_test_m, y_test_m_pred, target_names=['Reject', 'Standard', 'Premium']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_multi = confusion_matrix(y_test_m, y_test_m_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Reject', 'Standard', 'Premium'],\n",
    "            yticklabels=['Reject', 'Standard', 'Premium'],\n",
    "            annot_kws={'size': 14}, ax=ax)\n",
    "ax.set_xlabel('Predicted Bin', fontsize=12)\n",
    "ax.set_ylabel('True Bin', fontsize=12)\n",
    "ax.set_title('Multi-Class Confusion Matrix', fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49cec36",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Real-World Projects\n",
    "\n",
    "### \ud83d\udd2c Post-Silicon Validation Projects\n",
    "\n",
    "#### **Project 1: Parametric Test Pass/Fail Prediction**\n",
    "\n",
    "**Objective:** Predict device pass/fail from early parametric test results to enable fast screening.\n",
    "\n",
    "**Business Value:**\n",
    "- Reduce test time by 30% (skip remaining tests for predicted fails)\n",
    "- Early identification of process issues\n",
    "- Real-time yield monitoring\n",
    "- Lower cost per device tested\n",
    "\n",
    "**Dataset Features:**\n",
    "- Early tests: Basic DC parameters (Vdd, Idd, leakage)\n",
    "- Fast digital tests (scan, BIST results)\n",
    "- Temperature, voltage corner conditions\n",
    "- Wafer spatial data (die_x, die_y)\n",
    "\n",
    "**Implementation Guide:**\n",
    "1. Use LogisticRegression with L2 penalty for robustness\n",
    "2. Optimize threshold: Minimize FP (shipping bad devices)\n",
    "3. Monitor precision (avoid costly field returns)\n",
    "4. Cross-validate on different wafer lots\n",
    "5. Feature engineering: Add test ratios, deltas\n",
    "\n",
    "**Expected Outcomes:** 95%+ accuracy, <2% false positive rate\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 2: Multi-Bin Speed Grade Classification**\n",
    "\n",
    "**Objective:** Classify devices into speed bins (Premium/Standard/Value) for pricing tiers.\n",
    "\n",
    "**Business Value:**\n",
    "- Maximize revenue (charge more for faster devices)\n",
    "- Optimize product mix\n",
    "- Enable market segmentation\n",
    "- Reduce overtest (only test bins customers want)\n",
    "\n",
    "**Implementation Guide:**\n",
    "1. Use multinomial logistic regression (softmax)\n",
    "2. Features: Frequency at different voltages, timing paths\n",
    "3. Handle class imbalance (few premium devices)\n",
    "4. Validate bin boundaries with product team\n",
    "5. Consider cost of misclassification (Premium \u2192 Standard worse than Standard \u2192 Value)\n",
    "\n",
    "**Expected Outcomes:** 90%+ 3-class accuracy, revenue optimization 15%\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 3: Wafer-Level Defect Detection**\n",
    "\n",
    "**Objective:** Classify dies as defective vs good using spatial pattern analysis.\n",
    "\n",
    "**Business Value:**\n",
    "- Identify systematic defects (process issues)\n",
    "- Guide process improvements\n",
    "- Reduce false failures (improve yield)\n",
    "- Lower test costs (skip tests on known defects)\n",
    "\n",
    "**Implementation Guide:**\n",
    "1. Features: Parametric values + spatial coordinates\n",
    "2. Add neighbor features (defect clustering)\n",
    "3. Handle severe class imbalance (1-5% defect rate)\n",
    "4. Use class_weight='balanced' in LogisticRegression\n",
    "5. Focus on recall (catch all defects)\n",
    "\n",
    "**Expected Outcomes:** 98%+ recall, AUC > 0.95\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 4: Test Flow Optimization**\n",
    "\n",
    "**Objective:** Predict which test category devices will fail to optimize test sequence.\n",
    "\n",
    "**Business Value:**\n",
    "- Reduce average test time (fail fast)\n",
    "- Lower ATE costs\n",
    "- Increase throughput\n",
    "- Dynamic test reordering\n",
    "\n",
    "**Implementation Guide:**\n",
    "1. Multi-class: Predict fail category (Digital, Analog, Memory, Pass)\n",
    "2. Train on historical test sequences\n",
    "3. Optimize test order: High-failure tests first\n",
    "4. A/B test reordered sequences\n",
    "5. Monitor for process changes (retrain quarterly)\n",
    "\n",
    "**Expected Outcomes:** 20% test time reduction, same quality\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcca General AI/ML Projects\n",
    "\n",
    "#### **Project 5: Customer Churn Prediction**\n",
    "\n",
    "**Objective:** Predict which customers likely to cancel subscriptions.\n",
    "\n",
    "**Business Value:**\n",
    "- Proactive retention campaigns\n",
    "- Reduce churn rate by 25%\n",
    "- Increase customer lifetime value\n",
    "- Targeted interventions (discounts, support)\n",
    "\n",
    "**Implementation:** Binary logistic regression on usage patterns, support tickets, billing history\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 6: Fraud Detection in Transactions**\n",
    "\n",
    "**Objective:** Real-time classification of fraudulent vs legitimate transactions.\n",
    "\n",
    "**Business Value:**\n",
    "- Prevent financial losses\n",
    "- Improve customer trust\n",
    "- Regulatory compliance\n",
    "- Minimize false positives (avoid blocking real transactions)\n",
    "\n",
    "**Implementation:** Imbalanced classification (<1% fraud), optimize for high recall with acceptable precision\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 7: Email Spam Classification**\n",
    "\n",
    "**Objective:** Filter spam emails from inbox using text features.\n",
    "\n",
    "**Business Value:**\n",
    "- Improve user experience\n",
    "- Reduce security risks\n",
    "- Save time (no manual filtering)\n",
    "- Interpretable rules (explain why email is spam)\n",
    "\n",
    "**Implementation:** TF-IDF features + Logistic Regression with L1 (feature selection)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Project 8: Medical Diagnosis (Disease Prediction)**\n",
    "\n",
    "**Objective:** Predict disease presence from patient symptoms and test results.\n",
    "\n",
    "**Business Value:**\n",
    "- Early diagnosis\n",
    "- Guide treatment decisions\n",
    "- Reduce diagnostic costs\n",
    "- Interpretable (doctors understand coefficients)\n",
    "\n",
    "**Implementation:** Multi-class for disease types, careful threshold selection (minimize false negatives)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1add1d5",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways\n",
    "\n",
    "### \u2705 When to Use Logistic Regression\n",
    "\n",
    "1. **Binary or multi-class classification** with linearly separable classes\n",
    "2. **Need probability estimates** for decision making\n",
    "3. **Interpretability critical** (stakeholder approval)\n",
    "4. **Baseline model** before trying complex classifiers\n",
    "5. **Real-time inference** required (fast predictions)\n",
    "\n",
    "### \u26a0\ufe0f Limitations\n",
    "\n",
    "- **Linear decision boundary**: Can't capture complex non-linear patterns\n",
    "- **Feature engineering**: Need to manually create interactions/polynomials\n",
    "- **Assumption of independence**: Features assumed independent (rarely true)\n",
    "- **Sensitive to outliers**: Regularization helps but not perfect\n",
    "\n",
    "**Better Alternatives:**\n",
    "- **Tree-based models** (Random Forest, XGBoost): Non-linear, minimal tuning\n",
    "- **Neural networks**: Very complex decision boundaries\n",
    "- **SVM with kernels**: Non-linear with implicit feature spaces\n",
    "\n",
    "### \ud83c\udfaf Best Practices\n",
    "\n",
    "1. **Check class balance**: Use stratified split, handle imbalance if needed\n",
    "2. **Scale features**: StandardScaler for numerical stability\n",
    "3. **Use regularization**: L2 (Ridge) by default, L1 (Lasso) for feature selection\n",
    "4. **Multiple metrics**: Don't rely only on accuracy (especially with imbalance)\n",
    "5. **Optimize threshold**: Default 0.5 may not be optimal for your costs\n",
    "6. **Cross-validation**: Ensure robustness across data splits\n",
    "7. **Monitor calibration**: Probabilities should be well-calibrated\n",
    "\n",
    "### \ud83d\udcda Next Learning Steps\n",
    "\n",
    "1. **`014_Support_Vector_Regression.ipynb`** - SVMs and kernel methods\n",
    "2. **`016_Decision_Trees.ipynb`** - Non-linear classifiers\n",
    "3. **`024_Support_Vector_Machines.ipynb`** - SVM for classification\n",
    "4. **Neural networks** - Deep learning for complex patterns\n",
    "\n",
    "### \ud83d\udd11 Core Concepts Mastered\n",
    "\n",
    "\u2705 Sigmoid function and probability estimation  \n",
    "\u2705 Cross-entropy loss and gradient descent  \n",
    "\u2705 Confusion matrix and classification metrics  \n",
    "\u2705 ROC curve, AUC, and threshold selection  \n",
    "\u2705 Multi-class strategies (OvR, softmax)  \n",
    "\u2705 Feature interpretation via coefficients  \n",
    "\u2705 Handling class imbalance  \n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You now understand classification fundamentals, probability estimation, and how to evaluate classifiers properly. These skills apply to all classification algorithms, not just logistic regression.\n",
    "\n",
    "Continue to **014_Support_Vector_Regression** for robust regression with kernel methods."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}