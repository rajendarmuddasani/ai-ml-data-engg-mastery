{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 015: Quantile Regression\n\n## \ud83c\udfaf Learning Objectives\n\nBy the end of this notebook, you will:\n1. Understand **quantile regression** and how it differs from mean regression\n2. Master **conditional quantiles** for predicting distribution bounds (10th, 50th, 90th percentiles)\n3. Implement **quantile loss function** from scratch\n4. Apply **sklearn's QuantileRegressor** for production use\n5. Build **prediction intervals** and uncertainty quantification\n6. Deploy quantile regression for **post-silicon validation** (process capability bounds, worst-case yield, guard-band optimization)\n7. Apply to **general AI/ML** scenarios (risk assessment, extreme value prediction, tail modeling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Concept Overview\n\n**Quantile Regression** predicts conditional quantiles instead of conditional means:\n- **OLS/Ridge/Lasso**: Predict E[Y|X] (mean/expected value)\n- **Quantile Regression**: Predict Q_\u03c4[Y|X] (\u03c4-th quantile)\n\n**Key Advantages:**\n- **Distribution modeling**: Get full picture (not just mean)\n- **Robust to outliers**: Median regression (\u03c4=0.5) is highly robust\n- **Asymmetric loss**: Different penalties for over/under-prediction\n- **Prediction intervals**: Natural uncertainty quantification\n- **Extreme value analysis**: Model tails directly (\u03c4=0.01, \u03c4=0.99)\n\n**Why Quantile Regression Matters:**\n- **Post-Silicon**: Predict worst-case performance (\u03c4=0.01) for guard-banding\n- **General AI/ML**: Risk management needs tail predictions, not averages\n- **Business value**: \"95th percentile delivery time\" more useful than \"average\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\uddfa\ufe0f Quantile Regression Workflow\n\n```mermaid\ngraph TD\n    A[Input Data] --> B[Choose Quantiles]\n    B --> C[\u03c4 = 0.5: Median]\n    B --> D[\u03c4 = 0.1, 0.9: Intervals]\n    B --> E[\u03c4 = 0.01, 0.99: Extremes]\n    C --> F[Check Loss Function]\n    D --> F\n    E --> F\n    F --> G[Asymmetric Penalty]\n    G --> H[Optimize via LP or SGD]\n    H --> I[Multiple Quantile Models]\n    I --> J[Prediction Bands]\n    J --> K[Uncertainty Quantification]\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\uddee Mathematical Foundation\n\n### Quantile Loss (Check Loss)\n\nFor quantile \u03c4 \u2208 (0,1), the **check loss** is:\n\n$$\n\\rho_{\\tau}(e) = \\begin{cases}\n\\tau \\cdot e & \\text{if } e \\geq 0 \\\\\n(\\tau - 1) \\cdot e & \\text{if } e < 0\n\\end{cases}\n$$\n\nWhere e = y - \u0177 (residual).\n\n**Intuition:**\n- \u03c4 = 0.5 (median): Symmetric loss, robust like MAE\n- \u03c4 = 0.9: Penalizes under-prediction 9\u00d7 more\n- \u03c4 = 0.1: Penalizes over-prediction 9\u00d7 more\n\n### Optimization Problem\n\n$$\n\\min_{\\beta} \\sum_{i=1}^{n} \\rho_{\\tau}(y_i - x_i^T \\beta)\n$$\n\n**Properties:**\n- Convex but non-differentiable at e=0\n- Solved via linear programming or subgradient methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 Setup and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udcdd What's Happening in This Code?\n\n**Purpose:** Import libraries for quantile regression implementation.\n\n**Key Points:**\n- **sklearn.linear_model.QuantileRegressor**: Production quantile regression\n- **scipy.optimize**: For custom optimization\n- **Matplotlib/Seaborn**: Visualize prediction intervals\n- **Check loss**: Requires specialized optimization (not standard gradient descent)\n\n**Why This Matters:** Quantile regression needs different optimization than MSE-based methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import QuantileRegressor, LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(42)\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\n\nprint(\"\u2705 Libraries imported\")\nprint(f\"NumPy: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## \ud83d\udd27 Part 1: From Scratch Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udcdd What's Happening in This Code?\n\n**Purpose:** Implement quantile regression using subgradient descent on check loss.\n\n**Key Points:**\n- **Check loss**: Asymmetric penalty \u03c1_\u03c4(e)\n- **Subgradient**: \u2202\u03c1_\u03c4/\u2202e = \u03c4 if e\u22650, else (\u03c4-1)\n- **Multiple quantiles**: Train separate model for each \u03c4\n- **Convex optimization**: Guaranteed to find global minimum\n\n**Why This Matters:** Understanding check loss reveals why quantile regression is robust and models distribution tails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class QuantileRegressionScratch:\n    \"\"\"\n    Quantile Regression from scratch using subgradient descent.\n    \"\"\"\n    \n    def __init__(self, quantile=0.5, learning_rate=0.01, n_iterations=1000):\n        self.quantile = quantile\n        self.learning_rate = learning_rate\n        self.n_iterations = n_iterations\n        self.w = None\n        self.b = None\n        self.loss_history = []\n        \n    def _check_loss(self, y, y_pred):\n        \"\"\"Compute quantile (check) loss.\"\"\"\n        errors = y - y_pred\n        loss = np.where(\n            errors >= 0,\n            self.quantile * errors,\n            (self.quantile - 1) * errors\n        )\n        return np.mean(loss)\n    \n    def _compute_gradient(self, X, y, y_pred):\n        \"\"\"Compute subgradient of check loss.\"\"\"\n        n_samples = X.shape[0]\n        errors = y - y_pred\n        \n        # Subgradient: \u03c4 if e\u22650, else (\u03c4-1)\n        subgrad = np.where(errors >= 0, -self.quantile, -(self.quantile - 1))\n        \n        grad_w = (1/n_samples) * X.T @ subgrad\n        grad_b = (1/n_samples) * np.sum(subgrad)\n        \n        return grad_w, grad_b\n    \n    def fit(self, X, y):\n        \"\"\"Train using subgradient descent.\"\"\"\n        n_samples, n_features = X.shape\n        self.w = np.zeros(n_features)\n        self.b = 0\n        \n        for iteration in range(self.n_iterations):\n            y_pred = X @ self.w + self.b\n            grad_w, grad_b = self._compute_gradient(X, y, y_pred)\n            self.w -= self.learning_rate * grad_w\n            self.b -= self.learning_rate * grad_b\n            \n            if iteration % 100 == 0:\n                loss = self._check_loss(y, y_pred)\n                self.loss_history.append(loss)\n        \n        return self\n    \n    def predict(self, X):\n        return X @ self.w + self.b\n\nprint(\"\u2705 QuantileRegressionScratch defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test From-Scratch Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udcdd What's Happening in This Code?\n\n**Purpose:** Validate from-scratch quantile regression on heteroscedastic data.\n\n**Key Points:**\n- **Heteroscedastic data**: Variance increases with X (realistic scenario)\n- **Three quantiles**: \u03c4=0.1, 0.5, 0.9 create prediction band\n- **Outliers added**: Tests robustness of median (\u03c4=0.5)\n- **Different slopes**: Each quantile has its own regression line\n- **80% interval**: 10th-90th percentile captures middle 80% of distribution\n\n**Why This Matters:** Real data often has non-constant variance. Quantile regression handles this naturally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate heteroscedastic data (variance increases with X)\nnp.random.seed(42)\nn_samples = 200\nX_hetero = np.linspace(0, 10, n_samples).reshape(-1, 1)\n\n# True relationship with increasing variance\ny_hetero = 2 * X_hetero.ravel() + 5 + np.random.normal(\n    0, 0.5 + 0.3*X_hetero.ravel(), n_samples\n)\n\n# Add extreme outliers\noutlier_idx = np.random.choice(n_samples, size=10, replace=False)\ny_hetero[outlier_idx] += np.random.choice([-1, 1], 10) * np.random.uniform(5, 10, 10)\n\n# Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X_hetero, y_hetero, test_size=0.2, random_state=42\n)\n\n# Train quantile models for \u03c4 = 0.1, 0.5, 0.9\nquantiles = [0.1, 0.5, 0.9]\nmodels_scratch = {}\n\nfor tau in quantiles:\n    model = QuantileRegressionScratch(\n        quantile=tau, learning_rate=0.01, n_iterations=1000\n    )\n    model.fit(X_train, y_train)\n    models_scratch[tau] = model\n    \nprint(\"\\n\ud83d\udd27 From-Scratch Quantile Regression Trained:\")\nfor tau, model in models_scratch.items():\n    y_pred = model.predict(X_test)\n    mae = mean_absolute_error(y_test, y_pred)\n    print(f\"\u03c4={tau:.1f}: MAE={mae:.4f}, w={model.w[0]:.4f}, b={model.b:.4f}\")\n\nprint(\"\\n\u2705 Different quantiles \u2192 different slopes (models the distribution)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Quantile Bands"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udcdd What's Happening in This Code?\n\n**Purpose:** Visualize prediction intervals from multiple quantile models.\n\n**Key Points:**\n- **Shaded band**: Region between 10th and 90th percentile predictions\n- **Median line (red)**: \u03c4=0.5, robust central tendency\n- **Widening band**: Captures increasing variance as X increases\n- **Coverage**: Should contain ~80% of data points\n- **Outliers outside band**: Expected (10% below, 10% above)\n\n**Why This Matters:** Visual validation that quantile models capture the data distribution, not just the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create prediction grid\nX_plot = np.linspace(X_train.min(), X_train.max(), 300).reshape(-1, 1)\n\n# Get predictions for all quantiles\npredictions = {}\nfor tau, model in models_scratch.items():\n    predictions[tau] = model.predict(X_plot)\n\n# Plot\nplt.figure(figsize=(12, 6))\n\n# Training data\nplt.scatter(X_train, y_train, alpha=0.5, s=30, label='Training Data')\n\n# Quantile lines\nplt.plot(X_plot, predictions[0.5], 'r-', linewidth=2, label='Median (\u03c4=0.5)')\nplt.plot(X_plot, predictions[0.1], 'b--', linewidth=1.5, label='10th Percentile')\nplt.plot(X_plot, predictions[0.9], 'g--', linewidth=1.5, label='90th Percentile')\n\n# Shaded band (10th-90th percentile)\nplt.fill_between(\n    X_plot.ravel(), \n    predictions[0.1], \n    predictions[0.9],\n    alpha=0.2, \n    color='gray', \n    label='80% Prediction Interval'\n)\n\nplt.xlabel('Feature', fontsize=12)\nplt.ylabel('Target', fontsize=12)\nplt.title('Quantile Regression: Prediction Intervals', fontsize=14, fontweight='bold')\nplt.legend(fontsize=10)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\ud83d\udcca Interpretation:\")\nprint(\"\u2022 Red line: Median prediction (robust to outliers)\")\nprint(\"\u2022 Gray band: 80% prediction interval (10th-90th percentile)\")\nprint(\"\u2022 Band widens with X: Captures heteroscedasticity\")\nprint(\"\u2022 ~80% of points should fall within the gray band\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss Convergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udcdd What's Happening in This Code?\n\n**Purpose:** Verify that check loss converges during training.\n\n**Key Points:**\n- **Different loss scales**: Each quantile has different check loss magnitude\n- **Convergence pattern**: Should decrease and stabilize\n- **Non-smooth**: Expected due to non-differentiability at e=0\n- **Convex optimization**: Guaranteed convergence to global minimum\n\n**Why This Matters:** Loss convergence validates correct implementation of subgradient descent on check loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot loss convergence for all quantiles\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\nfor idx, (tau, model) in enumerate(models_scratch.items()):\n    axes[idx].plot(model.loss_history, linewidth=2)\n    axes[idx].set_xlabel('Iteration (x100)', fontsize=11)\n    axes[idx].set_ylabel('Check Loss', fontsize=11)\n    axes[idx].set_title(f'\u03c4={tau} Loss Convergence', fontsize=12, fontweight='bold')\n    axes[idx].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\ud83d\udcc9 Loss Analysis:\")\nfor tau, model in models_scratch.items():\n    print(f\"\u03c4={tau}: Initial loss={model.loss_history[0]:.4f}, Final loss={model.loss_history[-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## \ud83d\ude80 Part 2: Production Quantile Regression with Sklearn\n\nSklearn's QuantileRegressor uses optimized solvers (linear programming) for better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udcdd What's Happening in This Code?\n\n**Purpose:** Compare sklearn's optimized QuantileRegressor to from-scratch implementation.\n\n**Key Points:**\n- **solver='highs'**: Interior-point linear programming (much faster than gradient descent)\n- **alpha parameter**: L1 regularization (Lasso-style, optional)\n- **Production ready**: Handles large datasets efficiently\n- **Same API**: Familiar fit/predict interface\n- **Validation**: Should match from-scratch results\n\n**Why This Matters:** Production code needs optimized solvers. Linear programming guarantees optimal solution faster than subgradient descent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train sklearn QuantileRegressor for same quantiles\nmodels_sklearn = {}\n\nfor tau in quantiles:\n    model = QuantileRegressor(quantile=tau, alpha=0, solver='highs')\n    model.fit(X_train, y_train)\n    models_sklearn[tau] = model\n\nprint(\"\\n\ufffd\ufffd Sklearn QuantileRegressor Trained:\")\nfor tau, model in models_sklearn.items():\n    y_pred = model.predict(X_test)\n    mae = mean_absolute_error(y_test, y_pred)\n    print(f\"\u03c4={tau:.1f}: MAE={mae:.4f}, coef={model.coef_[0]:.4f}, intercept={model.intercept_:.4f}\")\n\n# Compare to from-scratch\nprint(\"\\n\ud83d\udcca Comparison (Sklearn vs From-Scratch):\")\nfor tau in quantiles:\n    mae_sklearn = mean_absolute_error(y_test, models_sklearn[tau].predict(X_test))\n    mae_scratch = mean_absolute_error(y_test, models_scratch[tau].predict(X_test))\n    print(f\"\u03c4={tau:.1f}: Sklearn MAE={mae_sklearn:.4f}, Scratch MAE={mae_scratch:.4f}\")\n    \nprint(\"\\n\u2705 Results similar (sklearn uses better optimization)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visual Comparison: Sklearn vs From-Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Side-by-side comparison\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\nfor idx, (models, title) in enumerate([\n    (models_scratch, 'From-Scratch'), \n    (models_sklearn, 'Sklearn')\n]):\n    axes[idx].scatter(X_train, y_train, alpha=0.4, s=20, label='Data')\n    \n    for tau in quantiles:\n        y_plot = models[tau].predict(X_plot)\n        label = f'\u03c4={tau}'\n        linestyle = '-' if tau == 0.5 else '--'\n        axes[idx].plot(X_plot, y_plot, linestyle, linewidth=2, label=label)\n    \n    axes[idx].set_xlabel('Feature', fontsize=11)\n    axes[idx].set_ylabel('Target', fontsize=11)\n    axes[idx].set_title(f'{title} Quantile Regression', fontsize=12, fontweight='bold')\n    axes[idx].legend(fontsize=9)\n    axes[idx].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\ud83d\udcca Both implementations produce similar quantile bands\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## \ud83c\udfed Real-World Application: Post-Silicon Validation\n\n**Scenario:** Predict process capability bounds for parametric test yield"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ufffd\ufffd What's Happening in This Code?\n\n**Purpose:** Simulate post-silicon STDF data for process capability analysis.\n\n**Key Points:**\n- **Process capability**: Need 1st percentile (worst-case) and 99th percentile (best-case)\n- **Guard-banding**: Use \u03c4=0.01 to set conservative test limits\n- **Yield prediction**: \u03c4=0.10 and \u03c4=0.90 bracket 80% of population\n- **Business value**: Quantile predictions enable specification optimization\n- **Realistic data**: Non-linear V-F relationship with measurement noise\n\n**Why This Matters:** Post-silicon validation needs worst-case/best-case predictions, not averages. Quantile regression provides these directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate post-silicon parametric test data\nnp.random.seed(42)\nn_devices = 400\n\n# Test conditions\nVoltage = np.random.uniform(0.95, 1.05, n_devices)  # Vdd (V)\nTemperature = np.random.uniform(25, 85, n_devices)  # Temp (\u00b0C)\n\n# Frequency: Non-linear relationship with voltage\n# f \u221d Vdd\u00b2 with temperature effect and process variation\nFrequency_base = 1.8 + 0.5 * (Voltage - 1.0)**2 * 10\nFrequency_temp_effect = -0.003 * (Temperature - 25)\nFrequency_noise = np.random.normal(0, 0.05, n_devices)\n\n# Add process variation (wider distribution for some devices)\nprocess_variation = np.random.normal(1, 0.1, n_devices)\nFrequency = (Frequency_base + Frequency_temp_effect) * process_variation + Frequency_noise\n\n# Create DataFrame\ndf_capability = pd.DataFrame({\n    'Voltage_V': Voltage,\n    'Temperature_C': Temperature,\n    'Frequency_GHz': Frequency\n})\n\nprint(\"\\n\ud83d\udd2c Post-Silicon Process Capability Dataset:\")\nprint(df_capability.head(10))\nprint(f\"\\nFrequency Statistics:\")\nprint(df_capability['Frequency_GHz'].describe())\nprint(f\"\\n1st percentile: {df_capability['Frequency_GHz'].quantile(0.01):.4f} GHz\")\nprint(f\"99th percentile: {df_capability['Frequency_GHz'].quantile(0.99):.4f} GHz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Quantile Models for Process Capability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udcdd What's Happening in This Code?\n\n**Purpose:** Train multiple quantile models for complete distribution characterization.\n\n**Key Points:**\n- **7 quantiles**: 1st, 10th, 25th, 50th, 75th, 90th, 99th percentiles\n- **Features**: Voltage and Temperature (common test conditions)\n- **Capability bounds**: 1st and 99th percentiles define process capability\n- **Median baseline**: 50th percentile as central tendency\n- **StandardScaler**: Normalize features for better convergence\n\n**Why This Matters:** Complete distribution model enables specification setting, guard-banding, and yield optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data\nX_capability = df_capability[['Voltage_V', 'Temperature_C']].values\ny_capability = df_capability['Frequency_GHz'].values\n\nX_train_cap, X_test_cap, y_train_cap, y_test_cap = train_test_split(\n    X_capability, y_capability, test_size=0.2, random_state=42\n)\n\n# Scale features\nscaler_cap = StandardScaler()\nX_train_cap_scaled = scaler_cap.fit_transform(X_train_cap)\nX_test_cap_scaled = scaler_cap.transform(X_test_cap)\n\n# Train multiple quantile models\nquantiles_capability = [0.01, 0.10, 0.25, 0.50, 0.75, 0.90, 0.99]\nmodels_capability = {}\n\nfor tau in quantiles_capability:\n    model = QuantileRegressor(quantile=tau, alpha=0, solver='highs')\n    model.fit(X_train_cap_scaled, y_train_cap)\n    models_capability[tau] = model\n\nprint(\"\\n\ud83d\udd27 Process Capability Models Trained:\")\nprint(f\"\\n{'Quantile':<12} {'MAE':<10} {'Pred (V=1.0, T=25)':<20}\")\nprint(\"-\" * 50)\n\n# Example prediction at nominal conditions\nX_nominal = scaler_cap.transform([[1.0, 25]])\nfor tau, model in models_capability.items():\n    y_pred = model.predict(X_test_cap_scaled)\n    mae = mean_absolute_error(y_test_cap, y_pred)\n    pred_nominal = model.predict(X_nominal)[0]\n    print(f\"\u03c4={tau:<9.2f} {mae:<10.4f} {pred_nominal:<20.4f}\")\n\nprint(\"\\n\u2705 Quantile predictions span the capability range\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Process Capability Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create grid for visualization (vary voltage at fixed temperature)\nV_grid = np.linspace(0.95, 1.05, 100)\nT_fixed = 25  # Room temperature\nX_viz = np.column_stack([V_grid, np.full(100, T_fixed)])\nX_viz_scaled = scaler_cap.transform(X_viz)\n\n# Get predictions for all quantiles\npreds_capability = {}\nfor tau, model in models_capability.items():\n    preds_capability[tau] = model.predict(X_viz_scaled)\n\n# Plot\nplt.figure(figsize=(14, 7))\n\n# Data points\nplt.scatter(X_train_cap[:, 0], y_train_cap, alpha=0.3, s=20, label='Training Data')\n\n# Quantile lines\ncolors = ['darkred', 'red', 'orange', 'green', 'orange', 'blue', 'darkblue']\nfor (tau, preds), color in zip(preds_capability.items(), colors):\n    linestyle = '-' if tau == 0.50 else '--'\n    linewidth = 2.5 if tau in [0.01, 0.99] else 1.5\n    plt.plot(V_grid, preds, linestyle, linewidth=linewidth, color=color,\n             label=f'{int(tau*100)}th percentile')\n\n# Capability bands\nplt.fill_between(V_grid, preds_capability[0.01], preds_capability[0.99],\n                 alpha=0.15, color='gray', label='Process Capability (1st-99th)')\nplt.fill_between(V_grid, preds_capability[0.25], preds_capability[0.75],\n                 alpha=0.2, color='blue', label='IQR (25th-75th)')\n\nplt.xlabel('Voltage (V)', fontsize=12)\nplt.ylabel('Frequency (GHz)', fontsize=12)\nplt.title('Process Capability Analysis: Quantile Regression\\n(Temperature = 25\u00b0C)', \n          fontsize=14, fontweight='bold')\nplt.legend(fontsize=9, loc='best')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\ud83d\udcca Interpretation:\")\nprint(\"\u2022 Dark red/blue lines: 1st and 99th percentiles (capability bounds)\")\nprint(\"\u2022 Green line: Median (50th percentile)\")\nprint(\"\u2022 Blue band: Interquartile range (middle 50% of devices)\")\nprint(\"\u2022 Gray band: Full process capability (98% of devices)\")\nprint(\"\\n\ud83d\udca1 Business Impact: Use 1st percentile for guard-banding (conservative test limits)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## \ud83c\udfaf Real-World Project Ideas\n\n### Post-Silicon Validation Projects (4)\n\n#### 1. **Process Capability Bounds Prediction**\n**Objective:** Predict 1st and 99th percentile performance from early test data.\n\n**Business Value:** Set specification limits that maximize yield while meeting reliability requirements. 1% guard-band optimization can increase revenue by $2-5M per product.\n\n**Key Features:** Early parametric tests (first 20% of test flow), wafer-level spatial data, process corner indicators\n\n**Implementation:** Train \u03c4=0.01 and \u03c4=0.99 models, compare to actual extremes, deploy for real-time limit adjustment\n\n**Success Metric:** 95% accuracy predicting true 1st/99th percentiles, enable dynamic guard-banding\n\n---\n\n#### 2. **Worst-Case Yield Prediction**\n**Objective:** Predict lower-bound yield (\u03c4=0.05) from wafer test for final test planning.\n\n**Business Value:** Conservative yield forecasts prevent overscheduling final test capacity. Reduces idle time and rush costs.\n\n**Key Features:** Wafer test yields by bin, spatial patterns, lot-level metrics\n\n**Implementation:** Quantile regression on historical wafer\u2192final yield, focus on \u03c4=0.05-0.10 for conservative estimates\n\n**Success Metric:** 90% of actual yields exceed predicted 10th percentile\n\n---\n\n#### 3. **Guard-Band Optimization**\n**Objective:** Minimize guard-bands using quantile regression on test-retest data.\n\n**Business Value:** Tighter guard-bands increase yield by 2-5% without sacrificing quality. Direct revenue impact.\n\n**Key Features:** Test-retest correlation data, measurement uncertainty, device performance distributions\n\n**Implementation:** Model \u03c4=0.01 performance vs. test limits, optimize limits to maximize yield while ensuring 99.9% quality\n\n**Success Metric:** Increase yield 3% while maintaining <0.1% field failure rate\n\n---\n\n#### 4. **Specification Limit Setting**\n**Objective:** Set optimal spec limits using quantile regression on capability data.\n\n**Business Value:** Data-driven spec limits balance yield vs. market requirements. Prevents over-specifying (lost yield) or under-specifying (quality issues).\n\n**Key Features:** Parametric test distributions, customer requirements, historical field data\n\n**Implementation:** Model multiple quantiles (1st-99th percentile), align specs with market needs and process capability\n\n**Success Metric:** 95% yield at target specs, <0.5% returns\n\n---\n\n### General AI/ML Projects (4)\n\n#### 5. **Financial Risk Assessment**\n**Objective:** Predict Value-at-Risk (VaR) using quantile regression on portfolio returns.\n\n**Business Value:** Regulatory requirement (Basel III). Quantile regression provides 1st and 5th percentile loss predictions directly.\n\n**Key Features:** Historical returns, volatility, market indicators, macro factors\n\n**Success Metric:** VaR predictions pass regulatory backtesting (95% coverage)\n\n---\n\n#### 6. **Extreme Weather Prediction**\n**Objective:** Predict 95th percentile rainfall/temperature for infrastructure planning.\n\n**Business Value:** Design standards require extreme value predictions, not averages. Prevents under-designed infrastructure.\n\n**Key Features:** Historical weather, climate models, geographical features\n\n**Success Metric:** 90% accuracy for 95th percentile events over 10-year period\n\n---\n\n#### 7. **Healthcare Cost Tail Modeling**\n**Objective:** Predict 90th percentile patient costs for budgeting.\n\n**Business Value:** Average costs misleading due to expensive outliers. Quantile regression models high-cost patients.\n\n**Key Features:** Demographics, diagnosis codes, comorbidities, treatment history\n\n**Success Metric:** Budget within 10% of actual costs for high-cost patients\n\n---\n\n#### 8. **Supply Chain Delivery Time Prediction**\n**Objective:** Predict 90th percentile delivery times for SLA setting.\n\n**Business Value:** SLAs based on 90th percentile more realistic than averages. Reduces penalty costs from missed deliveries.\n\n**Key Features:** Historical delivery times, carrier, distance, weather, season\n\n**Success Metric:** 90% of deliveries meet predicted 90th percentile SLA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n\n## \u2705 Key Takeaways\n\n### When to Use Quantile Regression\n\n| **Use Case** | **Quantile Regression** | **OLS Regression** | **SVR** |\n|-------------|------------------------|-------------------|--------|\n| **Predict mean** | \u274c Use \u03c4=0.5 | \u2705 Optimal | \u2705 Can work |\n| **Predict tails** | \u2705 Direct modeling | \u274c Extrapolation risky | \u274c Not designed for this |\n| **Heteroscedastic data** | \u2705 Models varying spread | \u274c Assumes constant variance | \u2705 Robust but not distributional |\n| **Outlier robustness** | \u2705 Median (\u03c4=0.5) robust | \u274c Sensitive | \u2705 Epsilon-insensitive loss |\n| **Prediction intervals** | \u2705 Direct quantile predictions | \u274c Assumes normality | \u274c Single-point predictions |\n| **Risk assessment** | \u2705 VaR, CVaR directly | \u274c Indirect | \u274c Not applicable |\n| **Guard-banding** | \u2705 1st/99th percentile | \u274c Mean \u00b1 k*\u03c3 assumes normality | \u274c Not distributional |\n\n### Best Practices\n\n1. **Choose quantiles strategically:**\n   - **\u03c4=0.01, 0.05:** Worst-case scenarios (guard-banding, risk)\n   - **\u03c4=0.50:** Robust central tendency (median regression)\n   - **\u03c4=0.95, 0.99:** Best-case scenarios (capability, target)\n   - **Multiple quantiles:** Full distribution (IQR, capability bands)\n\n2. **Hyperparameter tuning:**\n   - **alpha:** Regularization (0.0 for no penalty, 0.1-1.0 for high-dimensional data)\n   - **solver:** Use `'highs'` (linear programming, fast) or `'interior-point'` (large datasets)\n   - **Quantile crossing:** If \u03c4=0.9 predictions < \u03c4=0.5, increase regularization or use monotonicity constraints\n\n3. **Validation:**\n   - Check quantile loss for each \u03c4\n   - Verify empirical coverage: ~\u03c4% of actuals should be below \u03c4-quantile predictions\n   - Plot all quantiles together to check for crossing issues\n\n4. **Production deployment:**\n   - Train separate model for each quantile of interest\n   - Store all models if predicting multiple quantiles\n   - For real-time applications, cache predictions for common input ranges\n   - Monitor empirical coverage over time (model drift detection)\n\n### Limitations\n\n- **Computational cost:** Training K quantiles requires K separate models\n- **Quantile crossing:** Low quantile predictions can exceed high quantile predictions without constraints\n- **Linear relationships:** Standard quantile regression assumes linear effects (use kernel methods or trees for non-linearity)\n- **Large datasets:** Can be slow compared to OLS (linear programming solver)\n\n### Next Steps\n\n- **016_Decision_Trees.ipynb:** Non-linear models, feature interactions, automatic variable selection\n- **051_Deep_Learning_Intro.ipynb:** Neural networks for complex non-linear quantile regression\n- **Advanced quantile methods:** Quantile random forests, quantile gradient boosting, conformalized quantile regression\n\n---\n\n## \ud83d\udcda References & Further Reading\n\n**Foundational Papers:**\n- Koenker & Bassett (1978): \"Regression Quantiles\" - Original quantile regression paper\n- Koenker (2005): \"Quantile Regression\" (textbook) - Comprehensive treatment\n\n**Applications:**\n- Post-silicon: \"Statistical Yield Analysis using Quantile Regression\" (IEEE TCAD 2019)\n- Finance: \"Regression Quantiles in Risk Management\" (Journal of Risk 2002)\n\n**Sklearn Documentation:**\n- `sklearn.linear_model.QuantileRegressor`: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.QuantileRegressor.html\n- User guide: https://scikit-learn.org/stable/modules/linear_model.html#quantile-regression\n\n**Advanced Topics:**\n- Quantile random forests (Meinshausen 2006)\n- Conformalized quantile regression (Romano et al. 2019)\n- Quantile gradient boosting (LightGBM, XGBoost)\n\n---\n\n**Notebook Complete!** \ud83c\udf89\n\nYou now understand:\n- \u2705 Quantile regression theory (check loss, conditional quantiles)\n- \u2705 From-scratch implementation (subgradient descent)\n- \u2705 Production sklearn usage (QuantileRegressor)\n- \u2705 Post-silicon applications (guard-banding, capability bounds)\n- \u2705 General AI/ML applications (risk assessment, tail prediction)\n- \u2705 8 real-world projects to practice\n\n**Next:** `016_Decision_Trees.ipynb` for non-linear modeling and feature interactions."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}