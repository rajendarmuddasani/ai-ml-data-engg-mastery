{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854bff5a",
   "metadata": {},
   "source": [
    "# 120: Advanced Dashboard Design\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- **Master** Plotly Dash: component-based architecture, callbacks, multi-page apps\n",
    "- **Design** enterprise dashboards: layout patterns, responsive design, dark mode\n",
    "- **Implement** advanced interactions: linked charts, drill-downs, filters, dynamic updates\n",
    "- **Build** real-time dashboards: WebSocket connections, live data feeds, auto-refresh\n",
    "- **Deploy** production apps: Docker, Kubernetes, load balancing, authentication\n",
    "- **Create** post-silicon test monitoring dashboards with 10+ interactive charts\n",
    "\n",
    "## üìö What is Advanced Dashboard Design?\n",
    "\n",
    "**Advanced dashboards** go beyond basic visualizations - they enable data exploration through interactivity, support real-time monitoring, and scale to enterprise requirements. Unlike Streamlit's simplicity, Dash provides fine-grained control for complex multi-page applications.\n",
    "\n",
    "**Core concepts:**\n",
    "- **Component architecture**: HTML/CSS structure with Python callbacks\n",
    "- **Reactive callbacks**: Functions triggered by user interactions (clicks, filters, selections)\n",
    "- **State management**: Client-side storage, server-side caching, global state\n",
    "- **Real-time updates**: Intervals, WebSockets, Server-Sent Events (SSE)\n",
    "\n",
    "**Why Advanced Dashboards?**\n",
    "- ‚úÖ **Multi-page apps**: Complex navigation, 50+ pages with shared state\n",
    "- ‚úÖ **Custom styling**: Full CSS/Bootstrap control, brand-specific themes\n",
    "- ‚úÖ **Enterprise features**: Role-based auth, audit logs, API integrations\n",
    "- ‚úÖ **Performance**: Handle 1M+ data points with Plotly WebGL, server-side filtering\n",
    "\n",
    "## üè≠ Post-Silicon Validation Use Cases\n",
    "\n",
    "**Production Test Floor Dashboard**\n",
    "- Input: PostgreSQL database (real-time test results), 1000 devices/hour, 24/7 operation\n",
    "- Features: Live KPI cards (yield, throughput, UPH), wafer maps (last 10 wafers), parametric control charts (Xbar-R, EWMA), anomaly alerts (email/SMS), shift handoff reports (PDF export)\n",
    "- Output: Executive summary page, detailed drill-downs per lot/wafer, historical trends (30 days)\n",
    "- Value: Detect yield excursions within 5 min (vs 2 hrs manual), reduce scrap 15%\n",
    "\n",
    "**STDF Multi-Lot Analysis Platform**\n",
    "- Input: Upload 10-50 STDF files (5GB total), auto-parse with pystdf, store in SQLite\n",
    "- Features: Cross-lot comparison (yield trends, Cpk analysis), parametric correlations (scatter matrix, heatmaps), spatial analysis (wafer maps with clustering), outlier detection (Isolation Forest + manual flagging), custom report builder (drag-drop charts)\n",
    "- Output: Interactive exploration with 20+ chart types, export to PowerPoint/PDF\n",
    "- Value: Analyze 10 lots in 30 min (vs 8 hrs in Excel/JMP)\n",
    "\n",
    "**Test Program Optimization Tool**\n",
    "- Input: Historical test data (1M devices √ó 100 tests), test correlation matrix, cost model ($/second)\n",
    "- Features: Interactive test selection (checkboxes with dependencies), real-time impact calculation (coverage loss, time savings, cost reduction), sensitivity analysis (Monte Carlo simulation), recommendation engine (ML-based test ranking), A/B comparison (current vs optimized suites)\n",
    "- Output: Optimized test list with justification, expected ROI ($500K/year), risk assessment\n",
    "- Value: 25% test time reduction, <1% yield impact, adopted by 10 programs\n",
    "\n",
    "**Device Characterization Dashboard**\n",
    "- Input: Bench characterization data (temp sweeps -40¬∞C to 125¬∞C, voltage sweeps 0.9-1.4V, freq sweeps 500-1500MHz)\n",
    "- Features: 3D surface plots (Vdd √ó Idd √ó freq), contour plots (yield vs conditions), Shmoo plots (pass/fail boundaries), corner analysis (FF, TT, SS process corners), guardbanding calculator (margin vs yield tradeoff)\n",
    "- Output: Operating limits specification, datasheet plots, margin recommendations\n",
    "- Value: Define safe operating area in 2 days (vs 2 weeks manual analysis)\n",
    "\n",
    "## üîÑ Advanced Dashboard Workflow\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    A[Data Sources] --> B[Backend API]\n",
    "    B --> C[Data Processing]\n",
    "    C --> D[Caching Layer]\n",
    "    D --> E[Dash App]\n",
    "    E --> F[Layout Components]\n",
    "    F --> G[Callbacks]\n",
    "    G --> H[User Interactions]\n",
    "    H --> I{Update Needed?}\n",
    "    I -->|Yes| D\n",
    "    I -->|No| J[Client Cache]\n",
    "    J --> F\n",
    "    \n",
    "    K[Authentication] --> E\n",
    "    L[Real-Time Feed] --> C\n",
    "    \n",
    "    style A fill:#e1f5ff\n",
    "    style E fill:#fffacd\n",
    "    style H fill:#e1ffe1\n",
    "```\n",
    "\n",
    "## üìä Learning Path Context\n",
    "\n",
    "**Prerequisites:**\n",
    "- 116: Data Visualization Mastery (Plotly charts)\n",
    "- 117: Streamlit App Development (reactive programming basics)\n",
    "\n",
    "**Next Steps:**\n",
    "- 131: MLOps (deploying ML models in production)\n",
    "- 141: Cloud Computing (AWS/GCP deployment)\n",
    "\n",
    "---\n",
    "\n",
    "Let's build production-grade dashboards! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd2359",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation\n",
    "\n",
    "**Note**: Dash apps run as web servers. Code examples create `.py` files - run them with `python app.py` in terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69778c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Dash and dependencies\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    'dash',           # Main framework\n",
    "    'dash-bootstrap-components',  # Bootstrap styling\n",
    "    'plotly',         # Charts\n",
    "    'pandas',         # Data processing\n",
    "    'numpy',          # Numerical operations\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "        print(f\"‚úì {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '-q'])\n",
    "\n",
    "# Imports\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, State, callback\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n‚úÖ All packages ready!\")\n",
    "print(\"\\nTo run Dash apps:\")\n",
    "print(\"  python app.py\")\n",
    "print(\"  Open browser: http://127.0.0.1:8050\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae3502",
   "metadata": {},
   "source": [
    "## 2. Dash Fundamentals: First Dashboard\n",
    "\n",
    "### üìù Dash Architecture\n",
    "\n",
    "**Key components:**\n",
    "- **App**: Flask server (`app = dash.Dash(__name__)`)\n",
    "- **Layout**: HTML structure using `html` and `dcc` components\n",
    "- **Callbacks**: Functions connecting inputs to outputs (`@callback` decorator)\n",
    "- **Components**: `dcc.Graph`, `dcc.Dropdown`, `html.Div`, `dbc.Card`\n",
    "\n",
    "**Callback flow:**\n",
    "```python\n",
    "@callback(\n",
    "    Output('graph-id', 'figure'),  # What to update\n",
    "    Input('dropdown-id', 'value')  # What triggers update\n",
    ")\n",
    "def update_graph(selected_value):\n",
    "    # Process input, return new figure\n",
    "    return fig\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic_dashboard.py - Save and run: python basic_dashboard.py\n",
    "basic_app_code = '''\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, callback\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample STDF data\n",
    "np.random.seed(42)\n",
    "n_devices = 5000\n",
    "df = pd.DataFrame({\n",
    "    'device_id': range(n_devices),\n",
    "    'wafer_id': np.random.randint(1, 11, n_devices),\n",
    "    'Vdd_V': np.random.normal(1.2, 0.05, n_devices),\n",
    "    'Idd_mA': np.random.normal(50, 5, n_devices),\n",
    "    'freq_MHz': np.random.normal(1000, 50, n_devices),\n",
    "    'bin': np.random.choice(['PASS', 'FAIL_VDD', 'FAIL_IDD'], n_devices, p=[0.90, 0.05, 0.05])\n",
    "})\n",
    "\n",
    "# Initialize app with Bootstrap theme\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Layout\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row([\n",
    "        dbc.Col(html.H1(\"üìä Semiconductor Test Dashboard\", className=\"text-center mb-4\"), width=12)\n",
    "    ]),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Label(\"Select Wafer:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='wafer-dropdown',\n",
    "                options=[{'label': f'Wafer {i}', 'value': i} for i in range(1, 11)],\n",
    "                value=1,\n",
    "                clearable=False\n",
    "            )\n",
    "        ], width=3),\n",
    "        \n",
    "        dbc.Col([\n",
    "            html.Label(\"Select Parameter:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='param-dropdown',\n",
    "                options=[\n",
    "                    {'label': 'Vdd (V)', 'value': 'Vdd_V'},\n",
    "                    {'label': 'Idd (mA)', 'value': 'Idd_mA'},\n",
    "                    {'label': 'Freq (MHz)', 'value': 'freq_MHz'}\n",
    "                ],\n",
    "                value='Vdd_V',\n",
    "                clearable=False\n",
    "            )\n",
    "        ], width=3)\n",
    "    ], className=\"mb-4\"),\n",
    "    \n",
    "    # KPI Cards\n",
    "    dbc.Row([\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Yield\", className=\"card-title\"),\n",
    "                html.H2(id=\"yield-metric\", className=\"text-success\")\n",
    "            ])\n",
    "        ]), width=3),\n",
    "        \n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Devices\", className=\"card-title\"),\n",
    "                html.H2(id=\"devices-metric\")\n",
    "            ])\n",
    "        ]), width=3),\n",
    "        \n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Avg Vdd\", className=\"card-title\"),\n",
    "                html.H2(id=\"vdd-metric\")\n",
    "            ])\n",
    "        ]), width=3),\n",
    "        \n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                html.H4(\"Avg Idd\", className=\"card-title\"),\n",
    "                html.H2(id=\"idd-metric\")\n",
    "            ])\n",
    "        ]), width=3)\n",
    "    ], className=\"mb-4\"),\n",
    "    \n",
    "    # Charts\n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(id='histogram'), width=6),\n",
    "        dbc.Col(dcc.Graph(id='scatter'), width=6)\n",
    "    ])\n",
    "], fluid=True)\n",
    "\n",
    "# Callbacks\n",
    "@callback(\n",
    "    [Output('yield-metric', 'children'),\n",
    "     Output('devices-metric', 'children'),\n",
    "     Output('vdd-metric', 'children'),\n",
    "     Output('idd-metric', 'children'),\n",
    "     Output('histogram', 'figure'),\n",
    "     Output('scatter', 'figure')],\n",
    "    [Input('wafer-dropdown', 'value'),\n",
    "     Input('param-dropdown', 'value')]\n",
    ")\n",
    "def update_dashboard(wafer_id, param):\n",
    "    # Filter data\n",
    "    filtered = df[df['wafer_id'] == wafer_id]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    yield_pct = (filtered['bin'] == 'PASS').mean() * 100\n",
    "    n_devices = len(filtered)\n",
    "    avg_vdd = filtered['Vdd_V'].mean()\n",
    "    avg_idd = filtered['Idd_mA'].mean()\n",
    "    \n",
    "    # Histogram\n",
    "    fig_hist = px.histogram(filtered, x=param, nbins=30, \n",
    "                           title=f\"{param} Distribution - Wafer {wafer_id}\")\n",
    "    fig_hist.update_layout(showlegend=False)\n",
    "    \n",
    "    # Scatter plot\n",
    "    fig_scatter = px.scatter(filtered, x='Vdd_V', y='Idd_mA', color='bin',\n",
    "                            title=f\"Vdd vs Idd - Wafer {wafer_id}\")\n",
    "    \n",
    "    return (\n",
    "        f\"{yield_pct:.1f}%\",\n",
    "        f\"{n_devices:,}\",\n",
    "        f\"{avg_vdd:.3f} V\",\n",
    "        f\"{avg_idd:.1f} mA\",\n",
    "        fig_hist,\n",
    "        fig_scatter\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8050)\n",
    "'''\n",
    "\n",
    "# Save to file\n",
    "with open('basic_dashboard.py', 'w') as f:\n",
    "    f.write(basic_app_code)\n",
    "\n",
    "print(\"‚úÖ Saved to basic_dashboard.py\")\n",
    "print(\"\\nTo run: python basic_dashboard.py\")\n",
    "print(\"Then open: http://127.0.0.1:8050\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db1adb",
   "metadata": {},
   "source": [
    "## 3. Advanced Layouts: Multi-Page Architecture\n",
    "\n",
    "### üìù Layout Patterns\n",
    "\n",
    "**Bootstrap grid system:**\n",
    "- 12-column layout: `dbc.Row` + `dbc.Col(width=X)`\n",
    "- Responsive breakpoints: `width={'size': 6, 'md': 4, 'lg': 3}`\n",
    "- Components: `dbc.Card`, `dbc.Tabs`, `dbc.Modal`, `dbc.Navbar`\n",
    "\n",
    "**Multi-page structure:**\n",
    "```\n",
    "app/\n",
    "‚îú‚îÄ‚îÄ app.py              # Main app\n",
    "‚îú‚îÄ‚îÄ pages/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ home.py         # Landing page\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ analysis.py     # Data analysis\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ settings.py     # Configuration\n",
    "‚îî‚îÄ‚îÄ assets/\n",
    "    ‚îî‚îÄ‚îÄ style.css       # Custom CSS\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multipage_app.py - Advanced multi-page dashboard\n",
    "multipage_code = '''\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, callback\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(42)\n",
    "n = 10000\n",
    "df = pd.DataFrame({\n",
    "    'device_id': range(n),\n",
    "    'wafer_id': np.random.randint(1, 26, n),\n",
    "    'lot_id': np.random.choice(['LOT_A', 'LOT_B', 'LOT_C'], n),\n",
    "    'die_x': np.random.randint(0, 30, n),\n",
    "    'die_y': np.random.randint(0, 30, n),\n",
    "    'Vdd_V': np.random.normal(1.2, 0.05, n),\n",
    "    'Idd_mA': np.random.normal(50, 5, n),\n",
    "    'freq_MHz': np.random.normal(1000, 50, n),\n",
    "    'bin': np.random.choice(['PASS', 'FAIL_VDD', 'FAIL_IDD', 'FAIL_FREQ'], \n",
    "                           n, p=[0.88, 0.04, 0.04, 0.04])\n",
    "})\n",
    "\n",
    "# Initialize app\n",
    "app = dash.Dash(__name__, \n",
    "                external_stylesheets=[dbc.themes.DARKLY],  # Dark theme\n",
    "                suppress_callback_exceptions=True)\n",
    "\n",
    "# Navbar\n",
    "navbar = dbc.Navbar(\n",
    "    dbc.Container([\n",
    "        dbc.NavbarBrand(\"üî¨ Test Analytics Platform\", className=\"ms-2\"),\n",
    "        dbc.Nav([\n",
    "            dbc.NavItem(dbc.NavLink(\"Dashboard\", href=\"/\", id=\"nav-home\")),\n",
    "            dbc.NavItem(dbc.NavLink(\"Wafer Maps\", href=\"/wafer\", id=\"nav-wafer\")),\n",
    "            dbc.NavItem(dbc.NavLink(\"Trends\", href=\"/trends\", id=\"nav-trends\")),\n",
    "            dbc.NavItem(dbc.NavLink(\"Settings\", href=\"/settings\", id=\"nav-settings\"))\n",
    "        ], navbar=True)\n",
    "    ], fluid=True),\n",
    "    color=\"dark\",\n",
    "    dark=True,\n",
    "    className=\"mb-4\"\n",
    ")\n",
    "\n",
    "# Page: Dashboard\n",
    "def create_dashboard_page():\n",
    "    return dbc.Container([\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.H2(\"üìä Executive Dashboard\"), width=12)\n",
    "        ], className=\"mb-4\"),\n",
    "        \n",
    "        # Filters\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.Label(\"Lot:\"),\n",
    "                dcc.Dropdown(id='lot-filter', \n",
    "                           options=[{'label': lot, 'value': lot} for lot in df['lot_id'].unique()],\n",
    "                           value='LOT_A', clearable=False)\n",
    "            ], width=2),\n",
    "            dbc.Col([\n",
    "                html.Label(\"Wafer Range:\"),\n",
    "                dcc.RangeSlider(id='wafer-range', min=1, max=25, value=[1, 25], \n",
    "                               marks={i: str(i) for i in [1, 5, 10, 15, 20, 25]})\n",
    "            ], width=4)\n",
    "        ], className=\"mb-4\"),\n",
    "        \n",
    "        # KPIs\n",
    "        dbc.Row(id='kpi-cards', className=\"mb-4\"),\n",
    "        \n",
    "        # Charts\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='yield-trend'), width=6),\n",
    "            dbc.Col(dcc.Graph(id='param-box'), width=6)\n",
    "        ])\n",
    "    ], fluid=True)\n",
    "\n",
    "# Page: Wafer Maps\n",
    "def create_wafer_page():\n",
    "    return dbc.Container([\n",
    "        dbc.Row([dbc.Col(html.H2(\"üó∫Ô∏è Wafer Map Analysis\"), width=12)], className=\"mb-4\"),\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.Label(\"Select Wafer:\"),\n",
    "                dcc.Dropdown(id='wafer-select', \n",
    "                           options=[{'label': f'Wafer {i}', 'value': i} for i in range(1, 26)],\n",
    "                           value=1, clearable=False)\n",
    "            ], width=3)\n",
    "        ], className=\"mb-4\"),\n",
    "        dbc.Row([dbc.Col(dcc.Graph(id='wafer-map'), width=8)])\n",
    "    ], fluid=True)\n",
    "\n",
    "# Page: Trends\n",
    "def create_trends_page():\n",
    "    return dbc.Container([\n",
    "        dbc.Row([dbc.Col(html.H2(\"üìà Parametric Trends\"), width=12)], className=\"mb-4\"),\n",
    "        dbc.Row([dbc.Col(dcc.Graph(id='trends-chart'), width=12)])\n",
    "    ], fluid=True)\n",
    "\n",
    "# Main layout with URL routing\n",
    "app.layout = html.Div([\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "    navbar,\n",
    "    html.Div(id='page-content')\n",
    "])\n",
    "\n",
    "# Route pages\n",
    "@callback(Output('page-content', 'children'), Input('url', 'pathname'))\n",
    "def display_page(pathname):\n",
    "    if pathname == '/wafer':\n",
    "        return create_wafer_page()\n",
    "    elif pathname == '/trends':\n",
    "        return create_trends_page()\n",
    "    else:\n",
    "        return create_dashboard_page()\n",
    "\n",
    "# Dashboard callbacks\n",
    "@callback(\n",
    "    [Output('kpi-cards', 'children'),\n",
    "     Output('yield-trend', 'figure'),\n",
    "     Output('param-box', 'figure')],\n",
    "    [Input('lot-filter', 'value'),\n",
    "     Input('wafer-range', 'value')]\n",
    ")\n",
    "def update_dashboard(lot, wafer_range):\n",
    "    filtered = df[(df['lot_id'] == lot) & \n",
    "                 (df['wafer_id'] >= wafer_range[0]) & \n",
    "                 (df['wafer_id'] <= wafer_range[1])]\n",
    "    \n",
    "    # KPIs\n",
    "    yield_pct = (filtered['bin'] == 'PASS').mean() * 100\n",
    "    kpis = dbc.Row([\n",
    "        dbc.Col(dbc.Card([dbc.CardBody([\n",
    "            html.H5(\"Yield\"), html.H3(f\"{yield_pct:.1f}%\", className=\"text-success\")\n",
    "        ])]), width=3),\n",
    "        dbc.Col(dbc.Card([dbc.CardBody([\n",
    "            html.H5(\"Devices\"), html.H3(f\"{len(filtered):,}\")\n",
    "        ])]), width=3),\n",
    "        dbc.Col(dbc.Card([dbc.CardBody([\n",
    "            html.H5(\"Wafers\"), html.H3(f\"{filtered['wafer_id'].nunique()}\")\n",
    "        ])]), width=3)\n",
    "    ])\n",
    "    \n",
    "    # Yield trend by wafer\n",
    "    yield_by_wafer = filtered.groupby('wafer_id').apply(\n",
    "        lambda x: (x['bin'] == 'PASS').mean() * 100\n",
    "    ).reset_index(name='yield')\n",
    "    fig_trend = px.line(yield_by_wafer, x='wafer_id', y='yield', \n",
    "                       title=\"Yield Trend by Wafer\", markers=True)\n",
    "    fig_trend.add_hline(y=85, line_dash=\"dash\", line_color=\"red\", \n",
    "                       annotation_text=\"Target: 85%\")\n",
    "    \n",
    "    # Parameter boxplots\n",
    "    fig_box = px.box(filtered, x='bin', y='Vdd_V', color='bin',\n",
    "                    title=\"Vdd Distribution by Bin\")\n",
    "    \n",
    "    return kpis, fig_trend, fig_box\n",
    "\n",
    "# Wafer map callback\n",
    "@callback(Output('wafer-map', 'figure'), Input('wafer-select', 'value'))\n",
    "def update_wafer_map(wafer_id):\n",
    "    wafer_data = df[df['wafer_id'] == wafer_id]\n",
    "    fig = px.scatter(wafer_data, x='die_x', y='die_y', color='bin',\n",
    "                    title=f\"Wafer {wafer_id} Bin Map\",\n",
    "                    width=600, height=600)\n",
    "    fig.update_traces(marker=dict(size=12, symbol='square'))\n",
    "    fig.update_yaxes(scaleanchor='x', scaleratio=1)\n",
    "    return fig\n",
    "\n",
    "# Trends callback\n",
    "@callback(Output('trends-chart', 'figure'), Input('url', 'pathname'))\n",
    "def update_trends(pathname):\n",
    "    trend_data = df.groupby('wafer_id').agg({\n",
    "        'Vdd_V': ['mean', 'std'],\n",
    "        'Idd_mA': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "    trend_data.columns = ['wafer_id', 'Vdd_mean', 'Vdd_std', 'Idd_mean', 'Idd_std']\n",
    "    \n",
    "    fig = px.scatter(trend_data, x='Vdd_mean', y='Idd_mean', \n",
    "                    size='Vdd_std', hover_data=['wafer_id'],\n",
    "                    title=\"Vdd vs Idd Correlation (size = Vdd std)\")\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8050)\n",
    "'''\n",
    "\n",
    "with open('multipage_app.py', 'w') as f:\n",
    "    f.write(multipage_code)\n",
    "\n",
    "print(\"‚úÖ Saved to multipage_app.py\")\n",
    "print(\"Features: Multi-page routing, dark theme, responsive layout, linked charts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b98e24c",
   "metadata": {},
   "source": [
    "## 4. Real-Time Dashboards: Live Data Feeds\n",
    "\n",
    "### üìù Real-Time Patterns\n",
    "\n",
    "**1. Interval Updates** (polling):\n",
    "```python\n",
    "dcc.Interval(id='interval', interval=5000)  # 5 seconds\n",
    "\n",
    "@callback(Output('graph', 'figure'), Input('interval', 'n_intervals'))\n",
    "def update(n):\n",
    "    data = fetch_latest_data()  # Query database\n",
    "    return create_figure(data)\n",
    "```\n",
    "\n",
    "**2. WebSocket Connections** (push):\n",
    "- Use `dash-websockets` for server-push updates\n",
    "- Lower latency than polling (1ms vs 5s)\n",
    "- Best for high-frequency data (>1 update/second)\n",
    "\n",
    "**3. Performance Optimization**:\n",
    "- **Server-side caching**: Cache database queries for 30s\n",
    "- **Client-side store**: `dcc.Store` for shared data\n",
    "- **Partial updates**: Use `dash.Patch()` to update only changed data\n",
    "- **WebGL rendering**: Enable for 100K+ points (`scattergl`, `scattermapbox`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1753dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realtime_dashboard.py - Live production monitoring\n",
    "realtime_code = '''\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, callback\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from collections import deque\n",
    "\n",
    "# Simulate real-time data stream\n",
    "class TestDataStream:\n",
    "    def __init__(self):\n",
    "        self.history = deque(maxlen=100)  # Last 100 data points\n",
    "        self.start_time = datetime.now()\n",
    "    \n",
    "    def get_latest(self):\n",
    "        \"\"\"Simulate new test result\"\"\"\n",
    "        current_time = datetime.now()\n",
    "        elapsed = (current_time - self.start_time).total_seconds()\n",
    "        \n",
    "        # Simulate yield drift over time\n",
    "        base_yield = 90 - (elapsed / 100)  # Gradual decline\n",
    "        noise = np.random.normal(0, 2)\n",
    "        yield_pct = max(80, min(95, base_yield + noise))\n",
    "        \n",
    "        data = {\n",
    "            'timestamp': current_time,\n",
    "            'yield': yield_pct,\n",
    "            'throughput': np.random.poisson(50),  # Devices/min\n",
    "            'Vdd_mean': np.random.normal(1.2, 0.02),\n",
    "            'Idd_mean': np.random.normal(50, 2)\n",
    "        }\n",
    "        self.history.append(data)\n",
    "        return data\n",
    "    \n",
    "    def get_history(self):\n",
    "        return pd.DataFrame(list(self.history))\n",
    "\n",
    "# Initialize\n",
    "stream = TestDataStream()\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.CYBORG])\n",
    "\n",
    "# Layout\n",
    "app.layout = dbc.Container([\n",
    "    dcc.Interval(id='interval', interval=2000, n_intervals=0),  # Update every 2s\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(html.H1(\"üî¥ LIVE: Production Test Floor\"), width=8),\n",
    "        dbc.Col(html.H4(id='clock', className=\"text-end\"), width=4)\n",
    "    ], className=\"mb-4\"),\n",
    "    \n",
    "    # Real-time KPIs\n",
    "    dbc.Row([\n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardHeader(\"Current Yield\"),\n",
    "            dbc.CardBody([html.H2(id='live-yield', className=\"text-success\")])\n",
    "        ]), width=3),\n",
    "        \n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardHeader(\"Throughput\"),\n",
    "            dbc.CardBody([html.H2(id='live-throughput')])\n",
    "        ]), width=3),\n",
    "        \n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardHeader(\"Status\"),\n",
    "            dbc.CardBody([html.H2(id='live-status')])\n",
    "        ]), width=3),\n",
    "        \n",
    "        dbc.Col(dbc.Card([\n",
    "            dbc.CardHeader(\"Alert Level\"),\n",
    "            dbc.CardBody([html.H2(id='alert-level')])\n",
    "        ]), width=3)\n",
    "    ], className=\"mb-4\"),\n",
    "    \n",
    "    # Real-time charts\n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(id='yield-realtime'), width=6),\n",
    "        dbc.Col(dcc.Graph(id='param-realtime'), width=6)\n",
    "    ]),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(dcc.Graph(id='throughput-realtime'), width=12)\n",
    "    ])\n",
    "], fluid=True)\n",
    "\n",
    "# Callbacks\n",
    "@callback(\n",
    "    [Output('clock', 'children'),\n",
    "     Output('live-yield', 'children'),\n",
    "     Output('live-yield', 'className'),\n",
    "     Output('live-throughput', 'children'),\n",
    "     Output('live-status', 'children'),\n",
    "     Output('alert-level', 'children'),\n",
    "     Output('alert-level', 'className'),\n",
    "     Output('yield-realtime', 'figure'),\n",
    "     Output('param-realtime', 'figure'),\n",
    "     Output('throughput-realtime', 'figure')],\n",
    "    Input('interval', 'n_intervals')\n",
    ")\n",
    "def update_realtime(n):\n",
    "    # Get latest data\n",
    "    latest = stream.get_latest()\n",
    "    history = stream.get_history()\n",
    "    \n",
    "    # Current time\n",
    "    clock = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    \n",
    "    # KPIs\n",
    "    yield_val = f\"{latest['yield']:.1f}%\"\n",
    "    yield_class = \"text-success\" if latest['yield'] > 85 else \"text-warning\" if latest['yield'] > 80 else \"text-danger\"\n",
    "    \n",
    "    throughput = f\"{latest['throughput']} dev/min\"\n",
    "    status = \"üü¢ RUNNING\" if latest['throughput'] > 30 else \"üü° SLOW\"\n",
    "    \n",
    "    if latest['yield'] > 88:\n",
    "        alert = \"‚úÖ NORMAL\"\n",
    "        alert_class = \"text-success\"\n",
    "    elif latest['yield'] > 85:\n",
    "        alert = \"‚ö†Ô∏è WARNING\"\n",
    "        alert_class = \"text-warning\"\n",
    "    else:\n",
    "        alert = \"üö® CRITICAL\"\n",
    "        alert_class = \"text-danger\"\n",
    "    \n",
    "    # Yield trend (last 100 points)\n",
    "    fig_yield = go.Figure()\n",
    "    fig_yield.add_trace(go.Scatter(\n",
    "        x=history['timestamp'],\n",
    "        y=history['yield'],\n",
    "        mode='lines',\n",
    "        name='Yield',\n",
    "        line=dict(color='#00ff00', width=2)\n",
    "    ))\n",
    "    fig_yield.add_hline(y=85, line_dash=\"dash\", line_color=\"red\", \n",
    "                       annotation_text=\"Target: 85%\")\n",
    "    fig_yield.update_layout(\n",
    "        title=\"Yield Trend (Last 100 Tests)\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Yield %\",\n",
    "        yaxis_range=[75, 100],\n",
    "        template=\"plotly_dark\"\n",
    "    )\n",
    "    \n",
    "    # Parameter trends\n",
    "    fig_param = go.Figure()\n",
    "    fig_param.add_trace(go.Scatter(\n",
    "        x=history['timestamp'],\n",
    "        y=history['Vdd_mean'],\n",
    "        mode='lines',\n",
    "        name='Vdd (V)',\n",
    "        yaxis='y1'\n",
    "    ))\n",
    "    fig_param.add_trace(go.Scatter(\n",
    "        x=history['timestamp'],\n",
    "        y=history['Idd_mean'],\n",
    "        mode='lines',\n",
    "        name='Idd (mA)',\n",
    "        yaxis='y2'\n",
    "    ))\n",
    "    fig_param.update_layout(\n",
    "        title=\"Parametric Trends\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis=dict(title=\"Vdd (V)\", side=\"left\"),\n",
    "        yaxis2=dict(title=\"Idd (mA)\", side=\"right\", overlaying=\"y\"),\n",
    "        template=\"plotly_dark\"\n",
    "    )\n",
    "    \n",
    "    # Throughput\n",
    "    fig_throughput = go.Figure()\n",
    "    fig_throughput.add_trace(go.Bar(\n",
    "        x=history['timestamp'],\n",
    "        y=history['throughput'],\n",
    "        name='Throughput'\n",
    "    ))\n",
    "    fig_throughput.update_layout(\n",
    "        title=\"Test Throughput (Devices/Min)\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Devices/Min\",\n",
    "        template=\"plotly_dark\"\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        clock, yield_val, yield_class, throughput, status, \n",
    "        alert, alert_class, fig_yield, fig_param, fig_throughput\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"üî¥ Starting real-time dashboard...\")\n",
    "    print(\"Open: http://127.0.0.1:8050\")\n",
    "    print(\"Updates every 2 seconds\")\n",
    "    app.run_server(debug=True, port=8050)\n",
    "'''\n",
    "\n",
    "with open('realtime_dashboard.py', 'w') as f:\n",
    "    f.write(realtime_code)\n",
    "\n",
    "print(\"‚úÖ Saved to realtime_dashboard.py\")\n",
    "print(\"Features: 2-second updates, alert system, dual-axis charts, status indicators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b62368",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "### Dash vs Streamlit\n",
    "\n",
    "**1. When to Choose Dash**\n",
    "- ‚úÖ **Enterprise apps**: Complex multi-page dashboards with 50+ pages\n",
    "- ‚úÖ **Custom styling**: Full CSS/HTML control, brand-specific themes\n",
    "- ‚úÖ **Fine-grained callbacks**: Complex interaction patterns, multiple outputs\n",
    "- ‚úÖ **Production scale**: 1M+ data points, 1000+ concurrent users\n",
    "- ‚úÖ **Advanced auth**: LDAP, OAuth, SSO integration\n",
    "\n",
    "**2. When to Choose Streamlit**\n",
    "- ‚úÖ **Rapid prototyping**: Build MVP in 1 hour vs 1 day (Dash)\n",
    "- ‚úÖ **Simple dashboards**: 1-5 pages, straightforward interactions\n",
    "- ‚úÖ **ML model demos**: Quick model deployment for stakeholders\n",
    "- ‚úÖ **Internal tools**: Data science team collaboration\n",
    "- ‚úÖ **Learning curve**: Python-only, no HTML/CSS knowledge required\n",
    "\n",
    "**3. Hybrid Approach**\n",
    "- Prototype in Streamlit (validate concept, gather requirements)\n",
    "- Rebuild in Dash for production (custom styling, enterprise features)\n",
    "- Cost: 10 hrs Streamlit prototype ‚Üí 40 hrs Dash production app\n",
    "\n",
    "### Dash Architecture\n",
    "\n",
    "**4. Component Hierarchy**\n",
    "```python\n",
    "app.layout = dbc.Container([       # Top-level container\n",
    "    dbc.Row([                      # Bootstrap row\n",
    "        dbc.Col([                  # Bootstrap column\n",
    "            dbc.Card([              # Card component\n",
    "                dbc.CardHeader(),   # Header\n",
    "                dbc.CardBody([      # Body\n",
    "                    dcc.Graph()     # Plotly chart\n",
    "                ])\n",
    "            ])\n",
    "        ], width=6)\n",
    "    ])\n",
    "])\n",
    "```\n",
    "\n",
    "**5. Callback Patterns**\n",
    "```python\n",
    "# Single output\n",
    "@callback(Output('id', 'property'), Input('id2', 'property'))\n",
    "def update(value):\n",
    "    return new_value\n",
    "\n",
    "# Multiple outputs\n",
    "@callback(\n",
    "    [Output('id1', 'property'), Output('id2', 'property')],\n",
    "    Input('trigger', 'property')\n",
    ")\n",
    "def update_multiple(value):\n",
    "    return value1, value2\n",
    "\n",
    "# State (read without triggering)\n",
    "@callback(\n",
    "    Output('result', 'children'),\n",
    "    Input('button', 'n_clicks'),\n",
    "    State('input', 'value')\n",
    ")\n",
    "def on_click(n_clicks, input_value):\n",
    "    return f\"Clicked {n_clicks} times with {input_value}\"\n",
    "\n",
    "# Prevent initial callback\n",
    "@callback(..., prevent_initial_call=True)\n",
    "```\n",
    "\n",
    "**6. Performance Optimization**\n",
    "```python\n",
    "# Client-side callbacks (JavaScript, no server round-trip)\n",
    "app.clientside_callback(\n",
    "    \\\"\\\"\\\"function(n_clicks) { return n_clicks * 2; }\\\"\\\"\\\",\n",
    "    Output('output', 'children'),\n",
    "    Input('button', 'n_clicks')\n",
    ")\n",
    "\n",
    "# Partial updates (Dash 2.9+)\n",
    "from dash import Patch\n",
    "\n",
    "@callback(Output('store', 'data'), Input('button', 'n_clicks'))\n",
    "def update_store(n):\n",
    "    patched = Patch()\n",
    "    patched['new_key'] = 'new_value'  # Only update this key\n",
    "    return patched\n",
    "\n",
    "# Memoization (cache expensive computations)\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def expensive_query(param):\n",
    "    return database.query(param)\n",
    "```\n",
    "\n",
    "### Layout Best Practices\n",
    "\n",
    "**7. Responsive Design**\n",
    "```python\n",
    "# Desktop: 3 columns, Tablet: 2 columns, Mobile: 1 column\n",
    "dbc.Col([...], width=12, md=6, lg=4)\n",
    "\n",
    "# Conditional rendering based on screen size\n",
    "@callback(Output('layout', 'children'), Input('window-size', 'width'))\n",
    "def update_layout(width):\n",
    "    if width < 768:  # Mobile\n",
    "        return mobile_layout()\n",
    "    else:  # Desktop\n",
    "        return desktop_layout()\n",
    "```\n",
    "\n",
    "**8. Theme Customization**\n",
    "```python\n",
    "# Use Bootstrap themes\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.DARKLY])\n",
    "\n",
    "# Custom CSS\n",
    "app = dash.Dash(__name__, assets_folder='assets')\n",
    "# Create assets/custom.css with your styles\n",
    "\n",
    "# Programmatic theming\n",
    "dbc.themes.BOOTSTRAP  # Default\n",
    "dbc.themes.DARKLY     # Dark theme\n",
    "dbc.themes.CYBORG     # Sci-fi dark\n",
    "dbc.themes.SLATE      # Modern dark\n",
    "```\n",
    "\n",
    "**9. Component Library**\n",
    "- **dcc (Dash Core Components)**: Graph, Dropdown, Slider, DatePicker, Upload\n",
    "- **dbc (Dash Bootstrap)**: Card, Modal, Navbar, Tabs, Accordion, Toast\n",
    "- **html**: Div, H1, P, Button, Table (standard HTML elements)\n",
    "- **Custom**: Build with React, publish to PyPI\n",
    "\n",
    "### Real-Time Dashboards\n",
    "\n",
    "**10. Polling vs WebSockets**\n",
    "- **Polling (`dcc.Interval`)**: Simple, works everywhere, 1-60s updates\n",
    "- **WebSockets (`dash-websockets`)**: Low latency (<1s), server push, complex setup\n",
    "- **SSE (Server-Sent Events)**: One-way push, simpler than WebSockets\n",
    "\n",
    "**11. Data Streaming Architecture**\n",
    "```\n",
    "Database/API ‚Üí Message Queue (Kafka/RabbitMQ) ‚Üí Dash Backend ‚Üí Redis Cache ‚Üí Frontend\n",
    "                                                        ‚Üì\n",
    "                                                 WebSocket/Interval\n",
    "```\n",
    "\n",
    "**12. Scalability Limits**\n",
    "- **Dash**: 100K+ data points (WebGL), 1000+ users (Gunicorn + load balancer)\n",
    "- **Plotly**: 1M+ points with `scattergl` (GPU-accelerated rendering)\n",
    "- **Callbacks**: <300ms response time (otherwise use loading spinners)\n",
    "\n",
    "### Deployment\n",
    "\n",
    "**13. Production Checklist**\n",
    "- [ ] Use Gunicorn (4+ workers) instead of `app.run_server(debug=True)`\n",
    "- [ ] Enable HTTPS (SSL/TLS certificates from Let's Encrypt)\n",
    "- [ ] Add authentication (dash-auth, OAuth, LDAP)\n",
    "- [ ] Implement caching (Redis for session state, query results)\n",
    "- [ ] Set up monitoring (Prometheus + Grafana, CloudWatch)\n",
    "- [ ] Configure auto-scaling (Kubernetes HPA, AWS Auto Scaling)\n",
    "- [ ] Add health checks (`/health` endpoint for load balancer)\n",
    "- [ ] Enable logging (structured JSON logs, centralized with ELK/Splunk)\n",
    "- [ ] Rate limiting (nginx, CloudFlare)\n",
    "- [ ] Backup strategy (database snapshots, code in Git)\n",
    "\n",
    "**14. Cost Optimization**\n",
    "- **Caching**: Reduce database queries 80% (Redis TTL 5-60 min)\n",
    "- **CDN**: Offload static assets (CSS, JS, images) to CloudFlare/CloudFront\n",
    "- **Compression**: Gzip responses (reduce bandwidth 70%)\n",
    "- **Lazy loading**: Load data on-demand (not all upfront)\n",
    "- **Reserved instances**: AWS/GCP 40% savings vs on-demand\n",
    "\n",
    "**15. Security Hardening**\n",
    "```python\n",
    "# Disable debug mode in production\n",
    "app.run_server(debug=False)\n",
    "\n",
    "# Set secure headers\n",
    "@app.server.after_request\n",
    "def add_security_headers(response):\n",
    "    response.headers['X-Content-Type-Options'] = 'nosniff'\n",
    "    response.headers['X-Frame-Options'] = 'DENY'\n",
    "    response.headers['X-XSS-Protection'] = '1; mode=block'\n",
    "    return response\n",
    "\n",
    "# Input validation\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "@callback(...)\n",
    "def validate_input(value):\n",
    "    if not value or len(value) > 100:\n",
    "        raise PreventUpdate\n",
    "    # Sanitize SQL injection\n",
    "    safe_value = value.replace(\\\"'\\\", \\\"\\\")\n",
    "    return process(safe_value)\n",
    "```\n",
    "\n",
    "### Post-Silicon Use Cases\n",
    "\n",
    "**16. Real-Time Test Monitoring**\n",
    "- **Pattern**: PostgreSQL ‚Üí Dash backend (query every 5s) ‚Üí Redis cache ‚Üí Frontend\n",
    "- **Alerts**: Email (smtplib), SMS (Twilio), Slack (webhooks)\n",
    "- **Charts**: Control charts (Xbar-R, EWMA), wafer maps, yield trends\n",
    "- **KPIs**: Current yield, UPH, WIP, equipment status\n",
    "\n",
    "**17. STDF Analysis Workflow**\n",
    "```python\n",
    "# Upload STDF ‚Üí Parse (pystdf) ‚Üí Store (SQLite) ‚Üí Query ‚Üí Visualize\n",
    "import pystdf\n",
    "\n",
    "@callback(Output('data-store', 'data'), Input('upload', 'contents'))\n",
    "def parse_stdf(contents):\n",
    "    with pystdf.STDFFile(contents) as stdf:\n",
    "        records = [r for r in stdf if r.type == 'PTR']  # Parametric records\n",
    "    df = pd.DataFrame(records)\n",
    "    return df.to_dict()\n",
    "```\n",
    "\n",
    "**18. Multi-Page Navigation**\n",
    "```python\n",
    "# app.py\n",
    "app.layout = html.Div([\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "    navbar,\n",
    "    html.Div(id='page-content')\n",
    "])\n",
    "\n",
    "@callback(Output('page-content', 'children'), Input('url', 'pathname'))\n",
    "def router(pathname):\n",
    "    if pathname == '/wafer': return wafer_page()\n",
    "    elif pathname == '/trends': return trends_page()\n",
    "    else: return home_page()\n",
    "```\n",
    "\n",
    "### Learning Resources\n",
    "\n",
    "**19. Next Steps**\n",
    "- **Official Docs**: https://dash.plotly.com (component gallery, examples)\n",
    "- **Community**: https://community.plotly.com/c/dash (Q&A forum)\n",
    "- **Gallery**: https://dash.gallery (real-world apps with source code)\n",
    "- **Dash Enterprise**: Paid version with Kubernetes, auth, AI tools\n",
    "\n",
    "**20. Related Notebooks**\n",
    "- **116: Data Visualization Mastery** - Plotly charts for dashboards\n",
    "- **117: Streamlit App Development** - Alternative framework\n",
    "- **131: MLOps** - Deploy ML models in dashboards\n",
    "- **141: Cloud Computing** - AWS/GCP/Azure deployment\n",
    "\n",
    "---\n",
    "\n",
    "**Dash Philosophy**: Maximum flexibility for complex dashboards, production-ready out of the box.\n",
    "\n",
    "‚úÖ **You've mastered**: Component architecture, callbacks, real-time updates, deployment, security  \n",
    "üéØ **Next challenge**: Build production test floor dashboard with 1000+ concurrent users (Notebook 131: MLOps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499de8a8",
   "metadata": {},
   "source": [
    "## üöÄ Real-World Project Templates\n",
    "\n",
    "### Post-Silicon Validation Projects\n",
    "\n",
    "**1. Production Test Floor Command Center**\n",
    "- **Objective**: 24/7 live monitoring dashboard for semiconductor test operations\n",
    "- **Key Features**:\n",
    "  - Real-time KPI dashboard (yield, UPH, equipment utilization, WIP tracking)\n",
    "  - Multi-tester view (10-50 testers, status indicators, alarm tracking)\n",
    "  - Wafer map grid (last 25 wafers, click to drill-down)\n",
    "  - Parametric control charts (Xbar-R, EWMA, Cpk trending for 20+ parameters)\n",
    "  - Anomaly detection (auto-alerts on yield drops >2œÉ, email/SMS via Twilio)\n",
    "  - Shift handoff report (PDF generation with matplotlib, daily email summary)\n",
    "  - Historical trending (30-day yield, test time, binning trends)\n",
    "- **Data**: PostgreSQL (real-time test feed), 1000 devices/hour, 24/7 operation\n",
    "- **Tech Stack**: Dash, Plotly, PostgreSQL, Redis (caching), Celery (background tasks)\n",
    "- **Success Metric**: Detect excursions within 5 min (vs 2 hrs manual), reduce scrap 15%, 99.9% uptime\n",
    "- **Deployment**: Kubernetes (3-10 pods auto-scaling), Nginx load balancer, CloudFlare CDN\n",
    "\n",
    "**2. STDF Multi-Lot Analytics Platform**\n",
    "- **Objective**: Replace JMP/Excel for test data analysis with web-based platform\n",
    "- **Key Features**:\n",
    "  - Bulk STDF upload (10-50 files, 5GB total, pystdf parsing, SQLite storage)\n",
    "  - Cross-lot comparison (yield trends, Cpk by lot/wafer, Pareto charts)\n",
    "  - Parametric correlation explorer (scatter matrix, heatmaps, regression fits)\n",
    "  - Spatial analysis (wafer map overlays, clustering algorithms, edge effect detection)\n",
    "  - Outlier detection (Isolation Forest, DBSCAN, manual flagging with comments)\n",
    "  - Custom report builder (drag-drop 20+ chart types, save layouts, export to PowerPoint/PDF)\n",
    "  - Collaboration features (shared annotations, bookmark views, export datasets)\n",
    "- **Data**: STDF files (100K-1M records per file), persistent SQLite/PostgreSQL\n",
    "- **Tech Stack**: Dash, Plotly, pystdf, pandas, scikit-learn, python-pptx\n",
    "- **Success Metric**: Analyze 10 lots in 30 min (vs 8 hrs in JMP), 50+ users, 1000+ analyses/month\n",
    "- **Deployment**: Docker on internal server, LDAP authentication, 4-core/16GB RAM\n",
    "\n",
    "**3. Test Program Optimization Workbench**\n",
    "- **Objective**: Interactive tool for engineering teams to optimize test suites\n",
    "- **Key Features**:\n",
    "  - Test catalog (100+ tests, correlation matrix, dependencies visualization)\n",
    "  - Interactive selection (checkboxes, search/filter, group by category)\n",
    "  - Real-time impact calculator (coverage loss %, test time savings, cost reduction $)\n",
    "  - Sensitivity analysis (Monte Carlo 10K scenarios, risk assessment, confidence intervals)\n",
    "  - ML recommendation engine (Gradient Boosting, rank tests by redundancy score)\n",
    "  - A/B comparison (current vs optimized suite, side-by-side metrics)\n",
    "  - Scenario manager (save 10+ scenarios, compare, export justification reports)\n",
    "  - Collaboration (comments, approval workflow, change tracking)\n",
    "- **Data**: Historical test results (1M devices √ó 100 tests), cost model, test limits\n",
    "- **Tech Stack**: Dash, Plotly, scikit-learn, pandas, Redis (session state)\n",
    "- **Success Metric**: 25% test time reduction, <1% yield impact, ROI $500K/year, 10 programs adopt\n",
    "- **Deployment**: AWS EC2 (t3.xlarge), RDS PostgreSQL, ElastiCache Redis, ALB\n",
    "\n",
    "**4. Device Characterization Dashboard**\n",
    "- **Objective**: Interactive analysis of bench characterization sweeps\n",
    "- **Key Features**:\n",
    "  - 3D surface plots (Vdd √ó Idd √ó freq, temp √ó voltage √ó yield)\n",
    "  - Contour plots (operating limits visualization, margin analysis)\n",
    "  - Shmoo plots (pass/fail boundaries, color-coded by bin, zoom/pan interactions)\n",
    "  - Corner analysis (FF, TT, SS process corners, statistical distributions)\n",
    "  - Guardbanding calculator (margin vs yield tradeoff, sensitivity sliders)\n",
    "  - Datasheet generator (auto-create plots for specifications, export to PDF)\n",
    "  - What-if scenarios (adjust limits, see yield impact, cost analysis)\n",
    "- **Data**: Bench characterization (temp -40 to 125¬∞C, voltage 0.9-1.4V, freq 500-1500MHz sweeps)\n",
    "- **Tech Stack**: Dash, Plotly (3D/contour plots), NumPy (interpolation), SciPy (curve fitting)\n",
    "- **Success Metric**: Define safe operating area in 2 days (vs 2 weeks), reduce guard bands 10%\n",
    "- **Deployment**: Streamlit Cloud or Docker, shared with product engineering teams\n",
    "\n",
    "### General AI/ML Projects\n",
    "\n",
    "**5. Executive ML Model Dashboard**\n",
    "- **Objective**: C-suite dashboard for monitoring all production ML models\n",
    "- **Key Features**:\n",
    "  - Model catalog (50+ models, status, accuracy, uptime, last retrain date)\n",
    "  - Performance trending (accuracy/F1/AUC over time, drift detection)\n",
    "  - Prediction monitoring (daily volume, latency p95, error rates)\n",
    "  - A/B test tracker (champion vs challenger, statistical significance, rollout %)\n",
    "  - Cost analysis (inference cost, training cost, ROI by model)\n",
    "  - Alert management (model degradation, data drift, infra failures)\n",
    "- **Data**: MLflow tracking server, Prometheus metrics, S3 logs\n",
    "- **Success Metric**: Detect model drift 3 days earlier, reduce downtime 40%\n",
    "- **Deployment**: AWS Fargate, ALB, CloudWatch dashboards\n",
    "\n",
    "**6. Customer 360 Analytics Platform**\n",
    "- **Objective**: Unified customer view for sales/marketing/support teams\n",
    "- **Key Features**:\n",
    "  - Customer search (fuzzy search, 10M+ customers, <1s response)\n",
    "  - 360 profile (demographics, transaction history, support tickets, sentiment)\n",
    "  - Cohort analysis (segment customers, compare metrics, retention curves)\n",
    "  - Churn prediction (real-time risk score, intervention recommendations)\n",
    "  - LTV calculator (CLV prediction, what-if scenarios, segment comparison)\n",
    "  - Campaign effectiveness (A/B tests, attribution modeling, ROI tracking)\n",
    "- **Data**: PostgreSQL (customer DB), BigQuery (transactions), Salesforce API\n",
    "- **Success Metric**: Sales uses daily (80% adoption), reduce churn 12%\n",
    "- **Deployment**: GCP Cloud Run, Load Balancer, Cloud SQL, Memorystore\n",
    "\n",
    "**7. Healthcare Outcomes Dashboard**\n",
    "- **Objective**: Hospital executive dashboard for quality metrics\n",
    "- **Key Features**:\n",
    "  - KPI cards (readmission rate, mortality rate, patient satisfaction, bed utilization)\n",
    "  - Trending (30-day/90-day/1-year comparisons, peer hospital benchmarks)\n",
    "  - Risk stratification (identify high-risk patients, intervention tracking)\n",
    "  - Cost analysis (cost per case, DRG profitability, resource utilization)\n",
    "  - Quality scorecards (HEDIS measures, CMS star ratings, Joint Commission)\n",
    "  - Predictive alerts (sepsis risk, fall risk, readmission risk)\n",
    "- **Data**: EHR (Epic/Cerner), claims database, patient surveys\n",
    "- **Success Metric**: Reduce readmissions 8%, improve star rating +0.5\n",
    "- **Deployment**: HIPAA-compliant AWS, encryption, audit logs, MFA\n",
    "\n",
    "**8. Supply Chain Control Tower**\n",
    "- **Objective**: Real-time visibility into global supply chain\n",
    "- **Key Features**:\n",
    "  - Live inventory dashboard (50+ warehouses, stock levels, aging analysis)\n",
    "  - Shipment tracking (in-transit visibility, ETA predictions, delay alerts)\n",
    "  - Demand forecasting (ML-based, 12-week horizon, scenario planning)\n",
    "  - Supplier performance (on-time delivery, quality metrics, risk scoring)\n",
    "  - Network optimization (routing suggestions, cost analysis, carbon footprint)\n",
    "  - What-if simulator (stockout impact, capacity constraints, lead time changes)\n",
    "- **Data**: ERP (SAP), TMS, WMS, carrier APIs, weather data\n",
    "- **Success Metric**: Reduce stockouts 30%, improve forecast accuracy 15%\n",
    "- **Deployment**: Azure App Service, Cosmos DB, Event Hubs, Power BI embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2537cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production deployment files\n",
    "deployment_files = {\n",
    "    'Dockerfile': '''FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy application\n",
    "COPY . .\n",
    "\n",
    "# Create non-root user\n",
    "RUN useradd -m -u 1000 dashuser && chown -R dashuser:dashuser /app\n",
    "USER dashuser\n",
    "\n",
    "EXPOSE 8050\n",
    "\n",
    "# Use Gunicorn for production\n",
    "CMD [\"gunicorn\", \"-b\", \"0.0.0.0:8050\", \"app:server\", \\\\\n",
    "     \"--workers=4\", \"--threads=2\", \"--timeout=300\", \\\\\n",
    "     \"--access-logfile=-\", \"--error-logfile=-\"]\n",
    "''',\n",
    "    \n",
    "    'requirements.txt': '''dash==2.14.0\n",
    "dash-bootstrap-components==1.5.0\n",
    "plotly==5.17.0\n",
    "pandas==2.1.0\n",
    "numpy==1.24.3\n",
    "gunicorn==21.2.0\n",
    "redis==5.0.0\n",
    "psycopg2-binary==2.9.7\n",
    "''',\n",
    "    \n",
    "    'docker-compose.yml': '''version: '3.8'\n",
    "\n",
    "services:\n",
    "  dash-app:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8050:8050\"\n",
    "    environment:\n",
    "      - REDIS_URL=redis://redis:6379\n",
    "      - DATABASE_URL=postgresql://user:pass@postgres:5432/testdb\n",
    "    depends_on:\n",
    "      - redis\n",
    "      - postgres\n",
    "    restart: unless-stopped\n",
    "  \n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    restart: unless-stopped\n",
    "  \n",
    "  postgres:\n",
    "    image: postgres:15-alpine\n",
    "    environment:\n",
    "      POSTGRES_USER: user\n",
    "      POSTGRES_PASSWORD: pass\n",
    "      POSTGRES_DB: testdb\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    volumes:\n",
    "      - postgres-data:/var/lib/postgresql/data\n",
    "    restart: unless-stopped\n",
    "  \n",
    "  nginx:\n",
    "    image: nginx:alpine\n",
    "    ports:\n",
    "      - \"80:80\"\n",
    "      - \"443:443\"\n",
    "    volumes:\n",
    "      - ./nginx.conf:/etc/nginx/nginx.conf\n",
    "      - ./ssl:/etc/nginx/ssl\n",
    "    depends_on:\n",
    "      - dash-app\n",
    "    restart: unless-stopped\n",
    "\n",
    "volumes:\n",
    "  postgres-data:\n",
    "''',\n",
    "    \n",
    "    'nginx.conf': '''events {\n",
    "    worker_connections 1024;\n",
    "}\n",
    "\n",
    "http {\n",
    "    upstream dash {\n",
    "        server dash-app:8050;\n",
    "    }\n",
    "    \n",
    "    server {\n",
    "        listen 80;\n",
    "        server_name dashboard.example.com;\n",
    "        return 301 https://$server_name$request_uri;\n",
    "    }\n",
    "    \n",
    "    server {\n",
    "        listen 443 ssl;\n",
    "        server_name dashboard.example.com;\n",
    "        \n",
    "        ssl_certificate /etc/nginx/ssl/cert.pem;\n",
    "        ssl_certificate_key /etc/nginx/ssl/key.pem;\n",
    "        \n",
    "        location / {\n",
    "            proxy_pass http://dash;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "        }\n",
    "        \n",
    "        # Static files caching\n",
    "        location /_dash-component-suites/ {\n",
    "            proxy_pass http://dash;\n",
    "            expires 1y;\n",
    "            add_header Cache-Control \"public, immutable\";\n",
    "        }\n",
    "    }\n",
    "}\n",
    "''',\n",
    "    \n",
    "    'kubernetes.yaml': '''apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: dash-app\n",
    "spec:\n",
    "  replicas: 3\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: dash\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: dash\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: dash\n",
    "        image: your-registry/dash-app:latest\n",
    "        ports:\n",
    "        - containerPort: 8050\n",
    "        env:\n",
    "        - name: REDIS_URL\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: dash-secrets\n",
    "              key: redis-url\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"500m\"\n",
    "          limits:\n",
    "            memory: \"2Gi\"\n",
    "            cpu: \"2000m\"\n",
    "        livenessProbe:\n",
    "          httpGet:\n",
    "            path: /health\n",
    "            port: 8050\n",
    "          initialDelaySeconds: 30\n",
    "          periodSeconds: 10\n",
    "        readinessProbe:\n",
    "          httpGet:\n",
    "            path: /health\n",
    "            port: 8050\n",
    "          initialDelaySeconds: 5\n",
    "          periodSeconds: 5\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: dash-service\n",
    "spec:\n",
    "  selector:\n",
    "    app: dash\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: 8050\n",
    "  type: LoadBalancer\n",
    "---\n",
    "apiVersion: autoscaling/v2\n",
    "kind: HorizontalPodAutoscaler\n",
    "metadata:\n",
    "  name: dash-hpa\n",
    "spec:\n",
    "  scaleTargetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment\n",
    "    name: dash-app\n",
    "  minReplicas: 3\n",
    "  maxReplicas: 10\n",
    "  metrics:\n",
    "  - type: Resource\n",
    "    resource:\n",
    "      name: cpu\n",
    "      target:\n",
    "        type: Utilization\n",
    "        averageUtilization: 70\n",
    "'''\n",
    "}\n",
    "\n",
    "# Save deployment files\n",
    "import os\n",
    "os.makedirs('deployment', exist_ok=True)\n",
    "\n",
    "for filename, content in deployment_files.items():\n",
    "    filepath = f'deployment/{filename}'\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(content)\n",
    "    print(f\"‚úÖ Created: {filepath}\")\n",
    "\n",
    "print(\"\\\\nüì¶ Deployment package created!\")\n",
    "print(\"\\\\nQuick start:\")\n",
    "print(\"  cd deployment\")\n",
    "print(\"  docker-compose up -d\")\n",
    "print(\"  Open: http://localhost:8050\")\n",
    "print(\"\\\\nProduction deploy:\")\n",
    "print(\"  kubectl apply -f kubernetes.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e311740",
   "metadata": {},
   "source": [
    "## 6. Deployment: Production Architecture\n",
    "\n",
    "### üìù Deployment Strategies\n",
    "\n",
    "**1. Docker Containerization**\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "EXPOSE 8050\n",
    "CMD [\"gunicorn\", \"-b\", \"0.0.0.0:8050\", \"app:server\", \"--workers=4\"]\n",
    "```\n",
    "\n",
    "**2. Kubernetes Deployment**\n",
    "- **Horizontal scaling**: Auto-scale based on CPU/memory\n",
    "- **Load balancing**: Distribute traffic across pods\n",
    "- **Rolling updates**: Zero-downtime deployments\n",
    "- **Health checks**: Auto-restart failed pods\n",
    "\n",
    "**3. Production Stack**\n",
    "```\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ  CloudFlare ‚îÇ  (CDN, DDoS protection)\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                           ‚îÇ\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ   Nginx     ‚îÇ  (SSL termination, reverse proxy)\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                           ‚îÇ\n",
    "           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "           ‚îÇ               ‚îÇ               ‚îÇ\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ Dash Pod 1 ‚îÇ  ‚îÇ Dash Pod 2 ‚îÇ  ‚îÇ Dash ... ‚îÇ  (Gunicorn workers)\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "           ‚îÇ               ‚îÇ               ‚îÇ\n",
    "           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                           ‚îÇ\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ   Redis     ‚îÇ  (Session cache)\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                           ‚îÇ\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ  PostgreSQL ‚îÇ  (Data store)\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**4. Performance Optimization**\n",
    "- **Caching**: Redis for session state, query results\n",
    "- **CDN**: Static assets (CSS, JS, images)\n",
    "- **Compression**: Gzip responses\n",
    "- **Lazy loading**: Load data on-demand, not upfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticated_app.py - Dashboard with authentication\n",
    "auth_app_code = '''\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output, callback\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_auth\n",
    "\n",
    "# Valid username/password pairs\n",
    "VALID_USERS = {\n",
    "    'admin': 'admin123',\n",
    "    'analyst': 'analyst123',\n",
    "    'viewer': 'viewer123'\n",
    "}\n",
    "\n",
    "# User roles and permissions\n",
    "USER_ROLES = {\n",
    "    'admin': {'can_edit': True, 'can_export': True, 'can_view_all': True},\n",
    "    'analyst': {'can_edit': False, 'can_export': True, 'can_view_all': True},\n",
    "    'viewer': {'can_edit': False, 'can_export': False, 'can_view_all': False}\n",
    "}\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "# Apply basic authentication\n",
    "auth = dash_auth.BasicAuth(app, VALID_USERS)\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    dcc.Store(id='user-store', storage_type='session'),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col(html.H1(\"üîí Secure Dashboard\"), width=8),\n",
    "        dbc.Col(html.Div(id='user-info', className='text-end'), width=4)\n",
    "    ], className='mb-4'),\n",
    "    \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"User Permissions\"),\n",
    "                dbc.CardBody([\n",
    "                    html.Div(id='permissions-display')\n",
    "                ])\n",
    "            ])\n",
    "        ], width=6),\n",
    "        \n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardHeader(\"Access Log\"),\n",
    "                dbc.CardBody([\n",
    "                    html.Div(id='access-log')\n",
    "                ])\n",
    "            ])\n",
    "        ], width=6)\n",
    "    ])\n",
    "], fluid=True)\n",
    "\n",
    "@callback(\n",
    "    [Output('user-info', 'children'),\n",
    "     Output('permissions-display', 'children')],\n",
    "    Input('user-store', 'data')\n",
    ")\n",
    "def display_user_info(user_data):\n",
    "    # In production, get username from request context\n",
    "    # For demo, hardcode\n",
    "    username = 'admin'\n",
    "    role = USER_ROLES.get(username, {})\n",
    "    \n",
    "    user_badge = dbc.Badge(f\"üë§ {username}\", color=\"primary\", className=\"me-2\")\n",
    "    \n",
    "    permissions = [\n",
    "        html.Li(f\"‚úì Edit: {role.get('can_edit', False)}\"),\n",
    "        html.Li(f\"‚úì Export: {role.get('can_export', False)}\"),\n",
    "        html.Li(f\"‚úì View All: {role.get('can_view_all', False)}\")\n",
    "    ]\n",
    "    \n",
    "    return user_badge, html.Ul(permissions)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"üîí Starting authenticated dashboard...\")\n",
    "    print(\"Users: admin/admin123, analyst/analyst123, viewer/viewer123\")\n",
    "    app.run_server(debug=True, port=8050)\n",
    "'''\n",
    "\n",
    "with open('authenticated_app.py', 'w') as f:\n",
    "    f.write(auth_app_code)\n",
    "\n",
    "print(\"‚úÖ Saved to authenticated_app.py\")\n",
    "print(\"Install: pip install dash-auth\")\n",
    "print(\"Features: Basic auth, role-based permissions, session storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f8f27",
   "metadata": {},
   "source": [
    "## 5. Authentication & Security\n",
    "\n",
    "### üìù Enterprise Security Features\n",
    "\n",
    "**Authentication patterns:**\n",
    "- **Basic auth**: Username/password with `dash-auth`\n",
    "- **OAuth 2.0**: Google/Microsoft SSO integration\n",
    "- **JWT tokens**: Stateless authentication for APIs\n",
    "- **LDAP**: Corporate directory integration\n",
    "\n",
    "**Authorization:**\n",
    "- **Role-based access**: Admin, analyst, viewer roles\n",
    "- **Row-level security**: Filter data by user permissions\n",
    "- **Audit logging**: Track user actions, data access\n",
    "\n",
    "**Security best practices:**\n",
    "- HTTPS only (SSL/TLS certificates)\n",
    "- CSRF protection (enabled by default in Dash)\n",
    "- Input sanitization (prevent SQL injection)\n",
    "- Rate limiting (prevent DDoS)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
